
-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2018-11-20 23:35:56.540]  Devices available to tensorflow: [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 13430648485473958617
]
[2018-11-20 23:35:56.540]  Checkpoint path: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt
[2018-11-20 23:35:56.540]  Loading training data from: /Users/Aaron/Desktop/Code/tacotron/training/train.txt
[2018-11-20 23:35:56.540]  Using model: tacotron
[2018-11-20 23:35:56.541]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: english_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 250
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: True
[2018-11-20 23:35:56.544]  Loaded metadata for 398 examples (1.06 hours)
[2018-11-20 23:35:57.366]  Loaded CMUDict with 116869 unambiguous entries
[2018-11-20 23:36:00.991]  Initialized Tacotron model. Dimensions: 
[2018-11-20 23:36:00.991]    embedding:               256
[2018-11-20 23:36:00.991]    prenet out:              128
[2018-11-20 23:36:00.991]    encoder out:             256
[2018-11-20 23:36:00.991]    attention out:           256
[2018-11-20 23:36:00.991]    concat attn & out:       512
[2018-11-20 23:36:00.991]    decoder cell out:        256
[2018-11-20 23:36:00.991]    decoder out (5 frames):  400
[2018-11-20 23:36:00.991]    decoder out (1 frame):   80
[2018-11-20 23:36:00.991]    postnet out:             256
[2018-11-20 23:36:00.992]    linear out:              1025
[2018-11-20 23:36:16.658]  Resuming from checkpoint: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-250000 at commit: None
[2018-11-20 23:36:22.255]  Generated 32 batches of size 32 in 5.597 sec

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2018-11-20 23:37:00.755]  Devices available to tensorflow: [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 18340531210655292752
]
[2018-11-20 23:37:00.755]  Checkpoint path: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt
[2018-11-20 23:37:00.755]  Loading training data from: /Users/Aaron/Desktop/Code/tacotron/training/train.txt
[2018-11-20 23:37:00.755]  Using model: tacotron
[2018-11-20 23:37:00.755]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: english_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: True
[2018-11-20 23:37:00.758]  Loaded metadata for 398 examples (1.06 hours)
[2018-11-20 23:37:01.563]  Loaded CMUDict with 116869 unambiguous entries
[2018-11-20 23:37:05.109]  Initialized Tacotron model. Dimensions: 
[2018-11-20 23:37:05.109]    embedding:               256
[2018-11-20 23:37:05.109]    prenet out:              128
[2018-11-20 23:37:05.109]    encoder out:             256
[2018-11-20 23:37:05.109]    attention out:           256
[2018-11-20 23:37:05.109]    concat attn & out:       512
[2018-11-20 23:37:05.109]    decoder cell out:        256
[2018-11-20 23:37:05.109]    decoder out (5 frames):  400
[2018-11-20 23:37:05.109]    decoder out (1 frame):   80
[2018-11-20 23:37:05.109]    postnet out:             256
[2018-11-20 23:37:05.110]    linear out:              1025
[2018-11-20 23:37:20.567]  Resuming from checkpoint: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-250000 at commit: None
[2018-11-20 23:37:25.928]  Generated 32 batches of size 32 in 5.360 sec
[2018-11-20 23:38:13.962]  Step 250001  [53.391 sec/step, loss=0.27596, avg_loss=0.27596]
[2018-11-20 23:38:49.158]  Step 250002  [44.293 sec/step, loss=0.26801, avg_loss=0.27199]
[2018-11-20 23:39:13.588]  Step 250003  [37.672 sec/step, loss=0.22537, avg_loss=0.25645]
[2018-11-20 23:39:40.049]  Step 250004  [34.869 sec/step, loss=0.19553, avg_loss=0.24122]
[2018-11-20 23:39:59.752]  Step 250005  [31.836 sec/step, loss=0.18552, avg_loss=0.23008]
[2018-11-20 23:40:21.127]  Step 250006  [30.092 sec/step, loss=0.16149, avg_loss=0.21865]
[2018-11-20 23:40:40.649]  Step 250007  [28.582 sec/step, loss=0.16898, avg_loss=0.21155]
[2018-11-20 23:41:03.674]  Step 250008  [27.888 sec/step, loss=0.15446, avg_loss=0.20441]
[2018-11-20 23:41:20.014]  Step 250009  [26.605 sec/step, loss=0.15649, avg_loss=0.19909]
[2018-11-20 23:41:46.083]  Step 250010  [26.551 sec/step, loss=0.14133, avg_loss=0.19331]
[2018-11-20 23:41:57.893]  Step 250011  [25.211 sec/step, loss=0.14478, avg_loss=0.18890]
[2018-11-20 23:42:22.683]  Step 250012  [25.176 sec/step, loss=0.13730, avg_loss=0.18460]
[2018-11-20 23:42:44.332]  Step 250013  [24.904 sec/step, loss=0.13170, avg_loss=0.18053]
[2018-11-20 23:43:24.158]  Step 250014  [25.970 sec/step, loss=0.11951, avg_loss=0.17617]
[2018-11-20 23:43:32.997]  Step 250015  [24.828 sec/step, loss=0.11621, avg_loss=0.17217]
[2018-11-20 23:43:55.638]  Step 250016  [24.691 sec/step, loss=0.13014, avg_loss=0.16955]
[2018-11-20 23:44:19.907]  Step 250017  [24.667 sec/step, loss=0.12816, avg_loss=0.16711]
[2018-11-20 23:44:42.503]  Step 250018  [24.551 sec/step, loss=0.12569, avg_loss=0.16481]
[2018-11-20 23:45:09.527]  Step 250019  [24.682 sec/step, loss=0.12573, avg_loss=0.16275]
[2018-11-20 23:45:25.657]  Step 250020  [24.254 sec/step, loss=0.12472, avg_loss=0.16085]
[2018-11-20 23:45:49.716]  Step 250021  [24.245 sec/step, loss=0.12557, avg_loss=0.15917]
[2018-11-20 23:46:15.759]  Step 250022  [24.326 sec/step, loss=0.12373, avg_loss=0.15756]
[2018-11-20 23:46:40.152]  Step 250023  [24.329 sec/step, loss=0.12351, avg_loss=0.15608]
[2018-11-20 23:46:54.788]  Generated 32 batches of size 32 in 13.618 sec
[2018-11-20 23:47:13.022]  Step 250024  [24.685 sec/step, loss=0.11997, avg_loss=0.15458]
[2018-11-20 23:47:36.386]  Step 250025  [24.632 sec/step, loss=0.12107, avg_loss=0.15324]
[2018-11-20 23:47:56.716]  Step 250026  [24.467 sec/step, loss=0.12157, avg_loss=0.15202]
[2018-11-20 23:48:20.146]  Step 250027  [24.428 sec/step, loss=0.11988, avg_loss=0.15083]
[2018-11-20 23:48:45.163]  Step 250028  [24.449 sec/step, loss=0.11951, avg_loss=0.14971]
[2018-11-20 23:48:59.018]  Step 250029  [24.084 sec/step, loss=0.11914, avg_loss=0.14866]
[2018-11-20 23:49:09.537]  Step 250030  [23.632 sec/step, loss=0.11207, avg_loss=0.14744]
[2018-11-20 23:49:27.074]  Step 250031  [23.435 sec/step, loss=0.11869, avg_loss=0.14651]
[2018-11-20 23:49:47.393]  Step 250032  [23.338 sec/step, loss=0.11635, avg_loss=0.14557]
[2018-11-20 23:50:08.920]  Step 250033  [23.283 sec/step, loss=0.11875, avg_loss=0.14475]
[2018-11-20 23:50:23.604]  Step 250034  [23.030 sec/step, loss=0.11582, avg_loss=0.14390]
[2018-11-20 23:50:48.206]  Step 250035  [23.075 sec/step, loss=0.11640, avg_loss=0.14312]
[2018-11-20 23:51:01.161]  Step 250036  [22.794 sec/step, loss=0.11407, avg_loss=0.14231]
[2018-11-20 23:51:26.194]  Step 250037  [22.854 sec/step, loss=0.11508, avg_loss=0.14157]
[2018-11-20 23:51:42.792]  Step 250038  [22.690 sec/step, loss=0.11377, avg_loss=0.14084]
[2018-11-20 23:52:05.976]  Step 250039  [22.702 sec/step, loss=0.11344, avg_loss=0.14014]
[2018-11-20 23:52:23.980]  Step 250040  [22.585 sec/step, loss=0.11315, avg_loss=0.13947]
[2018-11-20 23:52:49.892]  Step 250041  [22.666 sec/step, loss=0.11509, avg_loss=0.13887]
[2018-11-20 23:53:16.588]  Step 250042  [22.762 sec/step, loss=0.11194, avg_loss=0.13823]
[2018-11-20 23:53:40.125]  Step 250043  [22.780 sec/step, loss=0.11347, avg_loss=0.13765]
[2018-11-20 23:53:59.586]  Step 250044  [22.705 sec/step, loss=0.11317, avg_loss=0.13710]
[2018-11-20 23:54:23.925]  Step 250045  [22.741 sec/step, loss=0.11223, avg_loss=0.13654]
[2018-11-20 23:54:43.759]  Step 250046  [22.678 sec/step, loss=0.11250, avg_loss=0.13602]
[2018-11-20 23:55:04.988]  Step 250047  [22.647 sec/step, loss=0.11336, avg_loss=0.13554]
[2018-11-20 23:55:21.090]  Step 250048  [22.510 sec/step, loss=0.10971, avg_loss=0.13500]
[2018-11-20 23:55:43.890]  Step 250049  [22.516 sec/step, loss=0.11389, avg_loss=0.13457]
[2018-11-20 23:56:02.614]  Step 250050  [22.441 sec/step, loss=0.11330, avg_loss=0.13414]
[2018-11-20 23:56:02.614]  Writing summary at step: 250050
[2018-11-20 23:56:54.001]  Step 250051  [22.437 sec/step, loss=0.11013, avg_loss=0.13367]
[2018-11-20 23:57:18.312]  Step 250052  [22.473 sec/step, loss=0.10901, avg_loss=0.13320]
[2018-11-20 23:57:28.750]  Step 250053  [22.246 sec/step, loss=0.09221, avg_loss=0.13243]
[2018-11-20 23:57:50.670]  Step 250054  [22.240 sec/step, loss=0.11120, avg_loss=0.13203]
[2018-11-20 23:58:03.722]  Generated 32 batches of size 32 in 12.272 sec
[2018-11-20 23:58:21.659]  Step 250055  [22.399 sec/step, loss=0.11088, avg_loss=0.13165]
[2018-11-20 23:59:00.328]  Step 250056  [22.690 sec/step, loss=0.09768, avg_loss=0.13104]
[2018-11-20 23:59:21.121]  Step 250057  [22.656 sec/step, loss=0.11015, avg_loss=0.13068]
[2018-11-20 23:59:46.782]  Step 250058  [22.708 sec/step, loss=0.11302, avg_loss=0.13037]
[2018-11-21 00:00:11.972]  Step 250059  [22.750 sec/step, loss=0.11068, avg_loss=0.13004]
[2018-11-21 00:00:22.778]  Step 250060  [22.551 sec/step, loss=0.10486, avg_loss=0.12962]
[2018-11-21 00:00:47.956]  Step 250061  [22.594 sec/step, loss=0.11052, avg_loss=0.12930]
[2018-11-21 00:01:06.790]  Step 250062  [22.533 sec/step, loss=0.11142, avg_loss=0.12902]
[2018-11-21 00:01:32.076]  Step 250063  [22.577 sec/step, loss=0.10988, avg_loss=0.12871]
[2018-11-21 00:01:51.568]  Step 250064  [22.529 sec/step, loss=0.11109, avg_loss=0.12844]
[2018-11-21 00:02:14.786]  Step 250065  [22.539 sec/step, loss=0.11037, avg_loss=0.12816]
[2018-11-21 00:02:36.965]  Step 250066  [22.534 sec/step, loss=0.10933, avg_loss=0.12787]
[2018-11-21 00:02:45.640]  Step 250067  [22.327 sec/step, loss=0.08959, avg_loss=0.12730]
[2018-11-21 00:03:10.696]  Step 250068  [22.367 sec/step, loss=0.10884, avg_loss=0.12703]
[2018-11-21 00:03:30.645]  Step 250069  [22.332 sec/step, loss=0.10841, avg_loss=0.12676]
[2018-11-21 00:03:52.614]  Step 250070  [22.327 sec/step, loss=0.10961, avg_loss=0.12652]
[2018-11-21 00:03:52.616]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-250070 (requested by user)
[2018-11-21 00:04:14.548]  Step 250071  [22.279 sec/step, loss=0.10963, avg_loss=0.12628]
[2018-11-21 00:04:39.531]  Step 250072  [22.316 sec/step, loss=0.10955, avg_loss=0.12605]
[2018-11-21 00:04:53.710]  Step 250073  [22.205 sec/step, loss=0.10778, avg_loss=0.12580]
[2018-11-21 00:05:09.505]  Step 250074  [22.118 sec/step, loss=0.10548, avg_loss=0.12552]
[2018-11-21 00:05:34.490]  Step 250075  [22.156 sec/step, loss=0.11043, avg_loss=0.12532]
[2018-11-21 00:05:53.229]  Step 250076  [22.111 sec/step, loss=0.10945, avg_loss=0.12511]
[2018-11-21 00:06:13.725]  Step 250077  [22.090 sec/step, loss=0.10808, avg_loss=0.12489]
[2018-11-21 00:06:24.448]  Step 250078  [21.945 sec/step, loss=0.09901, avg_loss=0.12456]
[2018-11-21 00:06:51.692]  Step 250079  [22.012 sec/step, loss=0.10929, avg_loss=0.12436]
[2018-11-21 00:07:13.929]  Step 250080  [22.015 sec/step, loss=0.10992, avg_loss=0.12418]
[2018-11-21 00:07:26.523]  Step 250081  [21.898 sec/step, loss=0.10393, avg_loss=0.12393]
[2018-11-21 00:07:48.624]  Step 250082  [21.901 sec/step, loss=0.10647, avg_loss=0.12372]
[2018-11-21 00:08:13.338]  Step 250083  [21.935 sec/step, loss=0.10694, avg_loss=0.12352]
[2018-11-21 00:08:57.020]  Step 250084  [22.193 sec/step, loss=0.09476, avg_loss=0.12318]
[2018-11-21 00:09:12.738]  Step 250085  [22.117 sec/step, loss=0.10561, avg_loss=0.12297]
[2018-11-21 00:09:35.654]  Step 250086  [22.127 sec/step, loss=0.10669, avg_loss=0.12278]
[2018-11-21 00:09:47.252]  Generated 32 batches of size 32 in 10.556 sec
[2018-11-21 00:10:06.630]  Step 250087  [22.228 sec/step, loss=0.10690, avg_loss=0.12260]
[2018-11-21 00:10:27.011]  Step 250088  [22.207 sec/step, loss=0.10569, avg_loss=0.12241]
[2018-11-21 00:10:45.149]  Step 250089  [22.162 sec/step, loss=0.10673, avg_loss=0.12223]
[2018-11-21 00:11:09.103]  Step 250090  [22.181 sec/step, loss=0.10783, avg_loss=0.12207]
[2018-11-21 00:11:31.706]  Step 250091  [22.186 sec/step, loss=0.10920, avg_loss=0.12193]
[2018-11-21 00:11:52.482]  Step 250092  [22.171 sec/step, loss=0.10802, avg_loss=0.12178]
[2018-11-21 00:12:17.582]  Step 250093  [22.202 sec/step, loss=0.10652, avg_loss=0.12161]
[2018-11-21 00:12:41.388]  Step 250094  [22.219 sec/step, loss=0.10671, avg_loss=0.12145]
[2018-11-21 00:13:04.573]  Step 250095  [22.230 sec/step, loss=0.10773, avg_loss=0.12131]
[2018-11-21 00:13:13.302]  Step 250096  [22.089 sec/step, loss=0.08580, avg_loss=0.12094]
[2018-11-21 00:13:36.564]  Step 250097  [22.101 sec/step, loss=0.10788, avg_loss=0.12081]
[2018-11-21 00:14:01.123]  Step 250098  [22.126 sec/step, loss=0.10604, avg_loss=0.12066]
[2018-11-21 00:14:26.361]  Step 250099  [22.157 sec/step, loss=0.10724, avg_loss=0.12052]
[2018-11-21 00:14:49.010]  Step 250100  [22.162 sec/step, loss=0.10655, avg_loss=0.12038]
[2018-11-21 00:14:49.010]  Writing summary at step: 250100
[2018-11-21 00:15:52.428]  Step 250101  [21.872 sec/step, loss=0.10581, avg_loss=0.11868]
[2018-11-21 00:16:06.436]  Step 250102  [21.660 sec/step, loss=0.10570, avg_loss=0.11706]
[2018-11-21 00:16:33.084]  Step 250103  [21.682 sec/step, loss=0.10555, avg_loss=0.11586]
[2018-11-21 00:16:50.190]  Step 250104  [21.589 sec/step, loss=0.10680, avg_loss=0.11497]
[2018-11-21 00:17:12.492]  Step 250105  [21.615 sec/step, loss=0.10809, avg_loss=0.11420]
[2018-11-21 00:17:28.128]  Step 250106  [21.557 sec/step, loss=0.10351, avg_loss=0.11362]
[2018-11-21 00:17:49.475]  Step 250107  [21.575 sec/step, loss=0.10751, avg_loss=0.11300]
[2018-11-21 00:18:05.358]  Step 250108  [21.504 sec/step, loss=0.10196, avg_loss=0.11248]
[2018-11-21 00:18:29.347]  Step 250109  [21.580 sec/step, loss=0.10729, avg_loss=0.11198]
[2018-11-21 00:18:47.244]  Step 250110  [21.499 sec/step, loss=0.10484, avg_loss=0.11162]
[2018-11-21 00:19:05.824]  Step 250111  [21.566 sec/step, loss=0.10611, avg_loss=0.11123]
[2018-11-21 00:19:28.980]  Step 250112  [21.550 sec/step, loss=0.10550, avg_loss=0.11091]
[2018-11-21 00:19:50.632]  Step 250113  [21.550 sec/step, loss=0.10523, avg_loss=0.11065]
[2018-11-21 00:20:11.311]  Step 250114  [21.359 sec/step, loss=0.10724, avg_loss=0.11053]
[2018-11-21 00:20:31.198]  Step 250115  [21.469 sec/step, loss=0.10470, avg_loss=0.11041]
[2018-11-21 00:20:55.857]  Step 250116  [21.489 sec/step, loss=0.10605, avg_loss=0.11017]
[2018-11-21 00:21:21.564]  Step 250117  [21.504 sec/step, loss=0.10482, avg_loss=0.10994]
[2018-11-21 00:21:31.331]  Generated 32 batches of size 32 in 8.864 sec
[2018-11-21 00:21:42.508]  Step 250118  [21.487 sec/step, loss=0.10609, avg_loss=0.10974]
[2018-11-21 00:22:04.792]  Step 250119  [21.440 sec/step, loss=0.10539, avg_loss=0.10954]
[2018-11-21 00:22:24.232]  Step 250120  [21.473 sec/step, loss=0.10593, avg_loss=0.10935]
[2018-11-21 00:22:47.492]  Step 250121  [21.465 sec/step, loss=0.10659, avg_loss=0.10916]
[2018-11-21 00:23:07.796]  Step 250122  [21.408 sec/step, loss=0.10372, avg_loss=0.10896]
[2018-11-21 00:23:20.924]  Step 250123  [21.295 sec/step, loss=0.10172, avg_loss=0.10874]
[2018-11-21 00:23:41.931]  Step 250124  [21.176 sec/step, loss=0.10549, avg_loss=0.10860]
[2018-11-21 00:23:52.421]  Step 250125  [21.048 sec/step, loss=0.09828, avg_loss=0.10837]
[2018-11-21 00:24:20.005]  Step 250126  [21.120 sec/step, loss=0.10451, avg_loss=0.10820]
[2018-11-21 00:24:47.861]  Step 250127  [21.164 sec/step, loss=0.10672, avg_loss=0.10807]
[2018-11-21 00:25:08.804]  Step 250128  [21.124 sec/step, loss=0.10451, avg_loss=0.10792]
[2018-11-21 00:25:31.853]  Step 250129  [21.216 sec/step, loss=0.10519, avg_loss=0.10778]
[2018-11-21 00:25:46.316]  Step 250130  [21.255 sec/step, loss=0.10136, avg_loss=0.10767]
[2018-11-21 00:26:05.460]  Step 250131  [21.271 sec/step, loss=0.10506, avg_loss=0.10753]
[2018-11-21 00:26:30.672]  Step 250132  [21.320 sec/step, loss=0.10535, avg_loss=0.10742]
[2018-11-21 00:26:57.786]  Step 250133  [21.376 sec/step, loss=0.10459, avg_loss=0.10728]
[2018-11-21 00:27:21.615]  Step 250134  [21.467 sec/step, loss=0.10614, avg_loss=0.10719]
[2018-11-21 00:27:54.233]  Step 250135  [21.547 sec/step, loss=0.10393, avg_loss=0.10706]
[2018-11-21 00:28:11.475]  Step 250136  [21.590 sec/step, loss=0.10193, avg_loss=0.10694]
[2018-11-21 00:28:41.034]  Step 250137  [21.636 sec/step, loss=0.10358, avg_loss=0.10683]
[2018-11-21 00:29:05.844]  Step 250138  [21.718 sec/step, loss=0.10323, avg_loss=0.10672]
[2018-11-21 00:29:28.322]  Step 250139  [21.711 sec/step, loss=0.10303, avg_loss=0.10662]
[2018-11-21 00:29:40.590]  Step 250140  [21.653 sec/step, loss=0.09685, avg_loss=0.10645]
[2018-11-21 00:30:06.510]  Step 250141  [21.653 sec/step, loss=0.10383, avg_loss=0.10634]
[2018-11-21 00:30:31.978]  Step 250142  [21.641 sec/step, loss=0.10441, avg_loss=0.10626]
[2018-11-21 00:30:49.587]  Step 250143  [21.582 sec/step, loss=0.10153, avg_loss=0.10615]
[2018-11-21 00:30:59.186]  Step 250144  [21.483 sec/step, loss=0.08375, avg_loss=0.10585]
[2018-11-21 00:31:27.382]  Step 250145  [21.522 sec/step, loss=0.10593, avg_loss=0.10579]
[2018-11-21 00:32:09.815]  Step 250146  [21.748 sec/step, loss=0.09166, avg_loss=0.10558]
[2018-11-21 00:32:30.194]  Step 250147  [21.739 sec/step, loss=0.10245, avg_loss=0.10547]
[2018-11-21 00:32:57.223]  Step 250148  [21.849 sec/step, loss=0.10446, avg_loss=0.10542]
[2018-11-21 00:33:13.006]  Step 250149  [21.778 sec/step, loss=0.10247, avg_loss=0.10530]
[2018-11-21 00:33:24.161]  Generated 32 batches of size 32 in 10.137 sec
[2018-11-21 00:33:34.872]  Step 250150  [21.810 sec/step, loss=0.10443, avg_loss=0.10522]
[2018-11-21 00:33:34.872]  Writing summary at step: 250150
[2018-11-21 00:34:21.028]  Step 250151  [21.828 sec/step, loss=0.10516, avg_loss=0.10517]
[2018-11-21 00:34:48.085]  Step 250152  [21.855 sec/step, loss=0.10512, avg_loss=0.10513]
[2018-11-21 00:35:09.935]  Step 250153  [21.969 sec/step, loss=0.10296, avg_loss=0.10523]
[2018-11-21 00:35:38.158]  Step 250154  [22.032 sec/step, loss=0.10332, avg_loss=0.10516]
[2018-11-21 00:36:06.749]  Step 250155  [22.009 sec/step, loss=0.10435, avg_loss=0.10509]
[2018-11-21 00:36:29.793]  Step 250156  [21.852 sec/step, loss=0.10404, avg_loss=0.10515]
[2018-11-21 00:36:56.123]  Step 250157  [21.908 sec/step, loss=0.10341, avg_loss=0.10509]
[2018-11-21 00:37:21.168]  Step 250158  [21.902 sec/step, loss=0.10367, avg_loss=0.10499]
[2018-11-21 00:37:44.775]  Step 250159  [21.886 sec/step, loss=0.10385, avg_loss=0.10492]
[2018-11-21 00:38:09.354]  Step 250160  [22.023 sec/step, loss=0.10312, avg_loss=0.10491]
[2018-11-21 00:38:30.852]  Step 250161  [21.987 sec/step, loss=0.10253, avg_loss=0.10483]
[2018-11-21 00:38:40.083]  Step 250162  [21.891 sec/step, loss=0.07960, avg_loss=0.10451]
[2018-11-21 00:39:09.602]  Step 250163  [21.933 sec/step, loss=0.10472, avg_loss=0.10446]
[2018-11-21 00:39:26.133]  Step 250164  [21.903 sec/step, loss=0.09951, avg_loss=0.10434]
[2018-11-21 00:39:53.225]  Step 250165  [21.942 sec/step, loss=0.10392, avg_loss=0.10428]
[2018-11-21 00:40:15.066]  Step 250166  [21.939 sec/step, loss=0.10109, avg_loss=0.10419]
[2018-11-21 00:40:39.918]  Step 250167  [22.101 sec/step, loss=0.10499, avg_loss=0.10435]
[2018-11-21 00:41:02.853]  Step 250168  [22.079 sec/step, loss=0.10487, avg_loss=0.10431]
[2018-11-21 00:41:25.534]  Step 250169  [22.107 sec/step, loss=0.10375, avg_loss=0.10426]
[2018-11-21 00:41:46.206]  Step 250170  [22.094 sec/step, loss=0.10140, avg_loss=0.10418]
[2018-11-21 00:42:09.132]  Step 250171  [22.134 sec/step, loss=0.10286, avg_loss=0.10411]
[2018-11-21 00:42:34.679]  Step 250172  [22.140 sec/step, loss=0.10294, avg_loss=0.10405]
[2018-11-21 00:42:53.439]  Step 250173  [22.185 sec/step, loss=0.10243, avg_loss=0.10399]
[2018-11-21 00:43:11.163]  Step 250174  [22.205 sec/step, loss=0.10319, avg_loss=0.10397]
[2018-11-21 00:43:24.956]  Step 250175  [22.093 sec/step, loss=0.10055, avg_loss=0.10387]
[2018-11-21 00:43:44.780]  Step 250176  [22.104 sec/step, loss=0.10229, avg_loss=0.10380]
[2018-11-21 00:44:13.646]  Step 250177  [22.187 sec/step, loss=0.10166, avg_loss=0.10374]
[2018-11-21 00:44:36.609]  Step 250178  [22.310 sec/step, loss=0.10262, avg_loss=0.10377]
[2018-11-21 00:44:58.339]  Step 250179  [22.255 sec/step, loss=0.10308, avg_loss=0.10371]
[2018-11-21 00:45:19.861]  Step 250180  [22.247 sec/step, loss=0.10233, avg_loss=0.10363]
[2018-11-21 00:45:29.633]  Generated 32 batches of size 32 in 8.854 sec
[2018-11-21 00:45:39.317]  Step 250181  [22.316 sec/step, loss=0.10088, avg_loss=0.10360]
[2018-11-21 00:46:04.404]  Step 250182  [22.346 sec/step, loss=0.10228, avg_loss=0.10356]
[2018-11-21 00:46:23.533]  Step 250183  [22.290 sec/step, loss=0.10244, avg_loss=0.10352]
[2018-11-21 00:46:35.436]  Step 250184  [21.972 sec/step, loss=0.09855, avg_loss=0.10355]
[2018-11-21 00:47:00.585]  Step 250185  [22.067 sec/step, loss=0.10140, avg_loss=0.10351]
[2018-11-21 00:47:10.882]  Step 250186  [21.940 sec/step, loss=0.09343, avg_loss=0.10338]
[2018-11-21 00:47:52.065]  Step 250187  [22.042 sec/step, loss=0.08963, avg_loss=0.10321]
[2018-11-21 00:48:15.978]  Step 250188  [22.078 sec/step, loss=0.10155, avg_loss=0.10317]
[2018-11-21 00:48:31.553]  Step 250189  [22.052 sec/step, loss=0.09908, avg_loss=0.10309]
[2018-11-21 00:48:53.451]  Step 250190  [22.032 sec/step, loss=0.10296, avg_loss=0.10304]
[2018-11-21 00:49:09.247]  Step 250191  [21.964 sec/step, loss=0.09834, avg_loss=0.10293]
[2018-11-21 00:49:24.540]  Step 250192  [21.909 sec/step, loss=0.09191, avg_loss=0.10277]
[2018-11-21 00:49:39.038]  Step 250193  [21.803 sec/step, loss=0.09967, avg_loss=0.10270]
[2018-11-21 00:49:56.653]  Step 250194  [21.741 sec/step, loss=0.10172, avg_loss=0.10265]
[2018-11-21 01:30:00.447]  Step 250195  [45.547 sec/step, loss=0.10129, avg_loss=0.10259]
[2018-11-21 01:30:38.629]  Step 250196  [45.841 sec/step, loss=0.10222, avg_loss=0.10275]
[2018-11-21 01:31:30.191]  Step 250197  [46.124 sec/step, loss=0.10087, avg_loss=0.10268]
[2018-11-21 03:32:09.243]  Step 250198  [118.269 sec/step, loss=0.10144, avg_loss=0.10264]
[2018-11-21 05:32:50.594]  Step 250199  [190.430 sec/step, loss=0.10136, avg_loss=0.10258]
[2018-11-21 07:33:29.673]  Step 250200  [262.595 sec/step, loss=0.10129, avg_loss=0.10252]
[2018-11-21 07:33:29.673]  Writing summary at step: 250200
[2018-11-21 09:34:50.157]  Step 250201  [334.696 sec/step, loss=0.10062, avg_loss=0.10247]
[2018-11-21 10:10:21.299]  Step 250202  [355.868 sec/step, loss=0.10105, avg_loss=0.10243]
[2018-11-21 10:20:18.800]  Step 250203  [361.576 sec/step, loss=0.10278, avg_loss=0.10240]
[2018-11-21 10:20:51.345]  Step 250204  [361.731 sec/step, loss=0.10145, avg_loss=0.10234]
[2018-11-21 10:21:22.828]  Step 250205  [361.823 sec/step, loss=0.10144, avg_loss=0.10228]
[2018-11-21 10:21:46.517]  Step 250206  [361.903 sec/step, loss=0.09966, avg_loss=0.10224]
[2018-11-21 10:22:06.615]  Step 250207  [361.891 sec/step, loss=0.09943, avg_loss=0.10216]
[2018-11-21 10:22:44.829]  Step 250208  [362.114 sec/step, loss=0.08891, avg_loss=0.10203]
[2018-11-21 10:23:09.443]  Step 250209  [362.120 sec/step, loss=0.09990, avg_loss=0.10195]
[2018-11-21 10:23:30.310]  Step 250210  [362.150 sec/step, loss=0.09975, avg_loss=0.10190]
[2018-11-21 10:23:52.450]  Step 250211  [362.185 sec/step, loss=0.10186, avg_loss=0.10186]
[2018-11-21 10:24:01.583]  Generated 32 batches of size 32 in 8.150 sec
[2018-11-21 10:24:02.831]  Step 250212  [362.058 sec/step, loss=0.07997, avg_loss=0.10161]
[2018-11-21 10:24:30.615]  Step 250213  [362.119 sec/step, loss=0.09967, avg_loss=0.10155]
[2018-11-21 10:24:50.199]  Step 250214  [362.108 sec/step, loss=0.10073, avg_loss=0.10149]
[2018-11-21 10:25:02.838]  Step 250215  [362.036 sec/step, loss=0.09632, avg_loss=0.10140]
[2018-11-21 10:25:25.516]  Step 250216  [362.016 sec/step, loss=0.10117, avg_loss=0.10135]
[2018-11-21 10:25:49.222]  Step 250217  [361.996 sec/step, loss=0.09965, avg_loss=0.10130]
[2018-11-21 10:26:19.901]  Step 250218  [362.093 sec/step, loss=0.10146, avg_loss=0.10125]
[2018-11-21 10:26:36.305]  Step 250219  [362.034 sec/step, loss=0.09855, avg_loss=0.10119]
[2018-11-21 10:26:54.715]  Step 250220  [362.024 sec/step, loss=0.09946, avg_loss=0.10112]
[2018-11-21 10:27:08.739]  Step 250221  [361.932 sec/step, loss=0.09863, avg_loss=0.10104]
[2018-11-21 10:27:36.017]  Step 250222  [362.001 sec/step, loss=0.09883, avg_loss=0.10099]
[2018-11-21 10:27:59.194]  Step 250223  [362.102 sec/step, loss=0.09970, avg_loss=0.10097]
[2018-11-21 10:28:15.045]  Step 250224  [362.050 sec/step, loss=0.09510, avg_loss=0.10087]
[2018-11-21 10:28:37.561]  Step 250225  [362.171 sec/step, loss=0.10159, avg_loss=0.10090]
[2018-11-21 10:29:02.035]  Step 250226  [362.139 sec/step, loss=0.09827, avg_loss=0.10084]
[2018-11-21 10:29:25.862]  Step 250227  [362.099 sec/step, loss=0.10055, avg_loss=0.10078]
[2018-11-21 10:29:45.505]  Step 250228  [362.086 sec/step, loss=0.09928, avg_loss=0.10073]
[2018-11-21 10:30:04.559]  Step 250229  [362.046 sec/step, loss=0.09917, avg_loss=0.10067]
[2018-11-21 10:30:27.906]  Step 250230  [362.135 sec/step, loss=0.09967, avg_loss=0.10065]
[2018-11-21 10:30:46.052]  Step 250231  [362.125 sec/step, loss=0.09798, avg_loss=0.10058]
[2018-11-21 10:31:10.942]  Step 250232  [362.122 sec/step, loss=0.09991, avg_loss=0.10052]
[2018-11-21 10:31:21.563]  Step 250233  [361.957 sec/step, loss=0.09108, avg_loss=0.10039]
[2018-11-21 10:31:33.761]  Step 250234  [361.841 sec/step, loss=0.09542, avg_loss=0.10028]
[2018-11-21 10:31:55.705]  Step 250235  [361.734 sec/step, loss=0.09958, avg_loss=0.10024]
[2018-11-21 10:32:04.655]  Step 250236  [361.651 sec/step, loss=0.07504, avg_loss=0.09997]
[2018-11-21 10:32:20.041]  Step 250237  [361.509 sec/step, loss=0.09618, avg_loss=0.09989]
[2018-11-21 10:32:44.134]  Step 250238  [361.502 sec/step, loss=0.09898, avg_loss=0.09985]
[2018-11-21 10:33:08.725]  Step 250239  [361.523 sec/step, loss=0.09892, avg_loss=0.09981]
[2018-11-21 10:33:26.028]  Step 250240  [361.574 sec/step, loss=0.09904, avg_loss=0.09983]
[2018-11-21 10:33:51.547]  Step 250241  [361.569 sec/step, loss=0.10034, avg_loss=0.09980]
[2018-11-21 10:34:14.132]  Step 250242  [361.541 sec/step, loss=0.09838, avg_loss=0.09974]
[2018-11-21 10:34:32.629]  Step 250243  [361.550 sec/step, loss=0.09894, avg_loss=0.09971]
[2018-11-21 10:34:44.336]  Generated 32 batches of size 32 in 10.867 sec
[2018-11-21 10:35:01.320]  Step 250244  [361.740 sec/step, loss=0.10103, avg_loss=0.09988]
[2018-11-21 10:35:23.080]  Step 250245  [361.676 sec/step, loss=0.09819, avg_loss=0.09981]
[2018-11-21 10:35:46.940]  Step 250246  [361.490 sec/step, loss=0.09978, avg_loss=0.09989]
[2018-11-21 10:36:08.458]  Step 250247  [361.502 sec/step, loss=0.09906, avg_loss=0.09985]
[2018-11-21 10:36:28.893]  Step 250248  [361.436 sec/step, loss=0.09824, avg_loss=0.09979]
[2018-11-21 10:37:08.893]  Step 250249  [361.678 sec/step, loss=0.08747, avg_loss=0.09964]
[2018-11-21 10:37:30.274]  Step 250250  [361.673 sec/step, loss=0.10041, avg_loss=0.09960]
[2018-11-21 10:37:30.274]  Writing summary at step: 250250
[2018-11-21 10:38:14.659]  Step 250251  [361.670 sec/step, loss=0.09946, avg_loss=0.09955]
[2018-11-21 10:38:38.615]  Step 250252  [361.639 sec/step, loss=0.09815, avg_loss=0.09948]
[2018-11-21 10:39:03.108]  Step 250253  [361.666 sec/step, loss=0.09715, avg_loss=0.09942]
[2018-11-21 10:39:23.015]  Step 250254  [361.583 sec/step, loss=0.09797, avg_loss=0.09936]
[2018-11-21 10:39:47.615]  Step 250255  [361.543 sec/step, loss=0.10026, avg_loss=0.09932]
[2018-11-21 10:39:55.871]  Step 250256  [361.395 sec/step, loss=0.07863, avg_loss=0.09907]
[2018-11-21 10:40:14.488]  Step 250257  [361.318 sec/step, loss=0.09803, avg_loss=0.09902]
[2018-11-21 10:40:38.846]  Step 250258  [361.311 sec/step, loss=0.09841, avg_loss=0.09896]
[2018-11-21 10:41:00.263]  Step 250259  [361.289 sec/step, loss=0.09907, avg_loss=0.09891]
[2018-11-21 10:41:22.635]  Step 250260  [361.267 sec/step, loss=0.10085, avg_loss=0.09889]
[2018-11-21 10:41:44.322]  Step 250261  [361.269 sec/step, loss=0.09824, avg_loss=0.09885]
[2018-11-21 10:42:07.650]  Step 250262  [361.410 sec/step, loss=0.09885, avg_loss=0.09904]
[2018-11-21 10:42:21.722]  Step 250263  [361.255 sec/step, loss=0.09595, avg_loss=0.09895]
[2018-11-21 10:42:42.590]  Step 250264  [361.299 sec/step, loss=0.09844, avg_loss=0.09894]
[2018-11-21 10:43:03.248]  Step 250265  [361.234 sec/step, loss=0.09782, avg_loss=0.09888]
[2018-11-21 10:43:26.578]  Step 250266  [361.249 sec/step, loss=0.09732, avg_loss=0.09884]
[2018-11-21 10:43:43.699]  Step 250267  [361.172 sec/step, loss=0.09860, avg_loss=0.09878]
[2018-11-21 10:44:06.257]  Step 250268  [361.168 sec/step, loss=0.09888, avg_loss=0.09872]
[2018-11-21 10:44:30.752]  Step 250269  [361.186 sec/step, loss=0.10067, avg_loss=0.09869]
[2018-11-21 10:44:53.441]  Step 250270  [361.206 sec/step, loss=0.09791, avg_loss=0.09866]
[2018-11-21 10:45:20.045]  Step 250271  [361.243 sec/step, loss=0.09733, avg_loss=0.09860]
[2018-11-21 10:45:41.595]  Step 250272  [361.203 sec/step, loss=0.09866, avg_loss=0.09856]
[2018-11-21 10:45:53.925]  Step 250273  [361.139 sec/step, loss=0.09379, avg_loss=0.09847]
[2018-11-21 10:46:31.975]  Step 250274  [361.342 sec/step, loss=0.08734, avg_loss=0.09831]
[2018-11-21 10:46:41.040]  Generated 32 batches of size 32 in 8.320 sec
[2018-11-21 10:46:55.017]  Step 250275  [361.435 sec/step, loss=0.09685, avg_loss=0.09828]
[2018-11-21 10:47:10.699]  Step 250276  [361.393 sec/step, loss=0.09445, avg_loss=0.09820]
[2018-11-21 10:47:31.338]  Step 250277  [361.311 sec/step, loss=0.09764, avg_loss=0.09816]
[2018-11-21 10:47:43.060]  Step 250278  [361.199 sec/step, loss=0.08730, avg_loss=0.09800]
[2018-11-21 10:48:03.415]  Step 250279  [361.185 sec/step, loss=0.09682, avg_loss=0.09794]
[2018-11-21 10:48:21.725]  Step 250280  [361.153 sec/step, loss=0.09472, avg_loss=0.09786]
[2018-11-21 10:48:42.110]  Step 250281  [361.162 sec/step, loss=0.09795, avg_loss=0.09784]
[2018-11-21 10:49:08.883]  Step 250282  [361.179 sec/step, loss=0.09885, avg_loss=0.09780]
[2018-11-21 10:49:31.069]  Step 250283  [361.210 sec/step, loss=0.09741, avg_loss=0.09775]
[2018-11-21 10:49:52.001]  Step 250284  [361.300 sec/step, loss=0.09838, avg_loss=0.09775]
[2018-11-21 10:50:17.383]  Step 250285  [361.302 sec/step, loss=0.09828, avg_loss=0.09772]
[2018-11-21 10:50:40.079]  Step 250286  [361.426 sec/step, loss=0.09799, avg_loss=0.09776]
[2018-11-21 10:50:55.837]  Step 250287  [361.172 sec/step, loss=0.09400, avg_loss=0.09781]
[2018-11-21 10:51:18.409]  Step 250288  [361.158 sec/step, loss=0.09703, avg_loss=0.09776]
[2018-11-21 10:51:31.221]  Step 250289  [361.131 sec/step, loss=0.09354, avg_loss=0.09771]
[2018-11-21 10:51:49.238]  Step 250290  [361.092 sec/step, loss=0.09696, avg_loss=0.09765]
[2018-11-21 10:52:13.981]  Step 250291  [361.181 sec/step, loss=0.09717, avg_loss=0.09764]
[2018-11-21 10:52:36.938]  Step 250292  [361.258 sec/step, loss=0.09869, avg_loss=0.09770]
[2018-11-21 10:52:47.748]  Step 250293  [361.221 sec/step, loss=0.08809, avg_loss=0.09759]
[2018-11-21 10:53:06.309]  Step 250294  [361.231 sec/step, loss=0.09652, avg_loss=0.09754]
[2018-11-21 10:53:31.647]  Step 250295  [337.446 sec/step, loss=0.09876, avg_loss=0.09751]
[2018-11-21 10:53:50.914]  Step 250296  [337.257 sec/step, loss=0.09586, avg_loss=0.09745]
[2018-11-21 10:54:06.616]  Step 250297  [336.898 sec/step, loss=0.09293, avg_loss=0.09737]
[2018-11-21 10:54:26.850]  Step 250298  [264.710 sec/step, loss=0.09649, avg_loss=0.09732]
[2018-11-21 10:54:47.094]  Step 250299  [192.499 sec/step, loss=0.09623, avg_loss=0.09727]
[2018-11-21 10:55:11.090]  Step 250300  [120.348 sec/step, loss=0.09717, avg_loss=0.09722]
[2018-11-21 10:55:11.090]  Writing summary at step: 250300
[2018-11-21 10:55:52.312]  Step 250301  [48.187 sec/step, loss=0.09556, avg_loss=0.09717]
[2018-11-21 10:56:19.426]  Step 250302  [27.147 sec/step, loss=0.09579, avg_loss=0.09712]
[2018-11-21 10:57:02.556]  Step 250303  [21.603 sec/step, loss=0.08574, avg_loss=0.09695]
[2018-11-21 10:57:26.838]  Step 250304  [21.521 sec/step, loss=0.09732, avg_loss=0.09691]
[2018-11-21 10:57:40.846]  Step 250305  [21.346 sec/step, loss=0.09420, avg_loss=0.09684]
[2018-11-21 10:57:50.289]  Generated 32 batches of size 32 in 8.331 sec
[2018-11-21 10:58:04.165]  Step 250306  [21.342 sec/step, loss=0.09560, avg_loss=0.09680]
[2018-11-21 10:58:27.973]  Step 250307  [21.379 sec/step, loss=0.09695, avg_loss=0.09677]
[2018-11-21 10:58:36.645]  Step 250308  [21.084 sec/step, loss=0.07476, avg_loss=0.09663]
[2018-11-21 10:59:01.162]  Step 250309  [21.083 sec/step, loss=0.09562, avg_loss=0.09659]
[2018-11-21 10:59:21.914]  Step 250310  [21.082 sec/step, loss=0.09640, avg_loss=0.09655]
[2018-11-21 10:59:45.587]  Step 250311  [21.097 sec/step, loss=0.09655, avg_loss=0.09650]
[2018-11-21 11:00:07.351]  Step 250312  [21.211 sec/step, loss=0.09680, avg_loss=0.09667]
[2018-11-21 11:00:27.096]  Step 250313  [21.131 sec/step, loss=0.09640, avg_loss=0.09664]
[2018-11-21 11:00:50.744]  Step 250314  [21.171 sec/step, loss=0.09604, avg_loss=0.09659]
[2018-11-21 11:01:09.497]  Step 250315  [21.232 sec/step, loss=0.09605, avg_loss=0.09659]
[2018-11-21 11:01:21.425]  Step 250316  [21.125 sec/step, loss=0.09127, avg_loss=0.09649]
[2018-11-21 11:01:37.251]  Step 250317  [21.046 sec/step, loss=0.09347, avg_loss=0.09643]
[2018-11-21 11:01:57.524]  Step 250318  [20.942 sec/step, loss=0.09406, avg_loss=0.09635]
[2018-11-21 11:02:07.645]  Step 250319  [20.879 sec/step, loss=0.08518, avg_loss=0.09622]
[2018-11-21 11:02:31.739]  Step 250320  [20.936 sec/step, loss=0.09526, avg_loss=0.09618]
[2018-11-21 11:02:54.734]  Step 250321  [21.026 sec/step, loss=0.09621, avg_loss=0.09615]
[2018-11-21 11:03:16.429]  Step 250322  [20.970 sec/step, loss=0.09699, avg_loss=0.09613]
[2018-11-21 11:03:42.768]  Step 250323  [21.001 sec/step, loss=0.09601, avg_loss=0.09610]
[2018-11-21 11:03:57.044]  Step 250324  [20.986 sec/step, loss=0.09355, avg_loss=0.09608]
[2018-11-21 11:04:12.752]  Step 250325  [20.918 sec/step, loss=0.09237, avg_loss=0.09599]
[2018-11-21 11:04:36.880]  Step 250326  [20.914 sec/step, loss=0.09780, avg_loss=0.09598]
[2018-11-21 11:04:57.491]  Step 250327  [20.882 sec/step, loss=0.09620, avg_loss=0.09594]
[2018-11-21 11:05:19.309]  Step 250328  [20.904 sec/step, loss=0.09672, avg_loss=0.09592]
[2018-11-21 11:05:27.003]  Step 250329  [20.790 sec/step, loss=0.07515, avg_loss=0.09568]
[2018-11-21 11:05:44.229]  Step 250330  [20.729 sec/step, loss=0.09592, avg_loss=0.09564]
[2018-11-21 11:06:08.761]  Step 250331  [20.793 sec/step, loss=0.09654, avg_loss=0.09562]
[2018-11-21 11:06:31.655]  Step 250332  [20.773 sec/step, loss=0.09786, avg_loss=0.09560]
[2018-11-21 11:06:49.972]  Step 250333  [20.850 sec/step, loss=0.09584, avg_loss=0.09565]
[2018-11-21 11:07:14.915]  Step 250334  [20.977 sec/step, loss=0.09425, avg_loss=0.09564]
[2018-11-21 11:07:39.165]  Step 250335  [21.000 sec/step, loss=0.09618, avg_loss=0.09560]
[2018-11-21 11:08:18.838]  Step 250336  [21.308 sec/step, loss=0.08441, avg_loss=0.09570]
[2018-11-21 11:08:41.351]  Step 250337  [21.379 sec/step, loss=0.09756, avg_loss=0.09571]
[2018-11-21 11:08:51.385]  Generated 32 batches of size 32 in 9.012 sec
[2018-11-21 11:09:06.693]  Step 250338  [21.391 sec/step, loss=0.09565, avg_loss=0.09568]
[2018-11-21 11:09:32.732]  Step 250339  [21.406 sec/step, loss=0.09682, avg_loss=0.09566]
[2018-11-21 11:09:53.492]  Step 250340  [21.440 sec/step, loss=0.09506, avg_loss=0.09562]
[2018-11-21 11:10:11.702]  Step 250341  [21.367 sec/step, loss=0.09323, avg_loss=0.09555]
[2018-11-21 11:10:36.323]  Step 250342  [21.388 sec/step, loss=0.09557, avg_loss=0.09552]
[2018-11-21 11:10:59.339]  Step 250343  [21.433 sec/step, loss=0.09542, avg_loss=0.09548]
[2018-11-21 11:11:20.384]  Step 250344  [21.356 sec/step, loss=0.09750, avg_loss=0.09545]
[2018-11-21 11:11:42.324]  Step 250345  [21.358 sec/step, loss=0.09567, avg_loss=0.09542]
[2018-11-21 11:12:01.627]  Step 250346  [21.313 sec/step, loss=0.09518, avg_loss=0.09538]
[2018-11-21 11:12:26.851]  Step 250347  [21.350 sec/step, loss=0.09482, avg_loss=0.09533]
[2018-11-21 11:12:51.055]  Step 250348  [21.387 sec/step, loss=0.09552, avg_loss=0.09531]
[2018-11-21 11:13:13.680]  Step 250349  [21.214 sec/step, loss=0.09531, avg_loss=0.09539]
[2018-11-21 11:13:31.687]  Step 250350  [21.180 sec/step, loss=0.09332, avg_loss=0.09532]
[2018-11-21 11:13:31.687]  Writing summary at step: 250350
[2018-11-21 11:14:20.933]  Step 250351  [21.185 sec/step, loss=0.09566, avg_loss=0.09528]
[2018-11-21 11:14:45.574]  Step 250352  [21.192 sec/step, loss=0.09459, avg_loss=0.09524]
[2018-11-21 11:15:10.291]  Step 250353  [21.195 sec/step, loss=0.09460, avg_loss=0.09522]
[2018-11-21 11:15:32.468]  Step 250354  [21.217 sec/step, loss=0.09638, avg_loss=0.09520]
[2018-11-21 11:15:44.646]  Step 250355  [21.093 sec/step, loss=0.09126, avg_loss=0.09511]
[2018-11-21 11:16:02.875]  Step 250356  [21.193 sec/step, loss=0.09420, avg_loss=0.09527]
[2018-11-21 11:16:24.096]  Step 250357  [21.219 sec/step, loss=0.09496, avg_loss=0.09524]
[2018-11-21 11:16:46.930]  Step 250358  [21.204 sec/step, loss=0.09559, avg_loss=0.09521]
[2018-11-21 11:17:05.944]  Step 250359  [21.179 sec/step, loss=0.09437, avg_loss=0.09516]
[2018-11-21 11:17:19.699]  Step 250360  [21.093 sec/step, loss=0.09245, avg_loss=0.09508]
[2018-11-21 11:17:40.865]  Step 250361  [21.088 sec/step, loss=0.09529, avg_loss=0.09505]
[2018-11-21 11:18:01.194]  Step 250362  [21.058 sec/step, loss=0.09442, avg_loss=0.09500]
[2018-11-21 11:18:26.181]  Step 250363  [21.167 sec/step, loss=0.09607, avg_loss=0.09500]
[2018-11-21 11:18:48.663]  Step 250364  [21.183 sec/step, loss=0.09478, avg_loss=0.09497]
[2018-11-21 11:19:13.306]  Step 250365  [21.223 sec/step, loss=0.09369, avg_loss=0.09493]
[2018-11-21 11:19:23.539]  Step 250366  [21.092 sec/step, loss=0.08564, avg_loss=0.09481]
[2018-11-21 11:19:45.380]  Step 250367  [21.140 sec/step, loss=0.09599, avg_loss=0.09478]
[2018-11-21 11:20:00.998]  Step 250368  [21.070 sec/step, loss=0.09187, avg_loss=0.09471]
[2018-11-21 11:20:10.479]  Generated 32 batches of size 32 in 8.689 sec
[2018-11-21 11:20:22.008]  Step 250369  [21.035 sec/step, loss=0.09452, avg_loss=0.09465]
[2018-11-21 11:20:44.711]  Step 250370  [21.035 sec/step, loss=0.09411, avg_loss=0.09461]
[2018-11-21 11:20:53.581]  Step 250371  [20.858 sec/step, loss=0.07321, avg_loss=0.09437]
[2018-11-21 11:21:13.203]  Step 250372  [20.839 sec/step, loss=0.09394, avg_loss=0.09432]
[2018-11-21 11:21:33.397]  Step 250373  [20.917 sec/step, loss=0.09398, avg_loss=0.09433]
[2018-11-21 11:22:02.739]  Step 250374  [20.830 sec/step, loss=0.09435, avg_loss=0.09440]
[2018-11-21 11:22:18.174]  Step 250375  [20.754 sec/step, loss=0.09128, avg_loss=0.09434]
[2018-11-21 11:22:35.369]  Step 250376  [20.769 sec/step, loss=0.09465, avg_loss=0.09434]
[2018-11-21 11:23:16.923]  Step 250377  [20.979 sec/step, loss=0.08388, avg_loss=0.09421]
[2018-11-21 11:23:39.161]  Step 250378  [21.084 sec/step, loss=0.09505, avg_loss=0.09428]
[2018-11-21 11:24:02.312]  Step 250379  [21.112 sec/step, loss=0.09487, avg_loss=0.09426]
[2018-11-21 11:24:20.940]  Step 250380  [21.115 sec/step, loss=0.09355, avg_loss=0.09425]
[2018-11-21 11:24:45.407]  Step 250381  [21.156 sec/step, loss=0.09423, avg_loss=0.09421]
[2018-11-21 11:25:02.738]  Step 250382  [21.061 sec/step, loss=0.09376, avg_loss=0.09416]
[2018-11-21 11:25:26.227]  Step 250383  [21.074 sec/step, loss=0.09387, avg_loss=0.09413]
[2018-11-21 11:25:38.500]  Step 250384  [20.988 sec/step, loss=0.09130, avg_loss=0.09406]
[2018-11-21 11:25:49.378]  Step 250385  [20.843 sec/step, loss=0.08563, avg_loss=0.09393]
[2018-11-21 11:26:13.715]  Step 250386  [20.859 sec/step, loss=0.09454, avg_loss=0.09390]
[2018-11-21 11:26:38.531]  Step 250387  [20.950 sec/step, loss=0.09331, avg_loss=0.09389]
[2018-11-21 11:27:02.505]  Step 250388  [20.964 sec/step, loss=0.09430, avg_loss=0.09386]
[2018-11-21 11:27:22.731]  Step 250389  [21.038 sec/step, loss=0.09292, avg_loss=0.09386]
[2018-11-21 11:27:49.032]  Step 250390  [21.121 sec/step, loss=0.09381, avg_loss=0.09382]
[2018-11-21 11:28:08.117]  Step 250391  [21.064 sec/step, loss=0.09409, avg_loss=0.09379]
[2018-11-21 11:28:30.189]  Step 250392  [21.055 sec/step, loss=0.09396, avg_loss=0.09375]
[2018-11-21 11:28:51.422]  Step 250393  [21.159 sec/step, loss=0.09456, avg_loss=0.09381]
[2018-11-21 11:29:15.911]  Step 250394  [21.219 sec/step, loss=0.09570, avg_loss=0.09380]
[2018-11-21 11:29:36.694]  Step 250395  [21.173 sec/step, loss=0.09463, avg_loss=0.09376]
[2018-11-21 11:29:45.718]  Step 250396  [21.071 sec/step, loss=0.07288, avg_loss=0.09353]
[2018-11-21 11:30:10.564]  Step 250397  [21.162 sec/step, loss=0.09570, avg_loss=0.09356]
[2018-11-21 11:30:27.254]  Step 250398  [21.127 sec/step, loss=0.09075, avg_loss=0.09350]
[2018-11-21 11:30:43.348]  Step 250399  [21.085 sec/step, loss=0.09096, avg_loss=0.09345]
[2018-11-21 11:31:07.892]  Step 250400  [21.091 sec/step, loss=0.09367, avg_loss=0.09341]
[2018-11-21 11:31:07.892]  Writing summary at step: 250400
[2018-11-21 11:31:22.429]  Generated 32 batches of size 32 in 13.628 sec
[2018-11-21 11:32:21.039]  Step 250401  [21.161 sec/step, loss=0.09540, avg_loss=0.09341]
[2018-11-21 11:32:35.043]  Step 250402  [21.030 sec/step, loss=0.09152, avg_loss=0.09337]
[2018-11-21 11:32:58.177]  Step 250403  [20.830 sec/step, loss=0.09496, avg_loss=0.09346]
[2018-11-21 11:33:21.667]  Step 250404  [20.822 sec/step, loss=0.09555, avg_loss=0.09344]
[2018-11-21 11:33:45.233]  Step 250405  [20.917 sec/step, loss=0.09424, avg_loss=0.09345]
[2018-11-21 11:34:03.346]  Step 250406  [20.865 sec/step, loss=0.09285, avg_loss=0.09342]
[2018-11-21 11:34:22.584]  Step 250407  [20.820 sec/step, loss=0.09374, avg_loss=0.09339]
[2018-11-21 11:34:43.119]  Step 250408  [20.938 sec/step, loss=0.09279, avg_loss=0.09357]
[2018-11-21 11:35:05.782]  Step 250409  [20.920 sec/step, loss=0.09519, avg_loss=0.09356]
[2018-11-21 11:35:44.664]  Step 250410  [21.101 sec/step, loss=0.08331, avg_loss=0.09343]
[2018-11-21 11:36:05.406]  Step 250411  [21.072 sec/step, loss=0.09203, avg_loss=0.09339]
[2018-11-21 11:36:27.773]  Step 250412  [21.078 sec/step, loss=0.09254, avg_loss=0.09334]
[2018-11-21 11:36:43.677]  Step 250413  [21.039 sec/step, loss=0.09021, avg_loss=0.09328]
[2018-11-21 11:37:04.730]  Step 250414  [21.013 sec/step, loss=0.09329, avg_loss=0.09325]
[2018-11-21 11:37:22.818]  Step 250415  [21.007 sec/step, loss=0.09178, avg_loss=0.09321]
[2018-11-21 11:37:47.518]  Step 250416  [21.134 sec/step, loss=0.09259, avg_loss=0.09322]
[2018-11-21 11:38:09.459]  Step 250417  [21.196 sec/step, loss=0.09416, avg_loss=0.09323]
[2018-11-21 11:38:33.372]  Step 250418  [21.232 sec/step, loss=0.09294, avg_loss=0.09322]
[2018-11-21 11:38:55.918]  Step 250419  [21.356 sec/step, loss=0.09395, avg_loss=0.09331]
[2018-11-21 11:39:21.647]  Step 250420  [21.373 sec/step, loss=0.09450, avg_loss=0.09330]
[2018-11-21 11:39:45.259]  Step 250421  [21.379 sec/step, loss=0.09241, avg_loss=0.09326]
[2018-11-21 11:40:10.311]  Step 250422  [21.412 sec/step, loss=0.09316, avg_loss=0.09322]
[2018-11-21 11:40:36.603]  Step 250423  [21.412 sec/step, loss=0.09464, avg_loss=0.09321]
[2018-11-21 11:40:51.606]  Step 250424  [21.419 sec/step, loss=0.09084, avg_loss=0.09318]
[2018-11-21 11:41:02.731]  Step 250425  [21.373 sec/step, loss=0.08249, avg_loss=0.09308]
[2018-11-21 11:41:22.849]  Step 250426  [21.333 sec/step, loss=0.09290, avg_loss=0.09303]
[2018-11-21 11:41:48.534]  Step 250427  [21.384 sec/step, loss=0.09495, avg_loss=0.09302]
[2018-11-21 11:42:11.616]  Step 250428  [21.397 sec/step, loss=0.09294, avg_loss=0.09298]
[2018-11-21 11:42:27.440]  Step 250429  [21.478 sec/step, loss=0.08945, avg_loss=0.09313]
[2018-11-21 11:42:50.281]  Step 250430  [21.534 sec/step, loss=0.09311, avg_loss=0.09310]
[2018-11-21 11:43:14.586]  Step 250431  [21.532 sec/step, loss=0.09342, avg_loss=0.09307]
[2018-11-21 11:43:24.029]  Generated 32 batches of size 32 in 8.686 sec
[2018-11-21 11:43:34.787]  Step 250432  [21.505 sec/step, loss=0.09277, avg_loss=0.09302]
[2018-11-21 11:43:56.842]  Step 250433  [21.542 sec/step, loss=0.09481, avg_loss=0.09301]
[2018-11-21 11:44:15.722]  Step 250434  [21.482 sec/step, loss=0.09247, avg_loss=0.09299]
[2018-11-21 11:44:40.357]  Step 250435  [21.485 sec/step, loss=0.09446, avg_loss=0.09297]
[2018-11-21 11:45:06.714]  Step 250436  [21.352 sec/step, loss=0.09257, avg_loss=0.09305]
[2018-11-21 11:45:24.250]  Step 250437  [21.302 sec/step, loss=0.09300, avg_loss=0.09301]
[2018-11-21 11:45:32.936]  Step 250438  [21.136 sec/step, loss=0.07055, avg_loss=0.09276]
[2018-11-21 11:45:44.859]  Step 250439  [20.995 sec/step, loss=0.08835, avg_loss=0.09267]
[2018-11-21 11:46:07.677]  Step 250440  [21.015 sec/step, loss=0.09465, avg_loss=0.09267]
[2018-11-21 11:46:23.232]  Step 250441  [20.989 sec/step, loss=0.08831, avg_loss=0.09262]
[2018-11-21 11:46:47.129]  Step 250442  [20.982 sec/step, loss=0.09353, avg_loss=0.09260]
[2018-11-21 11:47:05.073]  Step 250443  [20.931 sec/step, loss=0.09058, avg_loss=0.09255]
[2018-11-21 11:47:28.894]  Step 250444  [20.959 sec/step, loss=0.09381, avg_loss=0.09251]
[2018-11-21 11:47:50.663]  Step 250445  [20.957 sec/step, loss=0.09462, avg_loss=0.09250]
[2018-11-21 11:48:40.448]  Step 250446  [21.262 sec/step, loss=0.08323, avg_loss=0.09238]
[2018-11-21 11:49:07.198]  Step 250447  [21.277 sec/step, loss=0.09382, avg_loss=0.09237]
[2018-11-21 11:49:24.811]  Step 250448  [21.211 sec/step, loss=0.09215, avg_loss=0.09234]
[2018-11-21 11:49:49.042]  Step 250449  [21.227 sec/step, loss=0.09251, avg_loss=0.09231]
[2018-11-21 11:50:11.471]  Step 250450  [21.271 sec/step, loss=0.09350, avg_loss=0.09231]
[2018-11-21 11:50:11.471]  Writing summary at step: 250450
[2018-11-21 11:50:53.576]  Step 250451  [21.293 sec/step, loss=0.09088, avg_loss=0.09227]
[2018-11-21 11:51:15.554]  Step 250452  [21.266 sec/step, loss=0.09192, avg_loss=0.09224]
[2018-11-21 11:51:46.686]  Step 250453  [21.330 sec/step, loss=0.09277, avg_loss=0.09222]
[2018-11-21 11:52:09.466]  Step 250454  [21.336 sec/step, loss=0.09377, avg_loss=0.09219]
[2018-11-21 11:52:18.472]  Step 250455  [21.305 sec/step, loss=0.07228, avg_loss=0.09200]
[2018-11-21 11:52:37.966]  Step 250456  [21.317 sec/step, loss=0.09308, avg_loss=0.09199]
[2018-11-21 11:53:04.868]  Step 250457  [21.374 sec/step, loss=0.09360, avg_loss=0.09198]
[2018-11-21 11:53:21.923]  Step 250458  [21.316 sec/step, loss=0.08978, avg_loss=0.09192]
[2018-11-21 11:53:44.483]  Step 250459  [21.352 sec/step, loss=0.09213, avg_loss=0.09190]
[2018-11-21 11:54:09.029]  Step 250460  [21.460 sec/step, loss=0.09519, avg_loss=0.09193]
[2018-11-21 11:54:23.705]  Step 250461  [21.395 sec/step, loss=0.08842, avg_loss=0.09186]
[2018-11-21 11:54:44.493]  Step 250462  [21.399 sec/step, loss=0.09220, avg_loss=0.09184]
[2018-11-21 11:54:55.056]  Generated 32 batches of size 32 in 9.609 sec
[2018-11-21 11:55:07.773]  Step 250463  [21.382 sec/step, loss=0.09365, avg_loss=0.09181]
[2018-11-21 11:55:32.290]  Step 250464  [21.403 sec/step, loss=0.09293, avg_loss=0.09179]
[2018-11-21 11:55:53.873]  Step 250465  [21.372 sec/step, loss=0.09169, avg_loss=0.09177]
[2018-11-21 11:56:17.684]  Step 250466  [21.508 sec/step, loss=0.09374, avg_loss=0.09185]
[2018-11-21 11:56:42.529]  Step 250467  [21.538 sec/step, loss=0.09313, avg_loss=0.09183]
[2018-11-21 11:57:03.242]  Step 250468  [21.589 sec/step, loss=0.09389, avg_loss=0.09185]
[2018-11-21 11:57:25.726]  Step 250469  [21.603 sec/step, loss=0.09305, avg_loss=0.09183]
[2018-11-21 11:57:36.031]  Step 250470  [21.480 sec/step, loss=0.08390, avg_loss=0.09173]
[2018-11-21 11:57:55.386]  Step 250471  [21.584 sec/step, loss=0.09211, avg_loss=0.09192]
[2018-11-21 11:58:23.483]  Step 250472  [21.669 sec/step, loss=0.09074, avg_loss=0.09189]
[2018-11-21 11:58:49.079]  Step 250473  [21.723 sec/step, loss=0.09318, avg_loss=0.09188]
[2018-11-21 11:59:13.554]  Step 250474  [21.674 sec/step, loss=0.09149, avg_loss=0.09185]
[2018-11-21 11:59:31.444]  Step 250475  [21.699 sec/step, loss=0.08978, avg_loss=0.09183]
[2018-11-21 11:59:54.055]  Step 250476  [21.753 sec/step, loss=0.09248, avg_loss=0.09181]
[2018-11-21 12:00:15.772]  Step 250477  [21.555 sec/step, loss=0.09261, avg_loss=0.09190]
[2018-11-21 12:00:40.105]  Step 250478  [21.576 sec/step, loss=0.09313, avg_loss=0.09188]
[2018-11-21 12:01:00.070]  Step 250479  [21.544 sec/step, loss=0.09073, avg_loss=0.09184]
[2018-11-21 12:01:21.339]  Step 250480  [21.570 sec/step, loss=0.09293, avg_loss=0.09183]
[2018-11-21 12:01:37.112]  Step 250481  [21.483 sec/step, loss=0.08849, avg_loss=0.09178]
[2018-11-21 12:01:45.332]  Step 250482  [21.392 sec/step, loss=0.06929, avg_loss=0.09153]
[2018-11-21 12:02:08.620]  Step 250483  [21.390 sec/step, loss=0.09228, avg_loss=0.09151]
[2018-11-21 12:02:27.831]  Step 250484  [21.460 sec/step, loss=0.09161, avg_loss=0.09152]
[2018-11-21 12:02:51.511]  Step 250485  [21.588 sec/step, loss=0.09211, avg_loss=0.09158]
[2018-11-21 12:03:15.675]  Step 250486  [21.586 sec/step, loss=0.09165, avg_loss=0.09155]
[2018-11-21 12:03:36.022]  Step 250487  [21.541 sec/step, loss=0.09117, avg_loss=0.09153]
[2018-11-21 12:04:15.836]  Step 250488  [21.700 sec/step, loss=0.08175, avg_loss=0.09141]
[2018-11-21 12:04:29.881]  Step 250489  [21.638 sec/step, loss=0.09001, avg_loss=0.09138]
[2018-11-21 12:04:47.487]  Step 250490  [21.551 sec/step, loss=0.09136, avg_loss=0.09135]
[2018-11-21 12:05:08.840]  Step 250491  [21.574 sec/step, loss=0.09238, avg_loss=0.09134]
[2018-11-21 12:05:29.773]  Step 250492  [21.562 sec/step, loss=0.09213, avg_loss=0.09132]
[2018-11-21 12:05:49.622]  Step 250493  [21.548 sec/step, loss=0.09157, avg_loss=0.09129]
[2018-11-21 12:06:11.901]  Step 250494  [21.526 sec/step, loss=0.09357, avg_loss=0.09127]
[2018-11-21 12:06:20.962]  Generated 32 batches of size 32 in 8.276 sec
[2018-11-21 12:06:23.954]  Step 250495  [21.439 sec/step, loss=0.08105, avg_loss=0.09113]
[2018-11-21 12:06:43.259]  Step 250496  [21.542 sec/step, loss=0.09158, avg_loss=0.09132]
[2018-11-21 12:06:58.959]  Step 250497  [21.450 sec/step, loss=0.08935, avg_loss=0.09125]
[2018-11-21 12:07:23.331]  Step 250498  [21.527 sec/step, loss=0.09306, avg_loss=0.09128]
[2018-11-21 12:07:35.488]  Step 250499  [21.488 sec/step, loss=0.08736, avg_loss=0.09124]
[2018-11-21 12:07:56.898]  Step 250500  [21.456 sec/step, loss=0.09124, avg_loss=0.09122]
[2018-11-21 12:07:56.899]  Writing summary at step: 250500
[2018-11-21 12:08:19.322]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-250500
[2018-11-21 12:08:22.571]  Saving audio and alignment...
[2018-11-21 12:08:39.133]  Input: {W IY1} cannot live on air. the {F AE1 M IH0 SH T} jane will {HH AE1 V} to beg bread. eyre {CH AY1 M Z} with where, elsewhere, wherever, anywhere, everywhere. {AW1 T S AY1 D} lowood just before helen's death,~______________________________
[2018-11-21 12:09:03.699]  Step 250501  [21.448 sec/step, loss=0.09233, avg_loss=0.09119]
[2018-11-21 12:09:24.226]  Step 250502  [21.513 sec/step, loss=0.09109, avg_loss=0.09118]
[2018-11-21 12:09:47.659]  Step 250503  [21.516 sec/step, loss=0.09280, avg_loss=0.09116]
[2018-11-21 12:10:12.000]  Step 250504  [21.525 sec/step, loss=0.09240, avg_loss=0.09113]
[2018-11-21 12:10:31.451]  Step 250505  [21.484 sec/step, loss=0.09039, avg_loss=0.09109]
[2018-11-21 12:10:54.690]  Step 250506  [21.535 sec/step, loss=0.09153, avg_loss=0.09108]
[2018-11-21 12:11:07.028]  Step 250507  [21.466 sec/step, loss=0.08881, avg_loss=0.09103]
[2018-11-21 12:11:20.965]  Step 250508  [21.400 sec/step, loss=0.08978, avg_loss=0.09100]
[2018-11-21 12:11:41.994]  Step 250509  [21.384 sec/step, loss=0.09244, avg_loss=0.09097]
[2018-11-21 12:12:03.679]  Step 250510  [21.212 sec/step, loss=0.09183, avg_loss=0.09106]
[2018-11-21 12:12:22.141]  Step 250511  [21.189 sec/step, loss=0.09075, avg_loss=0.09104]
[2018-11-21 12:12:38.042]  Step 250512  [21.124 sec/step, loss=0.08748, avg_loss=0.09099]
[2018-11-21 12:13:02.139]  Step 250513  [21.206 sec/step, loss=0.09093, avg_loss=0.09100]
[2018-11-21 12:13:24.778]  Step 250514  [21.222 sec/step, loss=0.09091, avg_loss=0.09098]
[2018-11-21 12:13:53.129]  Step 250515  [21.325 sec/step, loss=0.09021, avg_loss=0.09096]
[2018-11-21 12:14:02.028]  Step 250516  [21.167 sec/step, loss=0.06927, avg_loss=0.09073]
[2018-11-21 12:14:23.612]  Step 250517  [21.163 sec/step, loss=0.09152, avg_loss=0.09070]
[2018-11-21 12:14:48.939]  Step 250518  [21.177 sec/step, loss=0.09204, avg_loss=0.09069]
[2018-11-21 12:15:12.784]  Step 250519  [21.190 sec/step, loss=0.09291, avg_loss=0.09068]
[2018-11-21 12:15:37.742]  Step 250520  [21.182 sec/step, loss=0.09139, avg_loss=0.09065]
[2018-11-21 12:15:58.274]  Step 250521  [21.152 sec/step, loss=0.09079, avg_loss=0.09063]
[2018-11-21 12:16:17.561]  Step 250522  [21.094 sec/step, loss=0.08852, avg_loss=0.09059]
[2018-11-21 12:16:43.727]  Step 250523  [21.093 sec/step, loss=0.09246, avg_loss=0.09057]
[2018-11-21 12:17:01.087]  Step 250524  [21.116 sec/step, loss=0.09110, avg_loss=0.09057]
[2018-11-21 12:17:10.494]  Generated 32 batches of size 32 in 8.433 sec
[2018-11-21 12:17:21.185]  Step 250525  [21.206 sec/step, loss=0.09205, avg_loss=0.09066]
[2018-11-21 12:17:42.682]  Step 250526  [21.220 sec/step, loss=0.09199, avg_loss=0.09065]
[2018-11-21 12:18:04.614]  Step 250527  [21.182 sec/step, loss=0.09221, avg_loss=0.09063]
[2018-11-21 12:18:15.248]  Step 250528  [21.058 sec/step, loss=0.08064, avg_loss=0.09050]
[2018-11-21 12:18:55.176]  Step 250529  [21.299 sec/step, loss=0.08118, avg_loss=0.09042]
[2018-11-21 12:19:14.598]  Step 250530  [21.265 sec/step, loss=0.09012, avg_loss=0.09039]
[2018-11-21 12:19:32.077]  Step 250531  [21.196 sec/step, loss=0.08946, avg_loss=0.09035]
[2018-11-21 12:19:53.329]  Step 250532  [21.207 sec/step, loss=0.09125, avg_loss=0.09034]
[2018-11-21 12:20:15.822]  Step 250533  [21.211 sec/step, loss=0.09109, avg_loss=0.09030]
[2018-11-21 12:20:29.160]  Step 250534  [21.156 sec/step, loss=0.08597, avg_loss=0.09023]
[2018-11-21 12:20:39.433]  Step 250535  [21.012 sec/step, loss=0.08134, avg_loss=0.09010]
[2018-11-21 12:20:53.395]  Step 250536  [20.888 sec/step, loss=0.08852, avg_loss=0.09006]
[2018-11-21 12:21:02.049]  Step 250537  [20.799 sec/step, loss=0.06823, avg_loss=0.08981]
[2018-11-21 12:21:26.346]  Step 250538  [20.956 sec/step, loss=0.09261, avg_loss=0.09004]
[2018-11-21 12:21:48.233]  Step 250539  [21.055 sec/step, loss=0.09229, avg_loss=0.09007]
[2018-11-21 12:22:12.785]  Step 250540  [21.073 sec/step, loss=0.09030, avg_loss=0.09003]
[2018-11-21 12:22:53.969]  Step 250541  [21.329 sec/step, loss=0.08122, avg_loss=0.08996]
[2018-11-21 12:23:18.301]  Step 250542  [21.333 sec/step, loss=0.09262, avg_loss=0.08995]
[2018-11-21 12:23:37.758]  Step 250543  [21.348 sec/step, loss=0.09000, avg_loss=0.08995]
[2018-11-21 12:23:55.487]  Step 250544  [21.287 sec/step, loss=0.08919, avg_loss=0.08990]
[2018-11-21 12:24:13.872]  Step 250545  [21.254 sec/step, loss=0.09010, avg_loss=0.08985]
[2018-11-21 12:24:37.472]  Step 250546  [20.992 sec/step, loss=0.09095, avg_loss=0.08993]
[2018-11-21 12:24:58.070]  Step 250547  [20.930 sec/step, loss=0.08925, avg_loss=0.08989]
[2018-11-21 12:25:16.471]  Step 250548  [20.938 sec/step, loss=0.09088, avg_loss=0.08987]
[2018-11-21 12:25:37.114]  Step 250549  [20.902 sec/step, loss=0.09086, avg_loss=0.08986]
[2018-11-21 12:25:59.959]  Step 250550  [20.906 sec/step, loss=0.09155, avg_loss=0.08984]
[2018-11-21 12:25:59.959]  Writing summary at step: 250550
[2018-11-21 12:26:43.540]  Step 250551  [20.813 sec/step, loss=0.09005, avg_loss=0.08983]
[2018-11-21 12:27:06.450]  Step 250552  [20.823 sec/step, loss=0.09074, avg_loss=0.08982]
[2018-11-21 12:27:26.247]  Step 250553  [20.709 sec/step, loss=0.08968, avg_loss=0.08979]
[2018-11-21 12:27:50.967]  Step 250554  [20.729 sec/step, loss=0.09220, avg_loss=0.08977]
[2018-11-21 12:28:15.406]  Step 250555  [20.883 sec/step, loss=0.09099, avg_loss=0.08996]
[2018-11-21 12:28:26.617]  Generated 32 batches of size 32 in 10.409 sec
[2018-11-21 12:28:45.181]  Step 250556  [20.986 sec/step, loss=0.09090, avg_loss=0.08994]
[2018-11-21 12:29:08.531]  Step 250557  [20.950 sec/step, loss=0.09037, avg_loss=0.08990]
[2018-11-21 12:29:32.094]  Step 250558  [21.015 sec/step, loss=0.09081, avg_loss=0.08991]
[2018-11-21 12:29:53.324]  Step 250559  [21.002 sec/step, loss=0.09236, avg_loss=0.08992]
[2018-11-21 12:30:09.241]  Step 250560  [20.916 sec/step, loss=0.08736, avg_loss=0.08984]
[2018-11-21 12:30:32.300]  Step 250561  [21.000 sec/step, loss=0.09140, avg_loss=0.08987]
[2018-11-21 12:30:57.404]  Step 250562  [21.043 sec/step, loss=0.09086, avg_loss=0.08985]
[2018-11-21 12:31:25.086]  Step 250563  [21.087 sec/step, loss=0.09128, avg_loss=0.08983]
[2018-11-21 12:31:42.393]  Step 250564  [21.015 sec/step, loss=0.08866, avg_loss=0.08979]
[2018-11-21 12:32:04.773]  Step 250565  [21.023 sec/step, loss=0.09138, avg_loss=0.08978]
[2018-11-21 12:32:28.367]  Step 250566  [21.020 sec/step, loss=0.08957, avg_loss=0.08974]
[2018-11-21 12:32:55.591]  Step 250567  [21.044 sec/step, loss=0.09183, avg_loss=0.08973]
[2018-11-21 12:33:36.260]  Step 250568  [21.244 sec/step, loss=0.08051, avg_loss=0.08960]
[2018-11-21 12:33:57.806]  Step 250569  [21.234 sec/step, loss=0.09015, avg_loss=0.08957]
[2018-11-21 12:34:20.446]  Step 250570  [21.358 sec/step, loss=0.08982, avg_loss=0.08963]
[2018-11-21 12:34:41.314]  Step 250571  [21.373 sec/step, loss=0.08824, avg_loss=0.08959]
[2018-11-21 12:35:05.504]  Step 250572  [21.334 sec/step, loss=0.08963, avg_loss=0.08958]
[2018-11-21 12:35:21.679]  Step 250573  [21.240 sec/step, loss=0.08820, avg_loss=0.08953]
[2018-11-21 12:35:47.676]  Step 250574  [21.255 sec/step, loss=0.09075, avg_loss=0.08952]
[2018-11-21 12:36:08.637]  Step 250575  [21.286 sec/step, loss=0.08549, avg_loss=0.08948]
[2018-11-21 12:36:41.300]  Step 250576  [21.386 sec/step, loss=0.09000, avg_loss=0.08945]
[2018-11-21 12:37:05.742]  Step 250577  [21.413 sec/step, loss=0.08968, avg_loss=0.08942]
[2018-11-21 12:37:34.993]  Step 250578  [21.462 sec/step, loss=0.09065, avg_loss=0.08940]
[2018-11-21 12:38:10.907]  Step 250579  [21.622 sec/step, loss=0.09082, avg_loss=0.08940]
[2018-11-21 12:38:27.955]  Step 250580  [21.580 sec/step, loss=0.08616, avg_loss=0.08933]
[2018-11-21 12:39:00.346]  Step 250581  [21.746 sec/step, loss=0.08994, avg_loss=0.08934]
[2018-11-21 12:39:19.337]  Step 250582  [21.854 sec/step, loss=0.08659, avg_loss=0.08952]
[2018-11-21 12:39:45.811]  Step 250583  [21.885 sec/step, loss=0.09023, avg_loss=0.08950]
[2018-11-21 12:40:13.205]  Step 250584  [21.967 sec/step, loss=0.09084, avg_loss=0.08949]
[2018-11-21 12:40:44.366]  Step 250585  [22.042 sec/step, loss=0.08974, avg_loss=0.08947]
[2018-11-21 12:40:55.597]  Step 250586  [21.913 sec/step, loss=0.06704, avg_loss=0.08922]
[2018-11-21 12:41:24.803]  Step 250587  [22.001 sec/step, loss=0.09177, avg_loss=0.08923]
[2018-11-21 12:41:40.666]  Generated 32 batches of size 32 in 14.797 sec
[2018-11-21 12:42:03.690]  Step 250588  [21.992 sec/step, loss=0.09228, avg_loss=0.08933]
[2018-11-21 12:42:35.357]  Step 250589  [22.168 sec/step, loss=0.09023, avg_loss=0.08933]
[2018-11-21 12:43:08.280]  Step 250590  [22.322 sec/step, loss=0.09121, avg_loss=0.08933]
[2018-11-21 12:43:30.589]  Step 250591  [22.331 sec/step, loss=0.08969, avg_loss=0.08931]
[2018-11-21 12:44:05.934]  Step 250592  [22.475 sec/step, loss=0.09074, avg_loss=0.08929]
[2018-11-21 12:44:39.046]  Step 250593  [22.608 sec/step, loss=0.08942, avg_loss=0.08927]
[2018-11-21 12:44:58.895]  Step 250594  [22.584 sec/step, loss=0.08952, avg_loss=0.08923]
[2018-11-21 12:45:09.732]  Step 250595  [22.571 sec/step, loss=0.08134, avg_loss=0.08923]
[2018-11-21 12:45:29.254]  Step 250596  [22.574 sec/step, loss=0.08976, avg_loss=0.08921]
[2018-11-21 12:45:49.601]  Step 250597  [22.620 sec/step, loss=0.08880, avg_loss=0.08921]
[2018-11-21 12:46:15.054]  Step 250598  [22.631 sec/step, loss=0.09114, avg_loss=0.08919]
[2018-11-21 12:46:33.903]  Step 250599  [22.698 sec/step, loss=0.08960, avg_loss=0.08921]
[2018-11-21 12:46:54.993]  Step 250600  [22.695 sec/step, loss=0.09080, avg_loss=0.08921]
[2018-11-21 12:46:54.993]  Writing summary at step: 250600
[2018-11-21 12:47:47.622]  Step 250601  [22.704 sec/step, loss=0.08923, avg_loss=0.08918]
[2018-11-21 12:48:11.581]  Step 250602  [22.738 sec/step, loss=0.08999, avg_loss=0.08917]
[2018-11-21 12:48:22.654]  Step 250603  [22.614 sec/step, loss=0.07839, avg_loss=0.08902]
[2018-11-21 12:48:43.689]  Step 250604  [22.581 sec/step, loss=0.08781, avg_loss=0.08898]
[2018-11-21 12:49:05.929]  Step 250605  [22.609 sec/step, loss=0.09014, avg_loss=0.08897]
[2018-11-21 12:49:18.533]  Step 250606  [22.503 sec/step, loss=0.08442, avg_loss=0.08890]
[2018-11-21 12:49:39.382]  Step 250607  [22.588 sec/step, loss=0.08939, avg_loss=0.08891]
[2018-11-21 12:49:47.019]  Step 250608  [22.525 sec/step, loss=0.07088, avg_loss=0.08872]
[2018-11-21 12:50:09.876]  Step 250609  [22.543 sec/step, loss=0.09061, avg_loss=0.08870]
[2018-11-21 12:50:30.428]  Step 250610  [22.532 sec/step, loss=0.08934, avg_loss=0.08868]
[2018-11-21 12:50:53.005]  Step 250611  [22.573 sec/step, loss=0.09061, avg_loss=0.08867]
[2018-11-21 12:51:16.852]  Step 250612  [22.652 sec/step, loss=0.08935, avg_loss=0.08869]
[2018-11-21 12:51:32.151]  Step 250613  [22.564 sec/step, loss=0.08668, avg_loss=0.08865]
[2018-11-21 12:51:48.768]  Step 250614  [22.504 sec/step, loss=0.08594, avg_loss=0.08860]
[2018-11-21 12:52:08.789]  Step 250615  [22.421 sec/step, loss=0.08853, avg_loss=0.08858]
[2018-11-21 12:52:29.957]  Step 250616  [22.544 sec/step, loss=0.08985, avg_loss=0.08879]
[2018-11-21 12:52:54.922]  Step 250617  [22.577 sec/step, loss=0.08959, avg_loss=0.08877]
[2018-11-21 12:53:18.410]  Step 250618  [22.559 sec/step, loss=0.08977, avg_loss=0.08875]
[2018-11-21 12:53:28.812]  Generated 32 batches of size 32 in 9.640 sec
[2018-11-21 12:53:42.477]  Step 250619  [22.561 sec/step, loss=0.08852, avg_loss=0.08870]
[2018-11-21 12:54:25.881]  Step 250620  [22.746 sec/step, loss=0.07960, avg_loss=0.08859]
[2018-11-21 12:54:42.905]  Step 250621  [22.711 sec/step, loss=0.08942, avg_loss=0.08857]
[2018-11-21 12:55:08.659]  Step 250622  [22.775 sec/step, loss=0.09131, avg_loss=0.08860]
[2018-11-21 12:55:31.585]  Step 250623  [22.743 sec/step, loss=0.08976, avg_loss=0.08857]
[2018-11-21 12:55:47.239]  Step 250624  [22.726 sec/step, loss=0.08653, avg_loss=0.08853]
[2018-11-21 12:56:11.862]  Step 250625  [22.771 sec/step, loss=0.09084, avg_loss=0.08852]
[2018-11-21 12:56:36.584]  Step 250626  [22.803 sec/step, loss=0.08979, avg_loss=0.08849]
[2018-11-21 12:56:58.417]  Step 250627  [22.802 sec/step, loss=0.09098, avg_loss=0.08848]
[2018-11-21 12:57:16.274]  Step 250628  [22.875 sec/step, loss=0.08747, avg_loss=0.08855]
[2018-11-21 12:57:38.278]  Step 250629  [22.695 sec/step, loss=0.08941, avg_loss=0.08863]
[2018-11-21 12:58:02.736]  Step 250630  [22.746 sec/step, loss=0.08948, avg_loss=0.08863]
[2018-11-21 12:58:15.066]  Step 250631  [22.694 sec/step, loss=0.08468, avg_loss=0.08858]
[2018-11-21 12:58:34.587]  Step 250632  [22.677 sec/step, loss=0.08915, avg_loss=0.08856]
[2018-11-21 12:58:57.212]  Step 250633  [22.678 sec/step, loss=0.08978, avg_loss=0.08854]
[2018-11-21 12:59:20.361]  Step 250634  [22.776 sec/step, loss=0.08877, avg_loss=0.08857]
[2018-11-21 12:59:29.605]  Step 250635  [22.766 sec/step, loss=0.06763, avg_loss=0.08843]
[2018-11-21 12:59:50.395]  Step 250636  [22.834 sec/step, loss=0.08891, avg_loss=0.08844]
[2018-11-21 13:00:12.368]  Step 250637  [22.968 sec/step, loss=0.09008, avg_loss=0.08866]
[2018-11-21 13:00:30.400]  Step 250638  [22.905 sec/step, loss=0.08843, avg_loss=0.08861]
[2018-11-21 13:00:56.135]  Step 250639  [22.943 sec/step, loss=0.08977, avg_loss=0.08859]
[2018-11-21 13:01:10.319]  Step 250640  [22.840 sec/step, loss=0.08598, avg_loss=0.08855]
[2018-11-21 13:01:35.072]  Step 250641  [22.675 sec/step, loss=0.09100, avg_loss=0.08864]
[2018-11-21 13:02:01.893]  Step 250642  [22.700 sec/step, loss=0.08956, avg_loss=0.08861]
[2018-11-21 13:02:26.848]  Step 250643  [22.755 sec/step, loss=0.08826, avg_loss=0.08860]
[2018-11-21 13:02:47.196]  Step 250644  [22.781 sec/step, loss=0.08847, avg_loss=0.08859]
[2018-11-21 13:03:07.208]  Step 250645  [22.798 sec/step, loss=0.08810, avg_loss=0.08857]
[2018-11-21 13:03:26.777]  Step 250646  [22.757 sec/step, loss=0.08803, avg_loss=0.08854]
[2018-11-21 13:03:51.047]  Step 250647  [22.794 sec/step, loss=0.09045, avg_loss=0.08855]
[2018-11-21 13:04:15.215]  Step 250648  [22.852 sec/step, loss=0.08830, avg_loss=0.08853]
[2018-11-21 13:04:38.161]  Step 250649  [22.875 sec/step, loss=0.08956, avg_loss=0.08851]
[2018-11-21 13:05:02.602]  Step 250650  [22.891 sec/step, loss=0.09042, avg_loss=0.08850]
[2018-11-21 13:05:02.602]  Writing summary at step: 250650
[2018-11-21 13:05:11.877]  Generated 32 batches of size 32 in 8.373 sec
[2018-11-21 13:05:31.939]  Step 250651  [22.889 sec/step, loss=0.08526, avg_loss=0.08845]
[2018-11-21 13:05:55.902]  Step 250652  [22.900 sec/step, loss=0.09045, avg_loss=0.08845]
[2018-11-21 13:06:18.857]  Step 250653  [22.931 sec/step, loss=0.08967, avg_loss=0.08845]
[2018-11-21 13:06:41.508]  Step 250654  [22.910 sec/step, loss=0.09179, avg_loss=0.08845]
[2018-11-21 13:07:02.411]  Step 250655  [22.875 sec/step, loss=0.08931, avg_loss=0.08843]
[2018-11-21 13:07:25.093]  Step 250656  [22.804 sec/step, loss=0.08893, avg_loss=0.08841]
[2018-11-21 13:08:08.045]  Step 250657  [23.000 sec/step, loss=0.07971, avg_loss=0.08830]
[2018-11-21 13:08:23.587]  Step 250658  [22.920 sec/step, loss=0.08661, avg_loss=0.08826]
[2018-11-21 13:08:34.138]  Step 250659  [22.813 sec/step, loss=0.08000, avg_loss=0.08814]
[2018-11-21 13:08:51.051]  Step 250660  [22.823 sec/step, loss=0.08793, avg_loss=0.08814]
[2018-11-21 13:09:26.870]  Step 250661  [22.951 sec/step, loss=0.07905, avg_loss=0.08802]
[2018-11-21 13:09:51.209]  Step 250662  [22.943 sec/step, loss=0.09002, avg_loss=0.08801]
[2018-11-21 13:10:16.514]  Step 250663  [22.919 sec/step, loss=0.09021, avg_loss=0.08800]
[2018-11-21 13:10:44.236]  Step 250664  [23.023 sec/step, loss=0.08827, avg_loss=0.08800]
[2018-11-21 13:10:53.267]  Step 250665  [22.890 sec/step, loss=0.06739, avg_loss=0.08776]
[2018-11-21 13:11:17.919]  Step 250666  [22.901 sec/step, loss=0.09062, avg_loss=0.08777]
[2018-11-21 13:11:30.472]  Step 250667  [22.754 sec/step, loss=0.08345, avg_loss=0.08768]
[2018-11-21 13:11:51.043]  Step 250668  [22.553 sec/step, loss=0.08865, avg_loss=0.08777]
[2018-11-21 13:12:11.476]  Step 250669  [22.542 sec/step, loss=0.08846, avg_loss=0.08775]
[2018-11-21 13:12:30.505]  Step 250670  [22.506 sec/step, loss=0.08840, avg_loss=0.08773]
[2018-11-21 13:12:50.413]  Step 250671  [22.496 sec/step, loss=0.08778, avg_loss=0.08773]
[2018-11-21 13:13:12.164]  Step 250672  [22.472 sec/step, loss=0.08926, avg_loss=0.08773]
[2018-11-21 13:13:28.094]  Step 250673  [22.469 sec/step, loss=0.08421, avg_loss=0.08769]
[2018-11-21 13:13:49.110]  Step 250674  [22.419 sec/step, loss=0.08853, avg_loss=0.08766]
[2018-11-21 13:14:12.720]  Step 250675  [22.446 sec/step, loss=0.08857, avg_loss=0.08770]
[2018-11-21 13:14:26.618]  Step 250676  [22.258 sec/step, loss=0.08579, avg_loss=0.08765]
[2018-11-21 13:14:51.371]  Step 250677  [22.261 sec/step, loss=0.08865, avg_loss=0.08764]
[2018-11-21 13:15:13.725]  Step 250678  [22.192 sec/step, loss=0.08915, avg_loss=0.08763]
[2018-11-21 13:15:36.750]  Step 250679  [22.063 sec/step, loss=0.08945, avg_loss=0.08761]
[2018-11-21 13:16:01.087]  Step 250680  [22.136 sec/step, loss=0.08919, avg_loss=0.08764]
[2018-11-21 13:16:24.562]  Step 250681  [22.047 sec/step, loss=0.08959, avg_loss=0.08764]
[2018-11-21 13:16:35.363]  Generated 32 batches of size 32 in 9.940 sec
[2018-11-21 13:16:52.541]  Step 250682  [22.137 sec/step, loss=0.08811, avg_loss=0.08766]
[2018-11-21 13:17:15.446]  Step 250683  [22.101 sec/step, loss=0.08878, avg_loss=0.08764]
[2018-11-21 13:17:36.715]  Step 250684  [22.040 sec/step, loss=0.08807, avg_loss=0.08761]
[2018-11-21 13:17:59.244]  Step 250685  [21.954 sec/step, loss=0.08847, avg_loss=0.08760]
[2018-11-21 13:18:17.355]  Step 250686  [22.023 sec/step, loss=0.08767, avg_loss=0.08781]
[2018-11-21 13:18:32.915]  Step 250687  [21.886 sec/step, loss=0.08522, avg_loss=0.08774]
[2018-11-21 13:18:50.900]  Step 250688  [21.677 sec/step, loss=0.08726, avg_loss=0.08769]
[2018-11-21 13:19:12.541]  Step 250689  [21.577 sec/step, loss=0.08921, avg_loss=0.08768]
[2018-11-21 13:19:31.337]  Step 250690  [21.436 sec/step, loss=0.08836, avg_loss=0.08765]
[2018-11-21 13:19:51.539]  Step 250691  [21.415 sec/step, loss=0.08780, avg_loss=0.08763]
[2018-11-21 13:20:14.957]  Step 250692  [21.295 sec/step, loss=0.08782, avg_loss=0.08760]
[2018-11-21 13:20:31.280]  Step 250693  [21.127 sec/step, loss=0.08466, avg_loss=0.08756]
[2018-11-21 13:21:10.821]  Step 250694  [21.324 sec/step, loss=0.07798, avg_loss=0.08744]
[2018-11-21 13:21:19.191]  Step 250695  [21.300 sec/step, loss=0.06709, avg_loss=0.08730]
[2018-11-21 13:21:43.458]  Step 250696  [21.347 sec/step, loss=0.08894, avg_loss=0.08729]
[2018-11-21 13:22:07.785]  Step 250697  [21.387 sec/step, loss=0.08935, avg_loss=0.08730]
[2018-11-21 13:22:32.096]  Step 250698  [21.375 sec/step, loss=0.08788, avg_loss=0.08726]
[2018-11-21 13:22:54.925]  Step 250699  [21.415 sec/step, loss=0.08858, avg_loss=0.08725]
[2018-11-21 13:23:17.516]  Step 250700  [21.430 sec/step, loss=0.08873, avg_loss=0.08723]
[2018-11-21 13:23:17.517]  Writing summary at step: 250700
[2018-11-21 13:23:48.641]  Step 250701  [21.380 sec/step, loss=0.08741, avg_loss=0.08721]
[2018-11-21 13:24:07.271]  Step 250702  [21.327 sec/step, loss=0.08694, avg_loss=0.08718]
[2018-11-21 13:24:28.351]  Step 250703  [21.427 sec/step, loss=0.08967, avg_loss=0.08730]
[2018-11-21 13:24:47.096]  Step 250704  [21.404 sec/step, loss=0.08830, avg_loss=0.08730]
[2018-11-21 13:25:10.152]  Step 250705  [21.412 sec/step, loss=0.08858, avg_loss=0.08729]
[2018-11-21 13:25:35.249]  Step 250706  [21.537 sec/step, loss=0.08834, avg_loss=0.08733]
[2018-11-21 13:26:01.678]  Step 250707  [21.593 sec/step, loss=0.08830, avg_loss=0.08731]
[2018-11-21 13:26:21.605]  Step 250708  [21.716 sec/step, loss=0.08752, avg_loss=0.08748]
[2018-11-21 13:26:43.599]  Step 250709  [21.707 sec/step, loss=0.08791, avg_loss=0.08745]
[2018-11-21 13:26:55.853]  Step 250710  [21.624 sec/step, loss=0.08426, avg_loss=0.08740]
[2018-11-21 13:27:09.877]  Step 250711  [21.538 sec/step, loss=0.08554, avg_loss=0.08735]
[2018-11-21 13:27:25.811]  Step 250712  [21.459 sec/step, loss=0.08439, avg_loss=0.08730]
[2018-11-21 13:27:36.873]  Generated 32 batches of size 32 in 10.284 sec
[2018-11-21 13:27:53.781]  Step 250713  [21.586 sec/step, loss=0.08904, avg_loss=0.08733]
[2018-11-21 13:28:16.911]  Step 250714  [21.651 sec/step, loss=0.08820, avg_loss=0.08735]
[2018-11-21 13:28:38.649]  Step 250715  [21.668 sec/step, loss=0.08888, avg_loss=0.08735]
[2018-11-21 13:28:55.778]  Step 250716  [21.628 sec/step, loss=0.08765, avg_loss=0.08733]
[2018-11-21 13:29:13.337]  Step 250717  [21.554 sec/step, loss=0.08629, avg_loss=0.08730]
[2018-11-21 13:29:35.486]  Step 250718  [21.541 sec/step, loss=0.08926, avg_loss=0.08729]
[2018-11-21 13:29:59.684]  Step 250719  [21.542 sec/step, loss=0.08879, avg_loss=0.08730]
[2018-11-21 13:30:19.408]  Step 250720  [21.305 sec/step, loss=0.08724, avg_loss=0.08737]
[2018-11-21 13:30:44.017]  Step 250721  [21.381 sec/step, loss=0.08937, avg_loss=0.08737]
[2018-11-21 13:31:02.789]  Step 250722  [21.311 sec/step, loss=0.08747, avg_loss=0.08733]
[2018-11-21 13:31:22.515]  Step 250723  [21.279 sec/step, loss=0.08668, avg_loss=0.08730]
[2018-11-21 13:31:38.427]  Step 250724  [21.282 sec/step, loss=0.08309, avg_loss=0.08727]
[2018-11-21 13:32:02.803]  Step 250725  [21.279 sec/step, loss=0.08792, avg_loss=0.08724]
[2018-11-21 13:32:24.810]  Step 250726  [21.252 sec/step, loss=0.08838, avg_loss=0.08722]
[2018-11-21 13:32:33.542]  Step 250727  [21.121 sec/step, loss=0.06597, avg_loss=0.08697]
[2018-11-21 13:32:57.682]  Step 250728  [21.184 sec/step, loss=0.08924, avg_loss=0.08699]
[2018-11-21 13:33:19.337]  Step 250729  [21.180 sec/step, loss=0.08861, avg_loss=0.08698]
[2018-11-21 13:33:41.932]  Step 250730  [21.162 sec/step, loss=0.08794, avg_loss=0.08697]
[2018-11-21 13:34:02.904]  Step 250731  [21.248 sec/step, loss=0.08886, avg_loss=0.08701]
[2018-11-21 13:34:24.838]  Step 250732  [21.272 sec/step, loss=0.08799, avg_loss=0.08700]
[2018-11-21 13:34:47.241]  Step 250733  [21.270 sec/step, loss=0.08869, avg_loss=0.08699]
[2018-11-21 13:35:05.867]  Step 250734  [21.225 sec/step, loss=0.08739, avg_loss=0.08697]
[2018-11-21 13:35:18.115]  Step 250735  [21.255 sec/step, loss=0.08327, avg_loss=0.08713]
[2018-11-21 13:35:38.908]  Step 250736  [21.255 sec/step, loss=0.08729, avg_loss=0.08711]
[2018-11-21 13:36:02.799]  Step 250737  [21.274 sec/step, loss=0.08882, avg_loss=0.08710]
[2018-11-21 13:36:27.133]  Step 250738  [21.337 sec/step, loss=0.08839, avg_loss=0.08710]
[2018-11-21 13:36:42.682]  Step 250739  [21.235 sec/step, loss=0.08475, avg_loss=0.08705]
[2018-11-21 13:37:02.046]  Step 250740  [21.287 sec/step, loss=0.08743, avg_loss=0.08707]
[2018-11-21 13:37:26.738]  Step 250741  [21.286 sec/step, loss=0.08932, avg_loss=0.08705]
[2018-11-21 13:37:49.175]  Step 250742  [21.243 sec/step, loss=0.08799, avg_loss=0.08703]
[2018-11-21 13:38:28.869]  Step 250743  [21.390 sec/step, loss=0.07899, avg_loss=0.08694]
[2018-11-21 13:38:46.127]  Step 250744  [21.359 sec/step, loss=0.08750, avg_loss=0.08693]
[2018-11-21 13:38:55.175]  Generated 32 batches of size 32 in 8.261 sec
[2018-11-21 13:38:58.074]  Step 250745  [21.278 sec/step, loss=0.07990, avg_loss=0.08685]
[2018-11-21 13:39:12.218]  Step 250746  [21.224 sec/step, loss=0.08542, avg_loss=0.08682]
[2018-11-21 13:39:37.323]  Step 250747  [21.233 sec/step, loss=0.08644, avg_loss=0.08678]
[2018-11-21 13:39:59.540]  Step 250748  [21.213 sec/step, loss=0.08873, avg_loss=0.08679]
[2018-11-21 13:40:17.471]  Step 250749  [21.163 sec/step, loss=0.08634, avg_loss=0.08675]
[2018-11-21 13:40:39.867]  Step 250750  [21.142 sec/step, loss=0.08800, avg_loss=0.08673]
[2018-11-21 13:40:39.867]  Writing summary at step: 250750
[2018-11-21 13:41:29.959]  Step 250751  [21.211 sec/step, loss=0.08805, avg_loss=0.08676]
[2018-11-21 13:41:56.190]  Step 250752  [21.234 sec/step, loss=0.08863, avg_loss=0.08674]
[2018-11-21 13:42:18.324]  Step 250753  [21.226 sec/step, loss=0.08836, avg_loss=0.08673]
[2018-11-21 13:42:35.276]  Step 250754  [21.169 sec/step, loss=0.08713, avg_loss=0.08668]
[2018-11-21 13:42:57.679]  Step 250755  [21.184 sec/step, loss=0.08780, avg_loss=0.08667]
[2018-11-21 13:43:08.083]  Step 250756  [21.061 sec/step, loss=0.08030, avg_loss=0.08658]
[2018-11-21 13:43:34.324]  Step 250757  [20.894 sec/step, loss=0.08767, avg_loss=0.08666]
[2018-11-21 13:43:58.560]  Step 250758  [20.981 sec/step, loss=0.08718, avg_loss=0.08666]
[2018-11-21 13:44:20.059]  Step 250759  [21.090 sec/step, loss=0.08753, avg_loss=0.08674]
[2018-11-21 13:44:37.737]  Step 250760  [21.098 sec/step, loss=0.08559, avg_loss=0.08672]
[2018-11-21 13:44:51.688]  Step 250761  [20.879 sec/step, loss=0.08413, avg_loss=0.08677]
[2018-11-21 13:45:10.255]  Step 250762  [20.821 sec/step, loss=0.08699, avg_loss=0.08674]
[2018-11-21 13:45:18.935]  Step 250763  [20.655 sec/step, loss=0.06698, avg_loss=0.08650]
[2018-11-21 13:45:31.149]  Step 250764  [20.500 sec/step, loss=0.08289, avg_loss=0.08645]
[2018-11-21 13:45:52.649]  Step 250765  [20.625 sec/step, loss=0.08796, avg_loss=0.08666]
[2018-11-21 13:46:12.936]  Step 250766  [20.581 sec/step, loss=0.08759, avg_loss=0.08663]
[2018-11-21 13:46:33.858]  Step 250767  [20.665 sec/step, loss=0.08801, avg_loss=0.08667]
[2018-11-21 13:46:56.964]  Step 250768  [20.690 sec/step, loss=0.08783, avg_loss=0.08666]
[2018-11-21 13:47:19.671]  Step 250769  [20.713 sec/step, loss=0.08812, avg_loss=0.08666]
[2018-11-21 13:47:41.374]  Step 250770  [20.740 sec/step, loss=0.08791, avg_loss=0.08665]
[2018-11-21 13:47:57.133]  Step 250771  [20.698 sec/step, loss=0.08415, avg_loss=0.08662]
[2018-11-21 13:48:17.727]  Step 250772  [20.687 sec/step, loss=0.08745, avg_loss=0.08660]
[2018-11-21 13:48:41.479]  Step 250773  [20.765 sec/step, loss=0.08737, avg_loss=0.08663]
[2018-11-21 13:49:07.730]  Step 250774  [20.817 sec/step, loss=0.08808, avg_loss=0.08663]
[2018-11-21 13:49:35.412]  Step 250775  [20.858 sec/step, loss=0.08799, avg_loss=0.08662]
[2018-11-21 13:49:47.191]  Generated 32 batches of size 32 in 10.915 sec
[2018-11-21 13:49:58.320]  Step 250776  [20.948 sec/step, loss=0.08713, avg_loss=0.08664]
[2018-11-21 13:50:23.429]  Step 250777  [20.952 sec/step, loss=0.08763, avg_loss=0.08662]
[2018-11-21 13:50:52.241]  Step 250778  [21.016 sec/step, loss=0.08941, avg_loss=0.08663]
[2018-11-21 13:51:12.470]  Step 250779  [20.988 sec/step, loss=0.08636, avg_loss=0.08660]
[2018-11-21 13:51:33.035]  Step 250780  [20.950 sec/step, loss=0.08710, avg_loss=0.08658]
[2018-11-21 13:51:58.991]  Step 250781  [20.975 sec/step, loss=0.08912, avg_loss=0.08657]
[2018-11-21 13:52:14.979]  Step 250782  [20.855 sec/step, loss=0.08412, avg_loss=0.08653]
[2018-11-21 13:52:55.474]  Step 250783  [21.031 sec/step, loss=0.07832, avg_loss=0.08643]
[2018-11-21 13:53:21.057]  Step 250784  [21.074 sec/step, loss=0.08876, avg_loss=0.08643]
[2018-11-21 13:53:33.070]  Step 250785  [20.969 sec/step, loss=0.08273, avg_loss=0.08638]
[2018-11-21 13:53:59.940]  Step 250786  [21.057 sec/step, loss=0.08687, avg_loss=0.08637]
[2018-11-21 13:54:25.150]  Step 250787  [21.153 sec/step, loss=0.08671, avg_loss=0.08638]
[2018-11-21 13:54:49.695]  Step 250788  [21.219 sec/step, loss=0.08680, avg_loss=0.08638]
[2018-11-21 13:55:07.585]  Step 250789  [21.181 sec/step, loss=0.08642, avg_loss=0.08635]
[2018-11-21 13:55:30.115]  Step 250790  [21.219 sec/step, loss=0.08759, avg_loss=0.08634]
[2018-11-21 13:55:47.909]  Step 250791  [21.195 sec/step, loss=0.08595, avg_loss=0.08632]
[2018-11-21 13:56:11.412]  Step 250792  [21.196 sec/step, loss=0.08713, avg_loss=0.08632]
[2018-11-21 13:56:27.414]  Step 250793  [21.192 sec/step, loss=0.08237, avg_loss=0.08629]
[2018-11-21 13:56:35.921]  Step 250794  [20.882 sec/step, loss=0.06698, avg_loss=0.08618]
[2018-11-21 13:56:55.302]  Step 250795  [20.992 sec/step, loss=0.08649, avg_loss=0.08638]
[2018-11-21 13:57:17.855]  Step 250796  [20.975 sec/step, loss=0.08737, avg_loss=0.08636]
[2018-11-21 13:57:39.650]  Step 250797  [20.950 sec/step, loss=0.08662, avg_loss=0.08634]
[2018-11-21 13:57:50.186]  Step 250798  [20.812 sec/step, loss=0.07742, avg_loss=0.08623]
[2018-11-21 13:58:12.969]  Step 250799  [20.811 sec/step, loss=0.08747, avg_loss=0.08622]
[2018-11-21 13:58:32.510]  Step 250800  [20.781 sec/step, loss=0.08624, avg_loss=0.08620]
[2018-11-21 13:58:32.510]  Writing summary at step: 250800
[2018-11-21 13:59:15.108]  Step 250801  [20.777 sec/step, loss=0.08566, avg_loss=0.08618]
[2018-11-21 13:59:40.752]  Step 250802  [20.847 sec/step, loss=0.08860, avg_loss=0.08619]
[2018-11-21 14:00:00.736]  Step 250803  [20.836 sec/step, loss=0.08670, avg_loss=0.08616]
[2018-11-21 14:00:23.814]  Step 250804  [20.879 sec/step, loss=0.08751, avg_loss=0.08616]
[2018-11-21 14:00:48.794]  Step 250805  [20.898 sec/step, loss=0.08785, avg_loss=0.08615]
[2018-11-21 14:01:13.486]  Step 250806  [20.894 sec/step, loss=0.08840, avg_loss=0.08615]
[2018-11-21 14:01:22.675]  Generated 32 batches of size 32 in 8.425 sec
[2018-11-21 14:01:37.091]  Step 250807  [20.866 sec/step, loss=0.08881, avg_loss=0.08616]
[2018-11-21 14:01:56.760]  Step 250808  [20.863 sec/step, loss=0.08683, avg_loss=0.08615]
[2018-11-21 14:02:10.067]  Step 250809  [20.777 sec/step, loss=0.08475, avg_loss=0.08612]
[2018-11-21 14:02:28.630]  Step 250810  [20.840 sec/step, loss=0.08629, avg_loss=0.08614]
[2018-11-21 14:02:49.995]  Step 250811  [20.913 sec/step, loss=0.08760, avg_loss=0.08616]
[2018-11-21 14:03:05.845]  Step 250812  [20.912 sec/step, loss=0.08415, avg_loss=0.08616]
[2018-11-21 14:03:49.426]  Step 250813  [21.068 sec/step, loss=0.07748, avg_loss=0.08604]
[2018-11-21 14:04:13.433]  Step 250814  [21.077 sec/step, loss=0.08763, avg_loss=0.08603]
[2018-11-21 14:04:36.868]  Step 250815  [21.094 sec/step, loss=0.08841, avg_loss=0.08603]
[2018-11-21 14:04:57.528]  Step 250816  [21.129 sec/step, loss=0.08652, avg_loss=0.08602]
[2018-11-21 14:05:20.938]  Step 250817  [21.188 sec/step, loss=0.08745, avg_loss=0.08603]
[2018-11-21 14:05:29.824]  Step 250818  [21.055 sec/step, loss=0.06371, avg_loss=0.08577]
[2018-11-21 14:05:45.783]  Step 250819  [20.973 sec/step, loss=0.08459, avg_loss=0.08573]
[2018-11-21 14:06:26.406]  Step 250820  [21.182 sec/step, loss=0.07711, avg_loss=0.08563]
[2018-11-21 14:06:42.064]  Step 250821  [21.092 sec/step, loss=0.08254, avg_loss=0.08556]
[2018-11-21 14:07:05.918]  Step 250822  [21.143 sec/step, loss=0.08678, avg_loss=0.08556]
[2018-11-21 14:07:24.327]  Step 250823  [21.130 sec/step, loss=0.08707, avg_loss=0.08556]
[2018-11-21 14:07:45.805]  Step 250824  [21.186 sec/step, loss=0.08659, avg_loss=0.08559]
[2018-11-21 14:08:09.383]  Step 250825  [21.178 sec/step, loss=0.08806, avg_loss=0.08560]
[2018-11-21 14:08:28.655]  Step 250826  [21.150 sec/step, loss=0.08640, avg_loss=0.08558]
[2018-11-21 14:08:53.558]  Step 250827  [21.312 sec/step, loss=0.08652, avg_loss=0.08578]
[2018-11-21 14:09:11.439]  Step 250828  [21.249 sec/step, loss=0.08457, avg_loss=0.08573]
[2018-11-21 14:09:33.695]  Step 250829  [21.255 sec/step, loss=0.08743, avg_loss=0.08572]
[2018-11-21 14:09:55.867]  Step 250830  [21.251 sec/step, loss=0.08738, avg_loss=0.08572]
[2018-11-21 14:10:16.565]  Step 250831  [21.249 sec/step, loss=0.08731, avg_loss=0.08570]
[2018-11-21 14:10:39.819]  Step 250832  [21.262 sec/step, loss=0.08743, avg_loss=0.08570]
[2018-11-21 14:10:50.239]  Step 250833  [21.142 sec/step, loss=0.07874, avg_loss=0.08560]
[2018-11-21 14:11:16.498]  Step 250834  [21.218 sec/step, loss=0.08708, avg_loss=0.08559]
[2018-11-21 14:11:40.746]  Step 250835  [21.338 sec/step, loss=0.08812, avg_loss=0.08564]
[2018-11-21 14:11:59.647]  Step 250836  [21.319 sec/step, loss=0.08601, avg_loss=0.08563]
[2018-11-21 14:12:24.647]  Step 250837  [21.330 sec/step, loss=0.08789, avg_loss=0.08562]
[2018-11-21 14:12:46.559]  Step 250838  [21.306 sec/step, loss=0.08738, avg_loss=0.08561]
[2018-11-21 14:12:55.886]  Generated 32 batches of size 32 in 8.530 sec
[2018-11-21 14:13:10.913]  Step 250839  [21.394 sec/step, loss=0.08681, avg_loss=0.08563]
[2018-11-21 14:13:27.814]  Step 250840  [21.370 sec/step, loss=0.08624, avg_loss=0.08562]
[2018-11-21 14:13:41.578]  Step 250841  [21.260 sec/step, loss=0.08346, avg_loss=0.08556]
[2018-11-21 14:14:05.880]  Step 250842  [21.279 sec/step, loss=0.08610, avg_loss=0.08554]
[2018-11-21 14:14:17.781]  Step 250843  [21.001 sec/step, loss=0.08249, avg_loss=0.08558]
[2018-11-21 14:14:41.585]  Step 250844  [21.067 sec/step, loss=0.08621, avg_loss=0.08556]
[2018-11-21 14:15:00.886]  Step 250845  [21.140 sec/step, loss=0.08560, avg_loss=0.08562]
[2018-11-21 14:15:22.010]  Step 250846  [21.210 sec/step, loss=0.08671, avg_loss=0.08563]
[2018-11-21 14:15:41.935]  Step 250847  [21.158 sec/step, loss=0.08692, avg_loss=0.08564]
[2018-11-21 14:16:02.516]  Step 250848  [21.142 sec/step, loss=0.08596, avg_loss=0.08561]
[2018-11-21 14:16:20.908]  Step 250849  [21.146 sec/step, loss=0.08547, avg_loss=0.08560]
[2018-11-21 14:16:46.035]  Step 250850  [21.174 sec/step, loss=0.08798, avg_loss=0.08560]
[2018-11-21 14:16:46.036]  Writing summary at step: 250850
[2018-11-21 14:17:32.295]  Step 250851  [21.159 sec/step, loss=0.08616, avg_loss=0.08558]
[2018-11-21 14:17:55.243]  Step 250852  [21.127 sec/step, loss=0.08638, avg_loss=0.08556]
[2018-11-21 14:18:17.181]  Step 250853  [21.125 sec/step, loss=0.08734, avg_loss=0.08555]
[2018-11-21 14:18:39.039]  Step 250854  [21.174 sec/step, loss=0.08731, avg_loss=0.08555]
[2018-11-21 14:19:03.737]  Step 250855  [21.197 sec/step, loss=0.08634, avg_loss=0.08554]
[2018-11-21 14:19:23.400]  Step 250856  [21.289 sec/step, loss=0.08476, avg_loss=0.08558]
[2018-11-21 14:19:47.546]  Step 250857  [21.268 sec/step, loss=0.08793, avg_loss=0.08558]
[2018-11-21 14:20:06.100]  Step 250858  [21.211 sec/step, loss=0.08585, avg_loss=0.08557]
[2018-11-21 14:20:28.318]  Step 250859  [21.219 sec/step, loss=0.08684, avg_loss=0.08556]
[2018-11-21 14:20:53.148]  Step 250860  [21.290 sec/step, loss=0.08739, avg_loss=0.08558]
[2018-11-21 14:21:03.808]  Step 250861  [21.257 sec/step, loss=0.07805, avg_loss=0.08552]
[2018-11-21 14:21:24.725]  Step 250862  [21.281 sec/step, loss=0.08731, avg_loss=0.08552]
[2018-11-21 14:21:33.334]  Step 250863  [21.280 sec/step, loss=0.06612, avg_loss=0.08552]
[2018-11-21 14:21:57.500]  Step 250864  [21.399 sec/step, loss=0.08690, avg_loss=0.08556]
[2018-11-21 14:22:14.420]  Step 250865  [21.354 sec/step, loss=0.08543, avg_loss=0.08553]
[2018-11-21 14:22:54.251]  Step 250866  [21.549 sec/step, loss=0.07655, avg_loss=0.08542]
[2018-11-21 14:23:09.519]  Step 250867  [21.493 sec/step, loss=0.08368, avg_loss=0.08538]
[2018-11-21 14:23:32.770]  Step 250868  [21.494 sec/step, loss=0.08814, avg_loss=0.08538]
[2018-11-21 14:23:52.167]  Step 250869  [21.461 sec/step, loss=0.08588, avg_loss=0.08536]
[2018-11-21 14:24:01.695]  Generated 32 batches of size 32 in 8.629 sec
[2018-11-21 14:24:05.703]  Step 250870  [21.379 sec/step, loss=0.08191, avg_loss=0.08530]
[2018-11-21 14:24:32.002]  Step 250871  [21.485 sec/step, loss=0.08670, avg_loss=0.08532]
[2018-11-21 14:24:56.355]  Step 250872  [21.522 sec/step, loss=0.08662, avg_loss=0.08531]
[2018-11-21 14:25:12.059]  Step 250873  [21.442 sec/step, loss=0.08165, avg_loss=0.08526]
[2018-11-21 14:25:33.515]  Step 250874  [21.394 sec/step, loss=0.08739, avg_loss=0.08525]
[2018-11-21 14:25:51.321]  Step 250875  [21.295 sec/step, loss=0.08528, avg_loss=0.08522]
[2018-11-21 14:26:06.387]  Step 250876  [21.217 sec/step, loss=0.08270, avg_loss=0.08518]
[2018-11-21 14:26:29.526]  Step 250877  [21.197 sec/step, loss=0.08599, avg_loss=0.08516]
[2018-11-21 14:26:50.312]  Step 250878  [21.117 sec/step, loss=0.08678, avg_loss=0.08514]
[2018-11-21 14:27:09.062]  Step 250879  [21.102 sec/step, loss=0.08565, avg_loss=0.08513]
[2018-11-21 14:27:49.711]  Step 250880  [21.303 sec/step, loss=0.07651, avg_loss=0.08502]
[2018-11-21 14:27:58.780]  Step 250881  [21.134 sec/step, loss=0.06310, avg_loss=0.08476]
[2018-11-21 14:28:21.313]  Step 250882  [21.199 sec/step, loss=0.08638, avg_loss=0.08479]
[2018-11-21 14:28:43.469]  Step 250883  [21.016 sec/step, loss=0.08696, avg_loss=0.08487]
[2018-11-21 14:29:09.969]  Step 250884  [21.025 sec/step, loss=0.08660, avg_loss=0.08485]
[2018-11-21 14:29:34.772]  Step 250885  [21.153 sec/step, loss=0.08547, avg_loss=0.08488]
[2018-11-21 14:29:58.099]  Step 250886  [21.118 sec/step, loss=0.08666, avg_loss=0.08488]
[2018-11-21 14:30:15.918]  Step 250887  [21.044 sec/step, loss=0.08448, avg_loss=0.08485]
[2018-11-21 14:30:31.029]  Step 250888  [20.949 sec/step, loss=0.08267, avg_loss=0.08481]
[2018-11-21 14:30:52.961]  Step 250889  [20.990 sec/step, loss=0.08585, avg_loss=0.08481]
[2018-11-21 14:31:13.467]  Step 250890  [20.970 sec/step, loss=0.08601, avg_loss=0.08479]
[2018-11-21 14:31:35.418]  Step 250891  [21.011 sec/step, loss=0.08710, avg_loss=0.08480]
[2018-11-21 14:31:56.233]  Step 250892  [20.984 sec/step, loss=0.08702, avg_loss=0.08480]
[2018-11-21 14:32:20.968]  Step 250893  [21.072 sec/step, loss=0.08749, avg_loss=0.08485]
[2018-11-21 14:32:38.487]  Step 250894  [21.162 sec/step, loss=0.08611, avg_loss=0.08504]
[2018-11-21 14:32:57.120]  Step 250895  [21.154 sec/step, loss=0.08560, avg_loss=0.08503]
[2018-11-21 14:33:17.633]  Step 250896  [21.134 sec/step, loss=0.08669, avg_loss=0.08503]
[2018-11-21 14:33:28.099]  Step 250897  [21.020 sec/step, loss=0.07812, avg_loss=0.08494]
[2018-11-21 14:33:52.351]  Step 250898  [21.158 sec/step, loss=0.08708, avg_loss=0.08504]
[2018-11-21 14:34:08.292]  Step 250899  [21.089 sec/step, loss=0.08297, avg_loss=0.08499]
[2018-11-21 14:34:20.597]  Step 250900  [21.017 sec/step, loss=0.08164, avg_loss=0.08495]
[2018-11-21 14:34:20.598]  Writing summary at step: 250900
[2018-11-21 14:34:54.194]  Generated 32 batches of size 32 in 8.618 sec
[2018-11-21 14:35:02.054]  Step 250901  [20.989 sec/step, loss=0.08199, avg_loss=0.08491]
[2018-11-21 14:35:27.568]  Step 250902  [20.988 sec/step, loss=0.08782, avg_loss=0.08490]
[2018-11-21 14:35:51.421]  Step 250903  [21.027 sec/step, loss=0.08669, avg_loss=0.08490]
[2018-11-21 14:36:14.954]  Step 250904  [21.031 sec/step, loss=0.08752, avg_loss=0.08490]
[2018-11-21 14:36:36.553]  Step 250905  [20.998 sec/step, loss=0.08674, avg_loss=0.08489]
[2018-11-21 14:36:55.973]  Step 250906  [20.945 sec/step, loss=0.08566, avg_loss=0.08487]
[2018-11-21 14:37:20.108]  Step 250907  [20.950 sec/step, loss=0.08638, avg_loss=0.08484]
[2018-11-21 14:37:42.258]  Step 250908  [20.975 sec/step, loss=0.08759, avg_loss=0.08485]
[2018-11-21 14:38:02.186]  Step 250909  [21.041 sec/step, loss=0.08496, avg_loss=0.08485]
[2018-11-21 14:38:25.236]  Step 250910  [21.086 sec/step, loss=0.08576, avg_loss=0.08485]
[2018-11-21 14:38:49.015]  Step 250911  [21.110 sec/step, loss=0.08597, avg_loss=0.08483]
[2018-11-21 14:39:13.219]  Step 250912  [21.194 sec/step, loss=0.08591, avg_loss=0.08485]
[2018-11-21 14:39:35.158]  Step 250913  [20.977 sec/step, loss=0.08633, avg_loss=0.08494]
[2018-11-21 14:39:56.351]  Step 250914  [20.949 sec/step, loss=0.08571, avg_loss=0.08492]
[2018-11-21 14:40:15.048]  Step 250915  [20.902 sec/step, loss=0.08507, avg_loss=0.08488]
[2018-11-21 14:40:40.891]  Step 250916  [20.954 sec/step, loss=0.08691, avg_loss=0.08489]
[2018-11-21 14:40:53.126]  Step 250917  [20.842 sec/step, loss=0.08083, avg_loss=0.08482]
[2018-11-21 14:41:19.312]  Step 250918  [21.015 sec/step, loss=0.08529, avg_loss=0.08504]
[2018-11-21 14:41:37.928]  Step 250919  [21.041 sec/step, loss=0.08592, avg_loss=0.08505]
[2018-11-21 14:41:57.175]  Step 250920  [20.828 sec/step, loss=0.08574, avg_loss=0.08514]
[2018-11-21 14:42:18.241]  Step 250921  [20.882 sec/step, loss=0.08655, avg_loss=0.08518]
[2018-11-21 14:42:32.475]  Step 250922  [20.786 sec/step, loss=0.08246, avg_loss=0.08513]
[2018-11-21 14:42:52.149]  Step 250923  [20.798 sec/step, loss=0.08456, avg_loss=0.08511]
[2018-11-21 14:43:12.440]  Step 250924  [20.786 sec/step, loss=0.08519, avg_loss=0.08509]
[2018-11-21 14:43:34.947]  Step 250925  [20.776 sec/step, loss=0.08622, avg_loss=0.08508]
[2018-11-21 14:43:50.494]  Step 250926  [20.738 sec/step, loss=0.08382, avg_loss=0.08505]
[2018-11-21 14:44:11.040]  Step 250927  [20.695 sec/step, loss=0.08584, avg_loss=0.08504]
[2018-11-21 14:44:27.262]  Step 250928  [20.678 sec/step, loss=0.08210, avg_loss=0.08502]
[2018-11-21 14:44:51.831]  Step 250929  [20.701 sec/step, loss=0.08535, avg_loss=0.08500]
[2018-11-21 14:45:10.203]  Step 250930  [20.663 sec/step, loss=0.08388, avg_loss=0.08496]
[2018-11-21 14:45:36.905]  Step 250931  [20.723 sec/step, loss=0.08611, avg_loss=0.08495]
[2018-11-21 14:46:08.646]  Step 250932  [20.808 sec/step, loss=0.08730, avg_loss=0.08495]
[2018-11-21 14:46:20.794]  Generated 32 batches of size 32 in 10.940 sec
[2018-11-21 14:46:39.579]  Step 250933  [21.013 sec/step, loss=0.08659, avg_loss=0.08503]
[2018-11-21 14:46:49.199]  Step 250934  [20.847 sec/step, loss=0.06708, avg_loss=0.08483]
[2018-11-21 14:47:16.403]  Step 250935  [20.877 sec/step, loss=0.08562, avg_loss=0.08480]
[2018-11-21 14:47:38.906]  Step 250936  [20.913 sec/step, loss=0.08513, avg_loss=0.08479]
[2018-11-21 14:47:49.597]  Step 250937  [20.769 sec/step, loss=0.07786, avg_loss=0.08469]
[2018-11-21 14:48:15.666]  Step 250938  [20.811 sec/step, loss=0.08692, avg_loss=0.08469]
[2018-11-21 14:48:34.761]  Step 250939  [20.758 sec/step, loss=0.08511, avg_loss=0.08467]
[2018-11-21 14:48:58.494]  Step 250940  [20.827 sec/step, loss=0.08547, avg_loss=0.08466]
[2018-11-21 14:49:45.138]  Step 250941  [21.156 sec/step, loss=0.07593, avg_loss=0.08459]
[2018-11-21 14:50:06.991]  Step 250942  [21.131 sec/step, loss=0.08445, avg_loss=0.08457]
[2018-11-21 14:50:19.041]  Step 250943  [21.133 sec/step, loss=0.07677, avg_loss=0.08451]
[2018-11-21 14:50:36.453]  Step 250944  [21.069 sec/step, loss=0.08041, avg_loss=0.08446]
[2018-11-21 14:51:01.415]  Step 250945  [21.125 sec/step, loss=0.08650, avg_loss=0.08447]
[2018-11-21 14:51:26.397]  Step 250946  [21.164 sec/step, loss=0.08554, avg_loss=0.08445]
[2018-11-21 14:51:46.195]  Step 250947  [21.163 sec/step, loss=0.08360, avg_loss=0.08442]
[2018-11-21 14:52:09.218]  Step 250948  [21.187 sec/step, loss=0.08593, avg_loss=0.08442]
[2018-11-21 14:52:37.755]  Step 250949  [21.288 sec/step, loss=0.08574, avg_loss=0.08442]
[2018-11-21 14:52:57.821]  Step 250950  [21.238 sec/step, loss=0.08513, avg_loss=0.08439]
[2018-11-21 14:52:57.821]  Writing summary at step: 250950
[2018-11-21 14:53:38.945]  Step 250951  [21.223 sec/step, loss=0.08444, avg_loss=0.08438]
[2018-11-21 14:54:01.573]  Step 250952  [21.220 sec/step, loss=0.08636, avg_loss=0.08438]
[2018-11-21 14:54:23.903]  Step 250953  [21.224 sec/step, loss=0.08555, avg_loss=0.08436]
[2018-11-21 14:54:36.046]  Step 250954  [21.127 sec/step, loss=0.08098, avg_loss=0.08430]
[2018-11-21 14:54:59.631]  Step 250955  [21.116 sec/step, loss=0.08577, avg_loss=0.08429]
[2018-11-21 14:55:22.090]  Step 250956  [21.144 sec/step, loss=0.08578, avg_loss=0.08430]
[2018-11-21 14:55:48.049]  Step 250957  [21.162 sec/step, loss=0.08467, avg_loss=0.08427]
[2018-11-21 14:56:11.454]  Step 250958  [21.211 sec/step, loss=0.08714, avg_loss=0.08428]
[2018-11-21 14:56:26.057]  Step 250959  [21.134 sec/step, loss=0.08150, avg_loss=0.08423]
[2018-11-21 14:56:51.059]  Step 250960  [21.136 sec/step, loss=0.08614, avg_loss=0.08422]
[2018-11-21 14:57:15.338]  Step 250961  [21.272 sec/step, loss=0.08735, avg_loss=0.08431]
[2018-11-21 14:57:32.330]  Step 250962  [21.233 sec/step, loss=0.08246, avg_loss=0.08426]
[2018-11-21 14:57:50.366]  Step 250963  [21.327 sec/step, loss=0.08563, avg_loss=0.08445]
[2018-11-21 14:58:02.922]  Generated 32 batches of size 32 in 11.689 sec
[2018-11-21 14:58:19.700]  Step 250964  [21.379 sec/step, loss=0.08600, avg_loss=0.08445]
[2018-11-21 14:58:27.829]  Step 250965  [21.291 sec/step, loss=0.06600, avg_loss=0.08425]
[2018-11-21 14:58:54.102]  Step 250966  [21.155 sec/step, loss=0.08671, avg_loss=0.08435]
[2018-11-21 14:59:15.261]  Step 250967  [21.214 sec/step, loss=0.08555, avg_loss=0.08437]
[2018-11-21 14:59:38.307]  Step 250968  [21.212 sec/step, loss=0.08552, avg_loss=0.08435]
[2018-11-21 15:00:03.540]  Step 250969  [21.271 sec/step, loss=0.08632, avg_loss=0.08435]
[2018-11-21 15:00:43.028]  Step 250970  [21.530 sec/step, loss=0.07640, avg_loss=0.08430]
[2018-11-21 15:01:08.202]  Step 250971  [21.519 sec/step, loss=0.08606, avg_loss=0.08429]
[2018-11-21 15:01:34.310]  Step 250972  [21.537 sec/step, loss=0.08470, avg_loss=0.08427]
[2018-11-21 15:01:58.223]  Step 250973  [21.619 sec/step, loss=0.08580, avg_loss=0.08431]
[2018-11-21 15:02:15.398]  Step 250974  [21.576 sec/step, loss=0.08205, avg_loss=0.08426]
[2018-11-21 15:02:42.642]  Step 250975  [21.670 sec/step, loss=0.08373, avg_loss=0.08424]
[2018-11-21 15:03:17.211]  Step 250976  [21.865 sec/step, loss=0.08595, avg_loss=0.08427]
[2018-11-21 15:03:48.993]  Step 250977  [21.952 sec/step, loss=0.08536, avg_loss=0.08427]
[2018-11-21 15:04:15.670]  Step 250978  [22.011 sec/step, loss=0.08509, avg_loss=0.08425]
[2018-11-21 15:04:39.511]  Step 250979  [22.061 sec/step, loss=0.08455, avg_loss=0.08424]
[2018-11-21 15:05:04.689]  Step 250980  [21.907 sec/step, loss=0.08514, avg_loss=0.08433]
[2018-11-21 15:05:38.922]  Step 250981  [22.158 sec/step, loss=0.08474, avg_loss=0.08454]
[2018-11-21 15:06:03.970]  Step 250982  [22.184 sec/step, loss=0.08588, avg_loss=0.08454]
[2018-11-21 15:06:23.144]  Step 250983  [22.154 sec/step, loss=0.08443, avg_loss=0.08451]
[2018-11-21 15:06:49.239]  Step 250984  [22.150 sec/step, loss=0.08484, avg_loss=0.08450]
[2018-11-21 15:07:10.444]  Step 250985  [22.114 sec/step, loss=0.08520, avg_loss=0.08449]
[2018-11-21 15:07:34.738]  Step 250986  [22.123 sec/step, loss=0.08659, avg_loss=0.08449]
[2018-11-21 15:08:14.877]  Step 250987  [22.347 sec/step, loss=0.07528, avg_loss=0.08440]
[2018-11-21 15:08:38.145]  Step 250988  [22.428 sec/step, loss=0.08584, avg_loss=0.08443]
[2018-11-21 15:08:56.710]  Step 250989  [22.394 sec/step, loss=0.08388, avg_loss=0.08441]
[2018-11-21 15:09:15.849]  Step 250990  [22.381 sec/step, loss=0.08513, avg_loss=0.08440]
[2018-11-21 15:09:35.773]  Step 250991  [22.361 sec/step, loss=0.08467, avg_loss=0.08438]
[2018-11-21 15:10:01.580]  Step 250992  [22.410 sec/step, loss=0.08525, avg_loss=0.08436]
[2018-11-21 15:10:29.433]  Step 250993  [22.442 sec/step, loss=0.08543, avg_loss=0.08434]
[2018-11-21 15:10:54.847]  Step 250994  [22.521 sec/step, loss=0.08528, avg_loss=0.08433]
[2018-11-21 15:11:07.054]  Step 250995  [22.456 sec/step, loss=0.07743, avg_loss=0.08425]
[2018-11-21 15:11:21.116]  Generated 32 batches of size 32 in 12.982 sec
[2018-11-21 15:11:41.202]  Step 250996  [22.593 sec/step, loss=0.08636, avg_loss=0.08425]
[2018-11-21 15:12:03.288]  Step 250997  [22.709 sec/step, loss=0.08488, avg_loss=0.08432]
[2018-11-21 15:12:14.011]  Step 250998  [22.574 sec/step, loss=0.06506, avg_loss=0.08409]
[2018-11-21 15:12:32.537]  Step 250999  [22.599 sec/step, loss=0.08117, avg_loss=0.08408]
[2018-11-21 15:13:00.218]  Step 251000  [22.753 sec/step, loss=0.08577, avg_loss=0.08412]
[2018-11-21 15:13:00.218]  Writing summary at step: 251000
[2018-11-21 15:13:31.588]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-251000
[2018-11-21 15:13:39.251]  Saving audio and alignment...
[2018-11-21 15:14:01.451]  Input: habitually {OW0 B IY1 D IY0 AH0 N T} to john, {AY1} {K EY1 M} up to his chair: {HH IY1} {S P EH1 N T} {S AH1 M} {TH R IY1} minutes in thrusting {AW1 T} his {T AH1 NG} {AE1 T} me as {F AA1 R} as {HH IY1} {K UH1 D} without {D AE1 M IH0 JH IH0 NG} the roots: {AY1} knew {HH IY1} would {S UW1 N} strike, and while dreading the blow,~___________________
[2018-11-21 15:14:17.502]  Step 251001  [22.741 sec/step, loss=0.08224, avg_loss=0.08412]
[2018-11-21 15:14:31.262]  Step 251002  [22.623 sec/step, loss=0.08080, avg_loss=0.08405]
[2018-11-21 15:14:50.145]  Step 251003  [22.574 sec/step, loss=0.08122, avg_loss=0.08400]
[2018-11-21 15:15:26.293]  Step 251004  [22.700 sec/step, loss=0.08620, avg_loss=0.08398]
[2018-11-21 15:16:00.137]  Step 251005  [22.822 sec/step, loss=0.08539, avg_loss=0.08397]
[2018-11-21 15:16:28.244]  Step 251006  [22.909 sec/step, loss=0.08526, avg_loss=0.08396]
[2018-11-21 15:16:46.143]  Step 251007  [22.847 sec/step, loss=0.08176, avg_loss=0.08392]
[2018-11-21 15:17:10.638]  Step 251008  [22.870 sec/step, loss=0.08423, avg_loss=0.08389]
[2018-11-21 15:17:44.020]  Step 251009  [23.005 sec/step, loss=0.08526, avg_loss=0.08389]
[2018-11-21 15:18:13.289]  Step 251010  [23.067 sec/step, loss=0.08566, avg_loss=0.08389]
[2018-11-21 15:18:39.927]  Step 251011  [23.096 sec/step, loss=0.08480, avg_loss=0.08388]
[2018-11-21 15:19:09.681]  Step 251012  [23.151 sec/step, loss=0.08502, avg_loss=0.08387]
[2018-11-21 15:19:21.291]  Step 251013  [23.048 sec/step, loss=0.07753, avg_loss=0.08378]
[2018-11-21 15:19:43.310]  Step 251014  [23.056 sec/step, loss=0.08405, avg_loss=0.08376]
[2018-11-21 15:19:59.588]  Step 251015  [23.032 sec/step, loss=0.07971, avg_loss=0.08371]
[2018-11-21 15:20:31.273]  Step 251016  [23.090 sec/step, loss=0.08492, avg_loss=0.08369]
[2018-11-21 15:20:59.442]  Step 251017  [23.250 sec/step, loss=0.08451, avg_loss=0.08373]
[2018-11-21 15:21:29.940]  Step 251018  [23.293 sec/step, loss=0.08463, avg_loss=0.08372]
[2018-11-21 15:21:56.983]  Step 251019  [23.377 sec/step, loss=0.08537, avg_loss=0.08371]
[2018-11-21 15:22:24.476]  Step 251020  [23.460 sec/step, loss=0.08591, avg_loss=0.08371]
[2018-11-21 15:22:46.889]  Step 251021  [23.473 sec/step, loss=0.08534, avg_loss=0.08370]
[2018-11-21 15:23:11.010]  Step 251022  [23.572 sec/step, loss=0.08465, avg_loss=0.08372]
[2018-11-21 15:23:38.626]  Step 251023  [23.651 sec/step, loss=0.08591, avg_loss=0.08374]
[2018-11-21 15:23:59.748]  Step 251024  [23.660 sec/step, loss=0.08429, avg_loss=0.08373]
[2018-11-21 15:24:22.538]  Step 251025  [23.662 sec/step, loss=0.08467, avg_loss=0.08371]
[2018-11-21 15:24:32.886]  Generated 32 batches of size 32 in 9.438 sec
[2018-11-21 15:24:40.471]  Step 251026  [23.686 sec/step, loss=0.08282, avg_loss=0.08370]
[2018-11-21 15:25:03.440]  Step 251027  [23.711 sec/step, loss=0.08600, avg_loss=0.08371]
[2018-11-21 15:25:12.421]  Step 251028  [23.638 sec/step, loss=0.06409, avg_loss=0.08353]
[2018-11-21 15:25:59.258]  Step 251029  [23.861 sec/step, loss=0.07520, avg_loss=0.08342]
[2018-11-21 15:26:42.138]  Step 251030  [24.106 sec/step, loss=0.08573, avg_loss=0.08344]
[2018-11-21 15:27:15.445]  Step 251031  [24.172 sec/step, loss=0.08664, avg_loss=0.08345]
[2018-11-21 15:27:38.332]  Step 251032  [24.083 sec/step, loss=0.08360, avg_loss=0.08341]
[2018-11-21 15:28:03.586]  Step 251033  [24.027 sec/step, loss=0.08644, avg_loss=0.08341]
[2018-11-21 15:28:21.686]  Step 251034  [24.111 sec/step, loss=0.08345, avg_loss=0.08357]
[2018-11-21 15:28:46.521]  Step 251035  [24.088 sec/step, loss=0.08575, avg_loss=0.08357]
[2018-11-21 15:29:00.669]  Step 251036  [24.004 sec/step, loss=0.08153, avg_loss=0.08354]
[2018-11-21 15:29:08.282]  Step 251037  [23.973 sec/step, loss=0.06620, avg_loss=0.08342]
[2018-11-21 15:29:33.841]  Step 251038  [23.968 sec/step, loss=0.08469, avg_loss=0.08340]
[2018-11-21 15:29:54.753]  Step 251039  [23.986 sec/step, loss=0.08445, avg_loss=0.08339]
[2018-11-21 16:00:55.231]  Step 251040  [42.354 sec/step, loss=0.08516, avg_loss=0.08339]
[2018-11-22 09:37:34.195]  Step 251041  [675.877 sec/step, loss=0.07486, avg_loss=0.08338]
[2018-11-22 09:37:56.760]  Step 251042  [675.884 sec/step, loss=0.08407, avg_loss=0.08337]
[2018-11-22 09:38:10.255]  Step 251043  [675.899 sec/step, loss=0.08029, avg_loss=0.08341]
[2018-11-22 09:38:39.416]  Step 251044  [676.016 sec/step, loss=0.08500, avg_loss=0.08346]
[2018-11-22 09:39:18.803]  Step 251045  [676.160 sec/step, loss=0.08438, avg_loss=0.08343]
[2018-11-22 09:40:06.014]  Step 251046  [676.383 sec/step, loss=0.08582, avg_loss=0.08344]
[2018-11-22 09:40:56.143]  Step 251047  [676.686 sec/step, loss=0.08486, avg_loss=0.08345]
[2018-11-22 09:41:30.839]  Step 251048  [676.803 sec/step, loss=0.08523, avg_loss=0.08344]
[2018-11-22 09:42:00.182]  Step 251049  [676.811 sec/step, loss=0.08317, avg_loss=0.08342]
[2018-11-22 09:42:26.517]  Step 251050  [676.873 sec/step, loss=0.08292, avg_loss=0.08340]
[2018-11-22 09:42:26.518]  Writing summary at step: 251050
[2018-11-22 09:43:32.589]  Step 251051  [676.937 sec/step, loss=0.08395, avg_loss=0.08339]
[2018-11-22 09:43:59.901]  Step 251052  [676.984 sec/step, loss=0.08425, avg_loss=0.08337]
[2018-11-22 09:44:44.527]  Step 251053  [677.207 sec/step, loss=0.08616, avg_loss=0.08338]
[2018-11-22 09:45:08.622]  Step 251054  [677.326 sec/step, loss=0.07491, avg_loss=0.08331]
[2018-11-22 09:46:08.272]  Step 251055  [677.687 sec/step, loss=0.08477, avg_loss=0.08330]
[2018-11-22 09:46:38.999]  Step 251056  [677.769 sec/step, loss=0.08194, avg_loss=0.08327]
[2018-11-22 09:47:01.076]  Generated 32 batches of size 32 in 20.734 sec
[2018-11-22 09:47:32.496]  Step 251057  [678.045 sec/step, loss=0.08514, avg_loss=0.08327]
[2018-11-22 09:48:23.265]  Step 251058  [678.318 sec/step, loss=0.08567, avg_loss=0.08326]
[2018-11-22 09:49:08.222]  Step 251059  [678.622 sec/step, loss=0.08485, avg_loss=0.08329]
[2018-11-22 09:49:47.945]  Step 251060  [678.769 sec/step, loss=0.08512, avg_loss=0.08328]
[2018-11-22 09:50:26.861]  Step 251061  [678.916 sec/step, loss=0.08424, avg_loss=0.08325]
[2018-11-22 09:51:02.121]  Step 251062  [679.098 sec/step, loss=0.08443, avg_loss=0.08327]
[2018-11-22 09:51:29.588]  Step 251063  [679.193 sec/step, loss=0.08092, avg_loss=0.08322]
[2018-11-22 09:52:15.979]  Step 251064  [679.363 sec/step, loss=0.08375, avg_loss=0.08320]
[2018-11-22 09:52:58.735]  Step 251065  [679.709 sec/step, loss=0.08545, avg_loss=0.08339]
[2018-11-22 09:54:31.158]  Step 251066  [680.371 sec/step, loss=0.08359, avg_loss=0.08336]
[2018-11-22 09:54:57.480]  Step 251067  [680.423 sec/step, loss=0.07596, avg_loss=0.08327]
[2018-11-22 09:55:49.091]  Step 251068  [680.708 sec/step, loss=0.08467, avg_loss=0.08326]
[2018-11-22 09:56:37.329]  Step 251069  [680.938 sec/step, loss=0.08626, avg_loss=0.08326]
[2018-11-22 09:57:20.930]  Step 251070  [680.979 sec/step, loss=0.08500, avg_loss=0.08334]
[2018-11-22 09:57:43.349]  Step 251071  [680.952 sec/step, loss=0.08360, avg_loss=0.08332]
[2018-11-22 09:58:11.571]  Step 251072  [680.973 sec/step, loss=0.08325, avg_loss=0.08330]
[2018-11-22 09:58:38.501]  Step 251073  [681.003 sec/step, loss=0.08365, avg_loss=0.08328]
[2018-11-22 09:59:08.832]  Step 251074  [681.135 sec/step, loss=0.08395, avg_loss=0.08330]
[2018-11-22 09:59:44.803]  Step 251075  [681.222 sec/step, loss=0.08495, avg_loss=0.08331]
[2018-11-22 10:00:14.332]  Step 251076  [681.172 sec/step, loss=0.08426, avg_loss=0.08330]
[2018-11-22 10:00:37.903]  Step 251077  [681.089 sec/step, loss=0.08370, avg_loss=0.08328]
[2018-11-22 10:01:08.719]  Step 251078  [681.131 sec/step, loss=0.08444, avg_loss=0.08327]
[2018-11-22 10:01:38.731]  Step 251079  [681.192 sec/step, loss=0.08472, avg_loss=0.08327]
[2018-11-22 10:02:09.562]  Step 251080  [681.249 sec/step, loss=0.08514, avg_loss=0.08327]
[2018-11-22 10:02:41.588]  Step 251081  [681.227 sec/step, loss=0.08509, avg_loss=0.08328]
[2018-11-22 10:03:13.328]  Step 251082  [681.294 sec/step, loss=0.08509, avg_loss=0.08327]
[2018-11-22 10:03:38.910]  Step 251083  [681.358 sec/step, loss=0.08458, avg_loss=0.08327]
[2018-11-22 10:04:08.577]  Step 251084  [681.394 sec/step, loss=0.08510, avg_loss=0.08327]
[2018-11-22 10:04:28.909]  Step 251085  [681.385 sec/step, loss=0.08325, avg_loss=0.08326]
[2018-11-22 10:04:47.188]  Step 251086  [681.325 sec/step, loss=0.08115, avg_loss=0.08320]
[2018-11-22 10:05:05.330]  Step 251087  [681.105 sec/step, loss=0.07974, avg_loss=0.08325]
[2018-11-22 10:05:15.354]  Step 251088  [680.972 sec/step, loss=0.06282, avg_loss=0.08301]
[2018-11-22 10:05:30.201]  Generated 32 batches of size 32 in 13.701 sec
[2018-11-22 10:05:45.164]  Step 251089  [681.085 sec/step, loss=0.08487, avg_loss=0.08302]
[2018-11-22 10:06:23.125]  Step 251090  [681.273 sec/step, loss=0.08552, avg_loss=0.08303]
[2018-11-22 10:06:56.402]  Step 251091  [681.407 sec/step, loss=0.08603, avg_loss=0.08304]
[2018-11-22 10:07:30.683]  Step 251092  [681.491 sec/step, loss=0.08507, avg_loss=0.08304]
[2018-11-22 10:07:30.687]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-251092 (requested by user)
[2018-11-22 10:08:03.345]  Step 251093  [681.502 sec/step, loss=0.08412, avg_loss=0.08303]
[2018-11-22 10:08:21.959]  Step 251094  [681.434 sec/step, loss=0.08200, avg_loss=0.08299]
[2018-11-22 10:08:37.435]  Step 251095  [681.466 sec/step, loss=0.07991, avg_loss=0.08302]
[2018-11-22 10:09:32.146]  Step 251096  [681.672 sec/step, loss=0.07550, avg_loss=0.08291]
[2018-11-22 10:09:58.661]  Step 251097  [681.716 sec/step, loss=0.08418, avg_loss=0.08290]
[2018-11-22 10:10:13.966]  Step 251098  [681.762 sec/step, loss=0.07988, avg_loss=0.08305]
[2018-11-22 10:10:47.690]  Step 251099  [681.914 sec/step, loss=0.08322, avg_loss=0.08307]
[2018-11-22 10:11:11.620]  Step 251100  [681.877 sec/step, loss=0.08143, avg_loss=0.08303]
[2018-11-22 10:11:11.620]  Writing summary at step: 251100
[2018-11-22 10:12:05.839]  Step 251101  [681.938 sec/step, loss=0.08408, avg_loss=0.08305]
[2018-11-22 10:12:27.993]  Step 251102  [682.022 sec/step, loss=0.08243, avg_loss=0.08306]
[2018-11-22 10:12:46.036]  Step 251103  [682.014 sec/step, loss=0.08108, avg_loss=0.08306]
[2018-11-22 10:13:15.741]  Step 251104  [681.950 sec/step, loss=0.08359, avg_loss=0.08304]
[2018-11-22 10:13:58.391]  Step 251105  [682.038 sec/step, loss=0.08441, avg_loss=0.08303]
[2018-11-22 10:14:29.761]  Step 251106  [682.070 sec/step, loss=0.08519, avg_loss=0.08303]
[2018-11-22 10:14:52.254]  Step 251107  [682.116 sec/step, loss=0.08405, avg_loss=0.08305]
[2018-11-22 10:14:52.255]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-251107 (requested by user)
[2018-11-22 10:15:22.818]  Step 251108  [682.136 sec/step, loss=0.08462, avg_loss=0.08305]
[2018-11-22 10:15:54.176]  Step 251109  [682.116 sec/step, loss=0.08533, avg_loss=0.08305]
[2018-11-22 10:16:32.755]  Step 251110  [682.209 sec/step, loss=0.08440, avg_loss=0.08304]
[2018-11-22 10:17:02.247]  Step 251111  [682.238 sec/step, loss=0.08449, avg_loss=0.08304]
[2018-11-22 10:17:26.067]  Step 251112  [682.178 sec/step, loss=0.08309, avg_loss=0.08302]
[2018-11-22 10:17:38.463]  Step 251113  [682.186 sec/step, loss=0.07632, avg_loss=0.08301]
[2018-11-22 10:17:58.718]  Step 251114  [682.168 sec/step, loss=0.08375, avg_loss=0.08300]
[2018-11-22 10:18:24.165]  Step 251115  [682.260 sec/step, loss=0.08351, avg_loss=0.08304]
[2018-11-22 10:18:41.231]  Step 251116  [682.114 sec/step, loss=0.07990, avg_loss=0.08299]
[2018-11-22 10:19:31.025]  Step 251117  [682.330 sec/step, loss=0.07480, avg_loss=0.08289]
[2018-11-22 10:20:00.352]  Step 251118  [682.318 sec/step, loss=0.08486, avg_loss=0.08290]
[2018-11-22 10:20:32.292]  Step 251119  [682.367 sec/step, loss=0.08545, avg_loss=0.08290]
[2018-11-22 10:20:46.091]  Generated 32 batches of size 32 in 13.035 sec
[2018-11-22 10:21:06.176]  Step 251120  [682.431 sec/step, loss=0.08424, avg_loss=0.08288]
[2018-11-22 10:21:33.881]  Step 251121  [682.484 sec/step, loss=0.08431, avg_loss=0.08287]
[2018-11-22 10:22:01.133]  Step 251122  [682.516 sec/step, loss=0.08475, avg_loss=0.08287]
[2018-11-22 10:22:10.502]  Step 251123  [682.333 sec/step, loss=0.06434, avg_loss=0.08266]
[2018-11-22 10:22:36.498]  Step 251124  [682.382 sec/step, loss=0.08493, avg_loss=0.08266]
[2018-11-22 10:23:02.859]  Step 251125  [682.418 sec/step, loss=0.08449, avg_loss=0.08266]

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2018-11-22 10:38:03.767]  Devices available to tensorflow: [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 10107014249177203728
]
[2018-11-22 10:38:03.767]  Checkpoint path: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt
[2018-11-22 10:38:03.767]  Loading training data from: /Users/Aaron/Desktop/Code/tacotron/training/train.txt
[2018-11-22 10:38:03.767]  Using model: tacotron
[2018-11-22 10:38:03.767]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: english_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: True
[2018-11-22 10:38:03.771]  Loaded metadata for 398 examples (1.06 hours)
[2018-11-22 10:38:04.613]  Loaded CMUDict with 116869 unambiguous entries
[2018-11-22 10:38:09.574]  Initialized Tacotron model. Dimensions: 
[2018-11-22 10:38:09.575]    embedding:               256
[2018-11-22 10:38:09.575]    prenet out:              128
[2018-11-22 10:38:09.575]    encoder out:             256
[2018-11-22 10:38:09.575]    attention out:           256
[2018-11-22 10:38:09.575]    concat attn & out:       512
[2018-11-22 10:38:09.575]    decoder cell out:        256
[2018-11-22 10:38:09.575]    decoder out (5 frames):  400
[2018-11-22 10:38:09.575]    decoder out (1 frame):   80
[2018-11-22 10:38:09.575]    postnet out:             256
[2018-11-22 10:38:09.576]    linear out:              1025
[2018-11-22 10:38:26.079]  Resuming from checkpoint: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-251107 at commit: None
[2018-11-22 10:38:31.522]  Generated 32 batches of size 32 in 5.443 sec
[2018-11-22 10:38:49.705]  Step 251108  [23.625 sec/step, loss=0.07512, avg_loss=0.07512]
[2018-11-22 10:38:59.384]  Step 251109  [16.652 sec/step, loss=0.06145, avg_loss=0.06828]
[2018-11-22 10:39:29.924]  Step 251110  [21.281 sec/step, loss=0.08472, avg_loss=0.07376]
[2018-11-22 10:39:48.599]  Step 251111  [20.630 sec/step, loss=0.07961, avg_loss=0.07522]
[2018-11-22 10:40:02.235]  Step 251112  [19.231 sec/step, loss=0.07928, avg_loss=0.07603]
[2018-11-22 10:40:21.318]  Step 251113  [19.206 sec/step, loss=0.08101, avg_loss=0.07686]
[2018-11-22 10:40:49.814]  Step 251114  [20.533 sec/step, loss=0.08502, avg_loss=0.07803]
[2018-11-22 10:41:15.484]  Step 251115  [21.175 sec/step, loss=0.08471, avg_loss=0.07886]
[2018-11-22 10:41:41.741]  Step 251116  [21.740 sec/step, loss=0.08353, avg_loss=0.07938]
[2018-11-22 10:42:28.515]  Step 251117  [24.243 sec/step, loss=0.07447, avg_loss=0.07889]
[2018-11-22 10:42:54.584]  Step 251118  [24.409 sec/step, loss=0.08560, avg_loss=0.07950]
[2018-11-22 10:43:09.977]  Step 251119  [23.658 sec/step, loss=0.08107, avg_loss=0.07963]
[2018-11-22 10:43:34.966]  Step 251120  [23.760 sec/step, loss=0.08380, avg_loss=0.07995]
[2018-11-22 10:44:05.514]  Step 251121  [24.245 sec/step, loss=0.08477, avg_loss=0.08030]
[2018-11-22 10:44:28.492]  Step 251122  [24.161 sec/step, loss=0.08365, avg_loss=0.08052]
[2018-11-22 10:44:48.806]  Step 251123  [23.920 sec/step, loss=0.08400, avg_loss=0.08074]
[2018-11-22 10:45:14.267]  Step 251124  [24.011 sec/step, loss=0.08435, avg_loss=0.08095]
[2018-11-22 10:45:41.405]  Step 251125  [24.184 sec/step, loss=0.08202, avg_loss=0.08101]
[2018-11-22 10:46:07.227]  Step 251126  [24.270 sec/step, loss=0.08281, avg_loss=0.08110]
[2018-11-22 10:46:32.807]  Step 251127  [24.336 sec/step, loss=0.08550, avg_loss=0.08132]
[2018-11-22 10:47:00.800]  Step 251128  [24.510 sec/step, loss=0.08422, avg_loss=0.08146]
[2018-11-22 10:47:29.561]  Step 251129  [24.703 sec/step, loss=0.08446, avg_loss=0.08160]
[2018-11-22 10:47:57.165]  Step 251130  [24.829 sec/step, loss=0.08525, avg_loss=0.08176]
[2018-11-22 10:48:09.431]  Generated 32 batches of size 32 in 11.093 sec
[2018-11-22 10:48:22.409]  Step 251131  [24.847 sec/step, loss=0.08389, avg_loss=0.08185]
[2018-11-22 10:48:42.362]  Step 251132  [24.651 sec/step, loss=0.08405, avg_loss=0.08193]
[2018-11-22 10:49:07.940]  Step 251133  [24.686 sec/step, loss=0.08482, avg_loss=0.08204]
[2018-11-22 10:49:41.391]  Step 251134  [25.011 sec/step, loss=0.08375, avg_loss=0.08211]
[2018-11-22 10:50:08.293]  Step 251135  [25.079 sec/step, loss=0.08582, avg_loss=0.08224]
[2018-11-22 10:50:37.958]  Step 251136  [25.237 sec/step, loss=0.08562, avg_loss=0.08236]
[2018-11-22 10:51:07.200]  Step 251137  [25.370 sec/step, loss=0.08437, avg_loss=0.08242]
[2018-11-22 10:51:30.833]  Step 251138  [25.314 sec/step, loss=0.08383, avg_loss=0.08247]
[2018-11-22 10:52:00.143]  Step 251139  [25.439 sec/step, loss=0.08474, avg_loss=0.08254]
[2018-11-22 10:52:30.035]  Step 251140  [25.574 sec/step, loss=0.08439, avg_loss=0.08260]
[2018-11-22 10:52:50.591]  Step 251141  [25.426 sec/step, loss=0.08081, avg_loss=0.08254]
[2018-11-22 10:53:14.206]  Step 251142  [25.375 sec/step, loss=0.08267, avg_loss=0.08255]
[2018-11-22 10:53:39.474]  Step 251143  [25.372 sec/step, loss=0.08407, avg_loss=0.08259]
[2018-11-22 10:54:09.691]  Step 251144  [25.503 sec/step, loss=0.08556, avg_loss=0.08267]
[2018-11-22 10:54:28.373]  Step 251145  [25.323 sec/step, loss=0.08055, avg_loss=0.08261]
[2018-11-22 10:55:02.439]  Step 251146  [25.547 sec/step, loss=0.08476, avg_loss=0.08267]
[2018-11-22 10:55:26.624]  Step 251147  [25.513 sec/step, loss=0.08300, avg_loss=0.08268]
[2018-11-22 10:55:53.190]  Step 251148  [25.539 sec/step, loss=0.08359, avg_loss=0.08270]
[2018-11-22 10:56:21.051]  Step 251149  [25.594 sec/step, loss=0.08343, avg_loss=0.08272]
[2018-11-22 10:56:56.106]  Step 251150  [25.814 sec/step, loss=0.08422, avg_loss=0.08275]
[2018-11-22 10:56:56.106]  Writing summary at step: 251150
[2018-11-22 10:57:58.138]  Step 251151  [25.831 sec/step, loss=0.08325, avg_loss=0.08276]
[2018-11-22 10:58:28.196]  Step 251152  [25.925 sec/step, loss=0.08331, avg_loss=0.08277]
[2018-11-22 10:59:09.272]  Step 251153  [26.254 sec/step, loss=0.08494, avg_loss=0.08282]
[2018-11-22 10:59:31.357]  Step 251154  [26.165 sec/step, loss=0.08317, avg_loss=0.08283]
[2018-11-22 11:00:28.884]  Step 251155  [26.819 sec/step, loss=0.07525, avg_loss=0.08267]
[2018-11-22 11:00:45.398]  Step 251156  [26.608 sec/step, loss=0.07949, avg_loss=0.08261]
[2018-11-22 11:01:15.246]  Step 251157  [26.673 sec/step, loss=0.08436, avg_loss=0.08264]
[2018-11-22 11:01:47.629]  Step 251158  [26.785 sec/step, loss=0.08446, avg_loss=0.08268]
[2018-11-22 11:02:13.145]  Step 251159  [26.761 sec/step, loss=0.08417, avg_loss=0.08271]
[2018-11-22 11:02:47.328]  Step 251160  [26.901 sec/step, loss=0.08347, avg_loss=0.08272]
[2018-11-22 11:03:19.789]  Step 251161  [27.004 sec/step, loss=0.08356, avg_loss=0.08274]
[2018-11-22 11:03:36.520]  Generated 32 batches of size 32 in 15.023 sec
[2018-11-22 11:03:37.953]  Step 251162  [26.843 sec/step, loss=0.06266, avg_loss=0.08237]
[2018-11-22 11:03:50.548]  Step 251163  [26.589 sec/step, loss=0.07606, avg_loss=0.08226]
[2018-11-22 11:04:09.200]  Step 251164  [26.449 sec/step, loss=0.08247, avg_loss=0.08226]
[2018-11-22 11:04:28.309]  Step 251165  [26.323 sec/step, loss=0.08391, avg_loss=0.08229]
[2018-11-22 11:04:52.314]  Step 251166  [26.283 sec/step, loss=0.08507, avg_loss=0.08234]
[2018-11-22 11:05:16.730]  Step 251167  [26.252 sec/step, loss=0.08301, avg_loss=0.08235]
[2018-11-22 11:05:37.664]  Step 251168  [26.165 sec/step, loss=0.08042, avg_loss=0.08232]
[2018-11-22 11:06:05.560]  Step 251169  [26.193 sec/step, loss=0.08536, avg_loss=0.08237]
[2018-11-22 11:06:29.070]  Step 251170  [26.150 sec/step, loss=0.08519, avg_loss=0.08241]
[2018-11-22 11:06:58.095]  Step 251171  [26.195 sec/step, loss=0.08375, avg_loss=0.08243]
[2018-11-22 11:07:24.261]  Step 251172  [26.195 sec/step, loss=0.08410, avg_loss=0.08246]
[2018-11-22 11:07:48.070]  Step 251173  [26.159 sec/step, loss=0.08331, avg_loss=0.08247]
[2018-11-22 11:08:08.491]  Step 251174  [26.073 sec/step, loss=0.08329, avg_loss=0.08248]
[2018-11-22 11:08:33.864]  Step 251175  [26.063 sec/step, loss=0.08357, avg_loss=0.08250]
[2018-11-22 11:08:54.608]  Step 251176  [25.986 sec/step, loss=0.08371, avg_loss=0.08252]
[2018-11-22 11:09:17.689]  Step 251177  [25.944 sec/step, loss=0.08404, avg_loss=0.08254]
[2018-11-22 11:09:59.275]  Step 251178  [26.164 sec/step, loss=0.07426, avg_loss=0.08242]
[2018-11-22 11:10:24.150]  Step 251179  [26.146 sec/step, loss=0.08329, avg_loss=0.08243]
[2018-11-22 11:10:38.860]  Step 251180  [25.990 sec/step, loss=0.08042, avg_loss=0.08241]
[2018-11-22 11:11:05.670]  Step 251181  [26.001 sec/step, loss=0.08500, avg_loss=0.08244]
[2018-11-22 11:11:32.461]  Step 251182  [26.011 sec/step, loss=0.08353, avg_loss=0.08246]
[2018-11-22 11:11:55.844]  Step 251183  [25.977 sec/step, loss=0.08429, avg_loss=0.08248]
[2018-11-22 11:12:20.570]  Step 251184  [25.961 sec/step, loss=0.08490, avg_loss=0.08251]
[2018-11-22 11:12:43.909]  Step 251185  [25.927 sec/step, loss=0.08440, avg_loss=0.08254]
[2018-11-22 11:13:08.795]  Step 251186  [25.914 sec/step, loss=0.08424, avg_loss=0.08256]
[2018-11-22 11:13:21.737]  Step 251187  [25.752 sec/step, loss=0.07869, avg_loss=0.08251]
[2018-11-22 11:13:41.169]  Step 251188  [25.674 sec/step, loss=0.08290, avg_loss=0.08251]
[2018-11-22 11:14:02.404]  Step 251189  [25.619 sec/step, loss=0.08371, avg_loss=0.08253]
[2018-11-22 11:14:22.696]  Step 251190  [25.555 sec/step, loss=0.08332, avg_loss=0.08254]
[2018-11-22 11:14:40.909]  Step 251191  [25.468 sec/step, loss=0.08252, avg_loss=0.08254]
[2018-11-22 11:15:03.090]  Step 251192  [25.429 sec/step, loss=0.08390, avg_loss=0.08255]
[2018-11-22 11:15:12.349]  Step 251193  [25.241 sec/step, loss=0.06521, avg_loss=0.08235]
[2018-11-22 11:15:22.570]  Generated 32 batches of size 32 in 9.015 sec
[2018-11-22 11:15:31.587]  Step 251194  [25.172 sec/step, loss=0.08294, avg_loss=0.08236]
[2018-11-22 11:15:56.064]  Step 251195  [25.164 sec/step, loss=0.08453, avg_loss=0.08238]
[2018-11-22 11:16:21.667]  Step 251196  [25.169 sec/step, loss=0.08477, avg_loss=0.08241]
[2018-11-22 11:16:40.993]  Step 251197  [25.104 sec/step, loss=0.08321, avg_loss=0.08242]
[2018-11-22 11:16:56.907]  Step 251198  [25.003 sec/step, loss=0.07969, avg_loss=0.08239]
[2018-11-22 11:17:07.462]  Step 251199  [24.846 sec/step, loss=0.07505, avg_loss=0.08231]
[2018-11-22 11:17:31.714]  Step 251200  [24.840 sec/step, loss=0.08369, avg_loss=0.08232]
[2018-11-22 11:17:31.714]  Writing summary at step: 251200
[2018-11-22 11:18:09.482]  Step 251201  [24.804 sec/step, loss=0.08529, avg_loss=0.08236]
[2018-11-22 11:18:18.586]  Step 251202  [24.638 sec/step, loss=0.06177, avg_loss=0.08214]
[2018-11-22 11:18:40.830]  Step 251203  [24.613 sec/step, loss=0.08426, avg_loss=0.08216]
[2018-11-22 11:19:06.644]  Step 251204  [24.626 sec/step, loss=0.08383, avg_loss=0.08218]
[2018-11-22 11:19:26.289]  Step 251205  [24.575 sec/step, loss=0.08224, avg_loss=0.08218]
[2018-11-22 11:19:42.831]  Step 251206  [24.494 sec/step, loss=0.08162, avg_loss=0.08217]
[2018-11-22 11:20:05.757]  Step 251207  [24.478 sec/step, loss=0.08442, avg_loss=0.08220]
[2018-11-22 11:20:30.360]  Step 251208  [24.488 sec/step, loss=0.08455, avg_loss=0.08229]
[2018-11-22 11:20:56.334]  Step 251209  [24.651 sec/step, loss=0.08321, avg_loss=0.08251]
[2018-11-22 11:21:21.677]  Step 251210  [24.599 sec/step, loss=0.08468, avg_loss=0.08251]
[2018-11-22 11:21:44.799]  Step 251211  [24.643 sec/step, loss=0.08317, avg_loss=0.08254]
[2018-11-22 11:22:04.029]  Step 251212  [24.699 sec/step, loss=0.08393, avg_loss=0.08259]
[2018-11-22 11:22:25.535]  Step 251213  [24.723 sec/step, loss=0.08459, avg_loss=0.08262]
[2018-11-22 11:22:48.061]  Step 251214  [24.664 sec/step, loss=0.08361, avg_loss=0.08261]
[2018-11-22 11:23:09.971]  Step 251215  [24.626 sec/step, loss=0.08330, avg_loss=0.08260]
[2018-11-22 11:23:27.356]  Step 251216  [24.537 sec/step, loss=0.08283, avg_loss=0.08259]
[2018-11-22 11:23:47.537]  Step 251217  [24.271 sec/step, loss=0.08250, avg_loss=0.08267]
[2018-11-22 11:24:11.732]  Step 251218  [24.253 sec/step, loss=0.08355, avg_loss=0.08265]
[2018-11-22 11:24:34.291]  Step 251219  [24.324 sec/step, loss=0.08444, avg_loss=0.08268]
[2018-11-22 11:24:47.208]  Step 251220  [24.204 sec/step, loss=0.07888, avg_loss=0.08263]
[2018-11-22 11:25:11.403]  Step 251221  [24.140 sec/step, loss=0.08505, avg_loss=0.08264]
[2018-11-22 11:25:29.462]  Step 251222  [24.091 sec/step, loss=0.08207, avg_loss=0.08262]
[2018-11-22 11:26:14.503]  Step 251223  [24.338 sec/step, loss=0.07500, avg_loss=0.08253]
[2018-11-22 11:26:37.040]  Step 251224  [24.309 sec/step, loss=0.08398, avg_loss=0.08253]
[2018-11-22 11:26:46.935]  Generated 32 batches of size 32 in 8.809 sec
[2018-11-22 11:26:54.711]  Step 251225  [24.214 sec/step, loss=0.08055, avg_loss=0.08251]
[2018-11-22 11:27:15.396]  Step 251226  [24.163 sec/step, loss=0.08233, avg_loss=0.08251]
[2018-11-22 11:27:34.641]  Step 251227  [24.100 sec/step, loss=0.08276, avg_loss=0.08248]
[2018-11-22 11:27:45.571]  Step 251228  [23.929 sec/step, loss=0.07521, avg_loss=0.08239]
[2018-11-22 11:28:10.806]  Step 251229  [23.894 sec/step, loss=0.08288, avg_loss=0.08237]
[2018-11-22 11:28:36.063]  Step 251230  [23.870 sec/step, loss=0.08408, avg_loss=0.08236]
[2018-11-22 11:29:02.525]  Step 251231  [23.882 sec/step, loss=0.08362, avg_loss=0.08236]
[2018-11-22 11:29:28.091]  Step 251232  [23.939 sec/step, loss=0.08496, avg_loss=0.08237]
[2018-11-22 11:29:42.364]  Step 251233  [23.826 sec/step, loss=0.08057, avg_loss=0.08233]
[2018-11-22 11:30:07.509]  Step 251234  [23.742 sec/step, loss=0.08317, avg_loss=0.08232]
[2018-11-22 11:30:27.404]  Step 251235  [23.672 sec/step, loss=0.08215, avg_loss=0.08228]
[2018-11-22 11:30:55.618]  Step 251236  [23.658 sec/step, loss=0.08332, avg_loss=0.08226]
[2018-11-22 11:31:19.378]  Step 251237  [23.603 sec/step, loss=0.08459, avg_loss=0.08226]
[2018-11-22 11:31:42.167]  Step 251238  [23.595 sec/step, loss=0.08320, avg_loss=0.08226]
[2018-11-22 11:31:54.251]  Step 251239  [23.422 sec/step, loss=0.07764, avg_loss=0.08219]
[2018-11-22 11:32:13.661]  Step 251240  [23.318 sec/step, loss=0.08238, avg_loss=0.08217]
[2018-11-22 11:32:52.043]  Step 251241  [23.496 sec/step, loss=0.07372, avg_loss=0.08210]
[2018-11-22 11:33:12.595]  Step 251242  [23.465 sec/step, loss=0.08288, avg_loss=0.08210]
[2018-11-22 11:33:32.696]  Step 251243  [23.414 sec/step, loss=0.08283, avg_loss=0.08209]
[2018-11-22 11:33:48.888]  Step 251244  [23.273 sec/step, loss=0.07904, avg_loss=0.08202]
[2018-11-22 11:34:13.491]  Step 251245  [23.332 sec/step, loss=0.08372, avg_loss=0.08205]
[2018-11-22 11:34:24.012]  Step 251246  [23.097 sec/step, loss=0.07297, avg_loss=0.08193]
[2018-11-22 11:34:48.748]  Step 251247  [23.103 sec/step, loss=0.08466, avg_loss=0.08195]
[2018-11-22 11:35:13.598]  Step 251248  [23.085 sec/step, loss=0.08483, avg_loss=0.08196]
[2018-11-22 11:35:36.891]  Step 251249  [23.040 sec/step, loss=0.08409, avg_loss=0.08197]
[2018-11-22 11:35:50.831]  Step 251250  [22.829 sec/step, loss=0.08019, avg_loss=0.08193]
[2018-11-22 11:35:50.831]  Writing summary at step: 251250
[2018-11-22 11:36:29.570]  Step 251251  [22.724 sec/step, loss=0.07993, avg_loss=0.08190]
[2018-11-22 11:36:53.459]  Step 251252  [22.663 sec/step, loss=0.08364, avg_loss=0.08190]
[2018-11-22 11:37:01.984]  Step 251253  [22.337 sec/step, loss=0.06385, avg_loss=0.08169]
[2018-11-22 11:37:21.193]  Step 251254  [22.309 sec/step, loss=0.08212, avg_loss=0.08168]
[2018-11-22 11:37:42.245]  Step 251255  [21.944 sec/step, loss=0.08314, avg_loss=0.08176]
[2018-11-22 11:37:54.834]  Generated 32 batches of size 32 in 11.701 sec
[2018-11-22 11:38:13.200]  Step 251256  [22.088 sec/step, loss=0.08363, avg_loss=0.08180]
[2018-11-22 11:38:30.272]  Step 251257  [21.960 sec/step, loss=0.08282, avg_loss=0.08178]
[2018-11-22 11:38:55.327]  Step 251258  [21.887 sec/step, loss=0.08348, avg_loss=0.08177]
[2018-11-22 11:39:17.319]  Step 251259  [21.852 sec/step, loss=0.08262, avg_loss=0.08176]
[2018-11-22 11:39:35.753]  Step 251260  [21.694 sec/step, loss=0.08282, avg_loss=0.08175]
[2018-11-22 11:39:53.782]  Step 251261  [21.550 sec/step, loss=0.08178, avg_loss=0.08173]
[2018-11-22 11:40:16.635]  Step 251262  [21.597 sec/step, loss=0.08399, avg_loss=0.08195]
[2018-11-22 11:40:39.485]  Step 251263  [21.700 sec/step, loss=0.08380, avg_loss=0.08202]
[2018-11-22 11:41:04.651]  Step 251264  [21.765 sec/step, loss=0.08402, avg_loss=0.08204]
[2018-11-22 11:41:13.449]  Step 251265  [21.662 sec/step, loss=0.06209, avg_loss=0.08182]
[2018-11-22 11:41:27.694]  Step 251266  [21.564 sec/step, loss=0.08037, avg_loss=0.08177]
[2018-11-22 11:41:40.605]  Step 251267  [21.449 sec/step, loss=0.07808, avg_loss=0.08172]
[2018-11-22 11:42:02.616]  Step 251268  [21.460 sec/step, loss=0.08254, avg_loss=0.08175]
[2018-11-22 11:42:22.369]  Step 251269  [21.378 sec/step, loss=0.08230, avg_loss=0.08172]
[2018-11-22 11:42:38.353]  Step 251270  [21.303 sec/step, loss=0.08041, avg_loss=0.08167]
[2018-11-22 11:42:56.804]  Step 251271  [21.197 sec/step, loss=0.08122, avg_loss=0.08164]
[2018-11-22 11:43:22.553]  Step 251272  [21.193 sec/step, loss=0.08454, avg_loss=0.08165]
[2018-11-22 11:43:44.542]  Step 251273  [21.175 sec/step, loss=0.08355, avg_loss=0.08165]
[2018-11-22 11:44:00.548]  Step 251274  [21.131 sec/step, loss=0.07964, avg_loss=0.08161]
[2018-11-22 11:44:20.290]  Step 251275  [21.075 sec/step, loss=0.08206, avg_loss=0.08160]
[2018-11-22 11:44:45.662]  Step 251276  [21.121 sec/step, loss=0.08364, avg_loss=0.08160]
[2018-11-22 11:45:10.244]  Step 251277  [21.136 sec/step, loss=0.08501, avg_loss=0.08161]
[2018-11-22 11:45:32.945]  Step 251278  [20.947 sec/step, loss=0.08356, avg_loss=0.08170]
[2018-11-22 11:45:53.807]  Step 251279  [20.907 sec/step, loss=0.08232, avg_loss=0.08169]
[2018-11-22 11:46:15.602]  Step 251280  [20.978 sec/step, loss=0.08361, avg_loss=0.08172]
[2018-11-22 11:46:41.140]  Step 251281  [20.965 sec/step, loss=0.08341, avg_loss=0.08171]
[2018-11-22 11:47:05.374]  Step 251282  [20.939 sec/step, loss=0.08333, avg_loss=0.08170]
[2018-11-22 11:47:24.159]  Step 251283  [20.893 sec/step, loss=0.08292, avg_loss=0.08169]
[2018-11-22 11:47:46.547]  Step 251284  [20.870 sec/step, loss=0.08360, avg_loss=0.08168]
[2018-11-22 11:48:06.730]  Step 251285  [20.839 sec/step, loss=0.08223, avg_loss=0.08166]
[2018-11-22 11:48:29.107]  Step 251286  [20.813 sec/step, loss=0.08480, avg_loss=0.08166]
[2018-11-22 11:48:46.332]  Step 251287  [20.856 sec/step, loss=0.08266, avg_loss=0.08170]
[2018-11-22 11:49:00.742]  Generated 32 batches of size 32 in 13.589 sec
[2018-11-22 11:49:30.444]  Step 251288  [21.103 sec/step, loss=0.07417, avg_loss=0.08161]
[2018-11-22 11:49:53.493]  Step 251289  [21.121 sec/step, loss=0.08342, avg_loss=0.08161]
[2018-11-22 11:50:04.053]  Step 251290  [21.024 sec/step, loss=0.07509, avg_loss=0.08153]
[2018-11-22 11:50:32.190]  Step 251291  [21.123 sec/step, loss=0.08246, avg_loss=0.08153]
[2018-11-22 11:50:57.926]  Step 251292  [21.159 sec/step, loss=0.08317, avg_loss=0.08152]
[2018-11-22 11:51:20.658]  Step 251293  [21.293 sec/step, loss=0.08277, avg_loss=0.08170]
[2018-11-22 11:51:45.332]  Step 251294  [21.348 sec/step, loss=0.08273, avg_loss=0.08169]
[2018-11-22 11:52:09.139]  Step 251295  [21.341 sec/step, loss=0.08298, avg_loss=0.08168]
[2018-11-22 11:52:31.091]  Step 251296  [21.305 sec/step, loss=0.08392, avg_loss=0.08167]
[2018-11-22 11:52:49.847]  Step 251297  [21.299 sec/step, loss=0.08132, avg_loss=0.08165]
[2018-11-22 11:53:14.216]  Step 251298  [21.383 sec/step, loss=0.08404, avg_loss=0.08169]
[2018-11-22 11:53:37.917]  Step 251299  [21.515 sec/step, loss=0.08414, avg_loss=0.08179]
[2018-11-22 11:53:49.642]  Step 251300  [21.390 sec/step, loss=0.07837, avg_loss=0.08173]
[2018-11-22 11:53:49.642]  Writing summary at step: 251300
[2018-11-22 11:54:47.994]  Step 251301  [21.399 sec/step, loss=0.08216, avg_loss=0.08170]
[2018-11-22 11:55:05.830]  Step 251302  [21.487 sec/step, loss=0.08224, avg_loss=0.08191]
[2018-11-22 11:55:31.086]  Step 251303  [21.517 sec/step, loss=0.08422, avg_loss=0.08190]
[2018-11-22 11:55:56.589]  Step 251304  [21.514 sec/step, loss=0.08237, avg_loss=0.08189]
[2018-11-22 11:56:23.090]  Step 251305  [21.582 sec/step, loss=0.08252, avg_loss=0.08189]
[2018-11-22 11:56:49.736]  Step 251306  [21.683 sec/step, loss=0.08304, avg_loss=0.08191]
[2018-11-22 11:57:13.423]  Step 251307  [21.691 sec/step, loss=0.08240, avg_loss=0.08189]
[2018-11-22 11:57:37.229]  Step 251308  [21.683 sec/step, loss=0.08280, avg_loss=0.08187]
[2018-11-22 11:57:47.603]  Step 251309  [21.527 sec/step, loss=0.07509, avg_loss=0.08179]
[2018-11-22 11:58:10.724]  Step 251310  [21.505 sec/step, loss=0.08274, avg_loss=0.08177]
[2018-11-22 11:58:31.158]  Step 251311  [21.478 sec/step, loss=0.08186, avg_loss=0.08176]
[2018-11-22 11:58:40.606]  Step 251312  [21.380 sec/step, loss=0.06255, avg_loss=0.08154]
[2018-11-22 11:58:56.754]  Step 251313  [21.326 sec/step, loss=0.08025, avg_loss=0.08150]
[2018-11-22 11:59:16.470]  Step 251314  [21.298 sec/step, loss=0.08230, avg_loss=0.08149]
[2018-11-22 11:59:40.518]  Step 251315  [21.320 sec/step, loss=0.08297, avg_loss=0.08148]
[2018-11-22 12:00:01.725]  Step 251316  [21.358 sec/step, loss=0.08183, avg_loss=0.08147]
[2018-11-22 12:00:24.438]  Step 251317  [21.383 sec/step, loss=0.08358, avg_loss=0.08148]
[2018-11-22 12:00:47.201]  Step 251318  [21.369 sec/step, loss=0.08277, avg_loss=0.08148]
[2018-11-22 12:00:56.669]  Generated 32 batches of size 32 in 8.694 sec
[2018-11-22 12:01:04.440]  Step 251319  [21.316 sec/step, loss=0.07829, avg_loss=0.08141]
[2018-11-22 12:01:26.133]  Step 251320  [21.404 sec/step, loss=0.08360, avg_loss=0.08146]
[2018-11-22 12:01:48.560]  Step 251321  [21.386 sec/step, loss=0.08356, avg_loss=0.08145]
[2018-11-22 12:02:13.894]  Step 251322  [21.459 sec/step, loss=0.08325, avg_loss=0.08146]
[2018-11-22 12:02:31.618]  Step 251323  [21.185 sec/step, loss=0.08172, avg_loss=0.08152]
[2018-11-22 12:02:56.969]  Step 251324  [21.214 sec/step, loss=0.08325, avg_loss=0.08152]
[2018-11-22 12:03:20.302]  Step 251325  [21.270 sec/step, loss=0.08285, avg_loss=0.08154]
[2018-11-22 12:03:42.753]  Step 251326  [21.288 sec/step, loss=0.08346, avg_loss=0.08155]
[2018-11-22 12:03:58.868]  Step 251327  [21.257 sec/step, loss=0.07961, avg_loss=0.08152]
[2018-11-22 12:04:23.613]  Step 251328  [21.395 sec/step, loss=0.08408, avg_loss=0.08161]
[2018-11-22 12:04:44.318]  Step 251329  [21.349 sec/step, loss=0.08237, avg_loss=0.08160]
[2018-11-22 12:05:07.316]  Step 251330  [21.327 sec/step, loss=0.08219, avg_loss=0.08159]
[2018-11-22 12:05:25.066]  Step 251331  [21.240 sec/step, loss=0.08095, avg_loss=0.08156]
[2018-11-22 12:05:49.881]  Step 251332  [21.232 sec/step, loss=0.08272, avg_loss=0.08154]
[2018-11-22 12:06:07.076]  Step 251333  [21.261 sec/step, loss=0.08201, avg_loss=0.08155]
[2018-11-22 12:06:16.111]  Step 251334  [21.100 sec/step, loss=0.06163, avg_loss=0.08134]
[2018-11-22 12:06:31.597]  Step 251335  [21.056 sec/step, loss=0.08030, avg_loss=0.08132]
[2018-11-22 12:06:53.533]  Step 251336  [20.993 sec/step, loss=0.08330, avg_loss=0.08132]
[2018-11-22 12:07:12.833]  Step 251337  [20.949 sec/step, loss=0.08127, avg_loss=0.08128]
[2018-11-22 12:07:36.447]  Step 251338  [20.957 sec/step, loss=0.08277, avg_loss=0.08128]
[2018-11-22 12:08:01.268]  Step 251339  [21.084 sec/step, loss=0.08314, avg_loss=0.08133]
[2018-11-22 12:08:20.454]  Step 251340  [21.082 sec/step, loss=0.08204, avg_loss=0.08133]
[2018-11-22 12:09:04.256]  Step 251341  [21.136 sec/step, loss=0.07431, avg_loss=0.08134]
[2018-11-22 12:09:26.544]  Step 251342  [21.154 sec/step, loss=0.08328, avg_loss=0.08134]
[2018-11-22 12:09:47.113]  Step 251343  [21.158 sec/step, loss=0.08183, avg_loss=0.08133]
[2018-11-22 12:10:10.681]  Step 251344  [21.232 sec/step, loss=0.08244, avg_loss=0.08136]
[2018-11-22 12:10:21.218]  Step 251345  [21.092 sec/step, loss=0.07506, avg_loss=0.08128]
[2018-11-22 12:10:46.100]  Step 251346  [21.235 sec/step, loss=0.08381, avg_loss=0.08139]
[2018-11-22 12:11:02.765]  Step 251347  [21.154 sec/step, loss=0.07884, avg_loss=0.08133]
[2018-11-22 12:11:27.746]  Step 251348  [21.156 sec/step, loss=0.08318, avg_loss=0.08131]
[2018-11-22 12:11:41.868]  Step 251349  [21.064 sec/step, loss=0.07974, avg_loss=0.08127]
[2018-11-22 12:12:00.657]  Step 251350  [21.113 sec/step, loss=0.08305, avg_loss=0.08130]
[2018-11-22 12:12:00.657]  Writing summary at step: 251350
[2018-11-22 12:12:10.861]  Generated 32 batches of size 32 in 9.133 sec
[2018-11-22 12:12:46.512]  Step 251351  [21.190 sec/step, loss=0.08343, avg_loss=0.08133]
[2018-11-22 12:13:07.342]  Step 251352  [21.159 sec/step, loss=0.08361, avg_loss=0.08133]
[2018-11-22 12:13:19.544]  Step 251353  [21.196 sec/step, loss=0.07884, avg_loss=0.08148]
[2018-11-22 12:13:45.573]  Step 251354  [21.264 sec/step, loss=0.08329, avg_loss=0.08149]
[2018-11-22 12:14:07.105]  Step 251355  [21.269 sec/step, loss=0.08265, avg_loss=0.08149]
[2018-11-22 12:14:31.804]  Step 251356  [21.207 sec/step, loss=0.08214, avg_loss=0.08147]
[2018-11-22 12:14:57.407]  Step 251357  [21.292 sec/step, loss=0.08341, avg_loss=0.08148]
[2018-11-22 12:15:19.105]  Step 251358  [21.258 sec/step, loss=0.08241, avg_loss=0.08147]
[2018-11-22 12:15:37.870]  Step 251359  [21.226 sec/step, loss=0.08126, avg_loss=0.08145]
[2018-11-22 12:16:01.661]  Step 251360  [21.280 sec/step, loss=0.08270, avg_loss=0.08145]
[2018-11-22 12:16:23.568]  Step 251361  [21.319 sec/step, loss=0.08278, avg_loss=0.08146]
[2018-11-22 12:16:50.598]  Step 251362  [21.360 sec/step, loss=0.08107, avg_loss=0.08143]
[2018-11-22 12:17:13.047]  Step 251363  [21.356 sec/step, loss=0.08386, avg_loss=0.08144]
[2018-11-22 12:17:26.862]  Step 251364  [21.243 sec/step, loss=0.07904, avg_loss=0.08139]
[2018-11-22 12:17:51.089]  Step 251365  [21.397 sec/step, loss=0.08334, avg_loss=0.08160]
[2018-11-22 12:18:16.727]  Step 251366  [21.511 sec/step, loss=0.08269, avg_loss=0.08162]
[2018-11-22 12:18:25.672]  Step 251367  [21.471 sec/step, loss=0.06046, avg_loss=0.08144]
[2018-11-22 12:18:50.529]  Step 251368  [21.500 sec/step, loss=0.08226, avg_loss=0.08144]
[2018-11-22 12:19:33.967]  Step 251369  [21.737 sec/step, loss=0.07309, avg_loss=0.08135]
[2018-11-22 12:19:53.336]  Step 251370  [21.770 sec/step, loss=0.08191, avg_loss=0.08136]
[2018-11-22 12:20:03.693]  Step 251371  [21.690 sec/step, loss=0.07338, avg_loss=0.08129]
[2018-11-22 12:20:26.277]  Step 251372  [21.658 sec/step, loss=0.08277, avg_loss=0.08127]
[2018-11-22 12:20:51.896]  Step 251373  [21.694 sec/step, loss=0.08325, avg_loss=0.08127]
[2018-11-22 12:21:13.938]  Step 251374  [21.755 sec/step, loss=0.08262, avg_loss=0.08130]
[2018-11-22 12:21:36.146]  Step 251375  [21.779 sec/step, loss=0.08238, avg_loss=0.08130]
[2018-11-22 12:21:57.474]  Step 251376  [21.739 sec/step, loss=0.08249, avg_loss=0.08129]
[2018-11-22 12:22:19.739]  Step 251377  [21.716 sec/step, loss=0.08289, avg_loss=0.08127]
[2018-11-22 12:22:40.326]  Step 251378  [21.694 sec/step, loss=0.08235, avg_loss=0.08125]
[2018-11-22 12:22:58.182]  Step 251379  [21.664 sec/step, loss=0.08132, avg_loss=0.08124]
[2018-11-22 12:23:20.649]  Step 251380  [21.671 sec/step, loss=0.08262, avg_loss=0.08123]
[2018-11-22 12:23:32.594]  Step 251381  [21.535 sec/step, loss=0.07783, avg_loss=0.08118]
[2018-11-22 12:23:42.090]  Generated 32 batches of size 32 in 8.471 sec
[2018-11-22 12:23:52.663]  Step 251382  [21.494 sec/step, loss=0.08144, avg_loss=0.08116]
[2018-11-22 12:24:12.247]  Step 251383  [21.502 sec/step, loss=0.08157, avg_loss=0.08115]
[2018-11-22 12:24:33.733]  Step 251384  [21.493 sec/step, loss=0.08174, avg_loss=0.08113]
[2018-11-22 12:24:51.052]  Step 251385  [21.464 sec/step, loss=0.08241, avg_loss=0.08113]
[2018-11-22 12:25:06.843]  Step 251386  [21.398 sec/step, loss=0.07976, avg_loss=0.08108]
[2018-11-22 12:25:31.511]  Step 251387  [21.472 sec/step, loss=0.08399, avg_loss=0.08109]
[2018-11-22 12:25:54.389]  Step 251388  [21.260 sec/step, loss=0.08308, avg_loss=0.08118]
[2018-11-22 12:26:18.165]  Step 251389  [21.267 sec/step, loss=0.08238, avg_loss=0.08117]
[2018-11-22 12:26:33.414]  Step 251390  [21.314 sec/step, loss=0.07844, avg_loss=0.08120]
[2018-11-22 12:26:52.431]  Step 251391  [21.223 sec/step, loss=0.08157, avg_loss=0.08120]
[2018-11-22 12:27:05.392]  Step 251392  [21.095 sec/step, loss=0.07894, avg_loss=0.08115]
[2018-11-22 12:27:13.912]  Step 251393  [20.953 sec/step, loss=0.06177, avg_loss=0.08094]
[2018-11-22 12:27:39.472]  Step 251394  [20.962 sec/step, loss=0.08314, avg_loss=0.08095]
[2018-11-22 12:27:58.940]  Step 251395  [20.919 sec/step, loss=0.08152, avg_loss=0.08093]
[2018-11-22 12:28:15.928]  Step 251396  [20.869 sec/step, loss=0.08132, avg_loss=0.08091]
[2018-11-22 12:28:40.310]  Step 251397  [20.925 sec/step, loss=0.08332, avg_loss=0.08093]
[2018-11-22 12:29:03.997]  Step 251398  [20.918 sec/step, loss=0.08227, avg_loss=0.08091]
[2018-11-22 12:29:28.460]  Step 251399  [20.926 sec/step, loss=0.08239, avg_loss=0.08089]
[2018-11-22 12:29:50.071]  Step 251400  [21.025 sec/step, loss=0.08297, avg_loss=0.08094]
[2018-11-22 12:29:50.071]  Writing summary at step: 251400
[2018-11-22 12:30:26.100]  Step 251401  [20.963 sec/step, loss=0.07935, avg_loss=0.08091]
[2018-11-22 12:30:48.967]  Step 251402  [21.013 sec/step, loss=0.08259, avg_loss=0.08091]
[2018-11-22 12:31:00.641]  Step 251403  [20.877 sec/step, loss=0.07857, avg_loss=0.08086]
[2018-11-22 12:31:20.882]  Step 251404  [20.825 sec/step, loss=0.08258, avg_loss=0.08086]
[2018-11-22 12:31:43.061]  Step 251405  [20.781 sec/step, loss=0.08314, avg_loss=0.08086]
[2018-11-22 12:32:09.996]  Step 251406  [20.784 sec/step, loss=0.08216, avg_loss=0.08086]
[2018-11-22 12:32:28.673]  Step 251407  [20.734 sec/step, loss=0.08181, avg_loss=0.08085]
[2018-11-22 12:32:44.334]  Step 251408  [20.653 sec/step, loss=0.07705, avg_loss=0.08079]
[2018-11-22 12:33:09.430]  Step 251409  [20.800 sec/step, loss=0.08242, avg_loss=0.08087]
[2018-11-22 12:33:30.491]  Step 251410  [20.779 sec/step, loss=0.08292, avg_loss=0.08087]
[2018-11-22 12:33:51.941]  Step 251411  [20.790 sec/step, loss=0.08310, avg_loss=0.08088]
[2018-11-22 12:34:17.690]  Step 251412  [20.953 sec/step, loss=0.08378, avg_loss=0.08109]
[2018-11-22 12:34:27.178]  Generated 32 batches of size 32 in 8.389 sec
[2018-11-22 12:34:41.142]  Step 251413  [21.026 sec/step, loss=0.08185, avg_loss=0.08111]
[2018-11-22 12:35:07.497]  Step 251414  [21.092 sec/step, loss=0.08279, avg_loss=0.08111]
[2018-11-22 12:35:30.475]  Step 251415  [21.081 sec/step, loss=0.08265, avg_loss=0.08111]
[2018-11-22 12:35:50.612]  Step 251416  [21.071 sec/step, loss=0.08225, avg_loss=0.08111]
[2018-11-22 12:36:15.039]  Step 251417  [21.088 sec/step, loss=0.08224, avg_loss=0.08110]
[2018-11-22 12:36:25.272]  Step 251418  [20.962 sec/step, loss=0.07438, avg_loss=0.08102]
[2018-11-22 12:36:44.040]  Step 251419  [20.978 sec/step, loss=0.08087, avg_loss=0.08104]
[2018-11-22 12:37:09.283]  Step 251420  [21.013 sec/step, loss=0.08383, avg_loss=0.08104]
[2018-11-22 12:37:48.590]  Step 251421  [21.182 sec/step, loss=0.07342, avg_loss=0.08094]
[2018-11-22 12:38:10.674]  Step 251422  [21.150 sec/step, loss=0.08224, avg_loss=0.08093]
[2018-11-22 12:38:35.141]  Step 251423  [21.217 sec/step, loss=0.08232, avg_loss=0.08094]
[2018-11-22 12:38:58.947]  Step 251424  [21.202 sec/step, loss=0.08290, avg_loss=0.08094]
[2018-11-22 12:39:09.955]  Step 251425  [21.078 sec/step, loss=0.07451, avg_loss=0.08085]
[2018-11-22 12:39:37.582]  Step 251426  [21.130 sec/step, loss=0.08311, avg_loss=0.08085]
[2018-11-22 12:39:58.206]  Step 251427  [21.175 sec/step, loss=0.08113, avg_loss=0.08086]
[2018-11-22 12:40:19.021]  Step 251428  [21.136 sec/step, loss=0.08260, avg_loss=0.08085]
[2018-11-22 12:40:27.904]  Step 251429  [21.018 sec/step, loss=0.06028, avg_loss=0.08063]
[2018-11-22 12:40:45.660]  Step 251430  [20.965 sec/step, loss=0.08182, avg_loss=0.08062]
[2018-11-22 12:41:05.893]  Step 251431  [20.990 sec/step, loss=0.08121, avg_loss=0.08063]
[2018-11-22 12:41:29.888]  Step 251432  [20.982 sec/step, loss=0.08254, avg_loss=0.08063]
[2018-11-22 12:41:54.862]  Step 251433  [21.060 sec/step, loss=0.08149, avg_loss=0.08062]
[2018-11-22 12:42:17.574]  Step 251434  [21.196 sec/step, loss=0.08202, avg_loss=0.08082]
[2018-11-22 12:42:55.656]  Step 251435  [21.422 sec/step, loss=0.07326, avg_loss=0.08075]
[2018-11-22 12:43:15.508]  Step 251436  [21.401 sec/step, loss=0.08163, avg_loss=0.08074]
[2018-11-22 12:43:36.848]  Step 251437  [21.422 sec/step, loss=0.08330, avg_loss=0.08076]
[2018-11-22 12:43:58.963]  Step 251438  [21.407 sec/step, loss=0.08293, avg_loss=0.08076]
[2018-11-22 12:44:17.642]  Step 251439  [21.345 sec/step, loss=0.08236, avg_loss=0.08075]
[2018-11-22 12:44:42.090]  Step 251440  [21.398 sec/step, loss=0.08304, avg_loss=0.08076]
[2018-11-22 12:44:57.932]  Step 251441  [21.118 sec/step, loss=0.07979, avg_loss=0.08082]
[2018-11-22 12:45:13.975]  Step 251442  [21.056 sec/step, loss=0.07810, avg_loss=0.08076]
[2018-11-22 12:45:39.767]  Step 251443  [21.108 sec/step, loss=0.08291, avg_loss=0.08078]
[2018-11-22 12:46:03.526]  Step 251444  [21.110 sec/step, loss=0.08233, avg_loss=0.08077]
[2018-11-22 12:46:12.775]  Generated 32 batches of size 32 in 8.373 sec
[2018-11-22 12:46:29.292]  Step 251445  [21.262 sec/step, loss=0.08327, avg_loss=0.08086]
[2018-11-22 12:46:52.140]  Step 251446  [21.242 sec/step, loss=0.08212, avg_loss=0.08084]
[2018-11-22 12:47:09.963]  Step 251447  [21.254 sec/step, loss=0.08048, avg_loss=0.08086]
[2018-11-22 12:47:29.621]  Step 251448  [21.200 sec/step, loss=0.08172, avg_loss=0.08084]
[2018-11-22 12:47:41.864]  Step 251449  [21.182 sec/step, loss=0.07775, avg_loss=0.08082]
[2018-11-22 12:48:05.149]  Step 251450  [21.227 sec/step, loss=0.08263, avg_loss=0.08082]
[2018-11-22 12:48:05.149]  Writing summary at step: 251450
[2018-11-22 12:48:42.023]  Step 251451  [21.132 sec/step, loss=0.07893, avg_loss=0.08077]
[2018-11-22 12:49:06.595]  Step 251452  [21.170 sec/step, loss=0.08383, avg_loss=0.08077]
[2018-11-22 12:49:31.696]  Step 251453  [21.299 sec/step, loss=0.08137, avg_loss=0.08080]
[2018-11-22 12:49:56.107]  Step 251454  [21.282 sec/step, loss=0.08292, avg_loss=0.08080]
[2018-11-22 12:50:20.122]  Step 251455  [21.307 sec/step, loss=0.08235, avg_loss=0.08079]
[2018-11-22 12:50:47.017]  Step 251456  [21.329 sec/step, loss=0.08013, avg_loss=0.08077]
[2018-11-22 12:51:09.390]  Step 251457  [21.297 sec/step, loss=0.08193, avg_loss=0.08076]
[2018-11-22 12:51:30.890]  Step 251458  [21.295 sec/step, loss=0.08189, avg_loss=0.08075]
[2018-11-22 12:51:53.257]  Step 251459  [21.331 sec/step, loss=0.08212, avg_loss=0.08076]
[2018-11-22 12:52:03.605]  Step 251460  [21.196 sec/step, loss=0.07371, avg_loss=0.08067]
[2018-11-22 12:52:26.277]  Step 251461  [21.204 sec/step, loss=0.08228, avg_loss=0.08067]
[2018-11-22 12:52:48.086]  Step 251462  [21.152 sec/step, loss=0.08257, avg_loss=0.08068]
[2018-11-22 12:53:24.966]  Step 251463  [21.296 sec/step, loss=0.07251, avg_loss=0.08057]
[2018-11-22 12:53:40.699]  Step 251464  [21.315 sec/step, loss=0.07919, avg_loss=0.08057]
[2018-11-22 12:53:58.851]  Step 251465  [21.255 sec/step, loss=0.08032, avg_loss=0.08054]
[2018-11-22 12:54:14.835]  Step 251466  [21.158 sec/step, loss=0.07827, avg_loss=0.08049]
[2018-11-22 12:54:28.750]  Step 251467  [21.208 sec/step, loss=0.07939, avg_loss=0.08068]
[2018-11-22 12:54:54.269]  Step 251468  [21.214 sec/step, loss=0.08260, avg_loss=0.08069]
[2018-11-22 12:55:15.148]  Step 251469  [20.989 sec/step, loss=0.08251, avg_loss=0.08078]
[2018-11-22 12:55:38.571]  Step 251470  [21.029 sec/step, loss=0.08197, avg_loss=0.08078]
[2018-11-22 12:56:03.231]  Step 251471  [21.172 sec/step, loss=0.08210, avg_loss=0.08087]
[2018-11-22 12:56:22.034]  Step 251472  [21.135 sec/step, loss=0.08158, avg_loss=0.08086]
[2018-11-22 12:56:45.836]  Step 251473  [21.116 sec/step, loss=0.08188, avg_loss=0.08084]
[2018-11-22 12:57:11.156]  Step 251474  [21.149 sec/step, loss=0.08218, avg_loss=0.08084]
[2018-11-22 12:57:34.776]  Step 251475  [21.163 sec/step, loss=0.08304, avg_loss=0.08085]
[2018-11-22 12:57:44.354]  Generated 32 batches of size 32 in 8.695 sec
[2018-11-22 12:57:57.170]  Step 251476  [21.174 sec/step, loss=0.08164, avg_loss=0.08084]
[2018-11-22 12:58:17.101]  Step 251477  [21.151 sec/step, loss=0.08116, avg_loss=0.08082]
[2018-11-22 12:58:37.524]  Step 251478  [21.149 sec/step, loss=0.08205, avg_loss=0.08082]
[2018-11-22 12:58:59.312]  Step 251479  [21.188 sec/step, loss=0.08114, avg_loss=0.08082]
[2018-11-22 12:59:08.359]  Step 251480  [21.054 sec/step, loss=0.06188, avg_loss=0.08061]
[2018-11-22 12:59:30.220]  Step 251481  [21.153 sec/step, loss=0.08225, avg_loss=0.08065]
[2018-11-22 12:59:42.752]  Step 251482  [21.078 sec/step, loss=0.07704, avg_loss=0.08061]
[2018-11-22 12:59:59.697]  Step 251483  [21.052 sec/step, loss=0.08152, avg_loss=0.08061]
[2018-11-22 13:00:19.331]  Step 251484  [21.033 sec/step, loss=0.08149, avg_loss=0.08061]
[2018-11-22 13:00:42.302]  Step 251485  [21.090 sec/step, loss=0.08195, avg_loss=0.08060]
[2018-11-22 13:01:04.127]  Step 251486  [21.150 sec/step, loss=0.08281, avg_loss=0.08063]
[2018-11-22 13:01:14.557]  Step 251487  [21.008 sec/step, loss=0.07406, avg_loss=0.08053]
[2018-11-22 13:01:34.372]  Step 251488  [20.977 sec/step, loss=0.08115, avg_loss=0.08051]
[2018-11-22 13:01:54.957]  Step 251489  [20.945 sec/step, loss=0.08171, avg_loss=0.08051]
[2018-11-22 13:02:17.288]  Step 251490  [21.016 sec/step, loss=0.08188, avg_loss=0.08054]
[2018-11-22 13:02:36.569]  Step 251491  [21.018 sec/step, loss=0.08100, avg_loss=0.08053]
[2018-11-22 13:02:56.029]  Step 251492  [21.083 sec/step, loss=0.08114, avg_loss=0.08056]
[2018-11-22 13:03:20.501]  Step 251493  [21.243 sec/step, loss=0.08336, avg_loss=0.08077]
[2018-11-22 13:03:29.155]  Step 251494  [21.074 sec/step, loss=0.06212, avg_loss=0.08056]
[2018-11-22 13:03:53.086]  Step 251495  [21.119 sec/step, loss=0.08132, avg_loss=0.08056]
[2018-11-22 13:04:07.713]  Step 251496  [21.095 sec/step, loss=0.07835, avg_loss=0.08053]
[2018-11-22 13:04:23.369]  Step 251497  [21.008 sec/step, loss=0.07914, avg_loss=0.08049]
[2018-11-22 13:04:50.276]  Step 251498  [21.040 sec/step, loss=0.08302, avg_loss=0.08050]
[2018-11-22 13:05:17.489]  Step 251499  [21.067 sec/step, loss=0.08237, avg_loss=0.08050]
[2018-11-22 13:05:29.872]  Step 251500  [20.975 sec/step, loss=0.07629, avg_loss=0.08043]
[2018-11-22 13:05:29.872]  Writing summary at step: 251500
[2018-11-22 13:05:56.272]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-251500
[2018-11-22 13:05:59.769]  Saving audio and alignment...
[2018-11-22 13:06:11.076]  Input: reviewers (themselves often women in an anomalous position as the female thought-police of a patriarchal ideology) were not wrong to see them there.~__________________
[2018-11-22 13:06:35.788]  Step 251501  [21.060 sec/step, loss=0.08168, avg_loss=0.08045]
[2018-11-22 13:06:57.890]  Step 251502  [21.053 sec/step, loss=0.08269, avg_loss=0.08045]
[2018-11-22 13:07:20.539]  Step 251503  [21.162 sec/step, loss=0.08245, avg_loss=0.08049]
[2018-11-22 13:07:40.078]  Step 251504  [21.155 sec/step, loss=0.08073, avg_loss=0.08047]
[2018-11-22 13:08:07.223]  Step 251505  [21.205 sec/step, loss=0.08117, avg_loss=0.08045]
[2018-11-22 13:08:19.386]  Generated 32 batches of size 32 in 11.085 sec
[2018-11-22 13:08:37.327]  Step 251506  [21.237 sec/step, loss=0.08171, avg_loss=0.08045]
[2018-11-22 13:08:59.329]  Step 251507  [21.270 sec/step, loss=0.08131, avg_loss=0.08045]
[2018-11-22 13:09:24.458]  Step 251508  [21.365 sec/step, loss=0.08182, avg_loss=0.08049]
[2018-11-22 13:09:47.173]  Step 251509  [21.341 sec/step, loss=0.08323, avg_loss=0.08050]
[2018-11-22 13:10:05.417]  Step 251510  [21.313 sec/step, loss=0.08054, avg_loss=0.08048]
[2018-11-22 13:10:24.189]  Step 251511  [21.286 sec/step, loss=0.08197, avg_loss=0.08047]
[2018-11-22 13:11:03.144]  Step 251512  [21.418 sec/step, loss=0.07285, avg_loss=0.08036]
[2018-11-22 13:11:28.201]  Step 251513  [21.434 sec/step, loss=0.08222, avg_loss=0.08036]
[2018-11-22 13:11:48.825]  Step 251514  [21.377 sec/step, loss=0.08128, avg_loss=0.08035]
[2018-11-22 13:12:09.524]  Step 251515  [21.354 sec/step, loss=0.08128, avg_loss=0.08033]
[2018-11-22 13:12:34.925]  Step 251516  [21.407 sec/step, loss=0.08273, avg_loss=0.08034]
[2018-11-22 13:13:01.628]  Step 251517  [21.429 sec/step, loss=0.08204, avg_loss=0.08033]
[2018-11-22 13:13:23.544]  Step 251518  [21.546 sec/step, loss=0.08188, avg_loss=0.08041]
[2018-11-22 13:13:42.340]  Step 251519  [21.546 sec/step, loss=0.08093, avg_loss=0.08041]
[2018-11-22 13:14:07.289]  Step 251520  [21.543 sec/step, loss=0.08254, avg_loss=0.08040]
[2018-11-22 13:14:25.489]  Step 251521  [21.332 sec/step, loss=0.08017, avg_loss=0.08046]
[2018-11-22 13:14:49.599]  Step 251522  [21.353 sec/step, loss=0.08149, avg_loss=0.08046]
[2018-11-22 13:15:09.292]  Step 251523  [21.305 sec/step, loss=0.08121, avg_loss=0.08045]
[2018-11-22 13:15:25.769]  Step 251524  [21.232 sec/step, loss=0.07752, avg_loss=0.08039]
[2018-11-22 13:15:43.851]  Step 251525  [21.302 sec/step, loss=0.08060, avg_loss=0.08045]
[2018-11-22 13:16:06.061]  Step 251526  [21.248 sec/step, loss=0.08105, avg_loss=0.08043]
[2018-11-22 13:16:28.664]  Step 251527  [21.268 sec/step, loss=0.08146, avg_loss=0.08044]
[2018-11-22 13:16:53.649]  Step 251528  [21.310 sec/step, loss=0.08191, avg_loss=0.08043]
[2018-11-22 13:17:15.017]  Step 251529  [21.435 sec/step, loss=0.08234, avg_loss=0.08065]
[2018-11-22 13:17:25.564]  Step 251530  [21.362 sec/step, loss=0.07374, avg_loss=0.08057]
[2018-11-22 13:17:44.303]  Step 251531  [21.347 sec/step, loss=0.08124, avg_loss=0.08057]
[2018-11-22 13:18:06.772]  Step 251532  [21.332 sec/step, loss=0.08196, avg_loss=0.08056]
[2018-11-22 13:18:26.882]  Step 251533  [21.284 sec/step, loss=0.08095, avg_loss=0.08056]
[2018-11-22 13:18:49.663]  Step 251534  [21.284 sec/step, loss=0.08209, avg_loss=0.08056]
[2018-11-22 13:19:15.002]  Step 251535  [21.157 sec/step, loss=0.08079, avg_loss=0.08063]
[2018-11-22 13:19:27.910]  Step 251536  [21.087 sec/step, loss=0.07689, avg_loss=0.08059]
[2018-11-22 13:19:57.536]  Step 251537  [21.170 sec/step, loss=0.08204, avg_loss=0.08057]
[2018-11-22 13:20:09.338]  Generated 32 batches of size 32 in 10.920 sec
[2018-11-22 13:20:18.102]  Step 251538  [21.155 sec/step, loss=0.07879, avg_loss=0.08053]
[2018-11-22 13:20:32.321]  Step 251539  [21.110 sec/step, loss=0.07819, avg_loss=0.08049]
[2018-11-22 13:20:56.171]  Step 251540  [21.104 sec/step, loss=0.08196, avg_loss=0.08048]
[2018-11-22 13:21:04.531]  Step 251541  [21.029 sec/step, loss=0.06128, avg_loss=0.08029]
[2018-11-22 13:21:42.305]  Step 251542  [21.247 sec/step, loss=0.07289, avg_loss=0.08024]
[2018-11-22 13:22:06.495]  Step 251543  [21.231 sec/step, loss=0.08270, avg_loss=0.08024]
[2018-11-22 13:22:29.903]  Step 251544  [21.227 sec/step, loss=0.08258, avg_loss=0.08024]
[2018-11-22 13:22:53.774]  Step 251545  [21.208 sec/step, loss=0.08195, avg_loss=0.08023]
[2018-11-22 13:23:13.819]  Step 251546  [21.180 sec/step, loss=0.08200, avg_loss=0.08023]
[2018-11-22 13:23:29.626]  Step 251547  [21.160 sec/step, loss=0.07705, avg_loss=0.08019]
[2018-11-22 13:23:54.156]  Step 251548  [21.209 sec/step, loss=0.08183, avg_loss=0.08020]
[2018-11-22 13:24:02.351]  Step 251549  [21.168 sec/step, loss=0.06100, avg_loss=0.08003]
[2018-11-22 13:24:22.212]  Step 251550  [21.134 sec/step, loss=0.08014, avg_loss=0.08000]
[2018-11-22 13:24:22.212]  Writing summary at step: 251550
[2018-11-22 13:25:03.472]  Step 251551  [21.217 sec/step, loss=0.08169, avg_loss=0.08003]
[2018-11-22 13:25:22.721]  Step 251552  [21.163 sec/step, loss=0.08126, avg_loss=0.08000]
[2018-11-22 13:25:41.970]  Step 251553  [21.105 sec/step, loss=0.08080, avg_loss=0.08000]
[2018-11-22 13:26:04.081]  Step 251554  [21.082 sec/step, loss=0.08110, avg_loss=0.07998]
[2018-11-22 13:26:27.618]  Step 251555  [21.077 sec/step, loss=0.08162, avg_loss=0.07997]
[2018-11-22 13:26:43.214]  Step 251556  [20.964 sec/step, loss=0.07858, avg_loss=0.07996]
[2018-11-22 13:27:05.237]  Step 251557  [20.960 sec/step, loss=0.08185, avg_loss=0.07996]
[2018-11-22 13:27:22.396]  Step 251558  [20.917 sec/step, loss=0.08043, avg_loss=0.07994]
[2018-11-22 13:27:48.673]  Step 251559  [20.956 sec/step, loss=0.08089, avg_loss=0.07993]
[2018-11-22 13:28:29.761]  Step 251560  [21.264 sec/step, loss=0.07267, avg_loss=0.07992]
[2018-11-22 13:28:42.417]  Step 251561  [21.163 sec/step, loss=0.07690, avg_loss=0.07987]
[2018-11-22 13:29:05.083]  Step 251562  [21.172 sec/step, loss=0.08247, avg_loss=0.07987]
[2018-11-22 13:29:31.567]  Step 251563  [21.068 sec/step, loss=0.08179, avg_loss=0.07996]
[2018-11-22 13:29:55.704]  Step 251564  [21.152 sec/step, loss=0.08213, avg_loss=0.07999]
[2018-11-22 13:30:18.563]  Step 251565  [21.199 sec/step, loss=0.08207, avg_loss=0.08001]
[2018-11-22 13:30:29.170]  Step 251566  [21.145 sec/step, loss=0.07322, avg_loss=0.07995]
[2018-11-22 13:30:50.510]  Step 251567  [21.220 sec/step, loss=0.08109, avg_loss=0.07997]
[2018-11-22 13:31:11.385]  Step 251568  [21.173 sec/step, loss=0.08139, avg_loss=0.07996]
[2018-11-22 13:31:20.836]  Generated 32 batches of size 32 in 8.487 sec
[2018-11-22 13:31:33.994]  Step 251569  [21.191 sec/step, loss=0.08162, avg_loss=0.07995]
[2018-11-22 13:31:55.862]  Step 251570  [21.175 sec/step, loss=0.08153, avg_loss=0.07995]
[2018-11-22 13:32:09.667]  Step 251571  [21.066 sec/step, loss=0.07795, avg_loss=0.07990]
[2018-11-22 13:32:34.702]  Step 251572  [21.129 sec/step, loss=0.08233, avg_loss=0.07991]
[2018-11-22 13:32:58.425]  Step 251573  [21.128 sec/step, loss=0.08128, avg_loss=0.07991]
[2018-11-22 13:33:19.967]  Step 251574  [21.090 sec/step, loss=0.08191, avg_loss=0.07990]
[2018-11-22 13:33:38.198]  Step 251575  [21.036 sec/step, loss=0.08096, avg_loss=0.07988]
[2018-11-22 13:34:02.314]  Step 251576  [21.053 sec/step, loss=0.08190, avg_loss=0.07989]
[2018-11-22 13:34:26.503]  Step 251577  [21.096 sec/step, loss=0.08235, avg_loss=0.07990]
[2018-11-22 13:34:40.597]  Step 251578  [21.033 sec/step, loss=0.07738, avg_loss=0.07985]
[2018-11-22 13:35:04.647]  Step 251579  [21.055 sec/step, loss=0.08105, avg_loss=0.07985]
[2018-11-22 13:35:24.989]  Step 251580  [21.168 sec/step, loss=0.08064, avg_loss=0.08004]
[2018-11-22 13:35:42.496]  Step 251581  [21.125 sec/step, loss=0.08013, avg_loss=0.08002]
[2018-11-22 13:36:04.787]  Step 251582  [21.222 sec/step, loss=0.08156, avg_loss=0.08006]
[2018-11-22 13:36:27.150]  Step 251583  [21.277 sec/step, loss=0.08024, avg_loss=0.08005]
[2018-11-22 13:36:43.635]  Step 251584  [21.245 sec/step, loss=0.07853, avg_loss=0.08002]
[2018-11-22 13:37:07.118]  Step 251585  [21.250 sec/step, loss=0.08204, avg_loss=0.08002]
[2018-11-22 13:37:24.788]  Step 251586  [21.209 sec/step, loss=0.08011, avg_loss=0.07999]
[2018-11-22 13:37:49.815]  Step 251587  [21.355 sec/step, loss=0.08101, avg_loss=0.08006]
[2018-11-22 13:38:29.240]  Step 251588  [21.551 sec/step, loss=0.07219, avg_loss=0.07997]
[2018-11-22 13:38:53.694]  Step 251589  [21.589 sec/step, loss=0.08118, avg_loss=0.07997]
[2018-11-22 13:39:03.998]  Step 251590  [21.469 sec/step, loss=0.07214, avg_loss=0.07987]
[2018-11-22 13:39:25.477]  Step 251591  [21.491 sec/step, loss=0.08188, avg_loss=0.07988]
[2018-11-22 13:39:50.667]  Step 251592  [21.548 sec/step, loss=0.08265, avg_loss=0.07989]
[2018-11-22 13:40:08.733]  Step 251593  [21.484 sec/step, loss=0.08014, avg_loss=0.07986]
[2018-11-22 13:40:32.666]  Step 251594  [21.637 sec/step, loss=0.08224, avg_loss=0.08006]
[2018-11-22 13:40:57.896]  Step 251595  [21.650 sec/step, loss=0.08162, avg_loss=0.08007]
[2018-11-22 13:41:13.483]  Step 251596  [21.660 sec/step, loss=0.07731, avg_loss=0.08006]
[2018-11-22 13:41:36.432]  Step 251597  [21.733 sec/step, loss=0.08154, avg_loss=0.08008]
[2018-11-22 13:41:55.881]  Step 251598  [21.658 sec/step, loss=0.08058, avg_loss=0.08005]
[2018-11-22 13:42:07.963]  Step 251599  [21.507 sec/step, loss=0.07617, avg_loss=0.07999]
[2018-11-22 13:42:34.163]  Step 251600  [21.645 sec/step, loss=0.08036, avg_loss=0.08003]
[2018-11-22 13:42:34.163]  Writing summary at step: 251600
[2018-11-22 13:42:44.133]  Generated 32 batches of size 32 in 8.956 sec
[2018-11-22 13:43:19.350]  Step 251601  [21.624 sec/step, loss=0.08189, avg_loss=0.08004]
[2018-11-22 13:43:41.391]  Step 251602  [21.624 sec/step, loss=0.08167, avg_loss=0.08003]
[2018-11-22 13:44:00.636]  Step 251603  [21.590 sec/step, loss=0.08060, avg_loss=0.08001]
[2018-11-22 13:44:09.299]  Step 251604  [21.481 sec/step, loss=0.05994, avg_loss=0.07980]
[2018-11-22 13:44:29.165]  Step 251605  [21.408 sec/step, loss=0.08075, avg_loss=0.07979]
[2018-11-22 13:44:53.405]  Step 251606  [21.349 sec/step, loss=0.08186, avg_loss=0.07980]
[2018-11-22 13:45:14.472]  Step 251607  [21.340 sec/step, loss=0.08271, avg_loss=0.07981]
[2018-11-22 13:45:36.245]  Step 251608  [21.306 sec/step, loss=0.08159, avg_loss=0.07981]
[2018-11-22 13:45:59.307]  Step 251609  [21.310 sec/step, loss=0.08134, avg_loss=0.07979]
[2018-11-22 13:46:15.095]  Step 251610  [21.285 sec/step, loss=0.07824, avg_loss=0.07977]
[2018-11-22 13:46:35.916]  Step 251611  [21.306 sec/step, loss=0.08116, avg_loss=0.07976]
[2018-11-22 13:46:57.774]  Step 251612  [21.135 sec/step, loss=0.08106, avg_loss=0.07984]
[2018-11-22 13:47:24.078]  Step 251613  [21.147 sec/step, loss=0.08102, avg_loss=0.07983]
[2018-11-22 13:48:05.333]  Step 251614  [21.354 sec/step, loss=0.07195, avg_loss=0.07973]
[2018-11-22 13:48:30.292]  Step 251615  [21.396 sec/step, loss=0.08213, avg_loss=0.07974]
[2018-11-22 13:48:54.929]  Step 251616  [21.389 sec/step, loss=0.08241, avg_loss=0.07974]
[2018-11-22 13:49:16.930]  Step 251617  [21.342 sec/step, loss=0.08149, avg_loss=0.07973]
[2018-11-22 13:49:35.849]  Step 251618  [21.312 sec/step, loss=0.08011, avg_loss=0.07972]
[2018-11-22 13:49:59.650]  Step 251619  [21.362 sec/step, loss=0.08092, avg_loss=0.07972]
[2018-11-22 13:50:20.009]  Step 251620  [21.316 sec/step, loss=0.08030, avg_loss=0.07969]
[2018-11-22 13:50:35.675]  Step 251621  [21.290 sec/step, loss=0.07955, avg_loss=0.07969]
[2018-11-22 13:50:56.497]  Step 251622  [21.258 sec/step, loss=0.08067, avg_loss=0.07968]
[2018-11-22 13:51:19.719]  Step 251623  [21.293 sec/step, loss=0.08191, avg_loss=0.07969]
[2018-11-22 13:51:32.185]  Step 251624  [21.253 sec/step, loss=0.07646, avg_loss=0.07968]
[2018-11-22 13:51:49.577]  Step 251625  [21.246 sec/step, loss=0.08067, avg_loss=0.07968]
[2018-11-22 13:52:00.198]  Step 251626  [21.130 sec/step, loss=0.07317, avg_loss=0.07960]
[2018-11-22 13:52:17.858]  Step 251627  [21.081 sec/step, loss=0.07999, avg_loss=0.07958]
[2018-11-22 13:52:31.866]  Step 251628  [20.971 sec/step, loss=0.07854, avg_loss=0.07955]
[2018-11-22 13:52:55.191]  Step 251629  [20.990 sec/step, loss=0.08114, avg_loss=0.07954]
[2018-11-22 13:53:13.763]  Step 251630  [21.071 sec/step, loss=0.08165, avg_loss=0.07962]
[2018-11-22 13:53:22.458]  Step 251631  [20.970 sec/step, loss=0.06203, avg_loss=0.07942]
[2018-11-22 13:53:31.776]  Generated 32 batches of size 32 in 8.499 sec
[2018-11-22 13:53:45.778]  Step 251632  [20.979 sec/step, loss=0.08186, avg_loss=0.07942]
[2018-11-22 13:54:10.103]  Step 251633  [21.021 sec/step, loss=0.08191, avg_loss=0.07943]
[2018-11-22 13:54:34.012]  Step 251634  [21.032 sec/step, loss=0.08140, avg_loss=0.07943]
[2018-11-22 13:54:58.423]  Step 251635  [21.023 sec/step, loss=0.08144, avg_loss=0.07943]
[2018-11-22 13:55:18.655]  Step 251636  [21.096 sec/step, loss=0.08198, avg_loss=0.07948]
[2018-11-22 13:55:43.165]  Step 251637  [21.045 sec/step, loss=0.08104, avg_loss=0.07947]
[2018-11-22 13:56:04.699]  Step 251638  [21.055 sec/step, loss=0.08132, avg_loss=0.07950]
[2018-11-22 13:56:23.897]  Step 251639  [21.104 sec/step, loss=0.08048, avg_loss=0.07952]
[2018-11-22 13:56:45.423]  Step 251640  [21.081 sec/step, loss=0.08225, avg_loss=0.07952]
[2018-11-22 13:57:07.526]  Step 251641  [21.219 sec/step, loss=0.08178, avg_loss=0.07973]
[2018-11-22 13:57:31.649]  Step 251642  [21.082 sec/step, loss=0.08126, avg_loss=0.07981]
[2018-11-22 13:57:51.370]  Step 251643  [21.037 sec/step, loss=0.08031, avg_loss=0.07979]
[2018-11-22 13:58:19.859]  Step 251644  [21.088 sec/step, loss=0.08170, avg_loss=0.07978]
[2018-11-22 13:58:39.747]  Step 251645  [21.048 sec/step, loss=0.07994, avg_loss=0.07976]
[2018-11-22 13:59:07.785]  Step 251646  [21.128 sec/step, loss=0.08175, avg_loss=0.07976]
[2018-11-22 13:59:16.401]  Step 251647  [21.056 sec/step, loss=0.05967, avg_loss=0.07958]
[2018-11-22 13:59:32.026]  Step 251648  [20.967 sec/step, loss=0.07835, avg_loss=0.07955]
[2018-11-22 13:59:44.191]  Step 251649  [21.007 sec/step, loss=0.07616, avg_loss=0.07970]
[2018-11-22 13:59:54.636]  Step 251650  [20.913 sec/step, loss=0.07325, avg_loss=0.07963]
[2018-11-22 13:59:54.636]  Writing summary at step: 251650
[2018-11-22 14:00:39.023]  Step 251651  [20.913 sec/step, loss=0.08117, avg_loss=0.07963]
[2018-11-22 14:01:00.906]  Step 251652  [20.939 sec/step, loss=0.08147, avg_loss=0.07963]
[2018-11-22 14:01:25.802]  Step 251653  [20.996 sec/step, loss=0.08083, avg_loss=0.07963]
[2018-11-22 14:01:49.363]  Step 251654  [21.010 sec/step, loss=0.08148, avg_loss=0.07963]
[2018-11-22 14:02:11.030]  Step 251655  [20.992 sec/step, loss=0.08141, avg_loss=0.07963]
[2018-11-22 14:02:26.776]  Step 251656  [20.993 sec/step, loss=0.07710, avg_loss=0.07962]
[2018-11-22 14:03:09.758]  Step 251657  [21.203 sec/step, loss=0.07287, avg_loss=0.07953]
[2018-11-22 14:03:32.509]  Step 251658  [21.259 sec/step, loss=0.08111, avg_loss=0.07953]
[2018-11-22 14:03:52.634]  Step 251659  [21.197 sec/step, loss=0.08104, avg_loss=0.07953]
[2018-11-22 14:04:16.206]  Step 251660  [21.022 sec/step, loss=0.08165, avg_loss=0.07962]
[2018-11-22 14:04:33.914]  Step 251661  [21.073 sec/step, loss=0.08010, avg_loss=0.07966]
[2018-11-22 14:05:00.516]  Step 251662  [21.112 sec/step, loss=0.08078, avg_loss=0.07964]
[2018-11-22 14:05:11.221]  Generated 32 batches of size 32 in 9.569 sec
[2018-11-22 14:05:27.320]  Step 251663  [21.115 sec/step, loss=0.08176, avg_loss=0.07964]
[2018-11-22 14:05:50.731]  Step 251664  [21.108 sec/step, loss=0.08145, avg_loss=0.07963]
[2018-11-22 14:06:11.130]  Step 251665  [21.083 sec/step, loss=0.08071, avg_loss=0.07962]
[2018-11-22 14:06:30.157]  Step 251666  [21.167 sec/step, loss=0.08084, avg_loss=0.07970]
[2018-11-22 14:06:43.971]  Step 251667  [21.092 sec/step, loss=0.07755, avg_loss=0.07966]
[2018-11-22 14:07:03.213]  Step 251668  [21.076 sec/step, loss=0.08041, avg_loss=0.07965]
[2018-11-22 14:07:24.859]  Step 251669  [21.066 sec/step, loss=0.08067, avg_loss=0.07964]
[2018-11-22 14:07:49.233]  Step 251670  [21.091 sec/step, loss=0.08238, avg_loss=0.07965]
[2018-11-22 14:08:10.849]  Step 251671  [21.169 sec/step, loss=0.08153, avg_loss=0.07969]
[2018-11-22 14:08:19.404]  Step 251672  [21.005 sec/step, loss=0.06174, avg_loss=0.07948]
[2018-11-22 14:08:40.876]  Step 251673  [20.982 sec/step, loss=0.08139, avg_loss=0.07948]
[2018-11-22 14:09:00.309]  Step 251674  [20.961 sec/step, loss=0.08025, avg_loss=0.07946]
[2018-11-22 14:09:24.323]  Step 251675  [21.019 sec/step, loss=0.08121, avg_loss=0.07947]
[2018-11-22 14:09:41.145]  Step 251676  [20.946 sec/step, loss=0.07987, avg_loss=0.07945]
[2018-11-22 14:10:05.324]  Step 251677  [20.946 sec/step, loss=0.08234, avg_loss=0.07945]
[2018-11-22 14:10:23.663]  Step 251678  [20.988 sec/step, loss=0.08036, avg_loss=0.07948]
[2018-11-22 14:10:45.811]  Step 251679  [20.969 sec/step, loss=0.08134, avg_loss=0.07948]
[2018-11-22 14:11:09.509]  Step 251680  [21.003 sec/step, loss=0.08082, avg_loss=0.07948]
[2018-11-22 14:11:32.295]  Step 251681  [21.056 sec/step, loss=0.08148, avg_loss=0.07949]
[2018-11-22 14:11:52.965]  Step 251682  [21.039 sec/step, loss=0.07987, avg_loss=0.07948]
[2018-11-22 14:12:15.596]  Step 251683  [21.042 sec/step, loss=0.08139, avg_loss=0.07949]
[2018-11-22 14:12:34.200]  Step 251684  [21.063 sec/step, loss=0.08039, avg_loss=0.07951]
[2018-11-22 14:12:49.845]  Step 251685  [20.985 sec/step, loss=0.07714, avg_loss=0.07946]
[2018-11-22 14:13:11.426]  Step 251686  [21.024 sec/step, loss=0.08012, avg_loss=0.07946]
[2018-11-22 14:13:35.858]  Step 251687  [21.018 sec/step, loss=0.08099, avg_loss=0.07946]
[2018-11-22 14:13:59.468]  Step 251688  [20.860 sec/step, loss=0.08197, avg_loss=0.07956]
[2018-11-22 14:14:10.156]  Step 251689  [20.722 sec/step, loss=0.07266, avg_loss=0.07947]
[2018-11-22 14:14:30.794]  Step 251690  [20.826 sec/step, loss=0.08188, avg_loss=0.07957]
[2018-11-22 14:14:44.730]  Step 251691  [20.750 sec/step, loss=0.07755, avg_loss=0.07952]
[2018-11-22 14:15:08.869]  Step 251692  [20.740 sec/step, loss=0.08103, avg_loss=0.07951]
[2018-11-22 14:15:26.714]  Step 251693  [20.737 sec/step, loss=0.07958, avg_loss=0.07950]
[2018-11-22 14:15:47.317]  Step 251694  [20.704 sec/step, loss=0.08115, avg_loss=0.07949]
[2018-11-22 14:15:58.786]  Generated 32 batches of size 32 in 10.559 sec
[2018-11-22 14:16:18.227]  Step 251695  [20.761 sec/step, loss=0.08095, avg_loss=0.07948]
[2018-11-22 14:16:33.853]  Step 251696  [20.761 sec/step, loss=0.07791, avg_loss=0.07949]
[2018-11-22 14:16:59.132]  Step 251697  [20.785 sec/step, loss=0.08214, avg_loss=0.07950]
[2018-11-22 14:17:21.762]  Step 251698  [20.816 sec/step, loss=0.08094, avg_loss=0.07950]
[2018-11-22 14:17:33.780]  Step 251699  [20.816 sec/step, loss=0.07641, avg_loss=0.07950]
[2018-11-22 14:17:55.685]  Step 251700  [20.773 sec/step, loss=0.08150, avg_loss=0.07951]
[2018-11-22 14:17:55.686]  Writing summary at step: 251700
[2018-11-22 14:18:57.676]  Step 251701  [20.915 sec/step, loss=0.07231, avg_loss=0.07942]
[2018-11-22 14:19:17.533]  Step 251702  [20.894 sec/step, loss=0.08062, avg_loss=0.07941]
[2018-11-22 14:19:42.339]  Step 251703  [20.949 sec/step, loss=0.08037, avg_loss=0.07941]
[2018-11-22 14:20:06.365]  Step 251704  [21.103 sec/step, loss=0.08062, avg_loss=0.07961]
[2018-11-22 14:20:24.062]  Step 251705  [21.081 sec/step, loss=0.07929, avg_loss=0.07960]
[2018-11-22 14:20:43.987]  Step 251706  [21.038 sec/step, loss=0.08061, avg_loss=0.07959]
[2018-11-22 14:21:06.057]  Step 251707  [21.048 sec/step, loss=0.08133, avg_loss=0.07957]
[2018-11-22 14:21:25.084]  Step 251708  [21.021 sec/step, loss=0.07988, avg_loss=0.07955]
[2018-11-22 14:21:40.621]  Step 251709  [20.945 sec/step, loss=0.07805, avg_loss=0.07952]
[2018-11-22 14:21:52.660]  Step 251710  [20.908 sec/step, loss=0.07634, avg_loss=0.07950]
[2018-11-22 14:22:16.924]  Step 251711  [20.942 sec/step, loss=0.08104, avg_loss=0.07950]
[2018-11-22 14:22:41.092]  Step 251712  [20.965 sec/step, loss=0.08228, avg_loss=0.07951]
[2018-11-22 14:22:50.102]  Step 251713  [20.792 sec/step, loss=0.05776, avg_loss=0.07928]
[2018-11-22 14:23:13.118]  Step 251714  [20.610 sec/step, loss=0.08137, avg_loss=0.07938]
[2018-11-22 14:23:34.930]  Step 251715  [20.579 sec/step, loss=0.08175, avg_loss=0.07937]
[2018-11-22 14:23:55.828]  Step 251716  [20.541 sec/step, loss=0.08178, avg_loss=0.07936]
[2018-11-22 14:24:20.363]  Step 251717  [20.566 sec/step, loss=0.08208, avg_loss=0.07937]
[2018-11-22 14:24:46.119]  Step 251718  [20.635 sec/step, loss=0.08170, avg_loss=0.07939]
[2018-11-22 14:25:09.813]  Step 251719  [20.634 sec/step, loss=0.08127, avg_loss=0.07939]
[2018-11-22 14:25:32.199]  Step 251720  [20.654 sec/step, loss=0.08160, avg_loss=0.07940]
[2018-11-22 14:25:48.505]  Step 251721  [20.660 sec/step, loss=0.07722, avg_loss=0.07938]
[2018-11-22 14:26:02.544]  Step 251722  [20.593 sec/step, loss=0.07788, avg_loss=0.07935]
[2018-11-22 14:26:24.745]  Step 251723  [20.582 sec/step, loss=0.08141, avg_loss=0.07935]
[2018-11-22 14:26:44.679]  Step 251724  [20.657 sec/step, loss=0.07984, avg_loss=0.07938]
[2018-11-22 14:27:06.493]  Step 251725  [20.701 sec/step, loss=0.08046, avg_loss=0.07938]
[2018-11-22 14:27:15.785]  Generated 32 batches of size 32 in 8.531 sec
[2018-11-22 14:27:25.020]  Step 251726  [20.780 sec/step, loss=0.08009, avg_loss=0.07945]
[2018-11-22 14:27:47.889]  Step 251727  [20.832 sec/step, loss=0.08115, avg_loss=0.07946]
[2018-11-22 14:28:13.803]  Step 251728  [20.952 sec/step, loss=0.08077, avg_loss=0.07948]
[2018-11-22 14:28:34.242]  Step 251729  [20.923 sec/step, loss=0.08092, avg_loss=0.07948]
[2018-11-22 14:28:57.825]  Step 251730  [20.973 sec/step, loss=0.08131, avg_loss=0.07948]
[2018-11-22 14:29:35.214]  Step 251731  [21.260 sec/step, loss=0.07201, avg_loss=0.07958]
[2018-11-22 14:29:45.675]  Step 251732  [21.131 sec/step, loss=0.07360, avg_loss=0.07949]
[2018-11-22 14:30:04.410]  Step 251733  [21.075 sec/step, loss=0.08149, avg_loss=0.07949]
[2018-11-22 14:30:25.049]  Step 251734  [21.043 sec/step, loss=0.08093, avg_loss=0.07948]
[2018-11-22 14:30:49.532]  Step 251735  [21.043 sec/step, loss=0.08114, avg_loss=0.07948]
[2018-11-22 14:31:13.560]  Step 251736  [21.081 sec/step, loss=0.08056, avg_loss=0.07947]
[2018-11-22 14:31:37.252]  Step 251737  [21.073 sec/step, loss=0.08194, avg_loss=0.07948]
[2018-11-22 14:31:56.853]  Step 251738  [21.054 sec/step, loss=0.07976, avg_loss=0.07946]
[2018-11-22 14:32:18.496]  Step 251739  [21.078 sec/step, loss=0.08088, avg_loss=0.07946]
[2018-11-22 14:32:39.159]  Step 251740  [21.070 sec/step, loss=0.07988, avg_loss=0.07944]
[2018-11-22 14:33:02.205]  Step 251741  [21.079 sec/step, loss=0.08157, avg_loss=0.07944]
[2018-11-22 14:33:26.320]  Step 251742  [21.079 sec/step, loss=0.08210, avg_loss=0.07945]
[2018-11-22 14:34:04.745]  Step 251743  [21.266 sec/step, loss=0.07197, avg_loss=0.07936]
[2018-11-22 14:34:18.548]  Step 251744  [21.119 sec/step, loss=0.07703, avg_loss=0.07932]
[2018-11-22 14:34:41.643]  Step 251745  [21.151 sec/step, loss=0.08076, avg_loss=0.07933]
[2018-11-22 14:34:57.477]  Step 251746  [21.029 sec/step, loss=0.07768, avg_loss=0.07928]
[2018-11-22 14:35:19.795]  Step 251747  [21.166 sec/step, loss=0.08084, avg_loss=0.07950]
[2018-11-22 14:35:42.541]  Step 251748  [21.237 sec/step, loss=0.08038, avg_loss=0.07952]
[2018-11-22 14:35:54.598]  Step 251749  [21.236 sec/step, loss=0.07614, avg_loss=0.07952]
[2018-11-22 14:36:16.429]  Step 251750  [21.350 sec/step, loss=0.07982, avg_loss=0.07958]
[2018-11-22 14:36:16.430]  Writing summary at step: 251750
[2018-11-22 14:36:47.773]  Step 251751  [21.208 sec/step, loss=0.06274, avg_loss=0.07940]
[2018-11-22 14:37:06.773]  Step 251752  [21.179 sec/step, loss=0.08039, avg_loss=0.07939]
[2018-11-22 14:37:31.292]  Step 251753  [21.175 sec/step, loss=0.08005, avg_loss=0.07938]
[2018-11-22 14:37:55.217]  Step 251754  [21.179 sec/step, loss=0.08139, avg_loss=0.07938]
[2018-11-22 14:38:15.520]  Step 251755  [21.165 sec/step, loss=0.08140, avg_loss=0.07938]
[2018-11-22 14:38:26.011]  Step 251756  [21.112 sec/step, loss=0.07158, avg_loss=0.07932]
[2018-11-22 14:38:36.987]  Generated 32 batches of size 32 in 10.189 sec
[2018-11-22 14:38:55.372]  Step 251757  [20.976 sec/step, loss=0.08039, avg_loss=0.07940]
[2018-11-22 14:39:14.493]  Step 251758  [20.940 sec/step, loss=0.08049, avg_loss=0.07939]
[2018-11-22 14:39:31.790]  Step 251759  [20.912 sec/step, loss=0.07979, avg_loss=0.07938]
[2018-11-22 14:39:52.500]  Step 251760  [20.883 sec/step, loss=0.08198, avg_loss=0.07938]
[2018-11-22 14:40:11.411]  Step 251761  [20.895 sec/step, loss=0.08013, avg_loss=0.07938]
[2018-11-22 14:40:29.818]  Step 251762  [20.813 sec/step, loss=0.07962, avg_loss=0.07937]
[2018-11-22 14:40:57.368]  Step 251763  [20.821 sec/step, loss=0.08145, avg_loss=0.07937]
[2018-11-22 14:41:13.005]  Step 251764  [20.743 sec/step, loss=0.07708, avg_loss=0.07932]
[2018-11-22 14:41:34.554]  Step 251765  [20.754 sec/step, loss=0.08121, avg_loss=0.07933]
[2018-11-22 14:42:00.756]  Step 251766  [20.826 sec/step, loss=0.07946, avg_loss=0.07932]
[2018-11-22 14:42:14.286]  Step 251767  [20.823 sec/step, loss=0.07642, avg_loss=0.07930]
[2018-11-22 14:42:33.722]  Step 251768  [20.825 sec/step, loss=0.07955, avg_loss=0.07930]
[2018-11-22 14:42:52.673]  Step 251769  [20.798 sec/step, loss=0.08020, avg_loss=0.07929]
[2018-11-22 14:43:14.859]  Step 251770  [20.776 sec/step, loss=0.08165, avg_loss=0.07928]
[2018-11-22 14:43:32.102]  Step 251771  [20.733 sec/step, loss=0.07929, avg_loss=0.07926]
[2018-11-22 14:43:53.110]  Step 251772  [20.857 sec/step, loss=0.08076, avg_loss=0.07945]
[2018-11-22 14:44:11.383]  Step 251773  [20.825 sec/step, loss=0.08013, avg_loss=0.07944]
[2018-11-22 14:44:49.533]  Step 251774  [21.012 sec/step, loss=0.07108, avg_loss=0.07935]
[2018-11-22 14:45:13.873]  Step 251775  [21.016 sec/step, loss=0.08153, avg_loss=0.07935]
[2018-11-22 14:45:35.322]  Step 251776  [21.062 sec/step, loss=0.08013, avg_loss=0.07935]
[2018-11-22 14:45:50.994]  Step 251777  [20.977 sec/step, loss=0.07769, avg_loss=0.07931]
[2018-11-22 14:46:02.530]  Step 251778  [20.909 sec/step, loss=0.07665, avg_loss=0.07927]
[2018-11-22 14:46:26.872]  Step 251779  [20.931 sec/step, loss=0.08131, avg_loss=0.07927]
[2018-11-22 14:46:47.103]  Step 251780  [20.896 sec/step, loss=0.08024, avg_loss=0.07926]
[2018-11-22 14:47:12.351]  Step 251781  [20.921 sec/step, loss=0.08131, avg_loss=0.07926]
[2018-11-22 14:47:22.813]  Step 251782  [20.819 sec/step, loss=0.07106, avg_loss=0.07917]
[2018-11-22 14:47:47.395]  Step 251783  [20.838 sec/step, loss=0.08062, avg_loss=0.07917]
[2018-11-22 14:48:10.074]  Step 251784  [20.879 sec/step, loss=0.08082, avg_loss=0.07917]
[2018-11-22 14:48:32.893]  Step 251785  [20.951 sec/step, loss=0.08089, avg_loss=0.07921]
[2018-11-22 14:48:50.052]  Step 251786  [20.906 sec/step, loss=0.07945, avg_loss=0.07920]
[2018-11-22 14:49:10.773]  Step 251787  [20.869 sec/step, loss=0.08122, avg_loss=0.07920]
[2018-11-22 14:49:19.214]  Step 251788  [20.718 sec/step, loss=0.06154, avg_loss=0.07900]
[2018-11-22 14:49:28.586]  Generated 32 batches of size 32 in 8.482 sec
[2018-11-22 14:49:42.233]  Step 251789  [20.841 sec/step, loss=0.08014, avg_loss=0.07907]
[2018-11-22 14:50:00.986]  Step 251790  [20.822 sec/step, loss=0.08034, avg_loss=0.07906]
[2018-11-22 14:50:23.374]  Step 251791  [20.907 sec/step, loss=0.08150, avg_loss=0.07910]
[2018-11-22 14:50:45.520]  Step 251792  [20.887 sec/step, loss=0.08156, avg_loss=0.07910]
[2018-11-22 14:51:10.780]  Step 251793  [20.961 sec/step, loss=0.08163, avg_loss=0.07912]
[2018-11-22 14:51:34.593]  Step 251794  [20.993 sec/step, loss=0.08054, avg_loss=0.07912]
[2018-11-22 14:51:50.309]  Step 251795  [20.841 sec/step, loss=0.07670, avg_loss=0.07908]
[2018-11-22 14:52:11.294]  Step 251796  [20.894 sec/step, loss=0.08101, avg_loss=0.07911]
[2018-11-22 14:52:34.071]  Step 251797  [20.869 sec/step, loss=0.08089, avg_loss=0.07909]
[2018-11-22 14:52:50.142]  Step 251798  [20.804 sec/step, loss=0.07648, avg_loss=0.07905]
[2018-11-22 14:53:14.480]  Step 251799  [20.927 sec/step, loss=0.08128, avg_loss=0.07910]
[2018-11-22 14:53:33.971]  Step 251800  [20.903 sec/step, loss=0.07957, avg_loss=0.07908]
[2018-11-22 14:53:33.971]  Writing summary at step: 251800
[2018-11-22 14:54:16.421]  Step 251801  [20.717 sec/step, loss=0.08014, avg_loss=0.07916]
[2018-11-22 14:54:40.819]  Step 251802  [20.762 sec/step, loss=0.08189, avg_loss=0.07917]
[2018-11-22 14:55:02.926]  Step 251803  [20.735 sec/step, loss=0.08087, avg_loss=0.07917]
[2018-11-22 14:55:23.595]  Step 251804  [20.702 sec/step, loss=0.08097, avg_loss=0.07918]
[2018-11-22 14:55:46.281]  Step 251805  [20.752 sec/step, loss=0.08110, avg_loss=0.07920]
[2018-11-22 14:56:23.501]  Step 251806  [20.925 sec/step, loss=0.07258, avg_loss=0.07912]
[2018-11-22 14:56:49.550]  Step 251807  [20.964 sec/step, loss=0.08159, avg_loss=0.07912]
[2018-11-22 14:57:11.291]  Step 251808  [20.992 sec/step, loss=0.08071, avg_loss=0.07913]
[2018-11-22 14:57:35.224]  Step 251809  [21.076 sec/step, loss=0.08116, avg_loss=0.07916]
[2018-11-22 14:57:47.375]  Step 251810  [21.077 sec/step, loss=0.07562, avg_loss=0.07915]
[2018-11-22 14:58:08.015]  Step 251811  [21.040 sec/step, loss=0.07978, avg_loss=0.07914]
[2018-11-22 14:58:39.275]  Step 251812  [21.111 sec/step, loss=0.08051, avg_loss=0.07912]
[2018-11-22 14:59:10.343]  Step 251813  [21.332 sec/step, loss=0.08098, avg_loss=0.07935]
[2018-11-22 14:59:17.863]  Step 251814  [21.177 sec/step, loss=0.06102, avg_loss=0.07915]
[2018-11-22 14:59:35.901]  Step 251815  [21.139 sec/step, loss=0.07946, avg_loss=0.07913]
[2018-11-22 14:59:46.478]  Step 251816  [21.036 sec/step, loss=0.07127, avg_loss=0.07902]
[2018-11-22 15:00:02.533]  Step 251817  [20.951 sec/step, loss=0.07793, avg_loss=0.07898]
[2018-11-22 15:00:23.880]  Step 251818  [20.907 sec/step, loss=0.07988, avg_loss=0.07896]
[2018-11-22 15:00:46.864]  Step 251819  [20.900 sec/step, loss=0.08092, avg_loss=0.07896]
[2018-11-22 15:00:57.898]  Generated 32 batches of size 32 in 10.090 sec
[2018-11-22 15:01:07.352]  Step 251820  [20.881 sec/step, loss=0.07965, avg_loss=0.07894]
[2018-11-22 15:01:30.361]  Step 251821  [20.948 sec/step, loss=0.08071, avg_loss=0.07897]
[2018-11-22 15:01:51.751]  Step 251822  [21.022 sec/step, loss=0.08157, avg_loss=0.07901]
[2018-11-22 15:02:17.001]  Step 251823  [21.052 sec/step, loss=0.08053, avg_loss=0.07900]
[2018-11-22 15:02:36.257]  Step 251824  [21.045 sec/step, loss=0.07950, avg_loss=0.07900]
[2018-11-22 15:02:59.929]  Step 251825  [21.064 sec/step, loss=0.08037, avg_loss=0.07900]
[2018-11-22 15:03:20.485]  Step 251826  [21.084 sec/step, loss=0.08053, avg_loss=0.07900]
[2018-11-22 15:03:34.359]  Step 251827  [20.994 sec/step, loss=0.07711, avg_loss=0.07896]
[2018-11-22 15:03:58.643]  Step 251828  [20.978 sec/step, loss=0.08049, avg_loss=0.07896]
[2018-11-22 15:04:18.010]  Step 251829  [20.967 sec/step, loss=0.07975, avg_loss=0.07895]
[2018-11-22 15:04:41.268]  Step 251830  [20.964 sec/step, loss=0.08180, avg_loss=0.07895]
[2018-11-22 15:05:03.406]  Step 251831  [20.811 sec/step, loss=0.08022, avg_loss=0.07903]
[2018-11-22 15:05:26.226]  Step 251832  [20.935 sec/step, loss=0.08105, avg_loss=0.07911]
[2018-11-22 15:05:43.903]  Step 251833  [20.924 sec/step, loss=0.07994, avg_loss=0.07909]
[2018-11-22 15:06:04.404]  Step 251834  [20.923 sec/step, loss=0.08002, avg_loss=0.07908]
[2018-11-22 15:06:18.666]  Step 251835  [20.821 sec/step, loss=0.07685, avg_loss=0.07904]
[2018-11-22 15:06:34.193]  Step 251836  [20.736 sec/step, loss=0.07768, avg_loss=0.07901]
[2018-11-22 15:06:54.282]  Step 251837  [20.700 sec/step, loss=0.07942, avg_loss=0.07899]
[2018-11-22 15:07:15.438]  Step 251838  [20.715 sec/step, loss=0.08121, avg_loss=0.07900]
[2018-11-22 15:07:58.972]  Step 251839  [20.934 sec/step, loss=0.07157, avg_loss=0.07891]
[2018-11-22 15:08:24.313]  Step 251840  [20.981 sec/step, loss=0.08062, avg_loss=0.07892]
[2018-11-22 15:08:42.909]  Step 251841  [20.937 sec/step, loss=0.08052, avg_loss=0.07891]
[2018-11-22 15:09:04.964]  Step 251842  [20.916 sec/step, loss=0.08052, avg_loss=0.07889]
[2018-11-22 15:09:27.473]  Step 251843  [20.757 sec/step, loss=0.08051, avg_loss=0.07897]
[2018-11-22 15:09:51.897]  Step 251844  [20.863 sec/step, loss=0.08064, avg_loss=0.07901]
[2018-11-22 15:10:15.693]  Step 251845  [20.870 sec/step, loss=0.08019, avg_loss=0.07901]
[2018-11-22 15:10:39.463]  Step 251846  [20.949 sec/step, loss=0.08036, avg_loss=0.07903]
[2018-11-22 15:11:07.282]  Step 251847  [21.004 sec/step, loss=0.07966, avg_loss=0.07902]
[2018-11-22 15:11:27.477]  Step 251848  [20.979 sec/step, loss=0.08030, avg_loss=0.07902]
[2018-11-22 15:11:43.425]  Step 251849  [21.018 sec/step, loss=0.07728, avg_loss=0.07903]
[2018-11-22 15:12:08.361]  Step 251850  [21.049 sec/step, loss=0.08152, avg_loss=0.07905]
[2018-11-22 15:12:08.361]  Writing summary at step: 251850
[2018-11-22 15:12:41.695]  Generated 32 batches of size 32 in 8.909 sec
[2018-11-22 15:12:44.648]  Step 251851  [21.093 sec/step, loss=0.07396, avg_loss=0.07916]
[2018-11-22 15:12:54.188]  Step 251852  [20.998 sec/step, loss=0.06139, avg_loss=0.07897]
[2018-11-22 15:13:12.747]  Step 251853  [20.938 sec/step, loss=0.07893, avg_loss=0.07896]
[2018-11-22 15:13:35.689]  Step 251854  [20.929 sec/step, loss=0.08076, avg_loss=0.07895]
[2018-11-22 15:13:47.942]  Step 251855  [20.848 sec/step, loss=0.07629, avg_loss=0.07890]
[2018-11-22 15:14:13.113]  Step 251856  [20.995 sec/step, loss=0.08107, avg_loss=0.07900]
[2018-11-22 15:14:37.963]  Step 251857  [20.950 sec/step, loss=0.08009, avg_loss=0.07899]
[2018-11-22 15:14:58.263]  Step 251858  [20.962 sec/step, loss=0.08011, avg_loss=0.07899]
[2018-11-22 15:15:20.244]  Step 251859  [21.008 sec/step, loss=0.08071, avg_loss=0.07900]
[2018-11-22 15:15:44.258]  Step 251860  [21.042 sec/step, loss=0.08055, avg_loss=0.07898]
[2018-11-22 15:16:08.532]  Step 251861  [21.095 sec/step, loss=0.08057, avg_loss=0.07899]
[2018-11-22 15:16:19.139]  Step 251862  [21.017 sec/step, loss=0.07101, avg_loss=0.07890]
[2018-11-22 15:16:40.830]  Step 251863  [20.959 sec/step, loss=0.07967, avg_loss=0.07888]
[2018-11-22 15:16:49.167]  Step 251864  [20.886 sec/step, loss=0.06133, avg_loss=0.07873]
[2018-11-22 15:17:15.996]  Step 251865  [20.938 sec/step, loss=0.08018, avg_loss=0.07872]
[2018-11-22 15:17:34.896]  Step 251866  [20.865 sec/step, loss=0.07908, avg_loss=0.07871]
[2018-11-22 15:17:53.802]  Step 251867  [20.919 sec/step, loss=0.07978, avg_loss=0.07875]
[2018-11-22 15:18:13.462]  Step 251868  [20.921 sec/step, loss=0.07969, avg_loss=0.07875]
[2018-11-22 15:18:37.867]  Step 251869  [20.976 sec/step, loss=0.08045, avg_loss=0.07875]
[2018-11-22 15:18:55.582]  Step 251870  [20.931 sec/step, loss=0.07905, avg_loss=0.07872]
[2018-11-22 15:19:19.289]  Step 251871  [20.996 sec/step, loss=0.08070, avg_loss=0.07874]
[2018-11-22 15:19:39.653]  Step 251872  [20.989 sec/step, loss=0.08109, avg_loss=0.07874]
[2018-11-22 15:20:01.433]  Step 251873  [21.024 sec/step, loss=0.08078, avg_loss=0.07875]
[2018-11-22 15:20:21.879]  Step 251874  [20.847 sec/step, loss=0.07996, avg_loss=0.07884]
[2018-11-22 15:20:37.624]  Step 251875  [20.761 sec/step, loss=0.07735, avg_loss=0.07880]
[2018-11-22 15:21:01.269]  Step 251876  [20.783 sec/step, loss=0.08042, avg_loss=0.07880]
[2018-11-22 15:21:15.359]  Step 251877  [20.768 sec/step, loss=0.07720, avg_loss=0.07879]
[2018-11-22 15:21:36.566]  Step 251878  [20.864 sec/step, loss=0.08073, avg_loss=0.07883]
[2018-11-22 15:22:01.947]  Step 251879  [20.875 sec/step, loss=0.08112, avg_loss=0.07883]
[2018-11-22 15:22:14.442]  Step 251880  [20.797 sec/step, loss=0.07559, avg_loss=0.07879]
[2018-11-22 15:22:31.551]  Step 251881  [20.716 sec/step, loss=0.07979, avg_loss=0.07877]
[2018-11-22 15:22:54.941]  Step 251882  [20.845 sec/step, loss=0.08215, avg_loss=0.07888]
[2018-11-22 15:23:04.028]  Generated 32 batches of size 32 in 8.425 sec
[2018-11-22 15:23:16.812]  Step 251883  [20.818 sec/step, loss=0.07899, avg_loss=0.07887]
[2018-11-22 15:23:56.758]  Step 251884  [20.991 sec/step, loss=0.07159, avg_loss=0.07877]
[2018-11-22 15:24:12.348]  Step 251885  [20.918 sec/step, loss=0.07622, avg_loss=0.07873]
[2018-11-22 15:24:36.600]  Step 251886  [20.989 sec/step, loss=0.08166, avg_loss=0.07875]
[2018-11-22 15:24:59.439]  Step 251887  [21.011 sec/step, loss=0.08025, avg_loss=0.07874]
[2018-11-22 15:25:26.011]  Step 251888  [21.192 sec/step, loss=0.08016, avg_loss=0.07893]
[2018-11-22 15:25:48.126]  Step 251889  [21.183 sec/step, loss=0.08098, avg_loss=0.07893]
[2018-11-22 15:26:12.774]  Step 251890  [21.242 sec/step, loss=0.07993, avg_loss=0.07893]
[2018-11-22 15:26:35.715]  Step 251891  [21.247 sec/step, loss=0.08076, avg_loss=0.07892]
[2018-11-22 15:27:02.017]  Step 251892  [21.289 sec/step, loss=0.08044, avg_loss=0.07891]
[2018-11-22 15:27:26.434]  Step 251893  [21.280 sec/step, loss=0.08035, avg_loss=0.07890]
[2018-11-22 15:27:51.530]  Step 251894  [21.293 sec/step, loss=0.08071, avg_loss=0.07890]
[2018-11-22 15:28:14.537]  Step 251895  [21.366 sec/step, loss=0.08028, avg_loss=0.07894]
[2018-11-22 15:28:28.438]  Step 251896  [21.295 sec/step, loss=0.07709, avg_loss=0.07890]
[2018-11-22 15:28:44.373]  Step 251897  [21.227 sec/step, loss=0.07571, avg_loss=0.07884]
[2018-11-22 15:29:06.751]  Step 251898  [21.290 sec/step, loss=0.08074, avg_loss=0.07889]
[2018-11-22 15:29:27.301]  Step 251899  [21.252 sec/step, loss=0.07979, avg_loss=0.07887]
[2018-11-22 15:29:51.491]  Step 251900  [21.299 sec/step, loss=0.08059, avg_loss=0.07888]
[2018-11-22 15:29:51.491]  Writing summary at step: 251900
[2018-11-22 15:30:28.205]  Step 251901  [21.301 sec/step, loss=0.08010, avg_loss=0.07888]
[2018-11-22 15:30:49.395]  Step 251902  [21.269 sec/step, loss=0.08084, avg_loss=0.07887]
[2018-11-22 15:31:13.800]  Step 251903  [21.292 sec/step, loss=0.08043, avg_loss=0.07887]
[2018-11-22 15:31:35.932]  Step 251904  [21.306 sec/step, loss=0.08037, avg_loss=0.07886]
[2018-11-22 15:31:54.935]  Step 251905  [21.269 sec/step, loss=0.07947, avg_loss=0.07885]
[2018-11-22 15:32:03.549]  Step 251906  [20.983 sec/step, loss=0.05935, avg_loss=0.07871]
[2018-11-22 15:32:28.224]  Step 251907  [20.970 sec/step, loss=0.07997, avg_loss=0.07870]
[2018-11-22 15:32:48.681]  Step 251908  [20.957 sec/step, loss=0.08015, avg_loss=0.07869]
[2018-11-22 15:33:27.428]  Step 251909  [21.105 sec/step, loss=0.07123, avg_loss=0.07859]
[2018-11-22 15:33:44.596]  Step 251910  [21.155 sec/step, loss=0.07917, avg_loss=0.07863]
[2018-11-22 15:34:08.371]  Step 251911  [21.186 sec/step, loss=0.08127, avg_loss=0.07864]
[2018-11-22 15:34:30.577]  Step 251912  [21.096 sec/step, loss=0.07978, avg_loss=0.07863]
[2018-11-22 15:34:41.240]  Step 251913  [20.892 sec/step, loss=0.07175, avg_loss=0.07854]
[2018-11-22 15:34:50.190]  Generated 32 batches of size 32 in 8.152 sec
[2018-11-22 15:35:04.166]  Step 251914  [21.046 sec/step, loss=0.08049, avg_loss=0.07874]
[2018-11-22 15:35:26.660]  Step 251915  [21.090 sec/step, loss=0.08051, avg_loss=0.07875]
[2018-11-22 15:35:52.074]  Step 251916  [21.239 sec/step, loss=0.08158, avg_loss=0.07885]
[2018-11-22 15:36:12.086]  Step 251917  [21.278 sec/step, loss=0.07933, avg_loss=0.07886]
[2018-11-22 15:36:34.391]  Step 251918  [21.288 sec/step, loss=0.07990, avg_loss=0.07887]
[2018-11-22 15:36:49.833]  Step 251919  [21.212 sec/step, loss=0.07728, avg_loss=0.07883]
[2018-11-22 15:37:02.069]  Step 251920  [21.130 sec/step, loss=0.07549, avg_loss=0.07879]
[2018-11-22 15:37:25.788]  Step 251921  [21.137 sec/step, loss=0.07996, avg_loss=0.07878]
[2018-11-22 15:37:45.579]  Step 251922  [21.121 sec/step, loss=0.07923, avg_loss=0.07876]
[2018-11-22 15:37:56.195]  Step 251923  [20.975 sec/step, loss=0.07267, avg_loss=0.07868]
[2018-11-22 15:38:18.832]  Step 251924  [21.009 sec/step, loss=0.08017, avg_loss=0.07868]
[2018-11-22 15:38:37.426]  Step 251925  [20.958 sec/step, loss=0.08030, avg_loss=0.07868]
[2018-11-22 15:38:58.496]  Step 251926  [20.963 sec/step, loss=0.08050, avg_loss=0.07868]
[2018-11-22 15:39:10.776]  Step 251927  [20.947 sec/step, loss=0.07623, avg_loss=0.07867]
[2018-11-22 15:39:35.212]  Step 251928  [20.948 sec/step, loss=0.08103, avg_loss=0.07868]
[2018-11-22 15:39:54.916]  Step 251929  [20.952 sec/step, loss=0.07858, avg_loss=0.07867]
[2018-11-22 15:40:10.852]  Step 251930  [20.879 sec/step, loss=0.07748, avg_loss=0.07863]
[2018-11-22 15:40:24.836]  Step 251931  [20.797 sec/step, loss=0.07679, avg_loss=0.07859]
[2018-11-22 15:40:47.353]  Step 251932  [20.794 sec/step, loss=0.07986, avg_loss=0.07858]
[2018-11-22 15:41:12.591]  Step 251933  [20.870 sec/step, loss=0.08038, avg_loss=0.07858]
[2018-11-22 15:41:53.592]  Step 251934  [21.075 sec/step, loss=0.07065, avg_loss=0.07849]
[2018-11-22 15:42:16.533]  Step 251935  [21.161 sec/step, loss=0.08016, avg_loss=0.07852]
[2018-11-22 15:42:38.851]  Step 251936  [21.229 sec/step, loss=0.08030, avg_loss=0.07855]
[2018-11-22 15:42:56.687]  Step 251937  [21.207 sec/step, loss=0.07856, avg_loss=0.07854]
[2018-11-22 15:43:18.777]  Step 251938  [21.216 sec/step, loss=0.07978, avg_loss=0.07853]
[2018-11-22 15:43:43.452]  Step 251939  [21.028 sec/step, loss=0.08149, avg_loss=0.07863]
[2018-11-22 15:44:07.075]  Step 251940  [21.010 sec/step, loss=0.07947, avg_loss=0.07861]
[2018-11-22 15:44:28.832]  Step 251941  [21.042 sec/step, loss=0.08050, avg_loss=0.07861]
[2018-11-22 15:44:52.891]  Step 251942  [21.062 sec/step, loss=0.08069, avg_loss=0.07862]
[2018-11-22 15:45:14.503]  Step 251943  [21.053 sec/step, loss=0.08049, avg_loss=0.07861]
[2018-11-22 15:45:35.457]  Step 251944  [21.018 sec/step, loss=0.08041, avg_loss=0.07861]
[2018-11-22 15:45:56.565]  Step 251945  [20.992 sec/step, loss=0.07895, avg_loss=0.07860]
[2018-11-22 15:46:05.394]  Generated 32 batches of size 32 in 8.018 sec
[2018-11-22 15:46:06.960]  Step 251946  [20.858 sec/step, loss=0.05855, avg_loss=0.07838]
[2018-11-22 15:46:23.522]  Step 251947  [20.745 sec/step, loss=0.07706, avg_loss=0.07836]
[2018-11-22 15:46:50.050]  Step 251948  [20.809 sec/step, loss=0.07992, avg_loss=0.07835]
[2018-11-22 15:47:15.046]  Step 251949  [20.899 sec/step, loss=0.07917, avg_loss=0.07837]
[2018-11-22 15:47:34.397]  Step 251950  [20.843 sec/step, loss=0.07945, avg_loss=0.07835]
[2018-11-22 15:47:34.397]  Writing summary at step: 251950
[2018-11-22 15:48:18.581]  Step 251951  [20.912 sec/step, loss=0.07920, avg_loss=0.07840]
[2018-11-22 15:48:35.516]  Step 251952  [20.986 sec/step, loss=0.07905, avg_loss=0.07858]
[2018-11-22 15:48:59.944]  Step 251953  [21.045 sec/step, loss=0.08046, avg_loss=0.07859]
[2018-11-22 15:49:22.716]  Step 251954  [21.043 sec/step, loss=0.08031, avg_loss=0.07859]
[2018-11-22 15:50:03.165]  Step 251955  [21.325 sec/step, loss=0.07103, avg_loss=0.07854]
[2018-11-22 15:50:25.317]  Step 251956  [21.295 sec/step, loss=0.08021, avg_loss=0.07853]
[2018-11-22 15:50:44.294]  Step 251957  [21.236 sec/step, loss=0.07902, avg_loss=0.07852]
[2018-11-22 15:51:11.166]  Step 251958  [21.302 sec/step, loss=0.07881, avg_loss=0.07851]
[2018-11-22 15:51:34.103]  Step 251959  [21.311 sec/step, loss=0.08122, avg_loss=0.07851]
[2018-11-22 15:51:44.427]  Step 251960  [21.174 sec/step, loss=0.07095, avg_loss=0.07841]
[2018-11-22 15:52:08.892]  Step 251961  [21.176 sec/step, loss=0.08096, avg_loss=0.07842]
[2018-11-22 15:52:21.785]  Step 251962  [21.199 sec/step, loss=0.07711, avg_loss=0.07848]
[2018-11-22 15:52:44.691]  Step 251963  [21.211 sec/step, loss=0.08022, avg_loss=0.07848]
[2018-11-22 15:52:52.922]  Step 251964  [21.210 sec/step, loss=0.06083, avg_loss=0.07848]
[2018-11-22 15:53:11.913]  Step 251965  [21.132 sec/step, loss=0.07916, avg_loss=0.07847]
[2018-11-22 15:53:35.474]  Step 251966  [21.178 sec/step, loss=0.07945, avg_loss=0.07847]
[2018-11-22 15:53:56.410]  Step 251967  [21.199 sec/step, loss=0.08115, avg_loss=0.07849]
[2018-11-22 15:54:20.611]  Step 251968  [21.244 sec/step, loss=0.07995, avg_loss=0.07849]
[2018-11-22 15:54:42.074]  Step 251969  [21.215 sec/step, loss=0.07998, avg_loss=0.07848]
[2018-11-22 15:55:05.013]  Step 251970  [21.267 sec/step, loss=0.08001, avg_loss=0.07849]
[2018-11-22 15:55:21.236]  Step 251971  [21.192 sec/step, loss=0.07648, avg_loss=0.07845]
[2018-11-22 15:55:38.238]  Step 251972  [21.158 sec/step, loss=0.07847, avg_loss=0.07843]
[2018-11-22 15:55:58.131]  Step 251973  [21.140 sec/step, loss=0.07926, avg_loss=0.07841]
[2018-11-22 15:56:20.046]  Step 251974  [21.154 sec/step, loss=0.07972, avg_loss=0.07841]
[2018-11-22 15:56:37.187]  Step 251975  [21.168 sec/step, loss=0.07885, avg_loss=0.07842]
[2018-11-22 15:57:02.459]  Step 251976  [21.185 sec/step, loss=0.08041, avg_loss=0.07842]
[2018-11-22 15:57:11.891]  Generated 32 batches of size 32 in 8.650 sec
[2018-11-22 15:57:22.482]  Step 251977  [21.244 sec/step, loss=0.08017, avg_loss=0.07845]
[2018-11-22 15:57:33.651]  Step 251978  [21.143 sec/step, loss=0.07626, avg_loss=0.07841]
[2018-11-22 15:57:55.401]  Step 251979  [21.107 sec/step, loss=0.08022, avg_loss=0.07840]
[2018-11-22 15:58:15.534]  Step 251980  [21.184 sec/step, loss=0.07929, avg_loss=0.07844]
[2018-11-22 15:58:30.265]  Step 251981  [21.160 sec/step, loss=0.07545, avg_loss=0.07839]
[2018-11-22 15:59:00.844]  Step 251982  [21.232 sec/step, loss=0.08062, avg_loss=0.07838]
[2018-11-22 15:59:24.752]  Step 251983  [21.252 sec/step, loss=0.07957, avg_loss=0.07838]
[2018-11-22 15:59:49.443]  Step 251984  [21.099 sec/step, loss=0.07999, avg_loss=0.07847]
[2018-11-22 16:00:11.740]  Step 251985  [21.167 sec/step, loss=0.08171, avg_loss=0.07852]
[2018-11-22 16:00:36.637]  Step 251986  [21.173 sec/step, loss=0.08025, avg_loss=0.07851]
[2018-11-22 16:00:59.488]  Step 251987  [21.173 sec/step, loss=0.07979, avg_loss=0.07850]
[2018-11-22 16:01:12.144]  Step 251988  [21.034 sec/step, loss=0.07587, avg_loss=0.07846]
[2018-11-22 16:01:34.958]  Step 251989  [21.041 sec/step, loss=0.08078, avg_loss=0.07846]
[2018-11-22 16:02:00.603]  Step 251990  [21.051 sec/step, loss=0.07950, avg_loss=0.07845]
[2018-11-22 16:02:25.420]  Step 251991  [21.070 sec/step, loss=0.08001, avg_loss=0.07845]
[2018-11-22 16:02:42.054]  Step 251992  [20.973 sec/step, loss=0.07902, avg_loss=0.07843]
[2018-11-22 16:02:52.553]  Step 251993  [20.834 sec/step, loss=0.07233, avg_loss=0.07835]
[2018-11-22 16:03:17.028]  Step 251994  [20.828 sec/step, loss=0.08078, avg_loss=0.07835]
[2018-11-22 16:03:38.252]  Step 251995  [20.810 sec/step, loss=0.07965, avg_loss=0.07835]
[2018-11-22 16:03:57.607]  Step 251996  [20.864 sec/step, loss=0.07924, avg_loss=0.07837]
[2018-11-22 16:04:21.859]  Step 251997  [20.947 sec/step, loss=0.07933, avg_loss=0.07840]
[2018-11-22 16:04:44.409]  Step 251998  [20.949 sec/step, loss=0.07990, avg_loss=0.07840]
[2018-11-22 16:05:26.229]  Step 251999  [21.162 sec/step, loss=0.07107, avg_loss=0.07831]
[2018-11-22 16:05:42.388]  Step 252000  [21.082 sec/step, loss=0.07699, avg_loss=0.07827]
[2018-11-22 16:05:42.389]  Writing summary at step: 252000
[2018-11-22 16:05:56.956]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-252000
[2018-11-22 16:06:00.349]  Saving audio and alignment...
[2018-11-22 16:06:16.841]  Input: wicked and cruel boy! {AY1} said. you are like a murderer--you are {L AY1 K} a slave-driver--you are like the roman emperors! i had read {G OW1 L D S M IH2 TH S} history of rome, and {HH AE1 D} formed my opinion of nero, caligula, etc.~_________________
[2018-11-22 16:06:36.833]  Step 252001  [21.097 sec/step, loss=0.07888, avg_loss=0.07826]
[2018-11-22 16:07:01.516]  Step 252002  [21.132 sec/step, loss=0.08002, avg_loss=0.07825]
[2018-11-22 16:07:25.032]  Step 252003  [21.123 sec/step, loss=0.08110, avg_loss=0.07826]
[2018-11-22 16:07:42.686]  Step 252004  [21.078 sec/step, loss=0.07885, avg_loss=0.07824]
[2018-11-22 16:08:07.675]  Step 252005  [21.138 sec/step, loss=0.08107, avg_loss=0.07826]
[2018-11-22 16:08:23.898]  Step 252006  [21.214 sec/step, loss=0.07792, avg_loss=0.07845]
[2018-11-22 16:08:33.863]  Generated 32 batches of size 32 in 9.050 sec
[2018-11-22 16:08:47.652]  Step 252007  [21.205 sec/step, loss=0.07959, avg_loss=0.07844]
[2018-11-22 16:08:56.267]  Step 252008  [21.087 sec/step, loss=0.06004, avg_loss=0.07824]
[2018-11-22 16:09:15.984]  Step 252009  [20.896 sec/step, loss=0.07849, avg_loss=0.07831]
[2018-11-22 16:09:35.982]  Step 252010  [20.925 sec/step, loss=0.07910, avg_loss=0.07831]
[2018-11-22 16:09:58.844]  Step 252011  [20.915 sec/step, loss=0.08051, avg_loss=0.07830]
[2018-11-22 16:10:20.584]  Step 252012  [20.911 sec/step, loss=0.08035, avg_loss=0.07831]
[2018-11-22 16:10:42.226]  Step 252013  [21.021 sec/step, loss=0.07990, avg_loss=0.07839]
[2018-11-22 16:11:01.141]  Step 252014  [20.980 sec/step, loss=0.07945, avg_loss=0.07838]
[2018-11-22 16:11:22.229]  Step 252015  [20.966 sec/step, loss=0.08006, avg_loss=0.07838]
[2018-11-22 16:11:42.428]  Step 252016  [20.914 sec/step, loss=0.07857, avg_loss=0.07835]
[2018-11-22 16:12:04.014]  Step 252017  [20.930 sec/step, loss=0.07870, avg_loss=0.07834]
[2018-11-22 16:12:23.261]  Step 252018  [20.899 sec/step, loss=0.07966, avg_loss=0.07834]
[2018-11-22 16:12:47.101]  Step 252019  [20.983 sec/step, loss=0.07895, avg_loss=0.07835]
[2018-11-22 16:13:12.413]  Step 252020  [21.114 sec/step, loss=0.08056, avg_loss=0.07841]
[2018-11-22 16:13:34.526]  Step 252021  [21.098 sec/step, loss=0.07923, avg_loss=0.07840]
[2018-11-22 16:13:42.019]  Step 252022  [20.975 sec/step, loss=0.05955, avg_loss=0.07820]
[2018-11-22 16:14:04.470]  Step 252023  [21.093 sec/step, loss=0.07934, avg_loss=0.07827]
[2018-11-22 16:14:25.325]  Step 252024  [21.076 sec/step, loss=0.08030, avg_loss=0.07827]
[2018-11-22 16:14:49.931]  Step 252025  [21.136 sec/step, loss=0.08085, avg_loss=0.07827]
[2018-11-22 16:15:05.072]  Step 252026  [21.076 sec/step, loss=0.07590, avg_loss=0.07823]
[2018-11-22 16:15:26.160]  Step 252027  [21.165 sec/step, loss=0.08033, avg_loss=0.07827]
[2018-11-22 16:15:45.078]  Step 252028  [21.109 sec/step, loss=0.07910, avg_loss=0.07825]
[2018-11-22 16:16:09.663]  Step 252029  [21.158 sec/step, loss=0.08037, avg_loss=0.07827]
[2018-11-22 16:16:25.534]  Step 252030  [21.158 sec/step, loss=0.07706, avg_loss=0.07826]
[2018-11-22 16:16:50.414]  Step 252031  [21.266 sec/step, loss=0.07924, avg_loss=0.07829]
[2018-11-22 16:17:12.202]  Step 252032  [21.259 sec/step, loss=0.08031, avg_loss=0.07829]
[2018-11-22 16:17:34.268]  Step 252033  [21.227 sec/step, loss=0.07999, avg_loss=0.07829]
[2018-11-22 16:18:00.078]  Step 252034  [21.076 sec/step, loss=0.07957, avg_loss=0.07838]
[2018-11-22 16:18:18.245]  Step 252035  [21.028 sec/step, loss=0.07891, avg_loss=0.07837]
[2018-11-22 16:18:41.067]  Step 252036  [21.033 sec/step, loss=0.08048, avg_loss=0.07837]
[2018-11-22 16:18:58.038]  Step 252037  [21.024 sec/step, loss=0.07843, avg_loss=0.07837]
[2018-11-22 16:19:11.803]  Step 252038  [20.941 sec/step, loss=0.07709, avg_loss=0.07834]
[2018-11-22 16:19:20.996]  Generated 32 batches of size 32 in 8.390 sec
[2018-11-22 16:19:33.846]  Step 252039  [20.915 sec/step, loss=0.07906, avg_loss=0.07832]
[2018-11-22 16:19:58.051]  Step 252040  [20.920 sec/step, loss=0.07975, avg_loss=0.07832]
[2018-11-22 16:20:16.442]  Step 252041  [20.887 sec/step, loss=0.07918, avg_loss=0.07831]
[2018-11-22 16:20:37.110]  Step 252042  [20.853 sec/step, loss=0.07944, avg_loss=0.07829]
[2018-11-22 16:21:02.239]  Step 252043  [20.888 sec/step, loss=0.07973, avg_loss=0.07828]
[2018-11-22 16:21:25.132]  Step 252044  [20.907 sec/step, loss=0.07946, avg_loss=0.07828]
[2018-11-22 16:22:09.474]  Step 252045  [21.140 sec/step, loss=0.07030, avg_loss=0.07819]
[2018-11-22 16:22:20.056]  Step 252046  [21.142 sec/step, loss=0.07000, avg_loss=0.07830]
[2018-11-22 16:22:31.906]  Step 252047  [21.095 sec/step, loss=0.07523, avg_loss=0.07829]
[2018-11-22 16:22:57.187]  Step 252048  [21.082 sec/step, loss=0.08063, avg_loss=0.07829]
[2018-11-22 16:23:17.950]  Step 252049  [21.040 sec/step, loss=0.08022, avg_loss=0.07830]
[2018-11-22 16:23:41.196]  Step 252050  [21.079 sec/step, loss=0.07950, avg_loss=0.07830]
[2018-11-22 16:23:41.196]  Writing summary at step: 252050
[2018-11-22 16:24:20.016]  Step 252051  [21.106 sec/step, loss=0.07993, avg_loss=0.07831]
[2018-11-22 16:24:38.249]  Step 252052  [21.118 sec/step, loss=0.07846, avg_loss=0.07830]
[2018-11-22 16:24:54.035]  Step 252053  [21.032 sec/step, loss=0.07764, avg_loss=0.07828]
[2018-11-22 16:25:14.304]  Step 252054  [21.007 sec/step, loss=0.07875, avg_loss=0.07826]
[2018-11-22 16:25:38.580]  Step 252055  [20.845 sec/step, loss=0.08013, avg_loss=0.07835]
[2018-11-22 16:26:02.775]  Step 252056  [20.866 sec/step, loss=0.07990, avg_loss=0.07835]
[2018-11-22 16:26:13.323]  Step 252057  [20.781 sec/step, loss=0.07340, avg_loss=0.07829]
[2018-11-22 16:26:37.729]  Step 252058  [20.757 sec/step, loss=0.08039, avg_loss=0.07831]
[2018-11-22 16:26:57.341]  Step 252059  [20.724 sec/step, loss=0.07878, avg_loss=0.07828]
[2018-11-22 16:27:16.119]  Step 252060  [20.808 sec/step, loss=0.08036, avg_loss=0.07838]
[2018-11-22 16:27:38.367]  Step 252061  [20.786 sec/step, loss=0.08041, avg_loss=0.07837]
[2018-11-22 16:28:00.041]  Step 252062  [20.874 sec/step, loss=0.08011, avg_loss=0.07840]
[2018-11-22 16:28:20.612]  Step 252063  [20.850 sec/step, loss=0.08002, avg_loss=0.07840]
[2018-11-22 16:28:33.197]  Step 252064  [20.894 sec/step, loss=0.07534, avg_loss=0.07855]
[2018-11-22 16:28:57.529]  Step 252065  [20.947 sec/step, loss=0.08015, avg_loss=0.07856]
[2018-11-22 16:29:20.690]  Step 252066  [20.943 sec/step, loss=0.07990, avg_loss=0.07856]
[2018-11-22 16:29:44.232]  Step 252067  [20.969 sec/step, loss=0.08140, avg_loss=0.07856]
[2018-11-22 16:30:03.370]  Step 252068  [20.919 sec/step, loss=0.07870, avg_loss=0.07855]
[2018-11-22 16:30:42.754]  Step 252069  [21.098 sec/step, loss=0.07144, avg_loss=0.07846]
[2018-11-22 16:30:51.982]  Generated 32 batches of size 32 in 8.462 sec
[2018-11-22 16:31:06.934]  Step 252070  [21.110 sec/step, loss=0.08012, avg_loss=0.07847]
[2018-11-22 16:31:24.099]  Step 252071  [21.120 sec/step, loss=0.07895, avg_loss=0.07849]
[2018-11-22 16:31:47.504]  Step 252072  [21.184 sec/step, loss=0.08006, avg_loss=0.07851]
[2018-11-22 16:32:07.111]  Step 252073  [21.181 sec/step, loss=0.07887, avg_loss=0.07850]
[2018-11-22 16:32:32.034]  Step 252074  [21.211 sec/step, loss=0.07888, avg_loss=0.07849]
[2018-11-22 16:32:41.318]  Step 252075  [21.132 sec/step, loss=0.06117, avg_loss=0.07832]
[2018-11-22 16:32:55.560]  Step 252076  [21.022 sec/step, loss=0.07751, avg_loss=0.07829]
[2018-11-22 16:33:22.096]  Step 252077  [21.087 sec/step, loss=0.08075, avg_loss=0.07829]
[2018-11-22 16:33:43.820]  Step 252078  [21.193 sec/step, loss=0.07963, avg_loss=0.07833]
[2018-11-22 16:34:04.125]  Step 252079  [21.178 sec/step, loss=0.07915, avg_loss=0.07832]
[2018-11-22 16:34:25.933]  Step 252080  [21.195 sec/step, loss=0.07943, avg_loss=0.07832]
[2018-11-22 16:34:49.297]  Step 252081  [21.281 sec/step, loss=0.07955, avg_loss=0.07836]
[2018-11-22 16:35:12.312]  Step 252082  [21.206 sec/step, loss=0.08037, avg_loss=0.07836]
[2018-11-22 16:35:33.777]  Step 252083  [21.181 sec/step, loss=0.07953, avg_loss=0.07836]
[2018-11-22 16:35:56.296]  Step 252084  [21.160 sec/step, loss=0.07938, avg_loss=0.07835]
[2018-11-22 16:36:19.719]  Step 252085  [21.171 sec/step, loss=0.07911, avg_loss=0.07832]
[2018-11-22 16:36:33.451]  Step 252086  [21.059 sec/step, loss=0.07605, avg_loss=0.07828]
[2018-11-22 16:36:56.161]  Step 252087  [21.058 sec/step, loss=0.08020, avg_loss=0.07829]
[2018-11-22 16:37:11.504]  Step 252088  [21.085 sec/step, loss=0.07683, avg_loss=0.07830]
[2018-11-22 16:37:27.252]  Step 252089  [21.014 sec/step, loss=0.07531, avg_loss=0.07824]
[2018-11-22 16:37:48.124]  Step 252090  [20.966 sec/step, loss=0.08022, avg_loss=0.07825]
[2018-11-22 16:38:12.360]  Step 252091  [20.961 sec/step, loss=0.08051, avg_loss=0.07825]
[2018-11-22 16:38:40.511]  Step 252092  [21.076 sec/step, loss=0.07993, avg_loss=0.07826]
[2018-11-22 16:38:51.078]  Step 252093  [21.076 sec/step, loss=0.05946, avg_loss=0.07813]
[2018-11-22 16:39:05.143]  Step 252094  [20.972 sec/step, loss=0.07475, avg_loss=0.07807]
[2018-11-22 16:39:28.662]  Step 252095  [20.995 sec/step, loss=0.07908, avg_loss=0.07807]
[2018-11-22 16:39:49.101]  Step 252096  [21.006 sec/step, loss=0.07878, avg_loss=0.07806]
[2018-11-22 16:40:00.527]  Step 252097  [20.878 sec/step, loss=0.07013, avg_loss=0.07797]
[2018-11-22 16:40:21.134]  Step 252098  [20.858 sec/step, loss=0.07870, avg_loss=0.07796]
[2018-11-22 16:40:44.560]  Step 252099  [20.674 sec/step, loss=0.07931, avg_loss=0.07804]
[2018-11-22 16:41:10.556]  Step 252100  [20.773 sec/step, loss=0.07890, avg_loss=0.07806]
[2018-11-22 16:41:10.556]  Writing summary at step: 252100
[2018-11-22 16:41:50.220]  Generated 32 batches of size 32 in 16.207 sec
[2018-11-22 16:42:19.043]  Step 252101  [21.032 sec/step, loss=0.07998, avg_loss=0.07807]
[2018-11-22 16:43:00.454]  Step 252102  [21.199 sec/step, loss=0.07943, avg_loss=0.07807]
[2018-11-22 16:43:36.577]  Step 252103  [21.325 sec/step, loss=0.08084, avg_loss=0.07806]
[2018-11-22 16:44:09.567]  Step 252104  [21.479 sec/step, loss=0.07934, avg_loss=0.07807]
[2018-11-22 16:44:46.462]  Step 252105  [21.598 sec/step, loss=0.08018, avg_loss=0.07806]
[2018-11-22 16:45:15.583]  Step 252106  [21.727 sec/step, loss=0.07863, avg_loss=0.07807]
[2018-11-22 16:45:55.721]  Step 252107  [21.891 sec/step, loss=0.07867, avg_loss=0.07806]
[2018-11-22 16:46:43.489]  Step 252108  [22.282 sec/step, loss=0.07056, avg_loss=0.07816]
[2018-11-22 16:47:16.421]  Step 252109  [22.414 sec/step, loss=0.07993, avg_loss=0.07818]
[2018-11-22 16:47:53.718]  Step 252110  [22.587 sec/step, loss=0.07885, avg_loss=0.07817]
[2018-11-22 16:48:21.740]  Step 252111  [22.639 sec/step, loss=0.07890, avg_loss=0.07816]
[2018-11-22 16:48:51.989]  Step 252112  [22.724 sec/step, loss=0.07999, avg_loss=0.07816]
[2018-11-22 16:49:27.868]  Step 252113  [22.866 sec/step, loss=0.08030, avg_loss=0.07816]
[2018-11-22 16:50:03.442]  Step 252114  [23.033 sec/step, loss=0.08045, avg_loss=0.07817]
[2018-11-22 16:50:32.633]  Step 252115  [23.114 sec/step, loss=0.07948, avg_loss=0.07816]
[2018-11-22 16:51:00.569]  Step 252116  [23.191 sec/step, loss=0.07905, avg_loss=0.07817]
[2018-11-22 16:51:32.695]  Step 252117  [23.297 sec/step, loss=0.07881, avg_loss=0.07817]
[2018-11-22 16:51:56.213]  Step 252118  [23.340 sec/step, loss=0.07822, avg_loss=0.07815]
[2018-11-22 16:52:24.535]  Step 252119  [23.384 sec/step, loss=0.07941, avg_loss=0.07816]
[2018-11-22 16:52:53.462]  Step 252120  [23.420 sec/step, loss=0.07982, avg_loss=0.07815]
[2018-11-22 16:53:26.468]  Step 252121  [23.529 sec/step, loss=0.08002, avg_loss=0.07816]
[2018-11-22 16:53:52.513]  Step 252122  [23.715 sec/step, loss=0.07874, avg_loss=0.07835]
[2018-11-22 16:54:19.556]  Step 252123  [23.761 sec/step, loss=0.07909, avg_loss=0.07835]
[2018-11-22 16:54:43.520]  Step 252124  [23.792 sec/step, loss=0.07933, avg_loss=0.07834]
[2018-11-22 16:55:35.355]  Step 252125  [24.064 sec/step, loss=0.07017, avg_loss=0.07823]
[2018-11-22 16:56:01.475]  Step 252126  [24.174 sec/step, loss=0.08007, avg_loss=0.07827]
[2018-11-22 16:56:33.118]  Step 252127  [24.280 sec/step, loss=0.07917, avg_loss=0.07826]
[2018-11-22 16:56:46.625]  Step 252128  [24.225 sec/step, loss=0.07082, avg_loss=0.07818]
[2018-11-22 16:57:07.027]  Step 252129  [24.184 sec/step, loss=0.07818, avg_loss=0.07816]
[2018-11-22 16:57:23.708]  Step 252130  [24.192 sec/step, loss=0.07583, avg_loss=0.07815]
[2018-11-22 16:57:50.226]  Step 252131  [24.208 sec/step, loss=0.07934, avg_loss=0.07815]
[2018-11-22 16:58:13.024]  Step 252132  [24.218 sec/step, loss=0.07860, avg_loss=0.07813]
[2018-11-22 16:58:27.040]  Generated 32 batches of size 32 in 12.910 sec
[2018-11-22 16:58:45.403]  Step 252133  [24.321 sec/step, loss=0.07987, avg_loss=0.07813]
[2018-11-22 16:59:21.363]  Step 252134  [24.423 sec/step, loss=0.07986, avg_loss=0.07813]
[2018-11-22 16:59:44.998]  Step 252135  [24.478 sec/step, loss=0.07630, avg_loss=0.07811]
[2018-11-22 17:00:04.755]  Step 252136  [24.447 sec/step, loss=0.07470, avg_loss=0.07805]
[2018-11-22 17:00:36.430]  Step 252137  [24.594 sec/step, loss=0.07904, avg_loss=0.07805]
[2018-11-22 17:01:07.450]  Step 252138  [24.766 sec/step, loss=0.07542, avg_loss=0.07804]
[2018-11-22 17:01:49.302]  Step 252139  [24.965 sec/step, loss=0.07921, avg_loss=0.07804]
[2018-11-22 17:02:11.781]  Step 252140  [24.947 sec/step, loss=0.07877, avg_loss=0.07803]
[2018-11-22 17:02:21.231]  Step 252141  [24.858 sec/step, loss=0.06162, avg_loss=0.07785]
[2018-11-22 17:02:48.233]  Step 252142  [24.921 sec/step, loss=0.07938, avg_loss=0.07785]
[2018-11-22 17:03:16.548]  Step 252143  [24.953 sec/step, loss=0.07946, avg_loss=0.07785]
[2018-11-22 17:03:42.095]  Step 252144  [24.980 sec/step, loss=0.07974, avg_loss=0.07785]
[2018-11-22 17:04:08.946]  Step 252145  [24.805 sec/step, loss=0.07944, avg_loss=0.07794]
[2018-11-22 17:04:31.207]  Step 252146  [24.922 sec/step, loss=0.07907, avg_loss=0.07803]
[2018-11-22 17:04:44.277]  Step 252147  [24.934 sec/step, loss=0.07031, avg_loss=0.07799]
[2018-11-22 17:05:06.636]  Step 252148  [24.904 sec/step, loss=0.07832, avg_loss=0.07796]
[2018-11-22 17:05:25.277]  Step 252149  [24.883 sec/step, loss=0.07538, avg_loss=0.07791]
[2018-11-22 17:05:46.820]  Step 252150  [24.866 sec/step, loss=0.07838, avg_loss=0.07790]
[2018-11-22 17:05:46.821]  Writing summary at step: 252150
[2018-11-22 17:06:40.142]  Step 252151  [24.893 sec/step, loss=0.07948, avg_loss=0.07790]
[2018-11-22 17:07:08.061]  Step 252152  [24.990 sec/step, loss=0.07963, avg_loss=0.07791]
[2018-11-22 17:07:27.940]  Step 252153  [25.031 sec/step, loss=0.07795, avg_loss=0.07791]
[2018-11-22 17:07:50.757]  Step 252154  [25.056 sec/step, loss=0.07870, avg_loss=0.07791]
[2018-11-22 17:08:00.295]  Step 252155  [24.909 sec/step, loss=0.05980, avg_loss=0.07771]
[2018-11-22 17:08:28.306]  Step 252156  [24.947 sec/step, loss=0.07977, avg_loss=0.07771]
[2018-11-22 17:08:42.100]  Step 252157  [24.979 sec/step, loss=0.07532, avg_loss=0.07773]
[2018-11-22 17:09:13.318]  Step 252158  [25.047 sec/step, loss=0.07950, avg_loss=0.07772]
[2018-11-22 17:09:32.229]  Step 252159  [25.040 sec/step, loss=0.07543, avg_loss=0.07768]
[2018-11-22 17:09:59.349]  Step 252160  [25.124 sec/step, loss=0.07955, avg_loss=0.07768]
[2018-11-22 17:10:25.654]  Step 252161  [25.164 sec/step, loss=0.07933, avg_loss=0.07767]
[2018-11-22 17:11:03.352]  Step 252162  [25.325 sec/step, loss=0.08038, avg_loss=0.07767]
[2018-11-22 17:11:38.953]  Step 252163  [25.475 sec/step, loss=0.07913, avg_loss=0.07766]
[2018-11-22 17:11:51.901]  Generated 32 batches of size 32 in 11.414 sec
[2018-11-22 17:12:01.290]  Step 252164  [25.572 sec/step, loss=0.07639, avg_loss=0.07767]
[2018-11-22 17:12:31.637]  Step 252165  [25.633 sec/step, loss=0.07985, avg_loss=0.07767]
[2018-11-22 17:13:05.441]  Step 252166  [25.739 sec/step, loss=0.07948, avg_loss=0.07766]
[2018-11-22 17:13:35.628]  Step 252167  [25.805 sec/step, loss=0.07822, avg_loss=0.07763]
[2018-11-22 17:14:29.686]  Step 252168  [26.155 sec/step, loss=0.07069, avg_loss=0.07755]
[2018-11-22 17:15:06.569]  Step 252169  [26.130 sec/step, loss=0.08069, avg_loss=0.07764]
[2018-11-22 17:15:47.680]  Step 252170  [26.299 sec/step, loss=0.07920, avg_loss=0.07763]
[2018-11-22 17:16:21.329]  Step 252171  [26.464 sec/step, loss=0.07896, avg_loss=0.07763]
[2018-11-22 17:16:40.929]  Step 252172  [26.426 sec/step, loss=0.07849, avg_loss=0.07762]
[2018-11-22 17:17:06.042]  Step 252173  [26.481 sec/step, loss=0.07866, avg_loss=0.07762]
[2018-11-22 17:17:22.364]  Step 252174  [26.395 sec/step, loss=0.07611, avg_loss=0.07759]
[2018-11-22 17:17:44.881]  Step 252175  [26.527 sec/step, loss=0.07869, avg_loss=0.07776]
[2018-11-22 17:18:09.175]  Step 252176  [26.628 sec/step, loss=0.08041, avg_loss=0.07779]
[2018-11-22 17:18:30.430]  Step 252177  [26.575 sec/step, loss=0.08007, avg_loss=0.07779]
[2018-11-22 17:18:53.047]  Step 252178  [26.584 sec/step, loss=0.07985, avg_loss=0.07779]
[2018-11-22 17:19:17.583]  Step 252179  [26.626 sec/step, loss=0.08003, avg_loss=0.07780]
[2018-11-22 17:19:28.212]  Step 252180  [26.514 sec/step, loss=0.07203, avg_loss=0.07772]
[2018-11-22 17:19:46.908]  Step 252181  [26.468 sec/step, loss=0.07918, avg_loss=0.07772]
[2018-11-22 17:20:09.512]  Step 252182  [26.463 sec/step, loss=0.07898, avg_loss=0.07771]
[2018-11-22 17:20:34.459]  Step 252183  [26.498 sec/step, loss=0.07922, avg_loss=0.07770]
[2018-11-22 17:20:52.133]  Step 252184  [26.450 sec/step, loss=0.07878, avg_loss=0.07770]
[2018-11-22 17:21:12.428]  Step 252185  [26.419 sec/step, loss=0.07829, avg_loss=0.07769]
[2018-11-22 17:21:28.812]  Step 252186  [26.445 sec/step, loss=0.07681, avg_loss=0.07770]
[2018-11-22 17:21:52.801]  Step 252187  [26.458 sec/step, loss=0.07881, avg_loss=0.07768]
[2018-11-22 17:22:15.738]  Step 252188  [26.534 sec/step, loss=0.07957, avg_loss=0.07771]
[2018-11-22 17:22:39.043]  Step 252189  [26.609 sec/step, loss=0.07925, avg_loss=0.07775]
[2018-11-22 17:23:06.409]  Step 252190  [26.674 sec/step, loss=0.07920, avg_loss=0.07774]
[2018-11-22 17:23:30.488]  Step 252191  [26.673 sec/step, loss=0.07943, avg_loss=0.07773]
[2018-11-22 17:23:44.720]  Step 252192  [26.534 sec/step, loss=0.07681, avg_loss=0.07770]
[2018-11-22 17:24:04.237]  Step 252193  [26.623 sec/step, loss=0.07807, avg_loss=0.07788]
[2018-11-22 17:24:24.915]  Step 252194  [26.689 sec/step, loss=0.07997, avg_loss=0.07794]
[2018-11-22 17:24:47.360]  Step 252195  [26.678 sec/step, loss=0.08030, avg_loss=0.07795]
[2018-11-22 17:25:01.641]  Generated 32 batches of size 32 in 13.435 sec
[2018-11-22 17:25:33.592]  Step 252196  [26.936 sec/step, loss=0.07013, avg_loss=0.07786]
[2018-11-22 17:26:00.691]  Step 252197  [27.093 sec/step, loss=0.07981, avg_loss=0.07796]
[2018-11-22 17:26:20.098]  Step 252198  [27.081 sec/step, loss=0.07825, avg_loss=0.07795]
[2018-11-22 17:26:38.722]  Step 252199  [27.033 sec/step, loss=0.07776, avg_loss=0.07794]
[2018-11-22 17:27:01.140]  Step 252200  [26.997 sec/step, loss=0.07830, avg_loss=0.07793]
[2018-11-22 17:27:01.140]  Writing summary at step: 252200
[2018-11-22 17:27:35.188]  Step 252201  [26.666 sec/step, loss=0.07425, avg_loss=0.07787]
[2018-11-22 17:27:44.343]  Step 252202  [26.343 sec/step, loss=0.05892, avg_loss=0.07767]
[2018-11-22 17:28:07.659]  Step 252203  [26.215 sec/step, loss=0.07944, avg_loss=0.07766]
[2018-11-22 17:28:32.038]  Step 252204  [26.129 sec/step, loss=0.07893, avg_loss=0.07765]
[2018-11-22 17:28:56.677]  Step 252205  [26.006 sec/step, loss=0.08010, avg_loss=0.07765]
[2018-11-22 17:29:22.102]  Step 252206  [25.969 sec/step, loss=0.07969, avg_loss=0.07766]
[2018-11-22 17:29:44.521]  Step 252207  [25.792 sec/step, loss=0.07904, avg_loss=0.07766]
[2018-11-22 17:30:05.070]  Step 252208  [25.520 sec/step, loss=0.07884, avg_loss=0.07775]
[2018-11-22 17:30:41.104]  Step 252209  [25.551 sec/step, loss=0.06984, avg_loss=0.07765]
[2018-11-22 17:31:00.366]  Step 252210  [25.371 sec/step, loss=0.07852, avg_loss=0.07764]
[2018-11-22 17:31:22.147]  Step 252211  [25.308 sec/step, loss=0.07946, avg_loss=0.07765]
[2018-11-22 17:31:36.283]  Step 252212  [25.147 sec/step, loss=0.07595, avg_loss=0.07761]
[2018-11-22 17:31:52.428]  Step 252213  [24.950 sec/step, loss=0.07490, avg_loss=0.07755]
[2018-11-22 17:32:15.257]  Step 252214  [24.822 sec/step, loss=0.07881, avg_loss=0.07754]
[2018-11-22 17:32:27.829]  Step 252215  [24.656 sec/step, loss=0.07449, avg_loss=0.07749]
[2018-11-22 17:32:49.831]  Step 252216  [24.597 sec/step, loss=0.07818, avg_loss=0.07748]
[2018-11-22 17:33:06.900]  Step 252217  [24.446 sec/step, loss=0.07824, avg_loss=0.07747]
[2018-11-22 17:33:33.254]  Step 252218  [24.475 sec/step, loss=0.07798, avg_loss=0.07747]
[2018-11-22 17:33:51.516]  Step 252219  [24.374 sec/step, loss=0.07726, avg_loss=0.07745]
[2018-11-22 17:34:15.336]  Step 252220  [24.323 sec/step, loss=0.07848, avg_loss=0.07744]
[2018-11-22 17:34:39.293]  Step 252221  [24.233 sec/step, loss=0.07935, avg_loss=0.07743]
[2018-11-22 17:35:04.092]  Step 252222  [24.220 sec/step, loss=0.07884, avg_loss=0.07743]
[2018-11-22 17:35:23.929]  Step 252223  [24.148 sec/step, loss=0.07778, avg_loss=0.07742]
[2018-11-22 17:35:49.005]  Step 252224  [24.159 sec/step, loss=0.07925, avg_loss=0.07742]
[2018-11-22 17:35:57.328]  Step 252225  [23.724 sec/step, loss=0.05938, avg_loss=0.07731]
[2018-11-22 17:36:12.980]  Step 252226  [23.619 sec/step, loss=0.07667, avg_loss=0.07728]
[2018-11-22 17:36:23.577]  Generated 32 batches of size 32 in 9.875 sec
[2018-11-22 17:36:40.370]  Step 252227  [23.577 sec/step, loss=0.07983, avg_loss=0.07728]
[2018-11-22 17:36:58.767]  Step 252228  [23.626 sec/step, loss=0.07914, avg_loss=0.07736]
[2018-11-22 17:37:21.629]  Step 252229  [23.650 sec/step, loss=0.07904, avg_loss=0.07737]
[2018-11-22 17:37:43.207]  Step 252230  [23.699 sec/step, loss=0.07912, avg_loss=0.07741]
[2018-11-22 17:38:06.222]  Step 252231  [23.664 sec/step, loss=0.07892, avg_loss=0.07740]
[2018-11-22 17:38:25.111]  Step 252232  [23.625 sec/step, loss=0.07838, avg_loss=0.07740]
[2018-11-22 17:38:47.014]  Step 252233  [23.520 sec/step, loss=0.07934, avg_loss=0.07739]
[2018-11-22 17:38:57.332]  Step 252234  [23.264 sec/step, loss=0.06974, avg_loss=0.07729]
[2018-11-22 17:39:17.555]  Step 252235  [23.230 sec/step, loss=0.07939, avg_loss=0.07732]
[2018-11-22 17:39:39.361]  Step 252236  [23.250 sec/step, loss=0.07941, avg_loss=0.07737]
[2018-11-22 17:40:00.877]  Step 252237  [23.149 sec/step, loss=0.07797, avg_loss=0.07736]
[2018-11-22 17:40:27.164]  Step 252238  [23.101 sec/step, loss=0.07883, avg_loss=0.07739]
[2018-11-22 17:40:48.841]  Step 252239  [22.900 sec/step, loss=0.07921, avg_loss=0.07739]
[2018-11-22 17:41:13.037]  Step 252240  [22.917 sec/step, loss=0.07878, avg_loss=0.07739]
[2018-11-22 17:41:34.960]  Step 252241  [23.042 sec/step, loss=0.07854, avg_loss=0.07756]
[2018-11-22 17:41:52.254]  Step 252242  [22.945 sec/step, loss=0.07857, avg_loss=0.07756]
[2018-11-22 17:42:15.051]  Step 252243  [22.889 sec/step, loss=0.07910, avg_loss=0.07755]
[2018-11-22 17:42:35.061]  Step 252244  [22.834 sec/step, loss=0.07890, avg_loss=0.07754]
[2018-11-22 17:42:43.971]  Step 252245  [22.655 sec/step, loss=0.05936, avg_loss=0.07734]
[2018-11-22 17:43:08.462]  Step 252246  [22.677 sec/step, loss=0.07956, avg_loss=0.07735]
[2018-11-22 17:43:33.323]  Step 252247  [22.795 sec/step, loss=0.07839, avg_loss=0.07743]
[2018-11-22 17:43:58.547]  Step 252248  [22.823 sec/step, loss=0.07992, avg_loss=0.07744]
[2018-11-22 17:44:18.805]  Step 252249  [22.840 sec/step, loss=0.07895, avg_loss=0.07748]
[2018-11-22 17:44:37.562]  Step 252250  [22.812 sec/step, loss=0.07799, avg_loss=0.07748]
[2018-11-22 17:44:37.562]  Writing summary at step: 252250
[2018-11-22 17:45:19.513]  Step 252251  [22.787 sec/step, loss=0.07902, avg_loss=0.07747]
[2018-11-22 17:45:37.760]  Step 252252  [22.690 sec/step, loss=0.07747, avg_loss=0.07745]
[2018-11-22 17:46:00.719]  Step 252253  [22.721 sec/step, loss=0.07909, avg_loss=0.07746]
[2018-11-22 17:46:24.897]  Step 252254  [22.734 sec/step, loss=0.07917, avg_loss=0.07747]
[2018-11-22 17:46:48.504]  Step 252255  [22.875 sec/step, loss=0.08006, avg_loss=0.07767]
[2018-11-22 17:47:12.634]  Step 252256  [22.836 sec/step, loss=0.07981, avg_loss=0.07767]
[2018-11-22 17:47:27.988]  Step 252257  [22.852 sec/step, loss=0.07523, avg_loss=0.07767]
[2018-11-22 17:47:38.591]  Generated 32 batches of size 32 in 9.750 sec
[2018-11-22 17:47:53.821]  Step 252258  [22.798 sec/step, loss=0.07935, avg_loss=0.07767]
[2018-11-22 17:48:17.988]  Step 252259  [22.851 sec/step, loss=0.07958, avg_loss=0.07771]
[2018-11-22 17:48:28.385]  Step 252260  [22.683 sec/step, loss=0.07238, avg_loss=0.07764]
[2018-11-22 17:48:48.070]  Step 252261  [22.617 sec/step, loss=0.07871, avg_loss=0.07763]
[2018-11-22 17:49:03.350]  Step 252262  [22.393 sec/step, loss=0.07652, avg_loss=0.07759]
[2018-11-22 17:49:15.373]  Step 252263  [22.157 sec/step, loss=0.07418, avg_loss=0.07754]
[2018-11-22 17:49:34.950]  Step 252264  [22.130 sec/step, loss=0.07761, avg_loss=0.07755]
[2018-11-22 17:49:48.648]  Step 252265  [21.963 sec/step, loss=0.07587, avg_loss=0.07752]
[2018-11-22 17:50:26.045]  Step 252266  [21.999 sec/step, loss=0.07050, avg_loss=0.07743]
[2018-11-22 17:50:39.923]  Step 252267  [21.836 sec/step, loss=0.07573, avg_loss=0.07740]
[2018-11-22 17:50:58.945]  Step 252268  [21.486 sec/step, loss=0.07773, avg_loss=0.07747]
[2018-11-22 17:51:17.443]  Step 252269  [21.302 sec/step, loss=0.07881, avg_loss=0.07745]
[2018-11-22 17:51:38.547]  Step 252270  [21.102 sec/step, loss=0.07888, avg_loss=0.07745]
[2018-11-22 17:51:46.865]  Step 252271  [20.848 sec/step, loss=0.05908, avg_loss=0.07725]
[2018-11-22 17:52:10.128]  Step 252272  [20.885 sec/step, loss=0.08038, avg_loss=0.07727]
[2018-11-22 17:52:22.197]  Step 252273  [20.755 sec/step, loss=0.07393, avg_loss=0.07722]
[2018-11-22 17:52:42.426]  Step 252274  [20.794 sec/step, loss=0.07812, avg_loss=0.07724]
[2018-11-22 17:53:06.393]  Step 252275  [20.808 sec/step, loss=0.07941, avg_loss=0.07725]
[2018-11-22 17:53:17.199]  Step 252276  [20.673 sec/step, loss=0.07080, avg_loss=0.07715]
[2018-11-22 17:53:39.370]  Step 252277  [20.682 sec/step, loss=0.07869, avg_loss=0.07714]
[2018-11-22 17:53:54.793]  Step 252278  [20.610 sec/step, loss=0.07477, avg_loss=0.07709]
[2018-11-22 17:54:10.208]  Step 252279  [20.519 sec/step, loss=0.07619, avg_loss=0.07705]
[2018-11-22 17:54:28.346]  Step 252280  [20.594 sec/step, loss=0.07796, avg_loss=0.07711]
[2018-11-22 17:54:47.802]  Step 252281  [20.602 sec/step, loss=0.07803, avg_loss=0.07710]
[2018-11-22 17:55:11.431]  Step 252282  [20.612 sec/step, loss=0.08004, avg_loss=0.07711]
[2018-11-22 17:55:38.882]  Step 252283  [20.637 sec/step, loss=0.07983, avg_loss=0.07711]
[2018-11-22 17:56:03.417]  Step 252284  [20.706 sec/step, loss=0.07906, avg_loss=0.07712]
[2018-11-22 17:56:25.420]  Step 252285  [20.723 sec/step, loss=0.08010, avg_loss=0.07714]
[2018-11-22 17:56:47.551]  Step 252286  [20.780 sec/step, loss=0.07910, avg_loss=0.07716]
[2018-11-22 17:57:11.383]  Step 252287  [20.779 sec/step, loss=0.07879, avg_loss=0.07716]
[2018-11-22 17:57:33.651]  Step 252288  [20.772 sec/step, loss=0.07862, avg_loss=0.07715]
[2018-11-22 17:58:00.586]  Step 252289  [20.808 sec/step, loss=0.07887, avg_loss=0.07714]
[2018-11-22 17:58:15.841]  Generated 32 batches of size 32 in 14.453 sec
[2018-11-22 17:58:47.509]  Step 252290  [21.004 sec/step, loss=0.07053, avg_loss=0.07706]
[2018-11-22 17:59:10.613]  Step 252291  [20.994 sec/step, loss=0.07978, avg_loss=0.07706]
[2018-11-22 17:59:37.658]  Step 252292  [21.122 sec/step, loss=0.07895, avg_loss=0.07708]
[2018-11-22 18:00:04.782]  Step 252293  [21.198 sec/step, loss=0.07906, avg_loss=0.07709]
[2018-11-22 18:00:32.115]  Step 252294  [21.265 sec/step, loss=0.07888, avg_loss=0.07708]
[2018-11-22 18:00:49.680]  Step 252295  [21.216 sec/step, loss=0.07798, avg_loss=0.07706]
[2018-11-22 18:01:14.487]  Step 252296  [21.002 sec/step, loss=0.07861, avg_loss=0.07714]
[2018-11-22 18:01:34.648]  Step 252297  [20.933 sec/step, loss=0.07845, avg_loss=0.07713]
[2018-11-22 18:01:55.593]  Step 252298  [20.948 sec/step, loss=0.07922, avg_loss=0.07714]
[2018-11-22 18:02:14.856]  Step 252299  [20.954 sec/step, loss=0.07854, avg_loss=0.07715]
[2018-11-22 18:02:35.845]  Step 252300  [20.940 sec/step, loss=0.07884, avg_loss=0.07715]
[2018-11-22 18:02:35.845]  Writing summary at step: 252300
[2018-11-22 18:03:23.931]  Step 252301  [21.031 sec/step, loss=0.07844, avg_loss=0.07719]
[2018-11-22 18:03:46.666]  Step 252302  [21.167 sec/step, loss=0.07896, avg_loss=0.07739]
[2018-11-22 18:04:01.836]  Step 252303  [21.086 sec/step, loss=0.07651, avg_loss=0.07737]
[2018-11-22 18:04:28.595]  Step 252304  [21.110 sec/step, loss=0.07859, avg_loss=0.07736]
[2018-11-22 18:04:46.877]  Step 252305  [21.046 sec/step, loss=0.07748, avg_loss=0.07734]
[2018-11-22 18:05:11.545]  Step 252306  [21.038 sec/step, loss=0.07951, avg_loss=0.07733]
[2018-11-22 18:05:31.837]  Step 252307  [21.017 sec/step, loss=0.07853, avg_loss=0.07733]
[2018-11-22 18:05:52.317]  Step 252308  [21.017 sec/step, loss=0.07782, avg_loss=0.07732]
[2018-11-22 18:06:03.484]  Step 252309  [20.768 sec/step, loss=0.07114, avg_loss=0.07733]
[2018-11-22 18:06:23.854]  Step 252310  [20.779 sec/step, loss=0.07765, avg_loss=0.07732]
[2018-11-22 18:06:45.500]  Step 252311  [20.778 sec/step, loss=0.07912, avg_loss=0.07732]
[2018-11-22 18:06:54.389]  Step 252312  [20.725 sec/step, loss=0.05798, avg_loss=0.07714]
[2018-11-22 18:07:13.767]  Step 252313  [20.757 sec/step, loss=0.07931, avg_loss=0.07718]
[2018-11-22 18:07:38.201]  Step 252314  [20.773 sec/step, loss=0.07894, avg_loss=0.07719]
[2018-11-22 18:07:58.952]  Step 252315  [20.855 sec/step, loss=0.07898, avg_loss=0.07723]
[2018-11-22 18:08:22.852]  Step 252316  [20.874 sec/step, loss=0.07891, avg_loss=0.07724]
[2018-11-22 18:08:46.630]  Step 252317  [20.941 sec/step, loss=0.07986, avg_loss=0.07725]
[2018-11-22 18:09:11.104]  Step 252318  [20.923 sec/step, loss=0.07915, avg_loss=0.07727]
[2018-11-22 18:09:50.294]  Step 252319  [21.132 sec/step, loss=0.06981, avg_loss=0.07719]
[2018-11-22 18:10:14.566]  Step 252320  [21.136 sec/step, loss=0.07868, avg_loss=0.07719]
[2018-11-22 18:10:24.254]  Generated 32 batches of size 32 in 8.855 sec
[2018-11-22 18:10:41.092]  Step 252321  [21.162 sec/step, loss=0.07951, avg_loss=0.07719]
[2018-11-22 18:11:04.654]  Step 252322  [21.150 sec/step, loss=0.07849, avg_loss=0.07719]
[2018-11-22 18:11:20.903]  Step 252323  [21.114 sec/step, loss=0.07498, avg_loss=0.07716]
[2018-11-22 18:11:38.932]  Step 252324  [21.043 sec/step, loss=0.07833, avg_loss=0.07715]
[2018-11-22 18:12:03.764]  Step 252325  [21.208 sec/step, loss=0.07961, avg_loss=0.07736]
[2018-11-22 18:12:26.263]  Step 252326  [21.277 sec/step, loss=0.07888, avg_loss=0.07738]
[2018-11-22 18:12:49.157]  Step 252327  [21.232 sec/step, loss=0.07908, avg_loss=0.07737]
[2018-11-22 18:13:01.644]  Step 252328  [21.173 sec/step, loss=0.07514, avg_loss=0.07733]
[2018-11-22 18:13:18.267]  Step 252329  [21.110 sec/step, loss=0.07612, avg_loss=0.07730]
[2018-11-22 18:13:41.310]  Step 252330  [21.125 sec/step, loss=0.07920, avg_loss=0.07730]
[2018-11-22 18:14:00.352]  Step 252331  [21.085 sec/step, loss=0.07897, avg_loss=0.07730]
[2018-11-22 18:14:19.337]  Step 252332  [21.086 sec/step, loss=0.07799, avg_loss=0.07730]
[2018-11-22 18:14:46.559]  Step 252333  [21.140 sec/step, loss=0.07849, avg_loss=0.07729]
[2018-11-22 18:15:00.410]  Step 252334  [21.175 sec/step, loss=0.07536, avg_loss=0.07735]
[2018-11-22 18:15:19.953]  Step 252335  [21.168 sec/step, loss=0.07787, avg_loss=0.07733]
[2018-11-22 18:15:37.884]  Step 252336  [21.129 sec/step, loss=0.07748, avg_loss=0.07731]
[2018-11-22 18:15:53.970]  Step 252337  [21.075 sec/step, loss=0.07583, avg_loss=0.07729]
[2018-11-22 18:16:11.011]  Step 252338  [20.983 sec/step, loss=0.07758, avg_loss=0.07728]
[2018-11-22 18:16:33.447]  Step 252339  [20.990 sec/step, loss=0.07796, avg_loss=0.07727]
[2018-11-22 18:16:42.558]  Step 252340  [20.839 sec/step, loss=0.05946, avg_loss=0.07707]
[2018-11-22 18:17:09.603]  Step 252341  [20.890 sec/step, loss=0.07854, avg_loss=0.07707]
[2018-11-22 18:17:35.844]  Step 252342  [20.980 sec/step, loss=0.07908, avg_loss=0.07708]
[2018-11-22 18:17:58.453]  Step 252343  [20.978 sec/step, loss=0.07910, avg_loss=0.07708]
[2018-11-22 18:18:23.413]  Step 252344  [21.028 sec/step, loss=0.07867, avg_loss=0.07708]
[2018-11-22 18:18:44.368]  Step 252345  [21.148 sec/step, loss=0.07925, avg_loss=0.07727]
[2018-11-22 18:19:06.006]  Step 252346  [21.119 sec/step, loss=0.07890, avg_loss=0.07727]
[2018-11-22 18:19:51.341]  Step 252347  [21.324 sec/step, loss=0.06986, avg_loss=0.07718]
[2018-11-22 18:20:03.840]  Step 252348  [21.197 sec/step, loss=0.07379, avg_loss=0.07712]
[2018-11-22 18:20:24.623]  Step 252349  [21.202 sec/step, loss=0.07946, avg_loss=0.07713]
[2018-11-22 18:20:49.786]  Step 252350  [21.266 sec/step, loss=0.07966, avg_loss=0.07714]
[2018-11-22 18:20:49.786]  Writing summary at step: 252350
[2018-11-22 18:21:25.248]  Step 252351  [21.287 sec/step, loss=0.07850, avg_loss=0.07714]
[2018-11-22 18:21:34.929]  Generated 32 batches of size 32 in 8.697 sec
[2018-11-22 18:21:42.585]  Step 252352  [21.277 sec/step, loss=0.07467, avg_loss=0.07711]
[2018-11-22 18:22:02.604]  Step 252353  [21.248 sec/step, loss=0.07812, avg_loss=0.07710]
[2018-11-22 18:22:28.564]  Step 252354  [21.266 sec/step, loss=0.07919, avg_loss=0.07710]
[2018-11-22 18:22:49.453]  Step 252355  [21.239 sec/step, loss=0.07923, avg_loss=0.07709]
[2018-11-22 18:23:11.651]  Step 252356  [21.219 sec/step, loss=0.07777, avg_loss=0.07707]
[2018-11-22 18:23:35.705]  Step 252357  [21.306 sec/step, loss=0.07894, avg_loss=0.07711]
[2018-11-22 18:23:58.602]  Step 252358  [21.277 sec/step, loss=0.07963, avg_loss=0.07711]
[2018-11-22 18:24:23.851]  Step 252359  [21.288 sec/step, loss=0.07980, avg_loss=0.07711]
[2018-11-22 18:24:47.761]  Step 252360  [21.423 sec/step, loss=0.07860, avg_loss=0.07718]
[2018-11-22 18:25:03.059]  Step 252361  [21.379 sec/step, loss=0.07559, avg_loss=0.07714]
[2018-11-22 18:25:13.634]  Step 252362  [21.332 sec/step, loss=0.07031, avg_loss=0.07708]
[2018-11-22 18:25:21.959]  Step 252363  [21.295 sec/step, loss=0.05817, avg_loss=0.07692]
[2018-11-22 18:25:46.596]  Step 252364  [21.346 sec/step, loss=0.07888, avg_loss=0.07694]
[2018-11-22 18:26:05.958]  Step 252365  [21.402 sec/step, loss=0.07825, avg_loss=0.07696]
[2018-11-22 18:26:26.202]  Step 252366  [21.231 sec/step, loss=0.07848, avg_loss=0.07704]
[2018-11-22 18:26:38.700]  Step 252367  [21.217 sec/step, loss=0.07348, avg_loss=0.07702]
[2018-11-22 18:26:56.710]  Step 252368  [21.207 sec/step, loss=0.07749, avg_loss=0.07701]
[2018-11-22 18:27:19.160]  Step 252369  [21.246 sec/step, loss=0.07889, avg_loss=0.07701]
[2018-11-22 18:27:44.012]  Step 252370  [21.284 sec/step, loss=0.07841, avg_loss=0.07701]
[2018-11-22 18:28:23.828]  Step 252371  [21.599 sec/step, loss=0.07034, avg_loss=0.07712]
[2018-11-22 18:28:50.123]  Step 252372  [21.629 sec/step, loss=0.07788, avg_loss=0.07710]
[2018-11-22 18:29:13.057]  Step 252373  [21.738 sec/step, loss=0.07915, avg_loss=0.07715]
[2018-11-22 18:29:34.717]  Step 252374  [21.752 sec/step, loss=0.07824, avg_loss=0.07715]
[2018-11-22 18:29:54.827]  Step 252375  [21.714 sec/step, loss=0.07836, avg_loss=0.07714]
[2018-11-22 18:30:18.675]  Step 252376  [21.844 sec/step, loss=0.07982, avg_loss=0.07723]
[2018-11-22 18:30:43.393]  Step 252377  [21.869 sec/step, loss=0.07842, avg_loss=0.07723]
[2018-11-22 18:31:04.868]  Step 252378  [21.930 sec/step, loss=0.07892, avg_loss=0.07727]
[2018-11-22 18:31:26.607]  Step 252379  [21.993 sec/step, loss=0.07879, avg_loss=0.07730]
[2018-11-22 18:31:45.832]  Step 252380  [22.004 sec/step, loss=0.07827, avg_loss=0.07730]
[2018-11-22 18:32:06.647]  Step 252381  [22.018 sec/step, loss=0.07875, avg_loss=0.07731]
[2018-11-22 18:32:31.808]  Step 252382  [22.033 sec/step, loss=0.07949, avg_loss=0.07730]
[2018-11-22 18:32:56.336]  Step 252383  [22.004 sec/step, loss=0.07944, avg_loss=0.07730]
[2018-11-22 18:33:05.858]  Generated 32 batches of size 32 in 8.672 sec
[2018-11-22 18:33:11.699]  Step 252384  [21.912 sec/step, loss=0.07593, avg_loss=0.07726]
[2018-11-22 18:33:28.532]  Step 252385  [21.860 sec/step, loss=0.07816, avg_loss=0.07725]
[2018-11-22 18:33:44.348]  Step 252386  [21.797 sec/step, loss=0.07457, avg_loss=0.07720]
[2018-11-22 18:34:06.091]  Step 252387  [21.776 sec/step, loss=0.07866, avg_loss=0.07720]
[2018-11-22 18:34:30.004]  Step 252388  [21.793 sec/step, loss=0.07857, avg_loss=0.07720]
[2018-11-22 18:34:48.626]  Step 252389  [21.710 sec/step, loss=0.07797, avg_loss=0.07719]
[2018-11-22 18:35:08.819]  Step 252390  [21.442 sec/step, loss=0.07870, avg_loss=0.07727]
[2018-11-22 18:35:30.880]  Step 252391  [21.432 sec/step, loss=0.07893, avg_loss=0.07726]
[2018-11-22 18:35:56.313]  Step 252392  [21.416 sec/step, loss=0.07978, avg_loss=0.07727]
[2018-11-22 18:36:04.928]  Step 252393  [21.231 sec/step, loss=0.05968, avg_loss=0.07708]
[2018-11-22 18:36:26.564]  Step 252394  [21.174 sec/step, loss=0.07908, avg_loss=0.07708]
[2018-11-22 18:36:42.337]  Step 252395  [21.156 sec/step, loss=0.07594, avg_loss=0.07706]
[2018-11-22 18:37:05.266]  Step 252396  [21.137 sec/step, loss=0.07889, avg_loss=0.07706]
[2018-11-22 18:37:19.114]  Step 252397  [21.074 sec/step, loss=0.07546, avg_loss=0.07703]
[2018-11-22 18:37:40.044]  Step 252398  [21.074 sec/step, loss=0.07939, avg_loss=0.07703]
[2018-11-22 18:38:04.921]  Step 252399  [21.130 sec/step, loss=0.07799, avg_loss=0.07703]
[2018-11-22 18:38:26.664]  Step 252400  [21.137 sec/step, loss=0.07819, avg_loss=0.07702]
[2018-11-22 18:38:26.664]  Writing summary at step: 252400
[2018-11-22 18:39:06.297]  Step 252401  [21.114 sec/step, loss=0.07809, avg_loss=0.07702]
[2018-11-22 18:39:29.695]  Step 252402  [21.121 sec/step, loss=0.07847, avg_loss=0.07701]
[2018-11-22 18:39:52.666]  Step 252403  [21.199 sec/step, loss=0.07918, avg_loss=0.07704]
[2018-11-22 18:40:08.484]  Step 252404  [21.090 sec/step, loss=0.07450, avg_loss=0.07700]
[2018-11-22 18:40:32.677]  Step 252405  [21.149 sec/step, loss=0.07966, avg_loss=0.07702]
[2018-11-22 18:41:12.533]  Step 252406  [21.301 sec/step, loss=0.06994, avg_loss=0.07693]
[2018-11-22 18:41:31.336]  Step 252407  [21.286 sec/step, loss=0.07925, avg_loss=0.07693]
[2018-11-22 18:41:54.061]  Step 252408  [21.308 sec/step, loss=0.07839, avg_loss=0.07694]
[2018-11-22 18:42:18.244]  Step 252409  [21.438 sec/step, loss=0.07940, avg_loss=0.07702]
[2018-11-22 18:42:30.174]  Step 252410  [21.354 sec/step, loss=0.07417, avg_loss=0.07699]
[2018-11-22 18:42:55.635]  Step 252411  [21.392 sec/step, loss=0.07918, avg_loss=0.07699]
[2018-11-22 18:43:14.450]  Step 252412  [21.491 sec/step, loss=0.07738, avg_loss=0.07718]
[2018-11-22 18:43:31.345]  Step 252413  [21.467 sec/step, loss=0.07803, avg_loss=0.07717]
[2018-11-22 18:43:55.522]  Step 252414  [21.464 sec/step, loss=0.07882, avg_loss=0.07717]
[2018-11-22 18:44:06.320]  Generated 32 batches of size 32 in 9.897 sec
[2018-11-22 18:44:24.821]  Step 252415  [21.549 sec/step, loss=0.07887, avg_loss=0.07717]
[2018-11-22 18:44:42.836]  Step 252416  [21.491 sec/step, loss=0.07698, avg_loss=0.07715]
[2018-11-22 18:45:07.060]  Step 252417  [21.495 sec/step, loss=0.07904, avg_loss=0.07714]
[2018-11-22 18:45:17.510]  Step 252418  [21.355 sec/step, loss=0.07083, avg_loss=0.07705]
[2018-11-22 18:45:40.267]  Step 252419  [21.191 sec/step, loss=0.07829, avg_loss=0.07714]
[2018-11-22 18:46:02.137]  Step 252420  [21.166 sec/step, loss=0.07879, avg_loss=0.07714]
[2018-11-22 18:46:24.607]  Step 252421  [21.126 sec/step, loss=0.07844, avg_loss=0.07713]
[2018-11-22 18:46:46.362]  Step 252422  [21.108 sec/step, loss=0.07819, avg_loss=0.07713]
[2018-11-22 18:47:08.332]  Step 252423  [21.165 sec/step, loss=0.07870, avg_loss=0.07716]
[2018-11-22 18:47:20.327]  Step 252424  [21.105 sec/step, loss=0.07486, avg_loss=0.07713]
[2018-11-22 18:47:39.875]  Step 252425  [21.052 sec/step, loss=0.07750, avg_loss=0.07711]
[2018-11-22 18:47:57.695]  Step 252426  [21.005 sec/step, loss=0.07694, avg_loss=0.07709]
[2018-11-22 18:48:18.042]  Step 252427  [20.980 sec/step, loss=0.07827, avg_loss=0.07708]
[2018-11-22 18:48:39.488]  Step 252428  [21.069 sec/step, loss=0.07863, avg_loss=0.07712]
[2018-11-22 18:49:02.550]  Step 252429  [21.134 sec/step, loss=0.07814, avg_loss=0.07714]
[2018-11-22 18:49:25.074]  Step 252430  [21.128 sec/step, loss=0.07821, avg_loss=0.07713]
[2018-11-22 18:49:49.226]  Step 252431  [21.180 sec/step, loss=0.07933, avg_loss=0.07713]
[2018-11-22 18:49:59.819]  Step 252432  [21.096 sec/step, loss=0.07122, avg_loss=0.07706]
[2018-11-22 18:50:21.205]  Step 252433  [21.037 sec/step, loss=0.07830, avg_loss=0.07706]
[2018-11-22 18:50:45.439]  Step 252434  [21.141 sec/step, loss=0.07858, avg_loss=0.07709]
[2018-11-22 18:51:02.497]  Step 252435  [21.116 sec/step, loss=0.07742, avg_loss=0.07709]
[2018-11-22 18:51:17.798]  Step 252436  [21.090 sec/step, loss=0.07610, avg_loss=0.07707]
[2018-11-22 18:51:26.389]  Step 252437  [21.015 sec/step, loss=0.05610, avg_loss=0.07688]
[2018-11-22 18:51:51.622]  Step 252438  [21.097 sec/step, loss=0.07933, avg_loss=0.07689]
[2018-11-22 18:52:18.625]  Step 252439  [21.143 sec/step, loss=0.07821, avg_loss=0.07690]
[2018-11-22 18:52:42.778]  Step 252440  [21.293 sec/step, loss=0.07863, avg_loss=0.07709]
[2018-11-22 18:53:01.347]  Step 252441  [21.208 sec/step, loss=0.07857, avg_loss=0.07709]
[2018-11-22 18:53:23.294]  Step 252442  [21.165 sec/step, loss=0.07877, avg_loss=0.07709]
[2018-11-22 18:53:45.466]  Step 252443  [21.161 sec/step, loss=0.07844, avg_loss=0.07708]
[2018-11-22 18:54:10.002]  Step 252444  [21.157 sec/step, loss=0.07897, avg_loss=0.07708]
[2018-11-22 18:54:25.643]  Step 252445  [21.104 sec/step, loss=0.07485, avg_loss=0.07704]
[2018-11-22 18:54:49.160]  Step 252446  [21.122 sec/step, loss=0.07895, avg_loss=0.07704]
[2018-11-22 18:54:58.463]  Generated 32 batches of size 32 in 8.473 sec
[2018-11-22 18:55:09.391]  Step 252447  [20.871 sec/step, loss=0.07792, avg_loss=0.07712]
[2018-11-22 18:55:30.439]  Step 252448  [20.957 sec/step, loss=0.07920, avg_loss=0.07717]
[2018-11-22 18:55:50.489]  Step 252449  [20.949 sec/step, loss=0.07808, avg_loss=0.07716]
[2018-11-22 18:56:13.096]  Step 252450  [20.924 sec/step, loss=0.07874, avg_loss=0.07715]
[2018-11-22 18:56:13.096]  Writing summary at step: 252450
[2018-11-22 18:56:51.951]  Step 252451  [20.926 sec/step, loss=0.07834, avg_loss=0.07715]
[2018-11-22 18:57:13.257]  Step 252452  [20.965 sec/step, loss=0.07888, avg_loss=0.07719]
[2018-11-22 18:57:52.887]  Step 252453  [21.162 sec/step, loss=0.07015, avg_loss=0.07711]
[2018-11-22 18:58:13.567]  Step 252454  [21.109 sec/step, loss=0.07770, avg_loss=0.07710]
[2018-11-22 18:58:34.892]  Step 252455  [21.113 sec/step, loss=0.07859, avg_loss=0.07709]
[2018-11-22 18:59:00.639]  Step 252456  [21.149 sec/step, loss=0.07860, avg_loss=0.07710]
[2018-11-22 18:59:24.533]  Step 252457  [21.147 sec/step, loss=0.07828, avg_loss=0.07709]
[2018-11-22 18:59:45.051]  Step 252458  [21.123 sec/step, loss=0.07845, avg_loss=0.07708]
[2018-11-22 19:00:07.529]  Step 252459  [21.096 sec/step, loss=0.07873, avg_loss=0.07707]
[2018-11-22 19:00:32.307]  Step 252460  [21.104 sec/step, loss=0.07820, avg_loss=0.07707]
[2018-11-22 19:00:45.480]  Step 252461  [21.083 sec/step, loss=0.07036, avg_loss=0.07701]
[2018-11-22 19:01:10.712]  Step 252462  [21.230 sec/step, loss=0.07973, avg_loss=0.07711]
[2018-11-22 19:01:30.568]  Step 252463  [21.345 sec/step, loss=0.07750, avg_loss=0.07730]
[2018-11-22 19:01:42.102]  Step 252464  [21.214 sec/step, loss=0.07406, avg_loss=0.07725]
[2018-11-22 19:02:00.927]  Step 252465  [21.208 sec/step, loss=0.07792, avg_loss=0.07725]
[2018-11-22 19:02:19.478]  Step 252466  [21.192 sec/step, loss=0.07800, avg_loss=0.07724]
[2018-11-22 19:02:36.885]  Step 252467  [21.241 sec/step, loss=0.07739, avg_loss=0.07728]
[2018-11-22 19:03:02.428]  Step 252468  [21.316 sec/step, loss=0.07874, avg_loss=0.07730]
[2018-11-22 19:03:24.835]  Step 252469  [21.316 sec/step, loss=0.07823, avg_loss=0.07729]
[2018-11-22 19:03:33.461]  Step 252470  [21.153 sec/step, loss=0.06026, avg_loss=0.07711]
[2018-11-22 19:03:57.985]  Step 252471  [21.000 sec/step, loss=0.07805, avg_loss=0.07718]
[2018-11-22 19:04:11.983]  Step 252472  [20.877 sec/step, loss=0.07515, avg_loss=0.07716]
[2018-11-22 19:04:27.343]  Step 252473  [20.802 sec/step, loss=0.07593, avg_loss=0.07713]
[2018-11-22 19:04:47.846]  Step 252474  [20.790 sec/step, loss=0.07745, avg_loss=0.07712]
[2018-11-22 19:05:11.000]  Step 252475  [20.821 sec/step, loss=0.07854, avg_loss=0.07712]
[2018-11-22 19:05:34.487]  Step 252476  [20.817 sec/step, loss=0.07800, avg_loss=0.07710]
[2018-11-22 19:05:51.446]  Step 252477  [20.739 sec/step, loss=0.07484, avg_loss=0.07707]
[2018-11-22 19:06:06.494]  Generated 32 batches of size 32 in 14.242 sec
[2018-11-22 19:06:37.716]  Step 252478  [20.987 sec/step, loss=0.06879, avg_loss=0.07696]
[2018-11-22 19:06:57.476]  Step 252479  [20.967 sec/step, loss=0.07809, avg_loss=0.07696]
[2018-11-22 19:07:19.265]  Step 252480  [20.993 sec/step, loss=0.07804, avg_loss=0.07695]
[2018-11-22 19:07:37.009]  Step 252481  [20.962 sec/step, loss=0.07732, avg_loss=0.07694]
[2018-11-22 19:07:57.956]  Step 252482  [20.920 sec/step, loss=0.07906, avg_loss=0.07694]
[2018-11-22 19:08:22.625]  Step 252483  [20.922 sec/step, loss=0.07945, avg_loss=0.07694]
[2018-11-22 19:08:46.940]  Step 252484  [21.011 sec/step, loss=0.07886, avg_loss=0.07697]
[2018-11-22 19:09:09.753]  Step 252485  [21.071 sec/step, loss=0.07906, avg_loss=0.07697]
[2018-11-22 19:09:36.279]  Step 252486  [21.178 sec/step, loss=0.07868, avg_loss=0.07702]
[2018-11-22 19:10:00.882]  Step 252487  [21.207 sec/step, loss=0.07790, avg_loss=0.07701]
[2018-11-22 19:10:19.827]  Step 252488  [21.157 sec/step, loss=0.07829, avg_loss=0.07701]
[2018-11-22 19:10:43.700]  Step 252489  [21.209 sec/step, loss=0.07835, avg_loss=0.07701]
[2018-11-22 19:11:08.759]  Step 252490  [21.258 sec/step, loss=0.07836, avg_loss=0.07701]
[2018-11-22 19:11:32.228]  Step 252491  [21.272 sec/step, loss=0.07833, avg_loss=0.07700]
[2018-11-22 19:11:54.314]  Step 252492  [21.239 sec/step, loss=0.07867, avg_loss=0.07699]
[2018-11-22 19:12:14.800]  Step 252493  [21.357 sec/step, loss=0.07873, avg_loss=0.07718]
[2018-11-22 19:12:37.849]  Step 252494  [21.372 sec/step, loss=0.07818, avg_loss=0.07717]
[2018-11-22 19:12:59.586]  Step 252495  [21.431 sec/step, loss=0.07766, avg_loss=0.07719]
[2018-11-22 19:13:13.885]  Step 252496  [21.345 sec/step, loss=0.07560, avg_loss=0.07715]
[2018-11-22 19:13:33.192]  Step 252497  [21.400 sec/step, loss=0.07756, avg_loss=0.07717]
[2018-11-22 19:13:57.563]  Step 252498  [21.434 sec/step, loss=0.07872, avg_loss=0.07717]
[2018-11-22 19:14:22.099]  Step 252499  [21.431 sec/step, loss=0.07927, avg_loss=0.07718]
[2018-11-22 19:14:31.053]  Step 252500  [21.303 sec/step, loss=0.05863, avg_loss=0.07699]
[2018-11-22 19:14:31.053]  Writing summary at step: 252500
[2018-11-22 19:14:50.988]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-252500
[2018-11-22 19:14:54.344]  Saving audio and alignment...
[2018-11-22 19:15:09.622]  Input: a master {M EY1} be a tyrant or a lover. 'my master': power, {S EH2 K SH UW0 AE1 L AH0 T IY0} and marriage. the most complex and {K AA2 N T R AH0 D IH1 K T ER0 IY0} {AE1 S P EH2 K T} of jane eyre~__________________________________________________________________________________________________
[2018-11-22 19:15:27.060]  Step 252501  [21.281 sec/step, loss=0.07741, avg_loss=0.07698]
[2018-11-22 19:15:43.651]  Step 252502  [21.213 sec/step, loss=0.07485, avg_loss=0.07694]
[2018-11-22 19:16:09.076]  Step 252503  [21.237 sec/step, loss=0.07914, avg_loss=0.07694]
[2018-11-22 19:16:35.357]  Step 252504  [21.342 sec/step, loss=0.07833, avg_loss=0.07698]
[2018-11-22 19:17:13.830]  Step 252505  [21.485 sec/step, loss=0.06975, avg_loss=0.07688]
[2018-11-22 19:17:34.857]  Step 252506  [21.297 sec/step, loss=0.07917, avg_loss=0.07697]
[2018-11-22 19:17:52.739]  Step 252507  [21.287 sec/step, loss=0.07728, avg_loss=0.07695]
[2018-11-22 19:18:01.796]  Generated 32 batches of size 32 in 8.228 sec
[2018-11-22 19:18:16.126]  Step 252508  [21.294 sec/step, loss=0.07881, avg_loss=0.07696]
[2018-11-22 19:18:38.062]  Step 252509  [21.271 sec/step, loss=0.07919, avg_loss=0.07696]
[2018-11-22 19:19:00.118]  Step 252510  [21.373 sec/step, loss=0.07844, avg_loss=0.07700]
[2018-11-22 19:19:20.003]  Step 252511  [21.317 sec/step, loss=0.07719, avg_loss=0.07698]
[2018-11-22 19:19:35.886]  Step 252512  [21.288 sec/step, loss=0.07634, avg_loss=0.07697]
[2018-11-22 19:19:46.910]  Step 252513  [21.229 sec/step, loss=0.07161, avg_loss=0.07690]
[2018-11-22 19:20:09.535]  Step 252514  [21.213 sec/step, loss=0.07870, avg_loss=0.07690]
[2018-11-22 19:20:21.748]  Step 252515  [21.043 sec/step, loss=0.07378, avg_loss=0.07685]
[2018-11-22 19:20:42.333]  Step 252516  [21.068 sec/step, loss=0.07834, avg_loss=0.07687]
[2018-11-22 19:21:03.065]  Step 252517  [21.033 sec/step, loss=0.07918, avg_loss=0.07687]
[2018-11-22 19:21:24.748]  Step 252518  [21.146 sec/step, loss=0.07864, avg_loss=0.07695]
[2018-11-22 19:21:31.763]  Step 252519  [20.988 sec/step, loss=0.06189, avg_loss=0.07678]
[2018-11-22 19:21:51.099]  Step 252520  [20.963 sec/step, loss=0.07820, avg_loss=0.07678]
[2018-11-22 19:22:11.460]  Step 252521  [20.942 sec/step, loss=0.07902, avg_loss=0.07678]
[2018-11-22 19:22:33.574]  Step 252522  [20.945 sec/step, loss=0.07791, avg_loss=0.07678]
[2018-11-22 19:22:59.648]  Step 252523  [20.986 sec/step, loss=0.07837, avg_loss=0.07678]
[2018-11-22 19:23:16.787]  Step 252524  [21.038 sec/step, loss=0.07783, avg_loss=0.07680]
[2018-11-22 19:23:40.804]  Step 252525  [21.083 sec/step, loss=0.07905, avg_loss=0.07682]
[2018-11-22 19:23:53.037]  Step 252526  [21.027 sec/step, loss=0.07379, avg_loss=0.07679]
[2018-11-22 19:24:16.019]  Step 252527  [21.053 sec/step, loss=0.07864, avg_loss=0.07679]
[2018-11-22 19:24:34.257]  Step 252528  [21.021 sec/step, loss=0.07765, avg_loss=0.07678]
[2018-11-22 19:24:53.854]  Step 252529  [20.986 sec/step, loss=0.07733, avg_loss=0.07677]
[2018-11-22 19:25:13.758]  Step 252530  [20.960 sec/step, loss=0.07867, avg_loss=0.07678]
[2018-11-22 19:25:28.082]  Step 252531  [20.862 sec/step, loss=0.07529, avg_loss=0.07674]
[2018-11-22 19:25:50.727]  Step 252532  [20.982 sec/step, loss=0.07946, avg_loss=0.07682]
[2018-11-22 19:26:12.902]  Step 252533  [20.990 sec/step, loss=0.07830, avg_loss=0.07682]
[2018-11-22 19:26:37.346]  Step 252534  [20.992 sec/step, loss=0.08001, avg_loss=0.07684]
[2018-11-22 19:26:56.287]  Step 252535  [21.011 sec/step, loss=0.07837, avg_loss=0.07684]
[2018-11-22 19:27:36.756]  Step 252536  [21.263 sec/step, loss=0.06958, avg_loss=0.07678]
[2018-11-22 19:27:52.087]  Step 252537  [21.330 sec/step, loss=0.07571, avg_loss=0.07698]
[2018-11-22 19:28:16.148]  Step 252538  [21.319 sec/step, loss=0.07900, avg_loss=0.07697]
[2018-11-22 19:28:38.122]  Step 252539  [21.268 sec/step, loss=0.07886, avg_loss=0.07698]
[2018-11-22 19:28:48.159]  Generated 32 batches of size 32 in 9.053 sec
[2018-11-22 19:28:55.568]  Step 252540  [21.201 sec/step, loss=0.07468, avg_loss=0.07694]
[2018-11-22 19:29:05.888]  Step 252541  [21.119 sec/step, loss=0.06913, avg_loss=0.07684]
[2018-11-22 19:29:29.702]  Step 252542  [21.137 sec/step, loss=0.07935, avg_loss=0.07685]
[2018-11-22 19:29:53.684]  Step 252543  [21.155 sec/step, loss=0.07794, avg_loss=0.07685]
[2018-11-22 19:30:11.326]  Step 252544  [21.087 sec/step, loss=0.07740, avg_loss=0.07683]
[2018-11-22 19:30:35.783]  Step 252545  [21.175 sec/step, loss=0.07908, avg_loss=0.07687]
[2018-11-22 19:31:01.499]  Step 252546  [21.197 sec/step, loss=0.07913, avg_loss=0.07687]
[2018-11-22 19:31:23.070]  Step 252547  [21.210 sec/step, loss=0.07814, avg_loss=0.07688]
[2018-11-22 19:31:47.644]  Step 252548  [21.245 sec/step, loss=0.07817, avg_loss=0.07687]
[2018-11-22 19:32:07.793]  Step 252549  [21.246 sec/step, loss=0.07813, avg_loss=0.07687]
[2018-11-22 19:32:49.042]  Step 252550  [21.433 sec/step, loss=0.06952, avg_loss=0.07677]
[2018-11-22 19:32:49.042]  Writing summary at step: 252550
[2018-11-22 19:33:27.132]  Step 252551  [21.396 sec/step, loss=0.07811, avg_loss=0.07677]
[2018-11-22 19:33:51.325]  Step 252552  [21.425 sec/step, loss=0.07856, avg_loss=0.07677]
[2018-11-22 19:34:12.981]  Step 252553  [21.246 sec/step, loss=0.07746, avg_loss=0.07684]
[2018-11-22 19:34:31.245]  Step 252554  [21.221 sec/step, loss=0.07764, avg_loss=0.07684]
[2018-11-22 19:34:51.249]  Step 252555  [21.208 sec/step, loss=0.07779, avg_loss=0.07683]
[2018-11-22 19:35:13.354]  Step 252556  [21.172 sec/step, loss=0.07878, avg_loss=0.07684]
[2018-11-22 19:35:37.323]  Step 252557  [21.173 sec/step, loss=0.07811, avg_loss=0.07683]
[2018-11-22 19:36:02.143]  Step 252558  [21.216 sec/step, loss=0.07979, avg_loss=0.07685]
[2018-11-22 19:36:14.209]  Step 252559  [21.111 sec/step, loss=0.07349, avg_loss=0.07679]
[2018-11-22 19:36:37.319]  Step 252560  [21.095 sec/step, loss=0.07879, avg_loss=0.07680]
[2018-11-22 19:37:02.434]  Step 252561  [21.214 sec/step, loss=0.07941, avg_loss=0.07689]
[2018-11-22 19:37:26.985]  Step 252562  [21.207 sec/step, loss=0.07913, avg_loss=0.07688]
[2018-11-22 19:37:44.742]  Step 252563  [21.186 sec/step, loss=0.07733, avg_loss=0.07688]
[2018-11-22 19:38:05.287]  Step 252564  [21.277 sec/step, loss=0.07889, avg_loss=0.07693]
[2018-11-22 19:38:19.488]  Step 252565  [21.230 sec/step, loss=0.07494, avg_loss=0.07690]
[2018-11-22 19:38:29.861]  Step 252566  [21.149 sec/step, loss=0.07014, avg_loss=0.07682]
[2018-11-22 19:38:52.428]  Step 252567  [21.200 sec/step, loss=0.07857, avg_loss=0.07683]
[2018-11-22 19:39:15.659]  Step 252568  [21.177 sec/step, loss=0.07942, avg_loss=0.07684]
[2018-11-22 19:39:38.569]  Step 252569  [21.182 sec/step, loss=0.07843, avg_loss=0.07684]
[2018-11-22 19:40:02.512]  Step 252570  [21.335 sec/step, loss=0.07779, avg_loss=0.07702]
[2018-11-22 19:40:11.562]  Generated 32 batches of size 32 in 8.226 sec
[2018-11-22 19:40:24.145]  Step 252571  [21.306 sec/step, loss=0.07935, avg_loss=0.07703]
[2018-11-22 19:40:46.688]  Step 252572  [21.392 sec/step, loss=0.07788, avg_loss=0.07706]
[2018-11-22 19:40:55.518]  Step 252573  [21.326 sec/step, loss=0.06049, avg_loss=0.07690]
[2018-11-22 19:41:14.261]  Step 252574  [21.309 sec/step, loss=0.07769, avg_loss=0.07691]
[2018-11-22 19:41:33.527]  Step 252575  [21.270 sec/step, loss=0.07837, avg_loss=0.07691]
[2018-11-22 19:42:00.173]  Step 252576  [21.302 sec/step, loss=0.07819, avg_loss=0.07691]
[2018-11-22 19:42:15.758]  Step 252577  [21.288 sec/step, loss=0.07467, avg_loss=0.07691]
[2018-11-22 19:42:31.082]  Step 252578  [20.978 sec/step, loss=0.07619, avg_loss=0.07698]
[2018-11-22 19:42:55.285]  Step 252579  [21.023 sec/step, loss=0.07882, avg_loss=0.07699]
[2018-11-22 19:43:16.626]  Step 252580  [21.018 sec/step, loss=0.07784, avg_loss=0.07698]
[2018-11-22 19:43:34.044]  Step 252581  [21.015 sec/step, loss=0.07710, avg_loss=0.07698]
[2018-11-22 19:44:18.284]  Step 252582  [21.248 sec/step, loss=0.06922, avg_loss=0.07688]
[2018-11-22 19:44:29.879]  Step 252583  [21.117 sec/step, loss=0.07526, avg_loss=0.07684]
[2018-11-22 19:44:50.573]  Step 252584  [21.081 sec/step, loss=0.07855, avg_loss=0.07684]
[2018-11-22 19:45:18.339]  Step 252585  [21.131 sec/step, loss=0.07735, avg_loss=0.07682]
[2018-11-22 19:45:43.102]  Step 252586  [21.113 sec/step, loss=0.07938, avg_loss=0.07683]
[2018-11-22 19:46:02.920]  Step 252587  [21.065 sec/step, loss=0.07850, avg_loss=0.07684]
[2018-11-22 19:46:25.726]  Step 252588  [21.104 sec/step, loss=0.07861, avg_loss=0.07684]
[2018-11-22 19:46:49.399]  Step 252589  [21.102 sec/step, loss=0.07803, avg_loss=0.07684]
[2018-11-22 19:46:58.066]  Step 252590  [20.938 sec/step, loss=0.05837, avg_loss=0.07664]
[2018-11-22 19:47:17.116]  Step 252591  [20.894 sec/step, loss=0.07827, avg_loss=0.07663]
[2018-11-22 19:47:42.422]  Step 252592  [20.926 sec/step, loss=0.07904, avg_loss=0.07664]
[2018-11-22 19:48:06.752]  Step 252593  [20.964 sec/step, loss=0.07967, avg_loss=0.07665]
[2018-11-22 19:48:29.233]  Step 252594  [20.959 sec/step, loss=0.07908, avg_loss=0.07666]
[2018-11-22 19:48:49.502]  Step 252595  [20.944 sec/step, loss=0.07906, avg_loss=0.07667]
[2018-11-22 19:49:13.709]  Step 252596  [21.043 sec/step, loss=0.07855, avg_loss=0.07670]
[2018-11-22 19:49:37.335]  Step 252597  [21.086 sec/step, loss=0.07916, avg_loss=0.07672]
[2018-11-22 19:49:51.262]  Step 252598  [20.982 sec/step, loss=0.07508, avg_loss=0.07668]
[2018-11-22 19:50:08.182]  Step 252599  [20.905 sec/step, loss=0.07738, avg_loss=0.07666]
[2018-11-22 19:50:29.263]  Step 252600  [21.027 sec/step, loss=0.07944, avg_loss=0.07687]
[2018-11-22 19:50:29.263]  Writing summary at step: 252600
[2018-11-22 19:51:14.631]  Step 252601  [21.071 sec/step, loss=0.07867, avg_loss=0.07688]
[2018-11-22 19:51:24.641]  Generated 32 batches of size 32 in 9.075 sec
[2018-11-22 19:51:39.308]  Step 252602  [21.152 sec/step, loss=0.07834, avg_loss=0.07692]
[2018-11-22 19:52:01.485]  Step 252603  [21.119 sec/step, loss=0.07836, avg_loss=0.07691]
[2018-11-22 19:52:16.742]  Step 252604  [21.009 sec/step, loss=0.07566, avg_loss=0.07688]
[2018-11-22 19:52:40.924]  Step 252605  [20.866 sec/step, loss=0.07876, avg_loss=0.07697]
[2018-11-22 19:52:56.804]  Step 252606  [20.815 sec/step, loss=0.07452, avg_loss=0.07693]
[2018-11-22 19:53:07.201]  Step 252607  [20.740 sec/step, loss=0.07179, avg_loss=0.07687]
[2018-11-22 19:53:26.846]  Step 252608  [20.702 sec/step, loss=0.07785, avg_loss=0.07686]
[2018-11-22 19:53:51.231]  Step 252609  [20.727 sec/step, loss=0.07863, avg_loss=0.07686]
[2018-11-22 19:54:10.056]  Step 252610  [20.694 sec/step, loss=0.07761, avg_loss=0.07685]
[2018-11-22 19:54:32.363]  Step 252611  [20.719 sec/step, loss=0.07808, avg_loss=0.07686]
[2018-11-22 19:54:58.495]  Step 252612  [20.821 sec/step, loss=0.07864, avg_loss=0.07688]
[2018-11-22 19:55:08.836]  Step 252613  [20.814 sec/step, loss=0.06953, avg_loss=0.07686]
[2018-11-22 19:55:27.749]  Step 252614  [20.777 sec/step, loss=0.07816, avg_loss=0.07685]
[2018-11-22 19:55:49.761]  Step 252615  [20.875 sec/step, loss=0.07799, avg_loss=0.07690]
[2018-11-22 19:56:06.457]  Step 252616  [20.836 sec/step, loss=0.07419, avg_loss=0.07685]
[2018-11-22 19:56:27.931]  Step 252617  [20.844 sec/step, loss=0.07882, avg_loss=0.07685]
[2018-11-22 19:56:41.846]  Step 252618  [20.766 sec/step, loss=0.07573, avg_loss=0.07682]
[2018-11-22 19:57:03.642]  Step 252619  [20.914 sec/step, loss=0.07846, avg_loss=0.07699]
[2018-11-22 19:57:25.670]  Step 252620  [20.941 sec/step, loss=0.07750, avg_loss=0.07698]
[2018-11-22 19:57:44.998]  Step 252621  [20.930 sec/step, loss=0.07695, avg_loss=0.07696]
[2018-11-22 19:58:08.758]  Step 252622  [20.947 sec/step, loss=0.07886, avg_loss=0.07697]
[2018-11-22 19:58:28.008]  Step 252623  [20.879 sec/step, loss=0.07721, avg_loss=0.07696]
[2018-11-22 19:58:53.546]  Step 252624  [20.963 sec/step, loss=0.07829, avg_loss=0.07696]
[2018-11-22 19:59:17.129]  Step 252625  [20.958 sec/step, loss=0.07799, avg_loss=0.07695]
[2018-11-22 19:59:42.332]  Step 252626  [21.088 sec/step, loss=0.07953, avg_loss=0.07701]
[2018-11-22 20:00:02.439]  Step 252627  [21.059 sec/step, loss=0.07802, avg_loss=0.07700]
[2018-11-22 20:00:20.943]  Step 252628  [21.062 sec/step, loss=0.07808, avg_loss=0.07701]
[2018-11-22 20:00:42.929]  Step 252629  [21.086 sec/step, loss=0.07859, avg_loss=0.07702]
[2018-11-22 20:00:59.208]  Step 252630  [21.050 sec/step, loss=0.07578, avg_loss=0.07699]
[2018-11-22 20:01:13.571]  Step 252631  [21.050 sec/step, loss=0.07351, avg_loss=0.07697]
[2018-11-22 20:01:41.598]  Step 252632  [21.104 sec/step, loss=0.07833, avg_loss=0.07696]
[2018-11-22 20:01:58.612]  Step 252633  [21.052 sec/step, loss=0.07780, avg_loss=0.07696]
[2018-11-22 20:02:08.323]  Generated 32 batches of size 32 in 8.882 sec
[2018-11-22 20:02:17.945]  Step 252634  [21.001 sec/step, loss=0.07702, avg_loss=0.07693]
[2018-11-22 20:02:41.746]  Step 252635  [21.050 sec/step, loss=0.07837, avg_loss=0.07693]
[2018-11-22 20:03:02.699]  Step 252636  [20.855 sec/step, loss=0.07889, avg_loss=0.07702]
[2018-11-22 20:03:26.223]  Step 252637  [20.936 sec/step, loss=0.07996, avg_loss=0.07706]
[2018-11-22 20:03:50.826]  Step 252638  [20.942 sec/step, loss=0.07921, avg_loss=0.07706]
[2018-11-22 20:03:59.268]  Step 252639  [20.807 sec/step, loss=0.05916, avg_loss=0.07687]
[2018-11-22 20:04:23.523]  Step 252640  [20.875 sec/step, loss=0.07873, avg_loss=0.07691]
[2018-11-22 20:05:04.643]  Step 252641  [21.183 sec/step, loss=0.06996, avg_loss=0.07692]
[2018-11-22 20:05:29.090]  Step 252642  [21.189 sec/step, loss=0.07808, avg_loss=0.07690]
[2018-11-22 20:05:54.197]  Step 252643  [21.200 sec/step, loss=0.07760, avg_loss=0.07690]
[2018-11-22 20:06:10.118]  Step 252644  [21.183 sec/step, loss=0.07387, avg_loss=0.07686]
[2018-11-22 20:06:34.297]  Step 252645  [21.180 sec/step, loss=0.07933, avg_loss=0.07687]
[2018-11-22 20:06:44.996]  Step 252646  [21.030 sec/step, loss=0.06963, avg_loss=0.07677]
[2018-11-22 20:07:08.762]  Step 252647  [21.052 sec/step, loss=0.07869, avg_loss=0.07678]
[2018-11-22 20:07:31.349]  Step 252648  [21.032 sec/step, loss=0.07851, avg_loss=0.07678]
[2018-11-22 20:07:55.657]  Step 252649  [21.074 sec/step, loss=0.07774, avg_loss=0.07678]
[2018-11-22 20:08:16.281]  Step 252650  [20.867 sec/step, loss=0.07807, avg_loss=0.07686]
[2018-11-22 20:08:16.281]  Writing summary at step: 252650
[2018-11-22 20:08:56.884]  Step 252651  [20.902 sec/step, loss=0.07850, avg_loss=0.07687]
[2018-11-22 20:09:34.831]  Step 252652  [21.039 sec/step, loss=0.06938, avg_loss=0.07677]
[2018-11-22 20:09:46.848]  Step 252653  [20.943 sec/step, loss=0.07331, avg_loss=0.07673]
[2018-11-22 20:10:13.508]  Step 252654  [21.027 sec/step, loss=0.07834, avg_loss=0.07674]
[2018-11-22 20:10:38.909]  Step 252655  [21.081 sec/step, loss=0.07853, avg_loss=0.07675]
[2018-11-22 20:11:03.333]  Step 252656  [21.104 sec/step, loss=0.07769, avg_loss=0.07674]
[2018-11-22 20:11:23.127]  Step 252657  [21.062 sec/step, loss=0.07699, avg_loss=0.07672]
[2018-11-22 20:11:46.039]  Step 252658  [21.043 sec/step, loss=0.07825, avg_loss=0.07671]
[2018-11-22 20:12:07.832]  Step 252659  [21.141 sec/step, loss=0.07781, avg_loss=0.07675]
[2018-11-22 20:12:21.797]  Step 252660  [21.049 sec/step, loss=0.07589, avg_loss=0.07672]
[2018-11-22 20:12:40.296]  Step 252661  [20.983 sec/step, loss=0.07801, avg_loss=0.07671]
[2018-11-22 20:13:01.063]  Step 252662  [20.945 sec/step, loss=0.07810, avg_loss=0.07670]
[2018-11-22 20:13:23.019]  Step 252663  [20.987 sec/step, loss=0.07793, avg_loss=0.07671]
[2018-11-22 20:13:44.553]  Step 252664  [20.997 sec/step, loss=0.07822, avg_loss=0.07670]
[2018-11-22 20:13:53.590]  Generated 32 batches of size 32 in 8.214 sec
[2018-11-22 20:14:06.098]  Step 252665  [21.070 sec/step, loss=0.07715, avg_loss=0.07672]
[2018-11-22 20:14:27.078]  Step 252666  [21.177 sec/step, loss=0.07836, avg_loss=0.07680]
[2018-11-22 20:14:35.383]  Step 252667  [21.034 sec/step, loss=0.05891, avg_loss=0.07661]
[2018-11-22 20:14:54.570]  Step 252668  [20.993 sec/step, loss=0.07713, avg_loss=0.07658]
[2018-11-22 20:15:16.313]  Step 252669  [20.982 sec/step, loss=0.07817, avg_loss=0.07658]
[2018-11-22 20:15:35.249]  Step 252670  [20.932 sec/step, loss=0.07793, avg_loss=0.07658]
[2018-11-22 20:15:59.274]  Step 252671  [20.956 sec/step, loss=0.07858, avg_loss=0.07657]
[2018-11-22 20:16:16.018]  Step 252672  [20.898 sec/step, loss=0.07749, avg_loss=0.07657]
[2018-11-22 20:16:33.553]  Step 252673  [20.985 sec/step, loss=0.07654, avg_loss=0.07673]
[2018-11-22 20:16:53.765]  Step 252674  [20.999 sec/step, loss=0.07773, avg_loss=0.07673]
[2018-11-22 20:17:04.022]  Step 252675  [20.909 sec/step, loss=0.07040, avg_loss=0.07665]
[2018-11-22 20:17:26.525]  Step 252676  [20.868 sec/step, loss=0.07857, avg_loss=0.07666]
[2018-11-22 20:17:47.209]  Step 252677  [20.919 sec/step, loss=0.07836, avg_loss=0.07669]
[2018-11-22 20:18:06.329]  Step 252678  [20.957 sec/step, loss=0.07668, avg_loss=0.07670]
[2018-11-22 20:18:28.179]  Step 252679  [20.933 sec/step, loss=0.07765, avg_loss=0.07669]
[2018-11-22 20:18:54.202]  Step 252680  [20.980 sec/step, loss=0.07733, avg_loss=0.07668]
[2018-11-22 20:19:06.205]  Step 252681  [20.926 sec/step, loss=0.07312, avg_loss=0.07664]
[2018-11-22 20:19:28.179]  Step 252682  [20.703 sec/step, loss=0.07734, avg_loss=0.07672]
[2018-11-22 20:19:43.468]  Step 252683  [20.740 sec/step, loss=0.07408, avg_loss=0.07671]
[2018-11-22 20:20:01.688]  Step 252684  [20.716 sec/step, loss=0.07715, avg_loss=0.07670]
[2018-11-22 20:20:19.797]  Step 252685  [20.619 sec/step, loss=0.07662, avg_loss=0.07669]
[2018-11-22 20:20:38.888]  Step 252686  [20.562 sec/step, loss=0.07733, avg_loss=0.07667]
[2018-11-22 20:21:02.543]  Step 252687  [20.601 sec/step, loss=0.07751, avg_loss=0.07666]
[2018-11-22 20:21:26.343]  Step 252688  [20.611 sec/step, loss=0.07821, avg_loss=0.07665]
[2018-11-22 20:21:50.771]  Step 252689  [20.618 sec/step, loss=0.07838, avg_loss=0.07666]
[2018-11-22 20:22:12.095]  Step 252690  [20.745 sec/step, loss=0.07772, avg_loss=0.07685]
[2018-11-22 20:22:34.821]  Step 252691  [20.781 sec/step, loss=0.07891, avg_loss=0.07686]
[2018-11-22 20:22:59.097]  Step 252692  [20.771 sec/step, loss=0.07853, avg_loss=0.07685]
[2018-11-22 20:23:23.557]  Step 252693  [20.772 sec/step, loss=0.07785, avg_loss=0.07683]
[2018-11-22 20:23:42.911]  Step 252694  [20.741 sec/step, loss=0.07758, avg_loss=0.07682]
[2018-11-22 20:24:05.740]  Step 252695  [20.767 sec/step, loss=0.07780, avg_loss=0.07681]
[2018-11-22 20:24:20.949]  Step 252696  [20.677 sec/step, loss=0.07559, avg_loss=0.07678]
[2018-11-22 20:24:29.118]  Generated 32 batches of size 32 in 7.481 sec
[2018-11-22 20:24:30.974]  Step 252697  [20.541 sec/step, loss=0.05722, avg_loss=0.07656]
[2018-11-22 20:24:45.084]  Step 252698  [20.543 sec/step, loss=0.07477, avg_loss=0.07656]
[2018-11-22 20:25:26.986]  Step 252699  [20.792 sec/step, loss=0.06849, avg_loss=0.07647]
[2018-11-22 20:25:48.731]  Step 252700  [20.799 sec/step, loss=0.07790, avg_loss=0.07645]
[2018-11-22 20:25:48.731]  Writing summary at step: 252700
[2018-11-22 20:26:27.429]  Step 252701  [20.794 sec/step, loss=0.07784, avg_loss=0.07644]
[2018-11-22 20:26:52.764]  Step 252702  [20.800 sec/step, loss=0.07876, avg_loss=0.07645]
[2018-11-22 20:27:16.792]  Step 252703  [20.819 sec/step, loss=0.07892, avg_loss=0.07645]
[2018-11-22 20:27:38.830]  Step 252704  [20.887 sec/step, loss=0.07833, avg_loss=0.07648]
[2018-11-22 20:28:01.887]  Step 252705  [20.876 sec/step, loss=0.07777, avg_loss=0.07647]
[2018-11-22 20:28:26.134]  Step 252706  [20.959 sec/step, loss=0.07840, avg_loss=0.07651]
[2018-11-22 20:28:38.219]  Step 252707  [20.976 sec/step, loss=0.07335, avg_loss=0.07652]
[2018-11-22 20:28:48.623]  Step 252708  [20.884 sec/step, loss=0.06934, avg_loss=0.07644]
[2018-11-22 20:29:25.175]  Step 252709  [21.005 sec/step, loss=0.06933, avg_loss=0.07635]
[2018-11-22 20:29:51.274]  Step 252710  [21.078 sec/step, loss=0.07762, avg_loss=0.07635]
[2018-11-22 20:30:12.842]  Step 252711  [21.071 sec/step, loss=0.07894, avg_loss=0.07635]
[2018-11-22 20:30:33.190]  Step 252712  [21.013 sec/step, loss=0.07780, avg_loss=0.07635]
[2018-11-22 20:30:54.489]  Step 252713  [21.122 sec/step, loss=0.07743, avg_loss=0.07642]
[2018-11-22 20:31:13.860]  Step 252714  [21.127 sec/step, loss=0.07662, avg_loss=0.07641]
[2018-11-22 20:31:39.233]  Step 252715  [21.161 sec/step, loss=0.07751, avg_loss=0.07640]
[2018-11-22 20:32:04.705]  Step 252716  [21.248 sec/step, loss=0.07822, avg_loss=0.07644]
[2018-11-22 20:32:24.112]  Step 252717  [21.228 sec/step, loss=0.07697, avg_loss=0.07643]
[2018-11-22 20:32:48.477]  Step 252718  [21.332 sec/step, loss=0.07922, avg_loss=0.07646]
[2018-11-22 20:33:10.302]  Step 252719  [21.333 sec/step, loss=0.07794, avg_loss=0.07646]
[2018-11-22 20:33:32.079]  Step 252720  [21.330 sec/step, loss=0.07787, avg_loss=0.07646]
[2018-11-22 20:33:49.948]  Step 252721  [21.315 sec/step, loss=0.07679, avg_loss=0.07646]
[2018-11-22 20:34:10.336]  Step 252722  [21.282 sec/step, loss=0.07758, avg_loss=0.07645]
[2018-11-22 20:34:27.390]  Step 252723  [21.260 sec/step, loss=0.07727, avg_loss=0.07645]
[2018-11-22 20:34:46.012]  Step 252724  [21.191 sec/step, loss=0.07761, avg_loss=0.07644]
[2018-11-22 20:35:05.807]  Step 252725  [21.153 sec/step, loss=0.07679, avg_loss=0.07643]
[2018-11-22 20:35:28.840]  Step 252726  [21.131 sec/step, loss=0.07764, avg_loss=0.07641]
[2018-11-22 20:35:45.246]  Step 252727  [21.094 sec/step, loss=0.07429, avg_loss=0.07637]
[2018-11-22 20:35:54.444]  Generated 32 batches of size 32 in 8.441 sec
[2018-11-22 20:36:02.372]  Step 252728  [21.080 sec/step, loss=0.07520, avg_loss=0.07634]
[2018-11-22 20:36:25.801]  Step 252729  [21.095 sec/step, loss=0.07776, avg_loss=0.07633]
[2018-11-22 20:36:50.309]  Step 252730  [21.177 sec/step, loss=0.07819, avg_loss=0.07636]
[2018-11-22 20:37:12.811]  Step 252731  [21.258 sec/step, loss=0.07769, avg_loss=0.07640]
[2018-11-22 20:37:36.275]  Step 252732  [21.213 sec/step, loss=0.07797, avg_loss=0.07640]
[2018-11-22 20:37:44.685]  Step 252733  [21.127 sec/step, loss=0.05958, avg_loss=0.07621]
[2018-11-22 20:38:06.763]  Step 252734  [21.154 sec/step, loss=0.07780, avg_loss=0.07622]
[2018-11-22 20:38:20.434]  Step 252735  [21.053 sec/step, loss=0.07466, avg_loss=0.07618]
[2018-11-22 20:38:44.869]  Step 252736  [21.088 sec/step, loss=0.07832, avg_loss=0.07618]
[2018-11-22 20:39:04.550]  Step 252737  [21.049 sec/step, loss=0.07683, avg_loss=0.07615]
[2018-11-22 20:39:27.220]  Step 252738  [21.030 sec/step, loss=0.07737, avg_loss=0.07613]
[2018-11-22 20:39:48.699]  Step 252739  [21.160 sec/step, loss=0.07751, avg_loss=0.07631]
[2018-11-22 20:40:08.872]  Step 252740  [21.119 sec/step, loss=0.07666, avg_loss=0.07629]
[2018-11-22 20:40:21.209]  Step 252741  [20.832 sec/step, loss=0.07289, avg_loss=0.07632]
[2018-11-22 20:40:37.944]  Step 252742  [20.754 sec/step, loss=0.07677, avg_loss=0.07631]
[2018-11-22 20:41:03.142]  Step 252743  [20.755 sec/step, loss=0.07826, avg_loss=0.07632]
[2018-11-22 20:41:22.281]  Step 252744  [20.788 sec/step, loss=0.07694, avg_loss=0.07635]
[2018-11-22 20:41:58.631]  Step 252745  [20.909 sec/step, loss=0.06874, avg_loss=0.07624]
[2018-11-22 20:42:14.085]  Step 252746  [20.957 sec/step, loss=0.07469, avg_loss=0.07629]
[2018-11-22 20:42:23.081]  Step 252747  [20.809 sec/step, loss=0.05648, avg_loss=0.07607]
[2018-11-22 20:42:44.682]  Step 252748  [20.799 sec/step, loss=0.07794, avg_loss=0.07606]
[2018-11-22 20:43:06.725]  Step 252749  [20.777 sec/step, loss=0.07788, avg_loss=0.07606]
[2018-11-22 20:43:30.619]  Step 252750  [20.809 sec/step, loss=0.07809, avg_loss=0.07606]
[2018-11-22 20:43:30.619]  Writing summary at step: 252750
[2018-11-22 20:44:09.935]  Step 252751  [20.738 sec/step, loss=0.07647, avg_loss=0.07604]
[2018-11-22 20:44:34.028]  Step 252752  [20.599 sec/step, loss=0.07834, avg_loss=0.07613]
[2018-11-22 20:44:53.155]  Step 252753  [20.670 sec/step, loss=0.07662, avg_loss=0.07617]
[2018-11-22 20:45:16.441]  Step 252754  [20.637 sec/step, loss=0.07773, avg_loss=0.07616]
[2018-11-22 20:45:26.664]  Step 252755  [20.485 sec/step, loss=0.07179, avg_loss=0.07609]
[2018-11-22 20:45:48.373]  Step 252756  [20.458 sec/step, loss=0.07855, avg_loss=0.07610]
[2018-11-22 20:46:04.069]  Step 252757  [20.417 sec/step, loss=0.07569, avg_loss=0.07609]
[2018-11-22 20:46:26.529]  Step 252758  [20.412 sec/step, loss=0.07811, avg_loss=0.07609]
[2018-11-22 20:46:36.354]  Generated 32 batches of size 32 in 9.050 sec
[2018-11-22 20:46:48.274]  Step 252759  [20.412 sec/step, loss=0.07820, avg_loss=0.07609]
[2018-11-22 20:47:10.998]  Step 252760  [20.499 sec/step, loss=0.07763, avg_loss=0.07611]
[2018-11-22 20:47:29.231]  Step 252761  [20.497 sec/step, loss=0.07835, avg_loss=0.07611]
[2018-11-22 20:47:53.828]  Step 252762  [20.535 sec/step, loss=0.07891, avg_loss=0.07612]
[2018-11-22 20:48:17.632]  Step 252763  [20.553 sec/step, loss=0.07812, avg_loss=0.07612]
[2018-11-22 20:48:31.395]  Step 252764  [20.476 sec/step, loss=0.07510, avg_loss=0.07609]
[2018-11-22 20:48:53.331]  Step 252765  [20.480 sec/step, loss=0.07775, avg_loss=0.07610]
[2018-11-22 20:49:19.465]  Step 252766  [20.531 sec/step, loss=0.07804, avg_loss=0.07609]
[2018-11-22 20:49:44.007]  Step 252767  [20.693 sec/step, loss=0.07739, avg_loss=0.07628]
[2018-11-22 20:49:52.600]  Step 252768  [20.588 sec/step, loss=0.05885, avg_loss=0.07610]
[2018-11-22 20:50:17.552]  Step 252769  [20.620 sec/step, loss=0.07824, avg_loss=0.07610]
[2018-11-22 20:50:35.982]  Step 252770  [20.615 sec/step, loss=0.07755, avg_loss=0.07609]
[2018-11-22 20:51:02.669]  Step 252771  [20.641 sec/step, loss=0.07686, avg_loss=0.07608]
[2018-11-22 20:51:20.982]  Step 252772  [20.657 sec/step, loss=0.07650, avg_loss=0.07607]
[2018-11-22 20:51:37.542]  Step 252773  [20.647 sec/step, loss=0.07733, avg_loss=0.07607]
[2018-11-22 20:51:59.388]  Step 252774  [20.663 sec/step, loss=0.07728, avg_loss=0.07607]
[2018-11-22 20:52:21.503]  Step 252775  [20.782 sec/step, loss=0.07748, avg_loss=0.07614]
[2018-11-22 20:52:40.157]  Step 252776  [20.744 sec/step, loss=0.07720, avg_loss=0.07613]
[2018-11-22 20:53:02.656]  Step 252777  [20.762 sec/step, loss=0.07812, avg_loss=0.07612]
[2018-11-22 20:53:24.107]  Step 252778  [20.785 sec/step, loss=0.07786, avg_loss=0.07614]
[2018-11-22 20:53:36.069]  Step 252779  [20.686 sec/step, loss=0.07359, avg_loss=0.07609]
[2018-11-22 20:53:52.086]  Step 252780  [20.586 sec/step, loss=0.07510, avg_loss=0.07607]
[2018-11-22 20:54:29.603]  Step 252781  [20.841 sec/step, loss=0.06901, avg_loss=0.07603]
[2018-11-22 20:54:54.333]  Step 252782  [20.869 sec/step, loss=0.07815, avg_loss=0.07604]
[2018-11-22 20:55:17.695]  Step 252783  [20.949 sec/step, loss=0.07863, avg_loss=0.07608]
[2018-11-22 20:55:39.280]  Step 252784  [20.983 sec/step, loss=0.07745, avg_loss=0.07609]
[2018-11-22 20:55:59.348]  Step 252785  [21.003 sec/step, loss=0.07757, avg_loss=0.07610]
[2018-11-22 20:56:20.927]  Step 252786  [21.028 sec/step, loss=0.07845, avg_loss=0.07611]
[2018-11-22 20:56:45.391]  Step 252787  [21.036 sec/step, loss=0.07749, avg_loss=0.07611]
[2018-11-22 20:56:59.157]  Step 252788  [20.935 sec/step, loss=0.07422, avg_loss=0.07607]
[2018-11-22 20:57:23.353]  Step 252789  [20.933 sec/step, loss=0.07828, avg_loss=0.07607]
[2018-11-22 20:57:38.255]  Step 252790  [20.869 sec/step, loss=0.07412, avg_loss=0.07603]
[2018-11-22 20:57:47.733]  Generated 32 batches of size 32 in 8.503 sec
[2018-11-22 20:57:57.396]  Step 252791  [20.833 sec/step, loss=0.07651, avg_loss=0.07601]
[2018-11-22 20:58:07.904]  Step 252792  [20.695 sec/step, loss=0.06955, avg_loss=0.07592]
[2018-11-22 20:58:31.689]  Step 252793  [20.689 sec/step, loss=0.07742, avg_loss=0.07591]
[2018-11-22 20:58:53.225]  Step 252794  [20.710 sec/step, loss=0.07679, avg_loss=0.07591]
[2018-11-22 20:59:16.333]  Step 252795  [20.713 sec/step, loss=0.07774, avg_loss=0.07590]
[2018-11-22 20:59:38.962]  Step 252796  [20.787 sec/step, loss=0.07806, avg_loss=0.07593]
[2018-11-22 20:59:59.111]  Step 252797  [20.889 sec/step, loss=0.07761, avg_loss=0.07613]
[2018-11-22 21:00:20.328]  Step 252798  [20.960 sec/step, loss=0.07828, avg_loss=0.07617]
[2018-11-22 21:00:45.143]  Step 252799  [20.789 sec/step, loss=0.07821, avg_loss=0.07627]
[2018-11-22 21:01:10.702]  Step 252800  [20.827 sec/step, loss=0.07739, avg_loss=0.07626]
[2018-11-22 21:01:10.702]  Writing summary at step: 252800
[2018-11-22 21:01:56.567]  Step 252801  [20.846 sec/step, loss=0.07718, avg_loss=0.07625]
[2018-11-22 21:02:18.280]  Step 252802  [20.810 sec/step, loss=0.07771, avg_loss=0.07624]
[2018-11-22 21:02:44.607]  Step 252803  [20.833 sec/step, loss=0.07700, avg_loss=0.07622]
[2018-11-22 21:02:53.109]  Step 252804  [20.697 sec/step, loss=0.05804, avg_loss=0.07602]
[2018-11-22 21:03:03.406]  Step 252805  [20.570 sec/step, loss=0.06926, avg_loss=0.07594]
[2018-11-22 21:03:28.321]  Step 252806  [20.576 sec/step, loss=0.07836, avg_loss=0.07594]
[2018-11-22 21:03:51.688]  Step 252807  [20.689 sec/step, loss=0.07819, avg_loss=0.07598]
[2018-11-22 21:04:16.457]  Step 252808  [20.833 sec/step, loss=0.07773, avg_loss=0.07607]
[2018-11-22 21:04:31.190]  Step 252809  [20.615 sec/step, loss=0.07331, avg_loss=0.07611]
[2018-11-22 21:04:53.336]  Step 252810  [20.575 sec/step, loss=0.07791, avg_loss=0.07611]
[2018-11-22 21:05:10.655]  Step 252811  [20.533 sec/step, loss=0.07714, avg_loss=0.07609]
[2018-11-22 21:05:55.092]  Step 252812  [20.774 sec/step, loss=0.06860, avg_loss=0.07600]
[2018-11-22 21:06:06.636]  Step 252813  [20.676 sec/step, loss=0.07376, avg_loss=0.07596]
[2018-11-22 21:06:25.772]  Step 252814  [20.674 sec/step, loss=0.07660, avg_loss=0.07596]
[2018-11-22 21:06:49.483]  Step 252815  [20.657 sec/step, loss=0.07727, avg_loss=0.07596]
[2018-11-22 21:07:13.611]  Step 252816  [20.644 sec/step, loss=0.07829, avg_loss=0.07596]
[2018-11-22 21:07:34.725]  Step 252817  [20.661 sec/step, loss=0.07789, avg_loss=0.07597]
[2018-11-22 21:07:59.131]  Step 252818  [20.661 sec/step, loss=0.07790, avg_loss=0.07596]
[2018-11-22 21:08:21.538]  Step 252819  [20.667 sec/step, loss=0.07756, avg_loss=0.07595]
[2018-11-22 21:08:40.228]  Step 252820  [20.636 sec/step, loss=0.07710, avg_loss=0.07595]
[2018-11-22 21:09:02.844]  Step 252821  [20.684 sec/step, loss=0.07787, avg_loss=0.07596]
[2018-11-22 21:09:12.305]  Generated 32 batches of size 32 in 8.424 sec
[2018-11-22 21:09:26.130]  Step 252822  [20.713 sec/step, loss=0.07773, avg_loss=0.07596]
[2018-11-22 21:09:39.495]  Step 252823  [20.676 sec/step, loss=0.07563, avg_loss=0.07594]
[2018-11-22 21:09:55.930]  Step 252824  [20.654 sec/step, loss=0.07501, avg_loss=0.07592]
[2018-11-22 21:10:13.419]  Step 252825  [20.631 sec/step, loss=0.07692, avg_loss=0.07592]
[2018-11-22 21:10:31.725]  Step 252826  [20.583 sec/step, loss=0.07809, avg_loss=0.07592]
[2018-11-22 21:10:55.153]  Step 252827  [20.654 sec/step, loss=0.07836, avg_loss=0.07596]
[2018-11-22 21:11:16.573]  Step 252828  [20.697 sec/step, loss=0.07771, avg_loss=0.07599]
[2018-11-22 21:11:40.756]  Step 252829  [20.704 sec/step, loss=0.07907, avg_loss=0.07600]
[2018-11-22 21:12:00.437]  Step 252830  [20.656 sec/step, loss=0.07708, avg_loss=0.07599]
[2018-11-22 21:12:19.710]  Step 252831  [20.624 sec/step, loss=0.07708, avg_loss=0.07598]
[2018-11-22 21:12:45.077]  Step 252832  [20.643 sec/step, loss=0.07834, avg_loss=0.07599]
[2018-11-22 21:13:03.839]  Step 252833  [20.746 sec/step, loss=0.07697, avg_loss=0.07616]
[2018-11-22 21:13:44.424]  Step 252834  [20.931 sec/step, loss=0.06903, avg_loss=0.07607]
[2018-11-22 21:14:05.815]  Step 252835  [21.008 sec/step, loss=0.07758, avg_loss=0.07610]
[2018-11-22 21:14:29.846]  Step 252836  [21.004 sec/step, loss=0.07794, avg_loss=0.07610]
[2018-11-22 21:14:53.943]  Step 252837  [21.049 sec/step, loss=0.07710, avg_loss=0.07610]
[2018-11-22 21:15:14.904]  Step 252838  [21.031 sec/step, loss=0.07812, avg_loss=0.07611]
[2018-11-22 21:15:40.184]  Step 252839  [21.069 sec/step, loss=0.07731, avg_loss=0.07611]
[2018-11-22 21:16:02.969]  Step 252840  [21.096 sec/step, loss=0.07819, avg_loss=0.07612]
[2018-11-22 21:16:25.186]  Step 252841  [21.194 sec/step, loss=0.07749, avg_loss=0.07617]
[2018-11-22 21:16:49.833]  Step 252842  [21.273 sec/step, loss=0.07807, avg_loss=0.07618]
[2018-11-22 21:17:06.659]  Step 252843  [21.190 sec/step, loss=0.07699, avg_loss=0.07617]
[2018-11-22 21:17:29.631]  Step 252844  [21.228 sec/step, loss=0.07776, avg_loss=0.07618]
[2018-11-22 21:17:50.004]  Step 252845  [21.068 sec/step, loss=0.07818, avg_loss=0.07627]
[2018-11-22 21:18:11.716]  Step 252846  [21.131 sec/step, loss=0.07772, avg_loss=0.07630]
[2018-11-22 21:18:36.093]  Step 252847  [21.285 sec/step, loss=0.07776, avg_loss=0.07651]
[2018-11-22 21:18:44.914]  Step 252848  [21.157 sec/step, loss=0.05676, avg_loss=0.07630]
[2018-11-22 21:18:57.012]  Step 252849  [21.057 sec/step, loss=0.07324, avg_loss=0.07626]
[2018-11-22 21:19:12.467]  Step 252850  [20.973 sec/step, loss=0.07511, avg_loss=0.07623]
[2018-11-22 21:19:12.467]  Writing summary at step: 252850
[2018-11-22 21:19:45.585]  Step 252851  [20.938 sec/step, loss=0.07463, avg_loss=0.07621]
[2018-11-22 21:20:00.958]  Step 252852  [20.851 sec/step, loss=0.07440, avg_loss=0.07617]
[2018-11-22 21:20:10.160]  Generated 32 batches of size 32 in 8.358 sec
[2018-11-22 21:20:13.022]  Step 252853  [20.780 sec/step, loss=0.06965, avg_loss=0.07610]
[2018-11-22 21:20:36.863]  Step 252854  [20.785 sec/step, loss=0.07777, avg_loss=0.07610]
[2018-11-22 21:21:01.416]  Step 252855  [20.929 sec/step, loss=0.07845, avg_loss=0.07617]
[2018-11-22 21:21:22.858]  Step 252856  [20.926 sec/step, loss=0.07764, avg_loss=0.07616]
[2018-11-22 21:21:41.019]  Step 252857  [20.951 sec/step, loss=0.07624, avg_loss=0.07616]
[2018-11-22 21:22:02.801]  Step 252858  [20.944 sec/step, loss=0.07723, avg_loss=0.07615]
[2018-11-22 21:22:22.581]  Step 252859  [20.924 sec/step, loss=0.07712, avg_loss=0.07614]
[2018-11-22 21:22:43.252]  Step 252860  [20.904 sec/step, loss=0.07692, avg_loss=0.07614]
[2018-11-22 21:23:09.085]  Step 252861  [20.980 sec/step, loss=0.07764, avg_loss=0.07613]
[2018-11-22 21:23:31.326]  Step 252862  [20.956 sec/step, loss=0.07818, avg_loss=0.07612]
[2018-11-22 21:23:52.202]  Step 252863  [20.927 sec/step, loss=0.07751, avg_loss=0.07612]
[2018-11-22 21:24:18.343]  Step 252864  [21.051 sec/step, loss=0.07675, avg_loss=0.07613]
[2018-11-22 21:24:26.926]  Step 252865  [20.917 sec/step, loss=0.05774, avg_loss=0.07593]
[2018-11-22 21:24:42.629]  Step 252866  [20.813 sec/step, loss=0.07337, avg_loss=0.07589]
[2018-11-22 21:24:54.764]  Step 252867  [20.689 sec/step, loss=0.07299, avg_loss=0.07584]
[2018-11-22 21:25:19.965]  Step 252868  [20.855 sec/step, loss=0.07825, avg_loss=0.07604]
[2018-11-22 21:25:44.675]  Step 252869  [20.852 sec/step, loss=0.07694, avg_loss=0.07602]
[2018-11-22 21:26:08.196]  Step 252870  [20.903 sec/step, loss=0.07752, avg_loss=0.07602]
[2018-11-22 21:26:26.139]  Step 252871  [20.816 sec/step, loss=0.07657, avg_loss=0.07602]
[2018-11-22 21:26:48.966]  Step 252872  [20.861 sec/step, loss=0.07788, avg_loss=0.07603]
[2018-11-22 21:27:07.885]  Step 252873  [20.885 sec/step, loss=0.07762, avg_loss=0.07604]
[2018-11-22 21:27:18.291]  Step 252874  [20.770 sec/step, loss=0.06987, avg_loss=0.07596]
[2018-11-22 21:27:42.856]  Step 252875  [20.795 sec/step, loss=0.07757, avg_loss=0.07596]
[2018-11-22 21:28:00.494]  Step 252876  [20.785 sec/step, loss=0.07645, avg_loss=0.07595]
[2018-11-22 21:28:24.298]  Step 252877  [20.798 sec/step, loss=0.07793, avg_loss=0.07595]
[2018-11-22 21:28:42.980]  Step 252878  [20.770 sec/step, loss=0.07705, avg_loss=0.07594]
[2018-11-22 21:29:07.086]  Step 252879  [20.891 sec/step, loss=0.07746, avg_loss=0.07598]
[2018-11-22 21:29:28.428]  Step 252880  [20.945 sec/step, loss=0.07752, avg_loss=0.07601]
[2018-11-22 21:29:48.365]  Step 252881  [20.769 sec/step, loss=0.07655, avg_loss=0.07608]
[2018-11-22 21:30:12.820]  Step 252882  [20.766 sec/step, loss=0.07728, avg_loss=0.07607]
[2018-11-22 21:30:33.243]  Step 252883  [20.737 sec/step, loss=0.07737, avg_loss=0.07606]
[2018-11-22 21:30:47.207]  Step 252884  [20.660 sec/step, loss=0.07494, avg_loss=0.07604]
[2018-11-22 21:30:56.953]  Generated 32 batches of size 32 in 8.905 sec
[2018-11-22 21:31:09.776]  Step 252885  [20.686 sec/step, loss=0.07768, avg_loss=0.07604]
[2018-11-22 21:31:53.592]  Step 252886  [20.908 sec/step, loss=0.06841, avg_loss=0.07594]
[2018-11-22 21:32:10.326]  Step 252887  [20.831 sec/step, loss=0.07485, avg_loss=0.07591]
[2018-11-22 21:32:29.021]  Step 252888  [20.880 sec/step, loss=0.07664, avg_loss=0.07594]
[2018-11-22 21:32:53.002]  Step 252889  [20.878 sec/step, loss=0.07713, avg_loss=0.07592]
[2018-11-22 21:33:15.067]  Step 252890  [20.949 sec/step, loss=0.07751, avg_loss=0.07596]
[2018-11-22 21:33:36.757]  Step 252891  [20.975 sec/step, loss=0.07693, avg_loss=0.07596]
[2018-11-22 21:34:00.584]  Step 252892  [21.108 sec/step, loss=0.07832, avg_loss=0.07605]
[2018-11-22 21:34:24.938]  Step 252893  [21.114 sec/step, loss=0.07825, avg_loss=0.07606]
[2018-11-22 21:34:50.357]  Step 252894  [21.153 sec/step, loss=0.07814, avg_loss=0.07607]
[2018-11-22 21:35:13.270]  Step 252895  [21.151 sec/step, loss=0.07798, avg_loss=0.07607]
[2018-11-22 21:35:36.790]  Step 252896  [21.160 sec/step, loss=0.07684, avg_loss=0.07606]
[2018-11-22 21:35:57.664]  Step 252897  [21.167 sec/step, loss=0.07647, avg_loss=0.07605]
[2018-11-22 21:36:17.019]  Step 252898  [21.148 sec/step, loss=0.07734, avg_loss=0.07604]
[2018-11-22 21:36:37.624]  Step 252899  [21.106 sec/step, loss=0.07781, avg_loss=0.07604]
[2018-11-22 21:37:02.175]  Step 252900  [21.096 sec/step, loss=0.07712, avg_loss=0.07603]
[2018-11-22 21:37:02.175]  Writing summary at step: 252900
[2018-11-22 21:37:48.906]  Step 252901  [21.093 sec/step, loss=0.07683, avg_loss=0.07603]
[2018-11-22 21:38:10.135]  Step 252902  [21.088 sec/step, loss=0.07738, avg_loss=0.07603]
[2018-11-22 21:38:31.856]  Step 252903  [21.042 sec/step, loss=0.07755, avg_loss=0.07603]
[2018-11-22 21:39:10.285]  Step 252904  [21.341 sec/step, loss=0.06853, avg_loss=0.07614]
[2018-11-22 21:39:29.988]  Step 252905  [21.435 sec/step, loss=0.07636, avg_loss=0.07621]
[2018-11-22 21:39:47.690]  Step 252906  [21.363 sec/step, loss=0.07612, avg_loss=0.07619]
[2018-11-22 21:40:09.957]  Step 252907  [21.352 sec/step, loss=0.07741, avg_loss=0.07618]
[2018-11-22 21:40:28.456]  Step 252908  [21.290 sec/step, loss=0.07708, avg_loss=0.07617]
[2018-11-22 21:40:37.187]  Step 252909  [21.229 sec/step, loss=0.05549, avg_loss=0.07599]
[2018-11-22 21:41:02.145]  Step 252910  [21.258 sec/step, loss=0.07747, avg_loss=0.07599]
[2018-11-22 21:41:12.694]  Step 252911  [21.190 sec/step, loss=0.06876, avg_loss=0.07591]
[2018-11-22 21:41:28.325]  Step 252912  [20.902 sec/step, loss=0.07477, avg_loss=0.07597]
[2018-11-22 21:41:47.311]  Step 252913  [20.976 sec/step, loss=0.07702, avg_loss=0.07600]
[2018-11-22 21:42:03.288]  Step 252914  [20.945 sec/step, loss=0.07328, avg_loss=0.07597]
[2018-11-22 21:42:27.674]  Step 252915  [20.951 sec/step, loss=0.07755, avg_loss=0.07597]
[2018-11-22 21:42:38.038]  Generated 32 batches of size 32 in 9.578 sec
[2018-11-22 21:42:55.088]  Step 252916  [20.984 sec/step, loss=0.07833, avg_loss=0.07597]
[2018-11-22 21:43:19.133]  Step 252917  [21.014 sec/step, loss=0.07779, avg_loss=0.07597]
[2018-11-22 21:43:40.923]  Step 252918  [20.987 sec/step, loss=0.07671, avg_loss=0.07596]
[2018-11-22 21:43:57.923]  Step 252919  [20.933 sec/step, loss=0.07629, avg_loss=0.07594]
[2018-11-22 21:44:19.682]  Step 252920  [20.964 sec/step, loss=0.07806, avg_loss=0.07595]
[2018-11-22 21:44:33.411]  Step 252921  [20.875 sec/step, loss=0.07383, avg_loss=0.07591]
[2018-11-22 21:44:55.205]  Step 252922  [20.860 sec/step, loss=0.07713, avg_loss=0.07591]
[2018-11-22 21:45:06.895]  Step 252923  [20.844 sec/step, loss=0.07352, avg_loss=0.07589]
[2018-11-22 21:45:33.720]  Step 252924  [20.947 sec/step, loss=0.07690, avg_loss=0.07591]
[2018-11-22 21:46:00.235]  Step 252925  [21.038 sec/step, loss=0.07800, avg_loss=0.07592]
[2018-11-22 21:46:23.075]  Step 252926  [21.083 sec/step, loss=0.07768, avg_loss=0.07591]
[2018-11-22 21:46:47.051]  Step 252927  [21.088 sec/step, loss=0.07732, avg_loss=0.07590]
[2018-11-22 21:47:13.627]  Step 252928  [21.140 sec/step, loss=0.07737, avg_loss=0.07590]
[2018-11-22 21:47:30.461]  Step 252929  [21.067 sec/step, loss=0.07688, avg_loss=0.07588]
[2018-11-22 21:47:50.149]  Step 252930  [21.067 sec/step, loss=0.07639, avg_loss=0.07587]
[2018-11-22 21:48:10.823]  Step 252931  [21.081 sec/step, loss=0.07691, avg_loss=0.07587]
[2018-11-22 21:48:26.985]  Step 252932  [20.989 sec/step, loss=0.07477, avg_loss=0.07583]
[2018-11-22 21:48:52.455]  Step 252933  [21.056 sec/step, loss=0.07807, avg_loss=0.07584]
[2018-11-22 21:49:06.538]  Step 252934  [20.791 sec/step, loss=0.07492, avg_loss=0.07590]
[2018-11-22 21:49:28.643]  Step 252935  [20.798 sec/step, loss=0.07702, avg_loss=0.07590]
[2018-11-22 21:50:11.389]  Step 252936  [20.985 sec/step, loss=0.06863, avg_loss=0.07580]
[2018-11-22 21:50:27.053]  Step 252937  [20.901 sec/step, loss=0.07585, avg_loss=0.07579]
[2018-11-22 21:50:48.151]  Step 252938  [20.902 sec/step, loss=0.07769, avg_loss=0.07579]
[2018-11-22 21:51:09.803]  Step 252939  [20.866 sec/step, loss=0.07789, avg_loss=0.07579]
[2018-11-22 21:51:34.223]  Step 252940  [20.882 sec/step, loss=0.07748, avg_loss=0.07579]
[2018-11-22 21:51:55.705]  Step 252941  [20.875 sec/step, loss=0.07690, avg_loss=0.07578]
[2018-11-22 21:52:08.172]  Step 252942  [20.753 sec/step, loss=0.07298, avg_loss=0.07573]
[2018-11-22 21:52:18.723]  Step 252943  [20.690 sec/step, loss=0.06955, avg_loss=0.07565]
[2018-11-22 21:52:37.087]  Step 252944  [20.644 sec/step, loss=0.07770, avg_loss=0.07565]
[2018-11-22 21:52:58.796]  Step 252945  [20.657 sec/step, loss=0.07739, avg_loss=0.07565]
[2018-11-22 21:53:17.936]  Step 252946  [20.632 sec/step, loss=0.07645, avg_loss=0.07563]
[2018-11-22 21:53:35.982]  Step 252947  [20.568 sec/step, loss=0.07608, avg_loss=0.07562]
[2018-11-22 21:53:46.036]  Generated 32 batches of size 32 in 9.155 sec
[2018-11-22 21:54:00.028]  Step 252948  [20.721 sec/step, loss=0.07810, avg_loss=0.07583]
[2018-11-22 21:54:19.278]  Step 252949  [20.792 sec/step, loss=0.07679, avg_loss=0.07587]
[2018-11-22 21:54:44.018]  Step 252950  [20.885 sec/step, loss=0.07732, avg_loss=0.07589]
[2018-11-22 21:54:44.018]  Writing summary at step: 252950
[2018-11-22 21:55:17.193]  Step 252951  [20.989 sec/step, loss=0.07797, avg_loss=0.07592]
[2018-11-22 21:55:41.083]  Step 252952  [21.074 sec/step, loss=0.07708, avg_loss=0.07595]
[2018-11-22 21:56:03.176]  Step 252953  [21.175 sec/step, loss=0.07759, avg_loss=0.07603]
[2018-11-22 21:56:26.110]  Step 252954  [21.166 sec/step, loss=0.07786, avg_loss=0.07603]
[2018-11-22 21:56:46.243]  Step 252955  [21.121 sec/step, loss=0.07764, avg_loss=0.07602]
[2018-11-22 21:56:56.515]  Step 252956  [21.010 sec/step, loss=0.06861, avg_loss=0.07593]
[2018-11-22 21:57:19.842]  Step 252957  [21.061 sec/step, loss=0.07696, avg_loss=0.07594]
[2018-11-22 21:57:37.395]  Step 252958  [21.019 sec/step, loss=0.07580, avg_loss=0.07592]
[2018-11-22 21:57:52.784]  Step 252959  [20.975 sec/step, loss=0.07429, avg_loss=0.07589]
[2018-11-22 21:58:13.261]  Step 252960  [20.973 sec/step, loss=0.07624, avg_loss=0.07589]
[2018-11-22 21:58:29.972]  Step 252961  [20.882 sec/step, loss=0.07638, avg_loss=0.07587]
[2018-11-22 21:58:56.397]  Step 252962  [20.924 sec/step, loss=0.07677, avg_loss=0.07586]
[2018-11-22 21:59:05.075]  Step 252963  [20.802 sec/step, loss=0.05789, avg_loss=0.07566]
[2018-11-22 21:59:29.550]  Step 252964  [20.785 sec/step, loss=0.07764, avg_loss=0.07567]
[2018-11-22 21:59:49.513]  Step 252965  [20.899 sec/step, loss=0.07725, avg_loss=0.07587]
[2018-11-22 22:00:13.216]  Step 252966  [20.979 sec/step, loss=0.07748, avg_loss=0.07591]
[2018-11-22 22:00:38.806]  Step 252967  [21.114 sec/step, loss=0.07783, avg_loss=0.07596]
[2018-11-22 22:01:02.227]  Step 252968  [21.096 sec/step, loss=0.07712, avg_loss=0.07595]
[2018-11-22 22:01:28.735]  Step 252969  [21.114 sec/step, loss=0.07678, avg_loss=0.07594]
[2018-11-22 22:01:42.305]  Step 252970  [21.014 sec/step, loss=0.07241, avg_loss=0.07589]
[2018-11-22 22:02:07.204]  Step 252971  [21.084 sec/step, loss=0.07775, avg_loss=0.07591]
[2018-11-22 22:02:29.211]  Step 252972  [21.076 sec/step, loss=0.07650, avg_loss=0.07589]
[2018-11-22 22:02:48.536]  Step 252973  [21.080 sec/step, loss=0.07650, avg_loss=0.07588]
[2018-11-22 22:03:11.647]  Step 252974  [21.207 sec/step, loss=0.07746, avg_loss=0.07596]
[2018-11-22 22:03:36.189]  Step 252975  [21.206 sec/step, loss=0.07874, avg_loss=0.07597]
[2018-11-22 22:03:57.900]  Step 252976  [21.247 sec/step, loss=0.07704, avg_loss=0.07597]
[2018-11-22 22:04:13.750]  Step 252977  [21.168 sec/step, loss=0.07294, avg_loss=0.07592]
[2018-11-22 22:04:35.844]  Step 252978  [21.202 sec/step, loss=0.07778, avg_loss=0.07593]
[2018-11-22 22:04:52.777]  Generated 32 batches of size 32 in 15.968 sec
[2018-11-22 22:05:23.497]  Step 252979  [21.437 sec/step, loss=0.06862, avg_loss=0.07584]
[2018-11-22 22:05:43.467]  Step 252980  [21.424 sec/step, loss=0.07755, avg_loss=0.07584]
[2018-11-22 22:05:58.609]  Step 252981  [21.376 sec/step, loss=0.07413, avg_loss=0.07582]
[2018-11-22 22:06:21.210]  Step 252982  [21.357 sec/step, loss=0.07647, avg_loss=0.07581]
[2018-11-22 22:06:44.391]  Step 252983  [21.385 sec/step, loss=0.07698, avg_loss=0.07581]
[2018-11-22 22:07:06.081]  Step 252984  [21.462 sec/step, loss=0.07741, avg_loss=0.07583]
[2018-11-22 22:07:27.443]  Step 252985  [21.450 sec/step, loss=0.07735, avg_loss=0.07583]
[2018-11-22 22:07:51.511]  Step 252986  [21.252 sec/step, loss=0.07763, avg_loss=0.07592]
[2018-11-22 22:08:17.860]  Step 252987  [21.348 sec/step, loss=0.07726, avg_loss=0.07594]
[2018-11-22 22:08:43.223]  Step 252988  [21.415 sec/step, loss=0.07796, avg_loss=0.07596]
[2018-11-22 22:09:08.012]  Step 252989  [21.423 sec/step, loss=0.07725, avg_loss=0.07596]
[2018-11-22 22:09:20.438]  Step 252990  [21.327 sec/step, loss=0.07302, avg_loss=0.07591]
[2018-11-22 22:09:38.647]  Step 252991  [21.292 sec/step, loss=0.07605, avg_loss=0.07591]
[2018-11-22 22:10:03.766]  Step 252992  [21.305 sec/step, loss=0.07720, avg_loss=0.07589]
[2018-11-22 22:10:27.959]  Step 252993  [21.303 sec/step, loss=0.07663, avg_loss=0.07588]
[2018-11-22 22:10:45.520]  Step 252994  [21.225 sec/step, loss=0.07626, avg_loss=0.07586]
[2018-11-22 22:11:08.475]  Step 252995  [21.225 sec/step, loss=0.07695, avg_loss=0.07585]
[2018-11-22 22:11:34.941]  Step 252996  [21.255 sec/step, loss=0.07688, avg_loss=0.07585]
[2018-11-22 22:11:55.660]  Step 252997  [21.253 sec/step, loss=0.07698, avg_loss=0.07585]
[2018-11-22 22:12:04.449]  Step 252998  [21.147 sec/step, loss=0.05660, avg_loss=0.07565]
[2018-11-22 22:12:23.717]  Step 252999  [21.134 sec/step, loss=0.07710, avg_loss=0.07564]
[2018-11-22 22:13:01.194]  Step 253000  [21.263 sec/step, loss=0.06832, avg_loss=0.07555]
[2018-11-22 22:13:01.194]  Writing summary at step: 253000
[2018-11-22 22:13:22.075]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-253000
[2018-11-22 22:13:26.577]  Saving audio and alignment...
[2018-11-22 22:13:41.049]  Input: he ought now to have been at school; but his mama had taken him home for a month or two, on account of his delicate health. mister miles, the master, affirmed that he would do very well~______
[2018-11-22 22:13:56.708]  Step 253001  [21.191 sec/step, loss=0.07468, avg_loss=0.07553]
[2018-11-22 22:14:20.594]  Step 253002  [21.217 sec/step, loss=0.07719, avg_loss=0.07553]
[2018-11-22 22:14:42.629]  Step 253003  [21.220 sec/step, loss=0.07742, avg_loss=0.07553]
[2018-11-22 22:15:05.514]  Step 253004  [21.065 sec/step, loss=0.07760, avg_loss=0.07562]
[2018-11-22 22:15:29.119]  Step 253005  [21.104 sec/step, loss=0.07776, avg_loss=0.07563]
[2018-11-22 22:15:39.964]  Step 253006  [21.035 sec/step, loss=0.07055, avg_loss=0.07558]
[2018-11-22 22:15:58.923]  Step 253007  [21.002 sec/step, loss=0.07714, avg_loss=0.07557]
[2018-11-22 22:16:18.287]  Step 253008  [21.011 sec/step, loss=0.07631, avg_loss=0.07557]
[2018-11-22 22:16:28.798]  Generated 32 batches of size 32 in 9.761 sec
[2018-11-22 22:16:43.072]  Step 253009  [21.172 sec/step, loss=0.07696, avg_loss=0.07578]
[2018-11-22 22:17:07.102]  Step 253010  [21.162 sec/step, loss=0.07771, avg_loss=0.07578]
[2018-11-22 22:17:22.866]  Step 253011  [21.214 sec/step, loss=0.07407, avg_loss=0.07584]
[2018-11-22 22:17:43.919]  Step 253012  [21.269 sec/step, loss=0.07738, avg_loss=0.07586]
[2018-11-22 22:18:06.345]  Step 253013  [21.303 sec/step, loss=0.07633, avg_loss=0.07586]
[2018-11-22 22:18:31.643]  Step 253014  [21.396 sec/step, loss=0.07808, avg_loss=0.07590]
[2018-11-22 22:18:53.632]  Step 253015  [21.372 sec/step, loss=0.07696, avg_loss=0.07590]
[2018-11-22 22:19:13.729]  Step 253016  [21.299 sec/step, loss=0.07728, avg_loss=0.07589]
[2018-11-22 22:19:27.624]  Step 253017  [21.198 sec/step, loss=0.07432, avg_loss=0.07585]
[2018-11-22 22:19:49.927]  Step 253018  [21.203 sec/step, loss=0.07736, avg_loss=0.07586]
[2018-11-22 22:20:14.256]  Step 253019  [21.276 sec/step, loss=0.07797, avg_loss=0.07588]
[2018-11-22 22:20:32.866]  Step 253020  [21.245 sec/step, loss=0.07693, avg_loss=0.07586]
[2018-11-22 22:20:41.640]  Step 253021  [21.195 sec/step, loss=0.05724, avg_loss=0.07570]
[2018-11-22 22:21:25.475]  Step 253022  [21.415 sec/step, loss=0.06817, avg_loss=0.07561]
[2018-11-22 22:21:42.721]  Step 253023  [21.471 sec/step, loss=0.07621, avg_loss=0.07564]
[2018-11-22 22:22:06.929]  Step 253024  [21.445 sec/step, loss=0.07744, avg_loss=0.07564]
[2018-11-22 22:22:27.883]  Step 253025  [21.389 sec/step, loss=0.07737, avg_loss=0.07563]
[2018-11-22 22:22:50.114]  Step 253026  [21.383 sec/step, loss=0.07612, avg_loss=0.07562]
[2018-11-22 22:23:09.672]  Step 253027  [21.339 sec/step, loss=0.07658, avg_loss=0.07561]
[2018-11-22 22:23:31.222]  Step 253028  [21.289 sec/step, loss=0.07618, avg_loss=0.07560]
[2018-11-22 22:23:53.435]  Step 253029  [21.342 sec/step, loss=0.07639, avg_loss=0.07559]
[2018-11-22 22:24:15.988]  Step 253030  [21.371 sec/step, loss=0.07785, avg_loss=0.07561]
[2018-11-22 22:24:34.383]  Step 253031  [21.348 sec/step, loss=0.07618, avg_loss=0.07560]
[2018-11-22 22:24:58.380]  Step 253032  [21.427 sec/step, loss=0.07687, avg_loss=0.07562]
[2018-11-22 22:25:18.414]  Step 253033  [21.372 sec/step, loss=0.07740, avg_loss=0.07562]
[2018-11-22 22:25:34.567]  Step 253034  [21.393 sec/step, loss=0.07460, avg_loss=0.07561]
[2018-11-22 22:25:58.639]  Step 253035  [21.413 sec/step, loss=0.07784, avg_loss=0.07562]
[2018-11-22 22:26:13.800]  Step 253036  [21.137 sec/step, loss=0.07302, avg_loss=0.07567]
[2018-11-22 22:26:38.367]  Step 253037  [21.226 sec/step, loss=0.07735, avg_loss=0.07568]
[2018-11-22 22:27:03.821]  Step 253038  [21.269 sec/step, loss=0.07806, avg_loss=0.07568]
[2018-11-22 22:27:26.150]  Step 253039  [21.276 sec/step, loss=0.07827, avg_loss=0.07569]
[2018-11-22 22:27:47.935]  Step 253040  [21.250 sec/step, loss=0.07723, avg_loss=0.07569]
[2018-11-22 22:27:59.535]  Generated 32 batches of size 32 in 10.703 sec
[2018-11-22 22:28:17.769]  Step 253041  [21.333 sec/step, loss=0.07690, avg_loss=0.07569]
[2018-11-22 22:28:37.793]  Step 253042  [21.409 sec/step, loss=0.07656, avg_loss=0.07572]
[2018-11-22 22:28:48.047]  Step 253043  [21.406 sec/step, loss=0.06939, avg_loss=0.07572]
[2018-11-22 22:28:59.518]  Step 253044  [21.337 sec/step, loss=0.07305, avg_loss=0.07567]
[2018-11-22 22:29:22.392]  Step 253045  [21.349 sec/step, loss=0.07778, avg_loss=0.07568]
[2018-11-22 22:29:44.323]  Step 253046  [21.377 sec/step, loss=0.07632, avg_loss=0.07568]
[2018-11-22 22:30:13.986]  Step 253047  [21.493 sec/step, loss=0.07711, avg_loss=0.07569]
[2018-11-22 22:30:39.841]  Step 253048  [21.511 sec/step, loss=0.07731, avg_loss=0.07568]
[2018-11-22 22:30:55.242]  Step 253049  [21.472 sec/step, loss=0.07426, avg_loss=0.07565]
[2018-11-22 22:31:14.721]  Step 253050  [21.420 sec/step, loss=0.07455, avg_loss=0.07563]
[2018-11-22 22:31:14.721]  Writing summary at step: 253050
[2018-11-22 22:32:16.301]  Step 253051  [21.519 sec/step, loss=0.07700, avg_loss=0.07562]
[2018-11-22 22:32:45.308]  Step 253052  [21.570 sec/step, loss=0.07639, avg_loss=0.07561]
[2018-11-22 22:32:59.442]  Step 253053  [21.490 sec/step, loss=0.06832, avg_loss=0.07552]
[2018-11-22 22:33:30.824]  Step 253054  [21.575 sec/step, loss=0.07713, avg_loss=0.07551]
[2018-11-22 22:33:49.155]  Step 253055  [21.557 sec/step, loss=0.07394, avg_loss=0.07547]
[2018-11-22 22:34:16.825]  Step 253056  [21.731 sec/step, loss=0.07715, avg_loss=0.07556]
[2018-11-22 22:34:39.107]  Step 253057  [21.720 sec/step, loss=0.07372, avg_loss=0.07552]
[2018-11-22 22:35:11.027]  Step 253058  [21.864 sec/step, loss=0.07707, avg_loss=0.07554]
[2018-11-22 22:35:42.065]  Step 253059  [22.020 sec/step, loss=0.07774, avg_loss=0.07557]
[2018-11-22 22:36:12.499]  Step 253060  [22.120 sec/step, loss=0.07666, avg_loss=0.07558]
[2018-11-22 22:36:35.810]  Step 253061  [22.186 sec/step, loss=0.07587, avg_loss=0.07557]
[2018-11-22 22:37:08.450]  Step 253062  [22.248 sec/step, loss=0.07685, avg_loss=0.07557]
[2018-11-22 22:37:33.139]  Step 253063  [22.408 sec/step, loss=0.07593, avg_loss=0.07575]
[2018-11-22 22:38:02.187]  Step 253064  [22.454 sec/step, loss=0.07667, avg_loss=0.07574]
[2018-11-22 22:38:30.802]  Step 253065  [22.540 sec/step, loss=0.07693, avg_loss=0.07574]
[2018-11-22 22:38:56.404]  Step 253066  [22.559 sec/step, loss=0.07649, avg_loss=0.07573]
[2018-11-22 22:39:23.659]  Step 253067  [22.576 sec/step, loss=0.07659, avg_loss=0.07572]
[2018-11-22 22:39:45.510]  Step 253068  [22.560 sec/step, loss=0.07609, avg_loss=0.07571]
[2018-11-22 22:40:00.712]  Step 253069  [22.447 sec/step, loss=0.07377, avg_loss=0.07568]
[2018-11-22 22:40:19.506]  Step 253070  [22.500 sec/step, loss=0.07759, avg_loss=0.07573]
[2018-11-22 22:40:40.858]  Step 253071  [22.464 sec/step, loss=0.07785, avg_loss=0.07573]
[2018-11-22 22:40:50.066]  Generated 32 batches of size 32 in 8.385 sec
[2018-11-22 22:41:04.040]  Step 253072  [22.476 sec/step, loss=0.07694, avg_loss=0.07573]
[2018-11-22 22:41:12.796]  Step 253073  [22.370 sec/step, loss=0.05760, avg_loss=0.07554]
[2018-11-22 22:41:35.471]  Step 253074  [22.366 sec/step, loss=0.07739, avg_loss=0.07554]
[2018-11-22 22:42:00.901]  Step 253075  [22.375 sec/step, loss=0.07763, avg_loss=0.07553]
[2018-11-22 22:42:27.924]  Step 253076  [22.428 sec/step, loss=0.07650, avg_loss=0.07553]
[2018-11-22 22:43:06.477]  Step 253077  [22.655 sec/step, loss=0.06826, avg_loss=0.07548]
[2018-11-22 22:43:28.499]  Step 253078  [22.654 sec/step, loss=0.07728, avg_loss=0.07548]
[2018-11-22 22:43:50.032]  Step 253079  [22.393 sec/step, loss=0.07751, avg_loss=0.07556]
[2018-11-22 22:44:13.877]  Step 253080  [22.432 sec/step, loss=0.07816, avg_loss=0.07557]
[2018-11-22 22:44:34.821]  Step 253081  [22.490 sec/step, loss=0.07744, avg_loss=0.07560]
[2018-11-22 22:44:57.479]  Step 253082  [22.490 sec/step, loss=0.07707, avg_loss=0.07561]
[2018-11-22 22:45:20.923]  Step 253083  [22.493 sec/step, loss=0.07718, avg_loss=0.07561]
[2018-11-22 22:45:41.754]  Step 253084  [22.484 sec/step, loss=0.07711, avg_loss=0.07561]
[2018-11-22 22:46:01.266]  Step 253085  [22.466 sec/step, loss=0.07667, avg_loss=0.07560]
[2018-11-22 22:46:16.968]  Step 253086  [22.382 sec/step, loss=0.07450, avg_loss=0.07557]
[2018-11-22 22:46:41.124]  Step 253087  [22.360 sec/step, loss=0.07663, avg_loss=0.07556]
[2018-11-22 22:47:05.678]  Step 253088  [22.352 sec/step, loss=0.07778, avg_loss=0.07556]
[2018-11-22 22:47:30.049]  Step 253089  [22.348 sec/step, loss=0.07703, avg_loss=0.07556]
[2018-11-22 22:47:49.708]  Step 253090  [22.420 sec/step, loss=0.07678, avg_loss=0.07560]
[2018-11-22 22:48:11.715]  Step 253091  [22.458 sec/step, loss=0.07611, avg_loss=0.07560]
[2018-11-22 22:48:36.259]  Step 253092  [22.453 sec/step, loss=0.07675, avg_loss=0.07559]
[2018-11-22 22:48:57.885]  Step 253093  [22.427 sec/step, loss=0.07640, avg_loss=0.07559]
[2018-11-22 22:49:08.333]  Step 253094  [22.356 sec/step, loss=0.06809, avg_loss=0.07551]
[2018-11-22 22:49:22.052]  Step 253095  [22.263 sec/step, loss=0.07401, avg_loss=0.07548]
[2018-11-22 22:49:34.195]  Step 253096  [22.120 sec/step, loss=0.07198, avg_loss=0.07543]
[2018-11-22 22:49:51.011]  Step 253097  [22.081 sec/step, loss=0.07617, avg_loss=0.07542]
[2018-11-22 22:50:11.348]  Step 253098  [22.197 sec/step, loss=0.07658, avg_loss=0.07562]
[2018-11-22 22:50:34.408]  Step 253099  [22.235 sec/step, loss=0.07666, avg_loss=0.07562]
[2018-11-22 22:50:58.894]  Step 253100  [22.105 sec/step, loss=0.07762, avg_loss=0.07571]
[2018-11-22 22:50:58.895]  Writing summary at step: 253100
[2018-11-22 22:51:39.512]  Step 253101  [22.170 sec/step, loss=0.07726, avg_loss=0.07574]
[2018-11-22 22:52:03.053]  Step 253102  [22.167 sec/step, loss=0.07701, avg_loss=0.07574]
[2018-11-22 22:52:12.472]  Generated 32 batches of size 32 in 8.569 sec
[2018-11-22 22:52:26.743]  Step 253103  [22.183 sec/step, loss=0.07753, avg_loss=0.07574]
[2018-11-22 22:53:05.139]  Step 253104  [22.338 sec/step, loss=0.06785, avg_loss=0.07564]
[2018-11-22 22:53:13.701]  Step 253105  [22.188 sec/step, loss=0.05729, avg_loss=0.07543]
[2018-11-22 22:53:33.238]  Step 253106  [22.275 sec/step, loss=0.07583, avg_loss=0.07549]
[2018-11-22 22:53:49.142]  Step 253107  [22.244 sec/step, loss=0.07361, avg_loss=0.07545]
[2018-11-22 22:54:15.892]  Step 253108  [22.318 sec/step, loss=0.07662, avg_loss=0.07546]
[2018-11-22 22:54:38.031]  Step 253109  [22.292 sec/step, loss=0.07730, avg_loss=0.07546]
[2018-11-22 22:55:03.705]  Step 253110  [22.308 sec/step, loss=0.07790, avg_loss=0.07546]
[2018-11-22 22:55:23.497]  Step 253111  [22.348 sec/step, loss=0.07620, avg_loss=0.07548]
[2018-11-22 22:55:42.915]  Step 253112  [22.332 sec/step, loss=0.07677, avg_loss=0.07548]
[2018-11-22 22:56:07.104]  Step 253113  [22.350 sec/step, loss=0.07680, avg_loss=0.07548]
[2018-11-22 22:56:28.492]  Step 253114  [22.310 sec/step, loss=0.07674, avg_loss=0.07547]
[2018-11-22 22:56:51.559]  Step 253115  [22.321 sec/step, loss=0.07715, avg_loss=0.07547]
[2018-11-22 22:57:12.868]  Step 253116  [22.333 sec/step, loss=0.07655, avg_loss=0.07546]
[2018-11-22 22:57:35.618]  Step 253117  [22.422 sec/step, loss=0.07690, avg_loss=0.07549]
[2018-11-22 22:57:54.687]  Step 253118  [22.390 sec/step, loss=0.07611, avg_loss=0.07548]
[2018-11-22 22:58:19.674]  Step 253119  [22.396 sec/step, loss=0.07664, avg_loss=0.07546]
[2018-11-22 22:58:44.105]  Step 253120  [22.454 sec/step, loss=0.07705, avg_loss=0.07546]
[2018-11-22 22:59:24.057]  Step 253121  [22.766 sec/step, loss=0.06824, avg_loss=0.07557]
[2018-11-22 22:59:40.222]  Step 253122  [22.489 sec/step, loss=0.07406, avg_loss=0.07563]
[2018-11-22 22:59:48.514]  Step 253123  [22.400 sec/step, loss=0.05791, avg_loss=0.07545]
[2018-11-22 23:00:05.727]  Step 253124  [22.330 sec/step, loss=0.07671, avg_loss=0.07544]
[2018-11-22 23:00:26.882]  Step 253125  [22.332 sec/step, loss=0.07712, avg_loss=0.07544]
[2018-11-22 23:00:47.250]  Step 253126  [22.313 sec/step, loss=0.07715, avg_loss=0.07545]
[2018-11-22 23:01:14.980]  Step 253127  [22.395 sec/step, loss=0.07634, avg_loss=0.07545]
[2018-11-22 23:01:37.364]  Step 253128  [22.403 sec/step, loss=0.07692, avg_loss=0.07545]
[2018-11-22 23:01:47.875]  Step 253129  [22.286 sec/step, loss=0.06778, avg_loss=0.07537]
[2018-11-22 23:02:13.967]  Step 253130  [22.322 sec/step, loss=0.07651, avg_loss=0.07536]
[2018-11-22 23:02:32.353]  Step 253131  [22.322 sec/step, loss=0.07548, avg_loss=0.07535]
[2018-11-22 23:02:54.734]  Step 253132  [22.305 sec/step, loss=0.07754, avg_loss=0.07535]
[2018-11-22 23:03:13.437]  Step 253133  [22.292 sec/step, loss=0.07677, avg_loss=0.07535]
[2018-11-22 23:03:25.559]  Step 253134  [22.252 sec/step, loss=0.07345, avg_loss=0.07534]
[2018-11-22 23:03:34.492]  Generated 32 batches of size 32 in 8.160 sec
[2018-11-22 23:03:46.501]  Step 253135  [22.221 sec/step, loss=0.07607, avg_loss=0.07532]
[2018-11-22 23:04:08.299]  Step 253136  [22.287 sec/step, loss=0.07673, avg_loss=0.07536]
[2018-11-22 23:04:23.245]  Step 253137  [22.191 sec/step, loss=0.07395, avg_loss=0.07532]
[2018-11-22 23:04:43.714]  Step 253138  [22.141 sec/step, loss=0.07668, avg_loss=0.07531]
[2018-11-22 23:05:07.393]  Step 253139  [22.154 sec/step, loss=0.07757, avg_loss=0.07530]
[2018-11-22 23:05:31.778]  Step 253140  [22.180 sec/step, loss=0.07778, avg_loss=0.07531]
[2018-11-22 23:05:56.179]  Step 253141  [22.126 sec/step, loss=0.07704, avg_loss=0.07531]
[2018-11-22 23:06:09.604]  Step 253142  [22.060 sec/step, loss=0.07464, avg_loss=0.07529]
[2018-11-22 23:06:34.208]  Step 253143  [22.204 sec/step, loss=0.07780, avg_loss=0.07537]
[2018-11-22 23:06:56.441]  Step 253144  [22.311 sec/step, loss=0.07699, avg_loss=0.07541]
[2018-11-22 23:07:18.819]  Step 253145  [22.306 sec/step, loss=0.07713, avg_loss=0.07541]
[2018-11-22 23:07:36.610]  Step 253146  [22.265 sec/step, loss=0.07559, avg_loss=0.07540]
[2018-11-22 23:07:54.689]  Step 253147  [22.149 sec/step, loss=0.07702, avg_loss=0.07540]
[2018-11-22 23:08:15.081]  Step 253148  [22.094 sec/step, loss=0.07618, avg_loss=0.07539]
[2018-11-22 23:08:29.415]  Step 253149  [22.084 sec/step, loss=0.07421, avg_loss=0.07539]
[2018-11-22 23:08:49.052]  Step 253150  [22.085 sec/step, loss=0.07609, avg_loss=0.07540]
[2018-11-22 23:08:49.052]  Writing summary at step: 253150
[2018-11-22 23:09:40.064]  Step 253151  [21.987 sec/step, loss=0.07740, avg_loss=0.07541]
[2018-11-22 23:09:59.457]  Step 253152  [21.891 sec/step, loss=0.07599, avg_loss=0.07540]
[2018-11-22 23:10:09.934]  Step 253153  [21.854 sec/step, loss=0.06994, avg_loss=0.07542]
[2018-11-22 23:10:34.390]  Step 253154  [21.785 sec/step, loss=0.07670, avg_loss=0.07541]
[2018-11-22 23:10:43.634]  Step 253155  [21.694 sec/step, loss=0.05808, avg_loss=0.07526]
[2018-11-22 23:11:05.015]  Step 253156  [21.631 sec/step, loss=0.07721, avg_loss=0.07526]
[2018-11-22 23:11:42.991]  Step 253157  [21.788 sec/step, loss=0.06783, avg_loss=0.07520]
[2018-11-22 23:12:05.059]  Step 253158  [21.690 sec/step, loss=0.07716, avg_loss=0.07520]
[2018-11-22 23:12:31.045]  Step 253159  [21.639 sec/step, loss=0.07719, avg_loss=0.07519]
[2018-11-22 23:12:46.676]  Step 253160  [21.491 sec/step, loss=0.07518, avg_loss=0.07518]
[2018-11-22 23:13:03.727]  Step 253161  [21.428 sec/step, loss=0.07598, avg_loss=0.07518]
[2018-11-22 23:13:25.464]  Step 253162  [21.319 sec/step, loss=0.07645, avg_loss=0.07517]
[2018-11-22 23:13:49.511]  Step 253163  [21.313 sec/step, loss=0.07654, avg_loss=0.07518]
[2018-11-22 23:14:16.496]  Step 253164  [21.292 sec/step, loss=0.07725, avg_loss=0.07519]
[2018-11-22 23:14:38.795]  Step 253165  [21.229 sec/step, loss=0.07650, avg_loss=0.07518]
[2018-11-22 23:14:49.871]  Generated 32 batches of size 32 in 10.025 sec
[2018-11-22 23:15:06.020]  Step 253166  [21.245 sec/step, loss=0.07716, avg_loss=0.07519]
[2018-11-22 23:15:18.974]  Step 253167  [21.102 sec/step, loss=0.07263, avg_loss=0.07515]
[2018-11-22 23:15:43.399]  Step 253168  [21.128 sec/step, loss=0.07663, avg_loss=0.07515]
[2018-11-22 23:16:06.909]  Step 253169  [21.211 sec/step, loss=0.07714, avg_loss=0.07519]
[2018-11-22 23:16:30.812]  Step 253170  [21.262 sec/step, loss=0.07717, avg_loss=0.07518]
[2018-11-22 23:16:51.226]  Step 253171  [21.253 sec/step, loss=0.07728, avg_loss=0.07518]
[2018-11-22 23:17:12.334]  Step 253172  [21.232 sec/step, loss=0.07718, avg_loss=0.07518]
[2018-11-22 23:17:27.954]  Step 253173  [21.301 sec/step, loss=0.07441, avg_loss=0.07535]
[2018-11-22 23:17:47.302]  Step 253174  [21.268 sec/step, loss=0.07613, avg_loss=0.07534]
[2018-11-22 23:18:08.602]  Step 253175  [21.226 sec/step, loss=0.07668, avg_loss=0.07533]
[2018-11-22 23:18:27.423]  Step 253176  [21.144 sec/step, loss=0.07577, avg_loss=0.07532]
[2018-11-22 23:18:43.292]  Step 253177  [20.917 sec/step, loss=0.07259, avg_loss=0.07536]
[2018-11-22 23:18:55.243]  Step 253178  [20.817 sec/step, loss=0.07215, avg_loss=0.07531]
[2018-11-22 23:19:19.474]  Step 253179  [20.844 sec/step, loss=0.07719, avg_loss=0.07531]
[2018-11-22 23:19:42.250]  Step 253180  [20.833 sec/step, loss=0.07681, avg_loss=0.07529]
[2018-11-22 23:19:50.844]  Step 253181  [20.709 sec/step, loss=0.05644, avg_loss=0.07508]
[2018-11-22 23:20:12.714]  Step 253182  [20.702 sec/step, loss=0.07730, avg_loss=0.07509]
[2018-11-22 23:20:28.323]  Step 253183  [20.623 sec/step, loss=0.07435, avg_loss=0.07506]
[2018-11-22 23:20:55.819]  Step 253184  [20.690 sec/step, loss=0.07663, avg_loss=0.07505]
[2018-11-22 23:21:20.468]  Step 253185  [20.741 sec/step, loss=0.07692, avg_loss=0.07506]
[2018-11-22 23:21:47.837]  Step 253186  [20.858 sec/step, loss=0.07759, avg_loss=0.07509]
[2018-11-22 23:22:00.497]  Step 253187  [20.743 sec/step, loss=0.06895, avg_loss=0.07501]
[2018-11-22 23:22:23.199]  Step 253188  [20.724 sec/step, loss=0.07605, avg_loss=0.07499]
[2018-11-22 23:23:11.867]  Step 253189  [20.967 sec/step, loss=0.06818, avg_loss=0.07490]
[2018-11-22 23:23:35.659]  Step 253190  [21.009 sec/step, loss=0.07726, avg_loss=0.07491]
[2018-11-22 23:24:07.269]  Step 253191  [21.105 sec/step, loss=0.07730, avg_loss=0.07492]
[2018-11-22 23:24:30.326]  Step 253192  [21.090 sec/step, loss=0.07734, avg_loss=0.07493]
[2018-11-22 23:24:57.690]  Step 253193  [21.147 sec/step, loss=0.07744, avg_loss=0.07494]
[2018-11-22 23:25:22.689]  Step 253194  [21.293 sec/step, loss=0.07648, avg_loss=0.07502]
[2018-11-22 23:25:45.565]  Step 253195  [21.384 sec/step, loss=0.07719, avg_loss=0.07505]
[2018-11-22 23:26:00.935]  Step 253196  [21.417 sec/step, loss=0.07380, avg_loss=0.07507]
[2018-11-22 23:26:22.309]  Step 253197  [21.462 sec/step, loss=0.07712, avg_loss=0.07508]
[2018-11-22 23:26:33.673]  Generated 32 batches of size 32 in 10.363 sec
[2018-11-22 23:26:51.115]  Step 253198  [21.547 sec/step, loss=0.07657, avg_loss=0.07508]
[2018-11-22 23:27:17.390]  Step 253199  [21.579 sec/step, loss=0.07794, avg_loss=0.07509]
[2018-11-22 23:27:43.497]  Step 253200  [21.595 sec/step, loss=0.07717, avg_loss=0.07509]
[2018-11-22 23:27:43.497]  Writing summary at step: 253200
[2018-11-22 23:28:27.746]  Step 253201  [21.576 sec/step, loss=0.07567, avg_loss=0.07507]
[2018-11-22 23:28:47.941]  Step 253202  [21.543 sec/step, loss=0.07589, avg_loss=0.07506]
[2018-11-22 23:29:14.588]  Step 253203  [21.572 sec/step, loss=0.07631, avg_loss=0.07505]
[2018-11-22 23:29:37.059]  Step 253204  [21.413 sec/step, loss=0.07684, avg_loss=0.07514]
[2018-11-22 23:30:07.293]  Step 253205  [21.630 sec/step, loss=0.07692, avg_loss=0.07534]
[2018-11-22 23:30:30.859]  Step 253206  [21.670 sec/step, loss=0.07624, avg_loss=0.07534]
[2018-11-22 23:30:51.478]  Step 253207  [21.717 sec/step, loss=0.07337, avg_loss=0.07534]
[2018-11-22 23:31:19.929]  Step 253208  [21.734 sec/step, loss=0.07645, avg_loss=0.07534]
[2018-11-22 23:32:16.450]  Step 253209  [22.078 sec/step, loss=0.06804, avg_loss=0.07524]
[2018-11-22 23:32:34.820]  Step 253210  [22.005 sec/step, loss=0.07425, avg_loss=0.07521]
[2018-11-22 23:33:00.642]  Step 253211  [22.065 sec/step, loss=0.07666, avg_loss=0.07521]
[2018-11-22 23:33:34.470]  Step 253212  [22.209 sec/step, loss=0.07663, avg_loss=0.07521]
[2018-11-22 23:34:14.013]  Step 253213  [22.363 sec/step, loss=0.07697, avg_loss=0.07521]
[2018-11-22 23:34:53.323]  Step 253214  [22.542 sec/step, loss=0.07621, avg_loss=0.07521]
[2018-11-22 23:35:20.466]  Step 253215  [22.583 sec/step, loss=0.07606, avg_loss=0.07520]
[2018-11-22 23:35:50.090]  Step 253216  [22.666 sec/step, loss=0.07613, avg_loss=0.07519]
[2018-11-22 23:36:16.884]  Step 253217  [22.706 sec/step, loss=0.07703, avg_loss=0.07519]
[2018-11-22 23:36:42.703]  Step 253218  [22.774 sec/step, loss=0.07676, avg_loss=0.07520]
[2018-11-22 23:37:12.728]  Step 253219  [22.824 sec/step, loss=0.07651, avg_loss=0.07520]
[2018-11-22 23:37:48.434]  Step 253220  [22.937 sec/step, loss=0.07695, avg_loss=0.07520]
[2018-11-22 23:38:00.892]  Step 253221  [22.662 sec/step, loss=0.05624, avg_loss=0.07508]
[2018-11-22 23:38:33.230]  Step 253222  [22.824 sec/step, loss=0.07761, avg_loss=0.07511]
[2018-11-22 23:39:01.258]  Step 253223  [23.021 sec/step, loss=0.07663, avg_loss=0.07530]
[2018-11-22 23:39:30.902]  Step 253224  [23.145 sec/step, loss=0.07690, avg_loss=0.07530]
[2018-11-22 23:40:01.280]  Step 253225  [23.238 sec/step, loss=0.07790, avg_loss=0.07531]
[2018-11-22 23:40:31.879]  Step 253226  [23.340 sec/step, loss=0.07687, avg_loss=0.07531]
[2018-11-22 23:41:04.358]  Step 253227  [23.388 sec/step, loss=0.07580, avg_loss=0.07530]
[2018-11-22 23:41:31.649]  Step 253228  [23.437 sec/step, loss=0.07586, avg_loss=0.07529]
[2018-11-22 23:41:51.024]  Generated 32 batches of size 32 in 18.310 sec
[2018-11-22 23:42:14.560]  Step 253229  [23.761 sec/step, loss=0.07668, avg_loss=0.07538]
[2018-11-22 23:42:56.433]  Step 253230  [23.918 sec/step, loss=0.07814, avg_loss=0.07540]
[2018-11-22 23:43:13.621]  Step 253231  [23.906 sec/step, loss=0.06927, avg_loss=0.07533]
[2018-11-22 23:43:43.419]  Step 253232  [23.981 sec/step, loss=0.07731, avg_loss=0.07533]
[2018-11-22 23:44:08.004]  Step 253233  [24.039 sec/step, loss=0.07708, avg_loss=0.07533]
[2018-11-22 23:44:29.852]  Step 253234  [24.137 sec/step, loss=0.07276, avg_loss=0.07533]
[2018-11-22 23:44:43.923]  Step 253235  [24.068 sec/step, loss=0.07310, avg_loss=0.07530]
[2018-11-22 23:45:06.095]  Step 253236  [24.072 sec/step, loss=0.07750, avg_loss=0.07531]
[2018-11-22 23:45:31.555]  Step 253237  [24.177 sec/step, loss=0.07707, avg_loss=0.07534]
[2018-11-22 23:46:06.935]  Step 253238  [24.326 sec/step, loss=0.07683, avg_loss=0.07534]
[2018-11-22 23:46:37.543]  Step 253239  [24.395 sec/step, loss=0.07720, avg_loss=0.07533]
[2018-11-22 23:47:01.410]  Step 253240  [24.390 sec/step, loss=0.07606, avg_loss=0.07532]
[2018-11-22 23:47:21.893]  Step 253241  [24.351 sec/step, loss=0.07615, avg_loss=0.07531]
[2018-11-22 23:47:38.892]  Step 253242  [24.387 sec/step, loss=0.07308, avg_loss=0.07529]
[2018-11-22 23:48:12.941]  Step 253243  [24.481 sec/step, loss=0.07719, avg_loss=0.07529]
[2018-11-22 23:48:41.253]  Step 253244  [24.542 sec/step, loss=0.07679, avg_loss=0.07529]
[2018-11-22 23:49:05.899]  Step 253245  [24.564 sec/step, loss=0.07702, avg_loss=0.07528]
[2018-11-22 23:49:48.755]  Step 253246  [24.815 sec/step, loss=0.06799, avg_loss=0.07521]
[2018-11-22 23:50:22.414]  Step 253247  [24.971 sec/step, loss=0.07669, avg_loss=0.07520]
[2018-11-22 23:50:53.667]  Step 253248  [25.080 sec/step, loss=0.07658, avg_loss=0.07521]
[2018-11-22 23:51:20.025]  Step 253249  [25.200 sec/step, loss=0.07600, avg_loss=0.07523]
[2018-11-22 23:51:48.588]  Step 253250  [25.289 sec/step, loss=0.07672, avg_loss=0.07523]
[2018-11-22 23:51:48.588]  Writing summary at step: 253250
[2018-11-22 23:52:34.315]  Step 253251  [25.206 sec/step, loss=0.07271, avg_loss=0.07519]
[2018-11-22 23:52:47.165]  Step 253252  [25.141 sec/step, loss=0.05674, avg_loss=0.07499]
[2018-11-22 23:53:15.247]  Step 253253  [25.317 sec/step, loss=0.07719, avg_loss=0.07507]
[2018-11-22 23:53:40.397]  Step 253254  [25.324 sec/step, loss=0.07686, avg_loss=0.07507]
[2018-11-22 23:54:07.635]  Step 253255  [25.504 sec/step, loss=0.07671, avg_loss=0.07525]
[2018-11-22 23:54:33.914]  Step 253256  [25.553 sec/step, loss=0.07731, avg_loss=0.07525]
[2018-11-22 23:54:51.828]  Step 253257  [25.352 sec/step, loss=0.07424, avg_loss=0.07532]
[2018-11-22 23:55:08.554]  Step 253258  [25.299 sec/step, loss=0.07425, avg_loss=0.07529]
[2018-11-22 23:55:31.337]  Step 253259  [25.267 sec/step, loss=0.07613, avg_loss=0.07528]
[2018-11-22 23:55:47.670]  Generated 32 batches of size 32 in 15.184 sec
[2018-11-22 23:56:08.046]  Step 253260  [25.477 sec/step, loss=0.07754, avg_loss=0.07530]
[2018-11-22 23:56:29.221]  Step 253261  [25.519 sec/step, loss=0.07536, avg_loss=0.07530]
[2018-11-22 23:56:55.019]  Step 253262  [25.559 sec/step, loss=0.07682, avg_loss=0.07530]
[2018-11-22 23:57:20.137]  Step 253263  [25.570 sec/step, loss=0.07747, avg_loss=0.07531]
[2018-11-22 23:57:47.462]  Step 253264  [25.573 sec/step, loss=0.07695, avg_loss=0.07531]
[2018-11-22 23:58:21.656]  Step 253265  [25.692 sec/step, loss=0.07684, avg_loss=0.07531]
[2018-11-22 23:59:06.080]  Step 253266  [25.864 sec/step, loss=0.07667, avg_loss=0.07530]
[2018-11-22 23:59:33.230]  Step 253267  [26.006 sec/step, loss=0.07677, avg_loss=0.07535]
[2018-11-22 23:59:44.772]  Step 253268  [25.877 sec/step, loss=0.06758, avg_loss=0.07526]
[2018-11-22 23:59:58.256]  Step 253269  [25.777 sec/step, loss=0.07202, avg_loss=0.07520]
[2018-11-23 00:00:20.548]  Step 253270  [25.761 sec/step, loss=0.07697, avg_loss=0.07520]
[2018-11-23 00:00:40.457]  Step 253271  [25.756 sec/step, loss=0.07746, avg_loss=0.07520]
[2018-11-23 00:01:07.633]  Step 253272  [25.817 sec/step, loss=0.07609, avg_loss=0.07519]
[2018-11-23 00:01:32.729]  Step 253273  [25.911 sec/step, loss=0.07717, avg_loss=0.07522]
[2018-11-23 00:01:49.436]  Step 253274  [25.885 sec/step, loss=0.07423, avg_loss=0.07520]
[2018-11-23 00:02:00.637]  Step 253275  [25.784 sec/step, loss=0.06839, avg_loss=0.07512]
[2018-11-23 00:02:20.280]  Step 253276  [25.792 sec/step, loss=0.07600, avg_loss=0.07512]
[2018-11-23 00:02:40.159]  Step 253277  [25.832 sec/step, loss=0.07636, avg_loss=0.07516]
[2018-11-23 00:02:58.216]  Step 253278  [25.893 sec/step, loss=0.07550, avg_loss=0.07519]
[2018-11-23 00:03:22.908]  Step 253279  [25.898 sec/step, loss=0.07701, avg_loss=0.07519]
[2018-11-23 00:03:47.751]  Step 253280  [25.919 sec/step, loss=0.07735, avg_loss=0.07520]
[2018-11-23 00:04:08.400]  Step 253281  [26.039 sec/step, loss=0.07686, avg_loss=0.07540]
[2018-11-23 00:04:48.718]  Step 253282  [26.224 sec/step, loss=0.06792, avg_loss=0.07531]
[2018-11-23 00:05:13.467]  Step 253283  [26.315 sec/step, loss=0.07661, avg_loss=0.07533]
[2018-11-23 00:05:34.027]  Step 253284  [26.246 sec/step, loss=0.07607, avg_loss=0.07532]
[2018-11-23 00:05:58.745]  Step 253285  [26.246 sec/step, loss=0.07659, avg_loss=0.07532]
[2018-11-23 00:06:08.185]  Step 253286  [26.067 sec/step, loss=0.05772, avg_loss=0.07512]
[2018-11-23 00:06:23.263]  Step 253287  [26.091 sec/step, loss=0.07349, avg_loss=0.07517]
[2018-11-23 00:06:47.587]  Step 253288  [26.108 sec/step, loss=0.07633, avg_loss=0.07517]
[2018-11-23 00:07:04.722]  Step 253289  [25.792 sec/step, loss=0.07495, avg_loss=0.07524]
[2018-11-23 00:07:32.266]  Step 253290  [25.830 sec/step, loss=0.07733, avg_loss=0.07524]
[2018-11-23 00:07:56.135]  Step 253291  [25.752 sec/step, loss=0.07701, avg_loss=0.07524]
[2018-11-23 00:08:06.339]  Generated 32 batches of size 32 in 9.299 sec
[2018-11-23 00:08:20.674]  Step 253292  [25.767 sec/step, loss=0.07713, avg_loss=0.07523]
[2018-11-23 00:08:38.182]  Step 253293  [25.669 sec/step, loss=0.07607, avg_loss=0.07522]
[2018-11-23 00:09:01.425]  Step 253294  [25.651 sec/step, loss=0.07655, avg_loss=0.07522]
[2018-11-23 00:09:21.641]  Step 253295  [25.624 sec/step, loss=0.07646, avg_loss=0.07521]
[2018-11-23 00:09:43.746]  Step 253296  [25.692 sec/step, loss=0.07761, avg_loss=0.07525]
[2018-11-23 00:10:06.551]  Step 253297  [25.706 sec/step, loss=0.07660, avg_loss=0.07525]
[2018-11-23 00:10:27.600]  Step 253298  [25.629 sec/step, loss=0.07711, avg_loss=0.07525]
[2018-11-23 00:10:50.358]  Step 253299  [25.593 sec/step, loss=0.07713, avg_loss=0.07524]
[2018-11-23 00:11:13.687]  Step 253300  [25.566 sec/step, loss=0.07812, avg_loss=0.07525]
[2018-11-23 00:11:13.687]  Writing summary at step: 253300
[2018-11-23 00:12:07.879]  Step 253301  [25.454 sec/step, loss=0.05764, avg_loss=0.07507]
[2018-11-23 00:12:25.142]  Step 253302  [25.424 sec/step, loss=0.07633, avg_loss=0.07508]
[2018-11-23 00:12:46.128]  Step 253303  [25.368 sec/step, loss=0.07588, avg_loss=0.07507]
[2018-11-23 00:13:08.335]  Step 253304  [25.365 sec/step, loss=0.07705, avg_loss=0.07507]
[2018-11-23 00:13:31.986]  Step 253305  [25.299 sec/step, loss=0.07720, avg_loss=0.07508]
[2018-11-23 00:13:49.866]  Step 253306  [25.242 sec/step, loss=0.07587, avg_loss=0.07507]
[2018-11-23 00:14:14.241]  Step 253307  [25.280 sec/step, loss=0.07745, avg_loss=0.07511]
[2018-11-23 00:14:38.728]  Step 253308  [25.240 sec/step, loss=0.07618, avg_loss=0.07511]
[2018-11-23 00:15:00.828]  Step 253309  [24.896 sec/step, loss=0.07679, avg_loss=0.07520]
[2018-11-23 00:15:16.714]  Step 253310  [24.871 sec/step, loss=0.07352, avg_loss=0.07519]
[2018-11-23 00:15:35.172]  Step 253311  [24.798 sec/step, loss=0.07711, avg_loss=0.07520]
[2018-11-23 00:15:56.466]  Step 253312  [24.672 sec/step, loss=0.07666, avg_loss=0.07520]
[2018-11-23 00:16:12.137]  Step 253313  [24.434 sec/step, loss=0.07454, avg_loss=0.07517]
[2018-11-23 00:16:36.843]  Step 253314  [24.288 sec/step, loss=0.07637, avg_loss=0.07517]
[2018-11-23 00:17:03.529]  Step 253315  [24.283 sec/step, loss=0.07736, avg_loss=0.07519]
[2018-11-23 00:17:25.721]  Step 253316  [24.209 sec/step, loss=0.07669, avg_loss=0.07519]
[2018-11-23 00:17:38.708]  Step 253317  [24.071 sec/step, loss=0.07194, avg_loss=0.07514]
[2018-11-23 00:18:03.320]  Step 253318  [24.059 sec/step, loss=0.07670, avg_loss=0.07514]
[2018-11-23 00:18:26.799]  Step 253319  [23.993 sec/step, loss=0.07703, avg_loss=0.07515]
[2018-11-23 00:18:46.117]  Step 253320  [23.829 sec/step, loss=0.07590, avg_loss=0.07514]
[2018-11-23 00:18:56.747]  Step 253321  [23.811 sec/step, loss=0.07069, avg_loss=0.07528]
[2018-11-23 00:19:18.060]  Step 253322  [23.701 sec/step, loss=0.07587, avg_loss=0.07526]
[2018-11-23 00:19:30.103]  Generated 32 batches of size 32 in 11.120 sec
[2018-11-23 00:19:47.453]  Step 253323  [23.714 sec/step, loss=0.07768, avg_loss=0.07527]
[2018-11-23 00:20:11.046]  Step 253324  [23.654 sec/step, loss=0.07685, avg_loss=0.07527]
[2018-11-23 00:20:31.670]  Step 253325  [23.556 sec/step, loss=0.07694, avg_loss=0.07526]
[2018-11-23 00:20:54.261]  Step 253326  [23.476 sec/step, loss=0.07694, avg_loss=0.07526]
[2018-11-23 00:21:16.871]  Step 253327  [23.377 sec/step, loss=0.07670, avg_loss=0.07527]
[2018-11-23 00:21:41.679]  Step 253328  [23.353 sec/step, loss=0.07733, avg_loss=0.07529]
[2018-11-23 00:21:55.658]  Step 253329  [23.063 sec/step, loss=0.07451, avg_loss=0.07527]
[2018-11-23 00:22:18.488]  Step 253330  [22.873 sec/step, loss=0.07669, avg_loss=0.07525]
[2018-11-23 00:22:37.938]  Step 253331  [22.896 sec/step, loss=0.07603, avg_loss=0.07532]
[2018-11-23 00:22:56.748]  Step 253332  [22.786 sec/step, loss=0.07719, avg_loss=0.07532]
[2018-11-23 00:23:13.290]  Step 253333  [22.705 sec/step, loss=0.07543, avg_loss=0.07530]
[2018-11-23 00:23:35.539]  Step 253334  [22.709 sec/step, loss=0.07794, avg_loss=0.07535]
[2018-11-23 00:23:55.604]  Step 253335  [22.769 sec/step, loss=0.07629, avg_loss=0.07539]
[2018-11-23 00:24:16.509]  Step 253336  [22.757 sec/step, loss=0.07656, avg_loss=0.07538]
[2018-11-23 00:24:31.401]  Step 253337  [22.651 sec/step, loss=0.07225, avg_loss=0.07533]
[2018-11-23 00:24:53.886]  Step 253338  [22.522 sec/step, loss=0.07712, avg_loss=0.07533]
[2018-11-23 00:25:17.962]  Step 253339  [22.457 sec/step, loss=0.07682, avg_loss=0.07533]
[2018-11-23 00:25:42.018]  Step 253340  [22.458 sec/step, loss=0.07684, avg_loss=0.07533]
[2018-11-23 00:26:06.571]  Step 253341  [22.499 sec/step, loss=0.07667, avg_loss=0.07534]
[2018-11-23 00:26:23.732]  Step 253342  [22.501 sec/step, loss=0.07596, avg_loss=0.07537]
[2018-11-23 00:26:43.587]  Step 253343  [22.359 sec/step, loss=0.07682, avg_loss=0.07536]
[2018-11-23 00:27:07.642]  Step 253344  [22.316 sec/step, loss=0.07690, avg_loss=0.07537]
[2018-11-23 00:27:30.841]  Step 253345  [22.302 sec/step, loss=0.07755, avg_loss=0.07537]
[2018-11-23 00:27:51.004]  Step 253346  [22.075 sec/step, loss=0.07668, avg_loss=0.07546]
[2018-11-23 00:28:01.168]  Step 253347  [21.840 sec/step, loss=0.06870, avg_loss=0.07538]
[2018-11-23 00:28:41.615]  Step 253348  [21.932 sec/step, loss=0.06800, avg_loss=0.07529]
[2018-11-23 00:29:02.936]  Step 253349  [21.882 sec/step, loss=0.07696, avg_loss=0.07530]
[2018-11-23 00:29:21.575]  Step 253350  [21.782 sec/step, loss=0.07611, avg_loss=0.07530]
[2018-11-23 00:29:21.575]  Writing summary at step: 253350
[2018-11-23 00:30:07.864]  Step 253351  [21.865 sec/step, loss=0.07701, avg_loss=0.07534]
[2018-11-23 00:30:15.477]  Step 253352  [21.813 sec/step, loss=0.05823, avg_loss=0.07535]
[2018-11-23 00:30:39.559]  Step 253353  [21.773 sec/step, loss=0.07658, avg_loss=0.07535]
[2018-11-23 00:30:49.166]  Generated 32 batches of size 32 in 8.672 sec
[2018-11-23 00:31:02.657]  Step 253354  [21.752 sec/step, loss=0.07735, avg_loss=0.07535]
[2018-11-23 00:31:25.258]  Step 253355  [21.706 sec/step, loss=0.07703, avg_loss=0.07536]
[2018-11-23 00:31:50.087]  Step 253356  [21.692 sec/step, loss=0.07717, avg_loss=0.07535]
[2018-11-23 00:32:02.780]  Step 253357  [21.639 sec/step, loss=0.07412, avg_loss=0.07535]
[2018-11-23 00:32:18.725]  Step 253358  [21.632 sec/step, loss=0.07370, avg_loss=0.07535]
[2018-11-23 00:32:40.732]  Step 253359  [21.624 sec/step, loss=0.07673, avg_loss=0.07535]
[2018-11-23 00:32:51.991]  Step 253360  [21.369 sec/step, loss=0.07340, avg_loss=0.07531]
[2018-11-23 00:33:10.025]  Step 253361  [21.338 sec/step, loss=0.07605, avg_loss=0.07532]
[2018-11-23 00:33:35.687]  Step 253362  [21.337 sec/step, loss=0.07605, avg_loss=0.07531]
[2018-11-23 00:33:51.533]  Step 253363  [21.244 sec/step, loss=0.07316, avg_loss=0.07527]
[2018-11-23 00:34:08.057]  Step 253364  [21.136 sec/step, loss=0.07618, avg_loss=0.07526]
[2018-11-23 00:34:29.278]  Step 253365  [21.006 sec/step, loss=0.07715, avg_loss=0.07526]
[2018-11-23 00:34:54.123]  Step 253366  [20.810 sec/step, loss=0.07647, avg_loss=0.07526]
[2018-11-23 00:35:17.574]  Step 253367  [20.773 sec/step, loss=0.07637, avg_loss=0.07526]
[2018-11-23 00:35:42.183]  Step 253368  [20.904 sec/step, loss=0.07708, avg_loss=0.07535]
[2018-11-23 00:36:05.960]  Step 253369  [21.007 sec/step, loss=0.07648, avg_loss=0.07540]
[2018-11-23 00:36:28.577]  Step 253370  [21.010 sec/step, loss=0.07670, avg_loss=0.07539]
[2018-11-23 00:36:46.122]  Step 253371  [20.986 sec/step, loss=0.07512, avg_loss=0.07537]
[2018-11-23 00:37:06.738]  Step 253372  [20.921 sec/step, loss=0.07670, avg_loss=0.07538]
[2018-11-23 00:37:27.010]  Step 253373  [20.873 sec/step, loss=0.07696, avg_loss=0.07538]
[2018-11-23 00:37:45.979]  Step 253374  [20.895 sec/step, loss=0.07590, avg_loss=0.07539]
[2018-11-23 00:38:09.980]  Step 253375  [21.023 sec/step, loss=0.07664, avg_loss=0.07547]
[2018-11-23 00:38:31.016]  Step 253376  [21.037 sec/step, loss=0.07589, avg_loss=0.07547]
[2018-11-23 00:38:39.470]  Step 253377  [20.923 sec/step, loss=0.05880, avg_loss=0.07530]
[2018-11-23 00:38:53.197]  Step 253378  [20.880 sec/step, loss=0.07371, avg_loss=0.07528]
[2018-11-23 00:39:03.595]  Step 253379  [20.737 sec/step, loss=0.06803, avg_loss=0.07519]
[2018-11-23 00:39:28.749]  Step 253380  [20.740 sec/step, loss=0.07726, avg_loss=0.07519]
[2018-11-23 00:39:44.172]  Step 253381  [20.688 sec/step, loss=0.07498, avg_loss=0.07517]
[2018-11-23 00:40:05.806]  Step 253382  [20.501 sec/step, loss=0.07631, avg_loss=0.07525]
[2018-11-23 00:40:29.647]  Step 253383  [20.492 sec/step, loss=0.07644, avg_loss=0.07525]
[2018-11-23 00:40:56.829]  Step 253384  [20.558 sec/step, loss=0.07656, avg_loss=0.07526]
[2018-11-23 00:41:19.077]  Step 253385  [20.533 sec/step, loss=0.07645, avg_loss=0.07526]
[2018-11-23 00:41:33.525]  Generated 32 batches of size 32 in 13.588 sec
[2018-11-23 00:42:03.493]  Step 253386  [20.883 sec/step, loss=0.06787, avg_loss=0.07536]
[2018-11-23 00:42:26.029]  Step 253387  [20.958 sec/step, loss=0.07730, avg_loss=0.07540]
[2018-11-23 00:42:50.396]  Step 253388  [20.958 sec/step, loss=0.07716, avg_loss=0.07540]
[2018-11-23 00:43:10.081]  Step 253389  [20.983 sec/step, loss=0.07600, avg_loss=0.07541]
[2018-11-23 00:43:31.568]  Step 253390  [20.923 sec/step, loss=0.07687, avg_loss=0.07541]
[2018-11-23 00:43:50.074]  Step 253391  [20.869 sec/step, loss=0.07698, avg_loss=0.07541]
[2018-11-23 00:44:09.691]  Step 253392  [20.820 sec/step, loss=0.07649, avg_loss=0.07540]
[2018-11-23 00:44:21.946]  Step 253393  [20.767 sec/step, loss=0.07192, avg_loss=0.07536]
[2018-11-23 00:44:45.712]  Step 253394  [20.773 sec/step, loss=0.07801, avg_loss=0.07538]
[2018-11-23 00:45:02.806]  Step 253395  [20.741 sec/step, loss=0.07565, avg_loss=0.07537]
[2018-11-23 00:45:21.821]  Step 253396  [20.711 sec/step, loss=0.07500, avg_loss=0.07534]
[2018-11-23 00:45:44.190]  Step 253397  [20.706 sec/step, loss=0.07607, avg_loss=0.07534]
[2018-11-23 00:46:03.561]  Step 253398  [20.689 sec/step, loss=0.07681, avg_loss=0.07533]
[2018-11-23 00:46:26.962]  Step 253399  [20.696 sec/step, loss=0.07608, avg_loss=0.07532]
[2018-11-23 00:46:48.778]  Step 253400  [20.681 sec/step, loss=0.07691, avg_loss=0.07531]
[2018-11-23 00:46:48.778]  Writing summary at step: 253400
[2018-11-23 00:47:40.308]  Step 253401  [20.852 sec/step, loss=0.07637, avg_loss=0.07550]
[2018-11-23 00:47:48.981]  Step 253402  [20.766 sec/step, loss=0.05804, avg_loss=0.07532]
[2018-11-23 00:48:10.924]  Step 253403  [20.776 sec/step, loss=0.07643, avg_loss=0.07532]
[2018-11-23 00:48:21.586]  Step 253404  [20.660 sec/step, loss=0.06895, avg_loss=0.07524]
[2018-11-23 00:48:42.566]  Step 253405  [20.634 sec/step, loss=0.07777, avg_loss=0.07525]
[2018-11-23 00:49:04.528]  Step 253406  [20.675 sec/step, loss=0.07654, avg_loss=0.07525]
[2018-11-23 00:49:23.992]  Step 253407  [20.625 sec/step, loss=0.07583, avg_loss=0.07524]
[2018-11-23 00:49:48.291]  Step 253408  [20.624 sec/step, loss=0.07680, avg_loss=0.07524]
[2018-11-23 00:50:11.604]  Step 253409  [20.636 sec/step, loss=0.07651, avg_loss=0.07524]
[2018-11-23 00:50:31.503]  Step 253410  [20.676 sec/step, loss=0.07572, avg_loss=0.07526]
[2018-11-23 00:50:53.271]  Step 253411  [20.709 sec/step, loss=0.07627, avg_loss=0.07525]
[2018-11-23 00:51:18.881]  Step 253412  [20.752 sec/step, loss=0.07759, avg_loss=0.07526]
[2018-11-23 00:51:56.267]  Step 253413  [20.969 sec/step, loss=0.06809, avg_loss=0.07520]
[2018-11-23 00:52:08.595]  Step 253414  [20.845 sec/step, loss=0.07218, avg_loss=0.07516]
[2018-11-23 00:52:28.773]  Step 253415  [20.780 sec/step, loss=0.07666, avg_loss=0.07515]
[2018-11-23 00:52:52.419]  Step 253416  [20.795 sec/step, loss=0.07710, avg_loss=0.07515]
[2018-11-23 00:53:01.483]  Generated 32 batches of size 32 in 8.352 sec
[2018-11-23 00:53:16.049]  Step 253417  [20.901 sec/step, loss=0.07670, avg_loss=0.07520]
[2018-11-23 00:53:29.779]  Step 253418  [20.792 sec/step, loss=0.07408, avg_loss=0.07518]
[2018-11-23 00:53:45.360]  Step 253419  [20.714 sec/step, loss=0.07299, avg_loss=0.07513]
[2018-11-23 00:54:03.094]  Step 253420  [20.698 sec/step, loss=0.07497, avg_loss=0.07513]
[2018-11-23 00:54:18.710]  Step 253421  [20.748 sec/step, loss=0.07386, avg_loss=0.07516]
[2018-11-23 00:54:43.155]  Step 253422  [20.779 sec/step, loss=0.07732, avg_loss=0.07517]
[2018-11-23 00:55:07.048]  Step 253423  [20.724 sec/step, loss=0.07656, avg_loss=0.07516]
[2018-11-23 00:55:29.099]  Step 253424  [20.708 sec/step, loss=0.07684, avg_loss=0.07516]
[2018-11-23 00:55:53.313]  Step 253425  [20.744 sec/step, loss=0.07771, avg_loss=0.07517]
[2018-11-23 00:56:10.903]  Step 253426  [20.694 sec/step, loss=0.07510, avg_loss=0.07515]
[2018-11-23 00:56:35.385]  Step 253427  [20.713 sec/step, loss=0.07650, avg_loss=0.07515]
[2018-11-23 00:57:01.214]  Step 253428  [20.723 sec/step, loss=0.07713, avg_loss=0.07515]
[2018-11-23 00:57:16.850]  Step 253429  [20.740 sec/step, loss=0.07245, avg_loss=0.07512]
[2018-11-23 00:57:33.650]  Step 253430  [20.680 sec/step, loss=0.07592, avg_loss=0.07512]
[2018-11-23 00:57:57.407]  Step 253431  [20.723 sec/step, loss=0.07617, avg_loss=0.07512]
[2018-11-23 00:58:17.444]  Step 253432  [20.735 sec/step, loss=0.07635, avg_loss=0.07511]
[2018-11-23 00:58:56.962]  Step 253433  [20.965 sec/step, loss=0.06781, avg_loss=0.07503]
[2018-11-23 00:59:19.430]  Step 253434  [20.967 sec/step, loss=0.07660, avg_loss=0.07502]
[2018-11-23 00:59:45.533]  Step 253435  [21.027 sec/step, loss=0.07655, avg_loss=0.07502]
[2018-11-23 01:00:09.603]  Step 253436  [21.059 sec/step, loss=0.07706, avg_loss=0.07503]
[2018-11-23 01:00:20.035]  Step 253437  [21.014 sec/step, loss=0.06876, avg_loss=0.07499]
[2018-11-23 01:00:43.064]  Step 253438  [21.020 sec/step, loss=0.07634, avg_loss=0.07499]
[2018-11-23 01:00:52.816]  Step 253439  [20.876 sec/step, loss=0.05520, avg_loss=0.07477]
[2018-11-23 01:01:11.583]  Step 253440  [20.824 sec/step, loss=0.07623, avg_loss=0.07476]
[2018-11-23 01:01:36.074]  Step 253441  [20.823 sec/step, loss=0.07633, avg_loss=0.07476]
[2018-11-23 01:01:55.112]  Step 253442  [20.842 sec/step, loss=0.07675, avg_loss=0.07477]
[2018-11-23 01:02:14.809]  Step 253443  [20.840 sec/step, loss=0.07572, avg_loss=0.07476]
[2018-11-23 01:02:27.110]  Step 253444  [20.723 sec/step, loss=0.07238, avg_loss=0.07471]
[2018-11-23 01:02:45.721]  Step 253445  [20.677 sec/step, loss=0.07588, avg_loss=0.07469]
[2018-11-23 01:03:00.871]  Step 253446  [20.627 sec/step, loss=0.07366, avg_loss=0.07466]
[2018-11-23 01:03:25.885]  Step 253447  [20.775 sec/step, loss=0.07621, avg_loss=0.07474]
[2018-11-23 01:03:54.676]  Step 253448  [20.659 sec/step, loss=0.07622, avg_loss=0.07482]
[2018-11-23 01:04:05.626]  Generated 32 batches of size 32 in 10.005 sec
[2018-11-23 01:04:22.030]  Step 253449  [20.719 sec/step, loss=0.07647, avg_loss=0.07482]
[2018-11-23 01:04:42.616]  Step 253450  [20.738 sec/step, loss=0.07640, avg_loss=0.07482]
[2018-11-23 01:04:42.616]  Writing summary at step: 253450
[2018-11-23 01:05:28.986]  Step 253451  [20.720 sec/step, loss=0.07713, avg_loss=0.07482]
[2018-11-23 01:05:51.565]  Step 253452  [20.870 sec/step, loss=0.07693, avg_loss=0.07501]
[2018-11-23 01:06:05.658]  Step 253453  [20.770 sec/step, loss=0.07358, avg_loss=0.07498]
[2018-11-23 01:06:28.238]  Step 253454  [20.764 sec/step, loss=0.07675, avg_loss=0.07497]
[2018-11-23 01:06:49.716]  Step 253455  [20.753 sec/step, loss=0.07701, avg_loss=0.07497]
[2018-11-23 01:07:10.558]  Step 253456  [20.713 sec/step, loss=0.07605, avg_loss=0.07496]
[2018-11-23 01:07:34.634]  Step 253457  [20.827 sec/step, loss=0.07635, avg_loss=0.07498]
[2018-11-23 01:07:52.651]  Step 253458  [20.848 sec/step, loss=0.07529, avg_loss=0.07500]
[2018-11-23 01:08:14.412]  Step 253459  [20.845 sec/step, loss=0.07638, avg_loss=0.07500]
[2018-11-23 01:08:39.089]  Step 253460  [20.980 sec/step, loss=0.07742, avg_loss=0.07504]
[2018-11-23 01:09:01.344]  Step 253461  [21.022 sec/step, loss=0.07635, avg_loss=0.07504]
[2018-11-23 01:09:20.417]  Step 253462  [20.956 sec/step, loss=0.07607, avg_loss=0.07504]
[2018-11-23 01:09:43.208]  Step 253463  [21.025 sec/step, loss=0.07643, avg_loss=0.07507]
[2018-11-23 01:10:04.684]  Step 253464  [21.075 sec/step, loss=0.07667, avg_loss=0.07508]
[2018-11-23 01:10:28.246]  Step 253465  [21.098 sec/step, loss=0.07679, avg_loss=0.07507]
[2018-11-23 01:10:41.541]  Step 253466  [20.983 sec/step, loss=0.07200, avg_loss=0.07503]
[2018-11-23 01:10:57.574]  Step 253467  [20.909 sec/step, loss=0.07264, avg_loss=0.07499]
[2018-11-23 01:11:18.091]  Step 253468  [20.868 sec/step, loss=0.07632, avg_loss=0.07498]
[2018-11-23 01:11:39.622]  Step 253469  [20.845 sec/step, loss=0.07673, avg_loss=0.07499]
[2018-11-23 01:11:50.017]  Step 253470  [20.723 sec/step, loss=0.06853, avg_loss=0.07490]
[2018-11-23 01:12:17.494]  Step 253471  [20.822 sec/step, loss=0.07625, avg_loss=0.07492]
[2018-11-23 01:12:34.594]  Step 253472  [20.787 sec/step, loss=0.07599, avg_loss=0.07491]
[2018-11-23 01:12:54.376]  Step 253473  [20.782 sec/step, loss=0.07542, avg_loss=0.07489]
[2018-11-23 01:13:08.661]  Step 253474  [20.736 sec/step, loss=0.07341, avg_loss=0.07487]
[2018-11-23 01:13:17.877]  Step 253475  [20.588 sec/step, loss=0.05786, avg_loss=0.07468]
[2018-11-23 01:13:42.615]  Step 253476  [20.625 sec/step, loss=0.07653, avg_loss=0.07469]
[2018-11-23 01:13:58.253]  Step 253477  [20.697 sec/step, loss=0.07405, avg_loss=0.07484]
[2018-11-23 01:14:21.367]  Step 253478  [20.790 sec/step, loss=0.07622, avg_loss=0.07486]
[2018-11-23 01:14:45.681]  Step 253479  [20.930 sec/step, loss=0.07652, avg_loss=0.07495]
[2018-11-23 01:14:55.340]  Generated 32 batches of size 32 in 8.759 sec
[2018-11-23 01:15:06.394]  Step 253480  [20.885 sec/step, loss=0.07637, avg_loss=0.07494]
[2018-11-23 01:15:29.599]  Step 253481  [20.963 sec/step, loss=0.07616, avg_loss=0.07495]
[2018-11-23 01:16:09.231]  Step 253482  [21.143 sec/step, loss=0.06782, avg_loss=0.07487]
[2018-11-23 01:16:33.815]  Step 253483  [21.150 sec/step, loss=0.07608, avg_loss=0.07486]
[2018-11-23 01:16:59.510]  Step 253484  [21.135 sec/step, loss=0.07733, avg_loss=0.07487]
[2018-11-23 01:17:17.862]  Step 253485  [21.097 sec/step, loss=0.07606, avg_loss=0.07487]
[2018-11-23 01:17:38.817]  Step 253486  [20.862 sec/step, loss=0.07658, avg_loss=0.07495]
[2018-11-23 01:18:00.399]  Step 253487  [20.852 sec/step, loss=0.07617, avg_loss=0.07494]
[2018-11-23 01:18:24.310]  Step 253488  [20.848 sec/step, loss=0.07657, avg_loss=0.07494]
[2018-11-23 01:18:38.170]  Step 253489  [20.790 sec/step, loss=0.07340, avg_loss=0.07491]
[2018-11-23 01:19:00.485]  Step 253490  [20.798 sec/step, loss=0.07633, avg_loss=0.07491]
[2018-11-23 01:19:23.093]  Step 253491  [20.839 sec/step, loss=0.07613, avg_loss=0.07490]
[2018-11-23 01:19:45.780]  Step 253492  [20.870 sec/step, loss=0.07714, avg_loss=0.07490]
[2018-11-23 01:20:04.159]  Step 253493  [20.931 sec/step, loss=0.07648, avg_loss=0.07495]
[2018-11-23 01:20:19.501]  Step 253494  [20.847 sec/step, loss=0.07372, avg_loss=0.07491]
[2018-11-23 01:20:44.921]  Step 253495  [20.930 sec/step, loss=0.07611, avg_loss=0.07491]
[2018-11-23 01:21:01.828]  Step 253496  [20.909 sec/step, loss=0.07527, avg_loss=0.07491]
[2018-11-23 01:21:10.357]  Step 253497  [20.770 sec/step, loss=0.05483, avg_loss=0.07470]
[2018-11-23 01:21:29.104]  Step 253498  [20.764 sec/step, loss=0.07548, avg_loss=0.07469]
[2018-11-23 01:21:49.886]  Step 253499  [20.738 sec/step, loss=0.07669, avg_loss=0.07469]
[2018-11-23 01:22:09.782]  Step 253500  [20.719 sec/step, loss=0.07530, avg_loss=0.07468]
[2018-11-23 01:22:09.782]  Writing summary at step: 253500
[2018-11-23 01:22:34.143]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-253500
[2018-11-23 01:22:37.391]  Saving audio and alignment...
[2018-11-23 01:22:52.089]  Input: jane eyre employs a simple rather than complex grammar as a stylistic basis. its sentences are often compounded of main clauses or phrases, whose short, emphatic words~_______________________________
[2018-11-23 01:23:11.505]  Step 253501  [20.651 sec/step, loss=0.07633, avg_loss=0.07468]
[2018-11-23 01:23:36.267]  Step 253502  [20.811 sec/step, loss=0.07575, avg_loss=0.07485]
[2018-11-23 01:23:58.685]  Step 253503  [20.816 sec/step, loss=0.07701, avg_loss=0.07486]
[2018-11-23 01:24:22.816]  Step 253504  [20.951 sec/step, loss=0.07733, avg_loss=0.07494]
[2018-11-23 01:24:50.100]  Step 253505  [21.014 sec/step, loss=0.07598, avg_loss=0.07493]
[2018-11-23 01:25:10.445]  Step 253506  [20.998 sec/step, loss=0.07698, avg_loss=0.07493]
[2018-11-23 01:25:32.362]  Step 253507  [21.022 sec/step, loss=0.07672, avg_loss=0.07494]
[2018-11-23 01:26:09.971]  Step 253508  [21.155 sec/step, loss=0.06768, avg_loss=0.07485]
[2018-11-23 01:26:20.421]  Step 253509  [21.027 sec/step, loss=0.06912, avg_loss=0.07477]
[2018-11-23 01:26:29.693]  Generated 32 batches of size 32 in 8.333 sec
[2018-11-23 01:26:43.511]  Step 253510  [21.059 sec/step, loss=0.07593, avg_loss=0.07478]
[2018-11-23 01:27:05.080]  Step 253511  [21.057 sec/step, loss=0.07690, avg_loss=0.07478]
[2018-11-23 01:27:22.846]  Step 253512  [20.978 sec/step, loss=0.07552, avg_loss=0.07476]
[2018-11-23 01:27:47.793]  Step 253513  [20.854 sec/step, loss=0.07710, avg_loss=0.07485]
[2018-11-23 01:28:08.123]  Step 253514  [20.934 sec/step, loss=0.07634, avg_loss=0.07489]
[2018-11-23 01:28:31.956]  Step 253515  [20.970 sec/step, loss=0.07653, avg_loss=0.07489]
[2018-11-23 01:28:56.973]  Step 253516  [20.984 sec/step, loss=0.07724, avg_loss=0.07489]
[2018-11-23 01:29:13.053]  Step 253517  [20.909 sec/step, loss=0.07245, avg_loss=0.07485]
[2018-11-23 01:29:25.265]  Step 253518  [20.893 sec/step, loss=0.07192, avg_loss=0.07483]
[2018-11-23 01:29:48.224]  Step 253519  [20.967 sec/step, loss=0.07620, avg_loss=0.07486]
[2018-11-23 01:30:05.848]  Step 253520  [20.966 sec/step, loss=0.07481, avg_loss=0.07486]
[2018-11-23 01:30:30.064]  Step 253521  [21.052 sec/step, loss=0.07715, avg_loss=0.07489]
[2018-11-23 01:30:46.469]  Step 253522  [20.972 sec/step, loss=0.07248, avg_loss=0.07484]
[2018-11-23 01:31:10.549]  Step 253523  [20.974 sec/step, loss=0.07580, avg_loss=0.07484]
[2018-11-23 01:31:22.580]  Step 253524  [20.873 sec/step, loss=0.07208, avg_loss=0.07479]
[2018-11-23 01:31:44.286]  Step 253525  [20.848 sec/step, loss=0.07667, avg_loss=0.07478]
[2018-11-23 01:32:03.649]  Step 253526  [20.866 sec/step, loss=0.07552, avg_loss=0.07478]
[2018-11-23 01:32:25.044]  Step 253527  [20.835 sec/step, loss=0.07704, avg_loss=0.07479]
[2018-11-23 01:32:49.143]  Step 253528  [20.818 sec/step, loss=0.07637, avg_loss=0.07478]
[2018-11-23 01:32:58.127]  Step 253529  [20.751 sec/step, loss=0.05619, avg_loss=0.07462]
[2018-11-23 01:33:19.731]  Step 253530  [20.799 sec/step, loss=0.07599, avg_loss=0.07462]
[2018-11-23 01:33:41.810]  Step 253531  [20.783 sec/step, loss=0.07638, avg_loss=0.07462]
[2018-11-23 01:34:03.257]  Step 253532  [20.797 sec/step, loss=0.07655, avg_loss=0.07462]
[2018-11-23 01:34:22.265]  Step 253533  [20.592 sec/step, loss=0.07611, avg_loss=0.07471]
[2018-11-23 01:34:40.635]  Step 253534  [20.551 sec/step, loss=0.07589, avg_loss=0.07470]
[2018-11-23 01:34:54.536]  Step 253535  [20.429 sec/step, loss=0.07355, avg_loss=0.07467]
[2018-11-23 01:35:10.078]  Step 253536  [20.343 sec/step, loss=0.07411, avg_loss=0.07464]
[2018-11-23 01:35:30.573]  Step 253537  [20.444 sec/step, loss=0.07612, avg_loss=0.07471]
[2018-11-23 01:35:40.966]  Step 253538  [20.318 sec/step, loss=0.06992, avg_loss=0.07465]
[2018-11-23 01:36:04.227]  Step 253539  [20.453 sec/step, loss=0.07679, avg_loss=0.07487]
[2018-11-23 01:36:28.294]  Step 253540  [20.506 sec/step, loss=0.07711, avg_loss=0.07487]
[2018-11-23 01:36:48.647]  Step 253541  [20.464 sec/step, loss=0.07588, avg_loss=0.07487]
[2018-11-23 01:37:03.459]  Generated 32 batches of size 32 in 13.995 sec
[2018-11-23 01:37:33.518]  Step 253542  [20.723 sec/step, loss=0.06749, avg_loss=0.07478]
[2018-11-23 01:37:50.734]  Step 253543  [20.698 sec/step, loss=0.07565, avg_loss=0.07478]
[2018-11-23 01:38:17.341]  Step 253544  [20.841 sec/step, loss=0.07627, avg_loss=0.07481]
[2018-11-23 01:38:42.042]  Step 253545  [20.902 sec/step, loss=0.07584, avg_loss=0.07481]
[2018-11-23 01:39:06.278]  Step 253546  [20.993 sec/step, loss=0.07733, avg_loss=0.07485]
[2018-11-23 01:39:27.102]  Step 253547  [20.951 sec/step, loss=0.07617, avg_loss=0.07485]
[2018-11-23 01:39:51.409]  Step 253548  [20.906 sec/step, loss=0.07651, avg_loss=0.07485]
[2018-11-23 01:40:09.958]  Step 253549  [20.818 sec/step, loss=0.07598, avg_loss=0.07485]
[2018-11-23 01:40:32.754]  Step 253550  [20.840 sec/step, loss=0.07664, avg_loss=0.07485]
[2018-11-23 01:40:32.754]  Writing summary at step: 253550
[2018-11-23 01:41:05.353]  Step 253551  [20.699 sec/step, loss=0.05616, avg_loss=0.07464]
[2018-11-23 01:41:26.185]  Step 253552  [20.681 sec/step, loss=0.07609, avg_loss=0.07463]
[2018-11-23 01:41:47.827]  Step 253553  [20.757 sec/step, loss=0.07664, avg_loss=0.07466]
[2018-11-23 01:42:02.871]  Step 253554  [20.681 sec/step, loss=0.07283, avg_loss=0.07462]
[2018-11-23 01:42:23.031]  Step 253555  [20.668 sec/step, loss=0.07661, avg_loss=0.07462]
[2018-11-23 01:42:59.677]  Step 253556  [20.826 sec/step, loss=0.06769, avg_loss=0.07454]
[2018-11-23 01:43:18.227]  Step 253557  [20.771 sec/step, loss=0.07588, avg_loss=0.07453]
[2018-11-23 01:43:40.119]  Step 253558  [20.810 sec/step, loss=0.07622, avg_loss=0.07454]
[2018-11-23 01:44:04.111]  Step 253559  [20.832 sec/step, loss=0.07643, avg_loss=0.07454]
[2018-11-23 01:44:30.126]  Step 253560  [20.845 sec/step, loss=0.07609, avg_loss=0.07453]
[2018-11-23 01:44:53.221]  Step 253561  [20.854 sec/step, loss=0.07618, avg_loss=0.07453]
[2018-11-23 01:45:17.485]  Step 253562  [20.906 sec/step, loss=0.07722, avg_loss=0.07454]
[2018-11-23 01:45:36.365]  Step 253563  [20.866 sec/step, loss=0.07543, avg_loss=0.07453]
[2018-11-23 01:46:00.055]  Step 253564  [20.889 sec/step, loss=0.07716, avg_loss=0.07453]
[2018-11-23 01:46:19.306]  Step 253565  [20.845 sec/step, loss=0.07606, avg_loss=0.07453]
[2018-11-23 01:46:35.430]  Step 253566  [20.874 sec/step, loss=0.07360, avg_loss=0.07454]
[2018-11-23 01:46:59.065]  Step 253567  [20.950 sec/step, loss=0.07632, avg_loss=0.07458]
[2018-11-23 01:47:22.924]  Step 253568  [20.983 sec/step, loss=0.07641, avg_loss=0.07458]
[2018-11-23 01:47:48.289]  Step 253569  [21.022 sec/step, loss=0.07713, avg_loss=0.07458]
[2018-11-23 01:48:10.814]  Step 253570  [21.143 sec/step, loss=0.07692, avg_loss=0.07467]
[2018-11-23 01:48:32.810]  Step 253571  [21.088 sec/step, loss=0.07582, avg_loss=0.07466]
[2018-11-23 01:48:52.970]  Step 253572  [21.119 sec/step, loss=0.07515, avg_loss=0.07466]
[2018-11-23 01:49:01.926]  Generated 32 batches of size 32 in 8.276 sec
[2018-11-23 01:49:04.723]  Step 253573  [21.038 sec/step, loss=0.06634, avg_loss=0.07456]
[2018-11-23 01:49:26.765]  Step 253574  [21.116 sec/step, loss=0.07631, avg_loss=0.07459]
[2018-11-23 01:49:43.936]  Step 253575  [21.195 sec/step, loss=0.07582, avg_loss=0.07477]
[2018-11-23 01:49:57.608]  Step 253576  [21.085 sec/step, loss=0.07426, avg_loss=0.07475]
[2018-11-23 01:50:09.115]  Step 253577  [21.043 sec/step, loss=0.07190, avg_loss=0.07473]
[2018-11-23 01:50:33.727]  Step 253578  [21.058 sec/step, loss=0.07673, avg_loss=0.07473]
[2018-11-23 01:50:54.192]  Step 253579  [21.020 sec/step, loss=0.07640, avg_loss=0.07473]
[2018-11-23 01:51:11.809]  Step 253580  [20.989 sec/step, loss=0.07521, avg_loss=0.07472]
[2018-11-23 01:51:35.839]  Step 253581  [20.997 sec/step, loss=0.07624, avg_loss=0.07472]
[2018-11-23 01:51:58.231]  Step 253582  [20.825 sec/step, loss=0.07589, avg_loss=0.07480]
[2018-11-23 01:52:21.699]  Step 253583  [20.814 sec/step, loss=0.07556, avg_loss=0.07480]
[2018-11-23 01:52:30.305]  Step 253584  [20.643 sec/step, loss=0.05672, avg_loss=0.07459]
[2018-11-23 01:52:44.341]  Step 253585  [20.600 sec/step, loss=0.07352, avg_loss=0.07457]
[2018-11-23 01:53:08.011]  Step 253586  [20.627 sec/step, loss=0.07719, avg_loss=0.07457]
[2018-11-23 01:53:27.027]  Step 253587  [20.601 sec/step, loss=0.07509, avg_loss=0.07456]
[2018-11-23 01:53:42.648]  Step 253588  [20.518 sec/step, loss=0.07425, avg_loss=0.07454]
[2018-11-23 01:54:02.415]  Step 253589  [20.577 sec/step, loss=0.07554, avg_loss=0.07456]
[2018-11-23 01:54:22.608]  Step 253590  [20.556 sec/step, loss=0.07591, avg_loss=0.07456]
[2018-11-23 01:54:44.656]  Step 253591  [20.550 sec/step, loss=0.07592, avg_loss=0.07455]
[2018-11-23 01:55:08.441]  Step 253592  [20.561 sec/step, loss=0.07603, avg_loss=0.07454]
[2018-11-23 01:55:27.604]  Step 253593  [20.569 sec/step, loss=0.07556, avg_loss=0.07453]
[2018-11-23 01:55:50.450]  Step 253594  [20.644 sec/step, loss=0.07719, avg_loss=0.07457]
[2018-11-23 01:56:14.253]  Step 253595  [20.628 sec/step, loss=0.07659, avg_loss=0.07457]
[2018-11-23 01:56:51.830]  Step 253596  [20.835 sec/step, loss=0.06746, avg_loss=0.07449]
[2018-11-23 01:57:08.596]  Step 253597  [20.917 sec/step, loss=0.07535, avg_loss=0.07470]
[2018-11-23 01:57:30.645]  Step 253598  [20.950 sec/step, loss=0.07651, avg_loss=0.07471]
[2018-11-23 01:57:49.077]  Step 253599  [20.927 sec/step, loss=0.07675, avg_loss=0.07471]
[2018-11-23 01:58:11.844]  Step 253600  [20.955 sec/step, loss=0.07609, avg_loss=0.07472]
[2018-11-23 01:58:11.844]  Writing summary at step: 253600
[2018-11-23 01:58:52.989]  Step 253601  [20.956 sec/step, loss=0.07493, avg_loss=0.07470]
[2018-11-23 01:59:13.851]  Step 253602  [20.917 sec/step, loss=0.07685, avg_loss=0.07471]
[2018-11-23 01:59:24.575]  Step 253603  [20.800 sec/step, loss=0.06974, avg_loss=0.07464]
[2018-11-23 01:59:35.393]  Generated 32 batches of size 32 in 9.907 sec
[2018-11-23 01:59:52.283]  Step 253604  [20.836 sec/step, loss=0.07689, avg_loss=0.07464]
[2018-11-23 02:00:07.700]  Step 253605  [20.717 sec/step, loss=0.07321, avg_loss=0.07461]
[2018-11-23 02:00:29.995]  Step 253606  [20.736 sec/step, loss=0.07631, avg_loss=0.07460]
[2018-11-23 02:00:51.102]  Step 253607  [20.728 sec/step, loss=0.07625, avg_loss=0.07460]
[2018-11-23 02:01:13.420]  Step 253608  [20.575 sec/step, loss=0.07668, avg_loss=0.07469]
[2018-11-23 02:01:37.740]  Step 253609  [20.714 sec/step, loss=0.07614, avg_loss=0.07476]
[2018-11-23 02:02:01.690]  Step 253610  [20.723 sec/step, loss=0.07666, avg_loss=0.07477]
[2018-11-23 02:02:13.710]  Step 253611  [20.627 sec/step, loss=0.07223, avg_loss=0.07472]
[2018-11-23 02:02:39.748]  Step 253612  [20.710 sec/step, loss=0.07542, avg_loss=0.07472]
[2018-11-23 02:03:03.523]  Step 253613  [20.698 sec/step, loss=0.07655, avg_loss=0.07471]
[2018-11-23 02:03:24.064]  Step 253614  [20.700 sec/step, loss=0.07595, avg_loss=0.07471]
[2018-11-23 02:03:50.328]  Step 253615  [20.725 sec/step, loss=0.07678, avg_loss=0.07471]
[2018-11-23 02:04:12.569]  Step 253616  [20.697 sec/step, loss=0.07636, avg_loss=0.07470]
[2018-11-23 02:04:37.318]  Step 253617  [20.784 sec/step, loss=0.07592, avg_loss=0.07474]
[2018-11-23 02:05:01.365]  Step 253618  [20.902 sec/step, loss=0.07663, avg_loss=0.07478]
[2018-11-23 02:05:23.275]  Step 253619  [20.891 sec/step, loss=0.07578, avg_loss=0.07478]
[2018-11-23 02:06:02.226]  Step 253620  [21.105 sec/step, loss=0.06729, avg_loss=0.07471]
[2018-11-23 02:06:26.076]  Step 253621  [21.101 sec/step, loss=0.07594, avg_loss=0.07469]
[2018-11-23 02:06:48.280]  Step 253622  [21.159 sec/step, loss=0.07623, avg_loss=0.07473]
[2018-11-23 02:07:14.351]  Step 253623  [21.179 sec/step, loss=0.07577, avg_loss=0.07473]
[2018-11-23 02:07:38.790]  Step 253624  [21.303 sec/step, loss=0.07617, avg_loss=0.07477]
[2018-11-23 02:07:47.549]  Step 253625  [21.174 sec/step, loss=0.05590, avg_loss=0.07456]
[2018-11-23 02:08:09.811]  Step 253626  [21.203 sec/step, loss=0.07602, avg_loss=0.07457]
[2018-11-23 02:08:25.726]  Step 253627  [21.148 sec/step, loss=0.07356, avg_loss=0.07453]
[2018-11-23 02:08:44.610]  Step 253628  [21.096 sec/step, loss=0.07540, avg_loss=0.07452]
[2018-11-23 02:09:04.137]  Step 253629  [21.201 sec/step, loss=0.07525, avg_loss=0.07471]
[2018-11-23 02:09:21.802]  Step 253630  [21.162 sec/step, loss=0.07493, avg_loss=0.07470]
[2018-11-23 02:09:32.207]  Step 253631  [21.045 sec/step, loss=0.06881, avg_loss=0.07463]
[2018-11-23 02:09:48.134]  Step 253632  [20.990 sec/step, loss=0.07249, avg_loss=0.07459]
[2018-11-23 02:10:12.465]  Step 253633  [21.043 sec/step, loss=0.07632, avg_loss=0.07459]
[2018-11-23 02:10:32.030]  Step 253634  [21.055 sec/step, loss=0.07506, avg_loss=0.07458]
[2018-11-23 02:10:44.606]  Step 253635  [21.042 sec/step, loss=0.07213, avg_loss=0.07457]
[2018-11-23 02:10:56.376]  Generated 32 batches of size 32 in 10.893 sec
[2018-11-23 02:11:13.211]  Step 253636  [21.172 sec/step, loss=0.07671, avg_loss=0.07459]
[2018-11-23 02:11:33.160]  Step 253637  [21.167 sec/step, loss=0.07648, avg_loss=0.07460]
[2018-11-23 02:11:54.436]  Step 253638  [21.276 sec/step, loss=0.07656, avg_loss=0.07466]
[2018-11-23 02:12:17.533]  Step 253639  [21.274 sec/step, loss=0.07564, avg_loss=0.07465]
[2018-11-23 02:12:37.663]  Step 253640  [21.235 sec/step, loss=0.07599, avg_loss=0.07464]
[2018-11-23 02:12:56.180]  Step 253641  [21.216 sec/step, loss=0.07596, avg_loss=0.07464]
[2018-11-23 02:13:09.913]  Step 253642  [20.905 sec/step, loss=0.07310, avg_loss=0.07470]
[2018-11-23 02:13:30.896]  Step 253643  [20.943 sec/step, loss=0.07625, avg_loss=0.07470]
[2018-11-23 02:13:54.188]  Step 253644  [20.909 sec/step, loss=0.07685, avg_loss=0.07471]
[2018-11-23 02:14:12.697]  Step 253645  [20.847 sec/step, loss=0.07545, avg_loss=0.07471]
[2018-11-23 02:14:37.526]  Step 253646  [20.853 sec/step, loss=0.07677, avg_loss=0.07470]
[2018-11-23 02:14:55.983]  Step 253647  [20.830 sec/step, loss=0.07550, avg_loss=0.07469]
[2018-11-23 02:15:15.433]  Step 253648  [20.781 sec/step, loss=0.07471, avg_loss=0.07467]
[2018-11-23 02:15:39.947]  Step 253649  [20.841 sec/step, loss=0.07724, avg_loss=0.07469]
[2018-11-23 02:15:49.033]  Step 253650  [20.704 sec/step, loss=0.05743, avg_loss=0.07450]
[2018-11-23 02:15:49.034]  Writing summary at step: 253650
[2018-11-23 02:16:39.171]  Step 253651  [20.739 sec/step, loss=0.07160, avg_loss=0.07465]
[2018-11-23 02:17:02.493]  Step 253652  [20.764 sec/step, loss=0.07581, avg_loss=0.07465]
[2018-11-23 02:17:25.998]  Step 253653  [20.783 sec/step, loss=0.07636, avg_loss=0.07464]
[2018-11-23 02:17:48.827]  Step 253654  [20.860 sec/step, loss=0.07597, avg_loss=0.07468]
[2018-11-23 02:18:04.471]  Step 253655  [20.815 sec/step, loss=0.07170, avg_loss=0.07463]
[2018-11-23 02:18:25.502]  Step 253656  [20.659 sec/step, loss=0.07639, avg_loss=0.07471]
[2018-11-23 02:18:43.048]  Step 253657  [20.649 sec/step, loss=0.07497, avg_loss=0.07470]
[2018-11-23 02:19:06.809]  Step 253658  [20.668 sec/step, loss=0.07620, avg_loss=0.07470]
[2018-11-23 02:19:24.043]  Step 253659  [20.600 sec/step, loss=0.07485, avg_loss=0.07469]
[2018-11-23 02:19:39.314]  Step 253660  [20.493 sec/step, loss=0.07313, avg_loss=0.07466]
[2018-11-23 02:20:01.178]  Step 253661  [20.480 sec/step, loss=0.07580, avg_loss=0.07466]
[2018-11-23 02:20:27.127]  Step 253662  [20.497 sec/step, loss=0.07589, avg_loss=0.07464]
[2018-11-23 02:20:51.375]  Step 253663  [20.551 sec/step, loss=0.07597, avg_loss=0.07465]
[2018-11-23 02:21:13.366]  Step 253664  [20.534 sec/step, loss=0.07549, avg_loss=0.07463]
[2018-11-23 02:21:37.573]  Step 253665  [20.584 sec/step, loss=0.07605, avg_loss=0.07463]
[2018-11-23 02:22:00.018]  Step 253666  [20.647 sec/step, loss=0.07644, avg_loss=0.07466]
[2018-11-23 02:22:08.855]  Generated 32 batches of size 32 in 8.125 sec
[2018-11-23 02:22:11.630]  Step 253667  [20.527 sec/step, loss=0.06794, avg_loss=0.07458]
[2018-11-23 02:22:33.091]  Step 253668  [20.503 sec/step, loss=0.07651, avg_loss=0.07458]
[2018-11-23 02:22:53.969]  Step 253669  [20.458 sec/step, loss=0.07627, avg_loss=0.07457]
[2018-11-23 02:23:14.009]  Step 253670  [20.433 sec/step, loss=0.07649, avg_loss=0.07456]
[2018-11-23 02:23:37.851]  Step 253671  [20.451 sec/step, loss=0.07674, avg_loss=0.07457]
[2018-11-23 02:23:59.242]  Step 253672  [20.464 sec/step, loss=0.07575, avg_loss=0.07458]
[2018-11-23 02:24:13.125]  Step 253673  [20.485 sec/step, loss=0.07296, avg_loss=0.07464]
[2018-11-23 02:24:31.963]  Step 253674  [20.453 sec/step, loss=0.07601, avg_loss=0.07464]
[2018-11-23 02:24:52.473]  Step 253675  [20.486 sec/step, loss=0.07614, avg_loss=0.07464]
[2018-11-23 02:25:13.934]  Step 253676  [20.564 sec/step, loss=0.07550, avg_loss=0.07466]
[2018-11-23 02:25:30.598]  Step 253677  [20.616 sec/step, loss=0.07503, avg_loss=0.07469]
[2018-11-23 02:25:55.750]  Step 253678  [20.621 sec/step, loss=0.07559, avg_loss=0.07468]
[2018-11-23 02:26:21.447]  Step 253679  [20.673 sec/step, loss=0.07635, avg_loss=0.07468]
[2018-11-23 02:26:43.723]  Step 253680  [20.720 sec/step, loss=0.07574, avg_loss=0.07468]
[2018-11-23 02:27:05.787]  Step 253681  [20.700 sec/step, loss=0.07546, avg_loss=0.07467]
[2018-11-23 02:27:25.718]  Step 253682  [20.676 sec/step, loss=0.07594, avg_loss=0.07467]
[2018-11-23 02:27:35.934]  Step 253683  [20.543 sec/step, loss=0.06891, avg_loss=0.07461]
[2018-11-23 02:27:54.604]  Step 253684  [20.644 sec/step, loss=0.07566, avg_loss=0.07480]
[2018-11-23 02:28:08.544]  Step 253685  [20.643 sec/step, loss=0.07279, avg_loss=0.07479]
[2018-11-23 02:28:30.238]  Step 253686  [20.623 sec/step, loss=0.07551, avg_loss=0.07477]
[2018-11-23 02:28:50.446]  Step 253687  [20.635 sec/step, loss=0.07581, avg_loss=0.07478]
[2018-11-23 02:29:05.875]  Step 253688  [20.633 sec/step, loss=0.07373, avg_loss=0.07478]
[2018-11-23 02:29:23.409]  Step 253689  [20.611 sec/step, loss=0.07482, avg_loss=0.07477]
[2018-11-23 02:29:44.080]  Step 253690  [20.616 sec/step, loss=0.07595, avg_loss=0.07477]
[2018-11-23 02:30:21.518]  Step 253691  [20.770 sec/step, loss=0.06756, avg_loss=0.07469]
[2018-11-23 02:30:33.747]  Step 253692  [20.654 sec/step, loss=0.07154, avg_loss=0.07464]
[2018-11-23 02:30:58.038]  Step 253693  [20.705 sec/step, loss=0.07623, avg_loss=0.07465]
[2018-11-23 02:31:17.455]  Step 253694  [20.671 sec/step, loss=0.07562, avg_loss=0.07463]
[2018-11-23 02:31:41.282]  Step 253695  [20.671 sec/step, loss=0.07631, avg_loss=0.07463]
[2018-11-23 02:31:49.693]  Step 253696  [20.380 sec/step, loss=0.05651, avg_loss=0.07452]
[2018-11-23 02:32:11.206]  Step 253697  [20.427 sec/step, loss=0.07649, avg_loss=0.07453]
[2018-11-23 02:32:36.922]  Step 253698  [20.464 sec/step, loss=0.07616, avg_loss=0.07453]
[2018-11-23 02:32:46.338]  Generated 32 batches of size 32 in 8.548 sec
[2018-11-23 02:32:57.573]  Step 253699  [20.486 sec/step, loss=0.07548, avg_loss=0.07451]
[2018-11-23 02:33:21.198]  Step 253700  [20.494 sec/step, loss=0.07702, avg_loss=0.07452]
[2018-11-23 02:33:21.198]  Writing summary at step: 253700
[2018-11-23 02:34:05.027]  Step 253701  [20.512 sec/step, loss=0.07652, avg_loss=0.07454]
[2018-11-23 02:34:28.145]  Step 253702  [20.535 sec/step, loss=0.07634, avg_loss=0.07453]
[2018-11-23 02:34:51.230]  Step 253703  [20.658 sec/step, loss=0.07583, avg_loss=0.07460]
[2018-11-23 02:35:06.633]  Step 253704  [20.535 sec/step, loss=0.07250, avg_loss=0.07455]
[2018-11-23 02:35:24.765]  Step 253705  [20.562 sec/step, loss=0.07583, avg_loss=0.07458]
[2018-11-23 02:35:49.919]  Step 253706  [20.591 sec/step, loss=0.07695, avg_loss=0.07458]
[2018-11-23 02:36:09.133]  Step 253707  [20.572 sec/step, loss=0.07538, avg_loss=0.07458]
[2018-11-23 02:36:32.986]  Step 253708  [20.587 sec/step, loss=0.07641, avg_loss=0.07457]
[2018-11-23 02:36:54.563]  Step 253709  [20.560 sec/step, loss=0.07592, avg_loss=0.07457]
[2018-11-23 02:37:19.419]  Step 253710  [20.569 sec/step, loss=0.07667, avg_loss=0.07457]
[2018-11-23 02:37:40.523]  Step 253711  [20.660 sec/step, loss=0.07630, avg_loss=0.07461]
[2018-11-23 02:38:04.682]  Step 253712  [20.641 sec/step, loss=0.07587, avg_loss=0.07462]
[2018-11-23 02:38:19.962]  Step 253713  [20.556 sec/step, loss=0.07347, avg_loss=0.07458]
[2018-11-23 02:38:28.207]  Step 253714  [20.433 sec/step, loss=0.05724, avg_loss=0.07440]
[2018-11-23 02:38:49.950]  Step 253715  [20.388 sec/step, loss=0.07600, avg_loss=0.07439]
[2018-11-23 02:39:10.411]  Step 253716  [20.370 sec/step, loss=0.07629, avg_loss=0.07439]
[2018-11-23 02:39:27.740]  Step 253717  [20.296 sec/step, loss=0.07478, avg_loss=0.07438]
[2018-11-23 02:39:51.059]  Step 253718  [20.289 sec/step, loss=0.07540, avg_loss=0.07437]
[2018-11-23 02:40:14.559]  Step 253719  [20.305 sec/step, loss=0.07648, avg_loss=0.07437]
[2018-11-23 02:40:33.973]  Step 253720  [20.109 sec/step, loss=0.07514, avg_loss=0.07445]
[2018-11-23 02:40:58.347]  Step 253721  [20.114 sec/step, loss=0.07584, avg_loss=0.07445]
[2018-11-23 02:41:37.063]  Step 253722  [20.280 sec/step, loss=0.06731, avg_loss=0.07436]
[2018-11-23 02:42:00.694]  Step 253723  [20.255 sec/step, loss=0.07592, avg_loss=0.07436]
[2018-11-23 02:42:19.233]  Step 253724  [20.196 sec/step, loss=0.07594, avg_loss=0.07436]
[2018-11-23 02:42:36.071]  Step 253725  [20.277 sec/step, loss=0.07497, avg_loss=0.07455]
[2018-11-23 02:42:58.675]  Step 253726  [20.280 sec/step, loss=0.07621, avg_loss=0.07455]
[2018-11-23 02:43:08.914]  Step 253727  [20.224 sec/step, loss=0.06747, avg_loss=0.07449]
[2018-11-23 02:43:29.057]  Step 253728  [20.236 sec/step, loss=0.07541, avg_loss=0.07449]
[2018-11-23 02:43:50.706]  Step 253729  [20.257 sec/step, loss=0.07594, avg_loss=0.07450]
[2018-11-23 02:43:59.919]  Generated 32 batches of size 32 in 8.294 sec
[2018-11-23 02:44:13.664]  Step 253730  [20.310 sec/step, loss=0.07645, avg_loss=0.07451]
[2018-11-23 02:44:35.668]  Step 253731  [20.426 sec/step, loss=0.07620, avg_loss=0.07459]
[2018-11-23 02:44:49.343]  Step 253732  [20.404 sec/step, loss=0.07349, avg_loss=0.07460]
[2018-11-23 02:45:07.571]  Step 253733  [20.343 sec/step, loss=0.07527, avg_loss=0.07459]
[2018-11-23 02:45:33.507]  Step 253734  [20.407 sec/step, loss=0.07542, avg_loss=0.07459]
[2018-11-23 02:45:57.180]  Step 253735  [20.517 sec/step, loss=0.07638, avg_loss=0.07463]
[2018-11-23 02:46:17.372]  Step 253736  [20.433 sec/step, loss=0.07594, avg_loss=0.07463]
[2018-11-23 02:46:29.347]  Step 253737  [20.354 sec/step, loss=0.07141, avg_loss=0.07457]
[2018-11-23 02:46:44.706]  Step 253738  [20.294 sec/step, loss=0.07212, avg_loss=0.07453]
[2018-11-23 02:47:08.159]  Step 253739  [20.298 sec/step, loss=0.07661, avg_loss=0.07454]
[2018-11-23 02:47:22.036]  Step 253740  [20.235 sec/step, loss=0.07236, avg_loss=0.07450]
[2018-11-23 02:47:43.523]  Step 253741  [20.265 sec/step, loss=0.07610, avg_loss=0.07451]
[2018-11-23 02:48:03.200]  Step 253742  [20.325 sec/step, loss=0.07520, avg_loss=0.07453]
[2018-11-23 02:48:24.409]  Step 253743  [20.327 sec/step, loss=0.07614, avg_loss=0.07453]
[2018-11-23 02:48:47.813]  Step 253744  [20.328 sec/step, loss=0.07526, avg_loss=0.07451]
[2018-11-23 02:49:06.934]  Step 253745  [20.334 sec/step, loss=0.07535, avg_loss=0.07451]
[2018-11-23 02:49:25.056]  Step 253746  [20.267 sec/step, loss=0.07613, avg_loss=0.07450]
[2018-11-23 02:49:36.714]  Step 253747  [20.199 sec/step, loss=0.07136, avg_loss=0.07446]
[2018-11-23 02:49:54.088]  Step 253748  [20.178 sec/step, loss=0.07507, avg_loss=0.07446]
[2018-11-23 02:50:15.652]  Step 253749  [20.149 sec/step, loss=0.07588, avg_loss=0.07445]
[2018-11-23 02:50:41.797]  Step 253750  [20.319 sec/step, loss=0.07524, avg_loss=0.07463]
[2018-11-23 02:50:41.797]  Writing summary at step: 253750
[2018-11-23 02:51:06.290]  Step 253751  [20.357 sec/step, loss=0.07179, avg_loss=0.07463]
[2018-11-23 02:51:25.986]  Step 253752  [20.320 sec/step, loss=0.07518, avg_loss=0.07462]
[2018-11-23 02:51:47.623]  Step 253753  [20.302 sec/step, loss=0.07576, avg_loss=0.07462]
[2018-11-23 02:52:02.691]  Step 253754  [20.224 sec/step, loss=0.07351, avg_loss=0.07459]
[2018-11-23 02:52:46.069]  Step 253755  [20.501 sec/step, loss=0.06709, avg_loss=0.07455]
[2018-11-23 02:53:10.471]  Step 253756  [20.535 sec/step, loss=0.07589, avg_loss=0.07454]
[2018-11-23 02:53:27.404]  Step 253757  [20.529 sec/step, loss=0.07504, avg_loss=0.07454]
[2018-11-23 02:53:51.712]  Step 253758  [20.534 sec/step, loss=0.07592, avg_loss=0.07454]
[2018-11-23 02:54:16.508]  Step 253759  [20.610 sec/step, loss=0.07682, avg_loss=0.07456]
[2018-11-23 02:54:40.849]  Step 253760  [20.701 sec/step, loss=0.07635, avg_loss=0.07459]
[2018-11-23 02:54:50.561]  Generated 32 batches of size 32 in 8.597 sec
[2018-11-23 02:55:02.940]  Step 253761  [20.703 sec/step, loss=0.07606, avg_loss=0.07459]
[2018-11-23 02:55:21.457]  Step 253762  [20.629 sec/step, loss=0.07527, avg_loss=0.07459]
[2018-11-23 02:55:42.436]  Step 253763  [20.596 sec/step, loss=0.07574, avg_loss=0.07459]
[2018-11-23 02:56:06.532]  Step 253764  [20.617 sec/step, loss=0.07689, avg_loss=0.07460]
[2018-11-23 02:56:29.131]  Step 253765  [20.601 sec/step, loss=0.07609, avg_loss=0.07460]
[2018-11-23 02:56:53.287]  Step 253766  [20.618 sec/step, loss=0.07596, avg_loss=0.07460]
[2018-11-23 02:57:14.549]  Step 253767  [20.715 sec/step, loss=0.07604, avg_loss=0.07468]
[2018-11-23 02:57:36.512]  Step 253768  [20.720 sec/step, loss=0.07538, avg_loss=0.07467]
[2018-11-23 02:57:47.207]  Step 253769  [20.618 sec/step, loss=0.06831, avg_loss=0.07459]
[2018-11-23 02:58:11.225]  Step 253770  [20.658 sec/step, loss=0.07572, avg_loss=0.07458]
[2018-11-23 02:58:31.822]  Step 253771  [20.625 sec/step, loss=0.07552, avg_loss=0.07457]
[2018-11-23 02:58:40.578]  Step 253772  [20.499 sec/step, loss=0.05598, avg_loss=0.07437]
[2018-11-23 02:58:57.447]  Step 253773  [20.529 sec/step, loss=0.07308, avg_loss=0.07437]
[2018-11-23 02:59:19.732]  Step 253774  [20.563 sec/step, loss=0.07642, avg_loss=0.07437]
[2018-11-23 02:59:45.557]  Step 253775  [20.616 sec/step, loss=0.07582, avg_loss=0.07437]
[2018-11-23 03:00:10.006]  Step 253776  [20.646 sec/step, loss=0.07596, avg_loss=0.07437]
[2018-11-23 03:00:20.162]  Step 253777  [20.581 sec/step, loss=0.06907, avg_loss=0.07432]
[2018-11-23 03:00:44.503]  Step 253778  [20.573 sec/step, loss=0.07652, avg_loss=0.07432]
[2018-11-23 03:01:01.808]  Step 253779  [20.489 sec/step, loss=0.07513, avg_loss=0.07431]
[2018-11-23 03:01:25.337]  Step 253780  [20.502 sec/step, loss=0.07623, avg_loss=0.07432]
[2018-11-23 03:01:46.812]  Step 253781  [20.496 sec/step, loss=0.07601, avg_loss=0.07432]
[2018-11-23 03:02:09.144]  Step 253782  [20.520 sec/step, loss=0.07626, avg_loss=0.07433]
[2018-11-23 03:02:30.887]  Step 253783  [20.635 sec/step, loss=0.07553, avg_loss=0.07439]
[2018-11-23 03:02:50.604]  Step 253784  [20.645 sec/step, loss=0.07515, avg_loss=0.07439]
[2018-11-23 03:03:12.478]  Step 253785  [20.725 sec/step, loss=0.07550, avg_loss=0.07441]
[2018-11-23 03:03:31.772]  Step 253786  [20.701 sec/step, loss=0.07549, avg_loss=0.07441]
[2018-11-23 03:03:54.148]  Step 253787  [20.722 sec/step, loss=0.07623, avg_loss=0.07442]
[2018-11-23 03:04:17.737]  Step 253788  [20.804 sec/step, loss=0.07598, avg_loss=0.07444]
[2018-11-23 03:04:39.002]  Step 253789  [20.841 sec/step, loss=0.07565, avg_loss=0.07445]
[2018-11-23 03:04:54.682]  Step 253790  [20.791 sec/step, loss=0.07186, avg_loss=0.07441]
[2018-11-23 03:05:06.799]  Step 253791  [20.538 sec/step, loss=0.07174, avg_loss=0.07445]
[2018-11-23 03:05:30.237]  Step 253792  [20.650 sec/step, loss=0.07555, avg_loss=0.07449]
[2018-11-23 03:05:40.370]  Generated 32 batches of size 32 in 9.387 sec
[2018-11-23 03:05:46.260]  Step 253793  [20.568 sec/step, loss=0.07319, avg_loss=0.07446]
[2018-11-23 03:06:10.716]  Step 253794  [20.618 sec/step, loss=0.07566, avg_loss=0.07446]
[2018-11-23 03:06:36.375]  Step 253795  [20.636 sec/step, loss=0.07647, avg_loss=0.07446]
[2018-11-23 03:06:55.653]  Step 253796  [20.745 sec/step, loss=0.07576, avg_loss=0.07465]
[2018-11-23 03:07:34.982]  Step 253797  [20.923 sec/step, loss=0.06770, avg_loss=0.07457]
[2018-11-23 03:07:53.418]  Step 253798  [20.850 sec/step, loss=0.07543, avg_loss=0.07456]
[2018-11-23 03:08:10.918]  Step 253799  [20.819 sec/step, loss=0.07476, avg_loss=0.07455]
[2018-11-23 03:08:30.650]  Step 253800  [20.780 sec/step, loss=0.07565, avg_loss=0.07454]
[2018-11-23 03:08:30.651]  Writing summary at step: 253800
[2018-11-23 03:09:16.643]  Step 253801  [20.802 sec/step, loss=0.07593, avg_loss=0.07453]
[2018-11-23 03:09:31.988]  Step 253802  [20.724 sec/step, loss=0.07342, avg_loss=0.07450]
[2018-11-23 03:09:54.701]  Step 253803  [20.721 sec/step, loss=0.07578, avg_loss=0.07450]
[2018-11-23 03:10:19.068]  Step 253804  [20.810 sec/step, loss=0.07583, avg_loss=0.07454]
[2018-11-23 03:10:43.155]  Step 253805  [20.870 sec/step, loss=0.07567, avg_loss=0.07453]
[2018-11-23 03:11:06.540]  Step 253806  [20.852 sec/step, loss=0.07549, avg_loss=0.07452]
[2018-11-23 03:11:28.824]  Step 253807  [20.883 sec/step, loss=0.07542, avg_loss=0.07452]
[2018-11-23 03:11:49.250]  Step 253808  [20.849 sec/step, loss=0.07500, avg_loss=0.07451]
[2018-11-23 03:11:59.600]  Step 253809  [20.736 sec/step, loss=0.06827, avg_loss=0.07443]
[2018-11-23 03:12:20.473]  Step 253810  [20.696 sec/step, loss=0.07651, avg_loss=0.07443]
[2018-11-23 03:12:42.920]  Step 253811  [20.710 sec/step, loss=0.07577, avg_loss=0.07442]
[2018-11-23 03:13:00.040]  Step 253812  [20.640 sec/step, loss=0.07493, avg_loss=0.07441]
[2018-11-23 03:13:15.778]  Step 253813  [20.644 sec/step, loss=0.07225, avg_loss=0.07440]
[2018-11-23 03:13:40.471]  Step 253814  [20.809 sec/step, loss=0.07656, avg_loss=0.07459]
[2018-11-23 03:13:59.766]  Step 253815  [20.784 sec/step, loss=0.07539, avg_loss=0.07459]
[2018-11-23 03:14:20.856]  Step 253816  [20.790 sec/step, loss=0.07611, avg_loss=0.07459]
[2018-11-23 03:14:42.327]  Step 253817  [20.832 sec/step, loss=0.07618, avg_loss=0.07460]
[2018-11-23 03:15:00.409]  Step 253818  [20.779 sec/step, loss=0.07489, avg_loss=0.07460]
[2018-11-23 03:15:23.827]  Step 253819  [20.779 sec/step, loss=0.07590, avg_loss=0.07459]
[2018-11-23 03:15:50.845]  Step 253820  [20.855 sec/step, loss=0.07562, avg_loss=0.07459]
[2018-11-23 03:16:03.058]  Step 253821  [20.733 sec/step, loss=0.07206, avg_loss=0.07456]
[2018-11-23 03:16:21.374]  Step 253822  [20.529 sec/step, loss=0.07620, avg_loss=0.07465]
[2018-11-23 03:16:42.936]  Step 253823  [20.508 sec/step, loss=0.07643, avg_loss=0.07465]
[2018-11-23 03:16:53.152]  Generated 32 batches of size 32 in 9.403 sec
[2018-11-23 03:17:09.281]  Step 253824  [20.586 sec/step, loss=0.07613, avg_loss=0.07465]
[2018-11-23 03:17:30.756]  Step 253825  [20.633 sec/step, loss=0.07613, avg_loss=0.07466]
[2018-11-23 03:17:44.832]  Step 253826  [20.548 sec/step, loss=0.07258, avg_loss=0.07463]
[2018-11-23 03:18:04.638]  Step 253827  [20.643 sec/step, loss=0.07518, avg_loss=0.07470]
[2018-11-23 03:18:28.445]  Step 253828  [20.680 sec/step, loss=0.07611, avg_loss=0.07471]
[2018-11-23 03:18:37.016]  Step 253829  [20.549 sec/step, loss=0.05468, avg_loss=0.07450]
[2018-11-23 03:19:14.966]  Step 253830  [20.699 sec/step, loss=0.06730, avg_loss=0.07441]
[2018-11-23 03:19:34.102]  Step 253831  [20.670 sec/step, loss=0.07503, avg_loss=0.07440]
[2018-11-23 03:19:58.556]  Step 253832  [20.778 sec/step, loss=0.07692, avg_loss=0.07443]
[2018-11-23 03:20:17.375]  Step 253833  [20.784 sec/step, loss=0.07493, avg_loss=0.07443]
[2018-11-23 03:20:36.149]  Step 253834  [20.712 sec/step, loss=0.07584, avg_loss=0.07443]
[2018-11-23 03:21:00.679]  Step 253835  [20.721 sec/step, loss=0.07572, avg_loss=0.07442]
[2018-11-23 03:21:17.650]  Step 253836  [20.689 sec/step, loss=0.07483, avg_loss=0.07441]
[2018-11-23 03:21:38.220]  Step 253837  [20.775 sec/step, loss=0.07571, avg_loss=0.07446]
[2018-11-23 03:21:59.675]  Step 253838  [20.836 sec/step, loss=0.07571, avg_loss=0.07449]
[2018-11-23 03:22:18.205]  Step 253839  [20.786 sec/step, loss=0.07486, avg_loss=0.07447]
[2018-11-23 03:22:39.969]  Step 253840  [20.865 sec/step, loss=0.07543, avg_loss=0.07451]
[2018-11-23 03:23:02.694]  Step 253841  [20.878 sec/step, loss=0.07623, avg_loss=0.07451]
[2018-11-23 03:23:26.761]  Step 253842  [20.922 sec/step, loss=0.07601, avg_loss=0.07451]
[2018-11-23 03:23:50.133]  Step 253843  [20.943 sec/step, loss=0.07536, avg_loss=0.07451]
[2018-11-23 03:24:05.644]  Step 253844  [20.864 sec/step, loss=0.07327, avg_loss=0.07449]
[2018-11-23 03:24:29.699]  Step 253845  [20.914 sec/step, loss=0.07642, avg_loss=0.07450]
[2018-11-23 03:24:51.509]  Step 253846  [20.950 sec/step, loss=0.07560, avg_loss=0.07449]
[2018-11-23 03:25:12.945]  Step 253847  [21.048 sec/step, loss=0.07620, avg_loss=0.07454]
[2018-11-23 03:25:35.588]  Step 253848  [21.101 sec/step, loss=0.07594, avg_loss=0.07455]
[2018-11-23 03:25:51.953]  Step 253849  [21.049 sec/step, loss=0.07199, avg_loss=0.07451]
[2018-11-23 03:26:04.418]  Step 253850  [20.912 sec/step, loss=0.07087, avg_loss=0.07447]
[2018-11-23 03:26:04.419]  Writing summary at step: 253850
[2018-11-23 03:26:51.577]  Step 253851  [20.958 sec/step, loss=0.07593, avg_loss=0.07451]
[2018-11-23 03:27:16.894]  Step 253852  [21.014 sec/step, loss=0.07652, avg_loss=0.07452]
[2018-11-23 03:27:30.477]  Step 253853  [20.934 sec/step, loss=0.07307, avg_loss=0.07449]
[2018-11-23 03:27:38.926]  Step 253854  [20.868 sec/step, loss=0.05878, avg_loss=0.07435]
[2018-11-23 03:27:47.995]  Generated 32 batches of size 32 in 8.295 sec
[2018-11-23 03:28:00.164]  Step 253855  [20.646 sec/step, loss=0.07577, avg_loss=0.07443]
[2018-11-23 03:28:24.683]  Step 253856  [20.647 sec/step, loss=0.07614, avg_loss=0.07444]
[2018-11-23 03:28:42.149]  Step 253857  [20.653 sec/step, loss=0.07463, avg_loss=0.07443]
[2018-11-23 03:28:52.421]  Step 253858  [20.512 sec/step, loss=0.06821, avg_loss=0.07436]
[2018-11-23 03:29:15.119]  Step 253859  [20.491 sec/step, loss=0.07634, avg_loss=0.07435]
[2018-11-23 03:29:34.506]  Step 253860  [20.442 sec/step, loss=0.07508, avg_loss=0.07434]
[2018-11-23 03:29:58.419]  Step 253861  [20.460 sec/step, loss=0.07585, avg_loss=0.07434]
[2018-11-23 03:30:20.032]  Step 253862  [20.491 sec/step, loss=0.07567, avg_loss=0.07434]
[2018-11-23 03:30:58.781]  Step 253863  [20.669 sec/step, loss=0.06701, avg_loss=0.07425]
[2018-11-23 03:31:18.494]  Step 253864  [20.625 sec/step, loss=0.07464, avg_loss=0.07423]
[2018-11-23 03:31:32.014]  Step 253865  [20.534 sec/step, loss=0.07242, avg_loss=0.07419]
[2018-11-23 03:31:56.821]  Step 253866  [20.541 sec/step, loss=0.07649, avg_loss=0.07420]
[2018-11-23 03:32:20.142]  Step 253867  [20.561 sec/step, loss=0.07521, avg_loss=0.07419]
[2018-11-23 03:32:38.366]  Step 253868  [20.524 sec/step, loss=0.07553, avg_loss=0.07419]
[2018-11-23 03:32:50.337]  Step 253869  [20.537 sec/step, loss=0.07112, avg_loss=0.07422]
[2018-11-23 03:33:14.268]  Step 253870  [20.536 sec/step, loss=0.07569, avg_loss=0.07422]
[2018-11-23 03:33:35.539]  Step 253871  [20.542 sec/step, loss=0.07527, avg_loss=0.07422]
[2018-11-23 03:33:58.269]  Step 253872  [20.682 sec/step, loss=0.07567, avg_loss=0.07441]
[2018-11-23 03:34:20.359]  Step 253873  [20.734 sec/step, loss=0.07524, avg_loss=0.07444]
[2018-11-23 03:34:28.730]  Step 253874  [20.595 sec/step, loss=0.05669, avg_loss=0.07424]
[2018-11-23 03:34:54.680]  Step 253875  [20.596 sec/step, loss=0.07565, avg_loss=0.07424]
[2018-11-23 03:35:18.940]  Step 253876  [20.595 sec/step, loss=0.07650, avg_loss=0.07424]
[2018-11-23 03:35:44.367]  Step 253877  [20.747 sec/step, loss=0.07562, avg_loss=0.07431]
[2018-11-23 03:35:54.796]  Step 253878  [20.608 sec/step, loss=0.06703, avg_loss=0.07421]
[2018-11-23 03:36:12.557]  Step 253879  [20.613 sec/step, loss=0.07480, avg_loss=0.07421]
[2018-11-23 03:36:32.601]  Step 253880  [20.578 sec/step, loss=0.07632, avg_loss=0.07421]
[2018-11-23 03:36:51.597]  Step 253881  [20.553 sec/step, loss=0.07562, avg_loss=0.07421]
[2018-11-23 03:37:13.493]  Step 253882  [20.549 sec/step, loss=0.07578, avg_loss=0.07420]
[2018-11-23 03:37:51.579]  Step 253883  [20.712 sec/step, loss=0.06730, avg_loss=0.07412]
[2018-11-23 03:38:11.863]  Step 253884  [20.718 sec/step, loss=0.07574, avg_loss=0.07412]
[2018-11-23 03:38:28.682]  Step 253885  [20.667 sec/step, loss=0.07461, avg_loss=0.07412]
[2018-11-23 03:38:44.097]  Step 253886  [20.629 sec/step, loss=0.07302, avg_loss=0.07409]
[2018-11-23 03:38:53.842]  Generated 32 batches of size 32 in 8.882 sec
[2018-11-23 03:39:09.270]  Step 253887  [20.656 sec/step, loss=0.07605, avg_loss=0.07409]
[2018-11-23 03:39:30.889]  Step 253888  [20.637 sec/step, loss=0.07653, avg_loss=0.07410]
[2018-11-23 03:39:54.295]  Step 253889  [20.658 sec/step, loss=0.07610, avg_loss=0.07410]
[2018-11-23 03:40:15.491]  Step 253890  [20.713 sec/step, loss=0.07623, avg_loss=0.07414]
[2018-11-23 03:40:37.271]  Step 253891  [20.810 sec/step, loss=0.07587, avg_loss=0.07418]
[2018-11-23 03:40:53.045]  Step 253892  [20.733 sec/step, loss=0.07219, avg_loss=0.07415]
[2018-11-23 03:41:16.497]  Step 253893  [20.808 sec/step, loss=0.07630, avg_loss=0.07418]
[2018-11-23 03:41:35.150]  Step 253894  [20.750 sec/step, loss=0.07555, avg_loss=0.07418]
[2018-11-23 03:41:56.638]  Step 253895  [20.708 sec/step, loss=0.07584, avg_loss=0.07417]
[2018-11-23 03:42:08.603]  Step 253896  [20.635 sec/step, loss=0.07105, avg_loss=0.07413]
[2018-11-23 03:42:34.839]  Step 253897  [20.504 sec/step, loss=0.07560, avg_loss=0.07421]
[2018-11-23 03:42:53.274]  Step 253898  [20.504 sec/step, loss=0.07570, avg_loss=0.07421]
[2018-11-23 03:43:13.067]  Step 253899  [20.527 sec/step, loss=0.07606, avg_loss=0.07422]
[2018-11-23 03:43:23.387]  Step 253900  [20.433 sec/step, loss=0.06790, avg_loss=0.07414]
[2018-11-23 03:43:23.387]  Writing summary at step: 253900
[2018-11-23 03:44:05.801]  Step 253901  [20.431 sec/step, loss=0.07561, avg_loss=0.07414]
[2018-11-23 03:44:29.834]  Step 253902  [20.518 sec/step, loss=0.07577, avg_loss=0.07417]
[2018-11-23 03:44:54.216]  Step 253903  [20.535 sec/step, loss=0.07579, avg_loss=0.07417]
[2018-11-23 03:45:18.954]  Step 253904  [20.539 sec/step, loss=0.07652, avg_loss=0.07417]
[2018-11-23 03:45:40.694]  Step 253905  [20.515 sec/step, loss=0.07609, avg_loss=0.07418]
[2018-11-23 03:46:01.515]  Step 253906  [20.490 sec/step, loss=0.07588, avg_loss=0.07418]
[2018-11-23 03:46:23.327]  Step 253907  [20.485 sec/step, loss=0.07611, avg_loss=0.07419]
[2018-11-23 03:46:45.479]  Step 253908  [20.502 sec/step, loss=0.07538, avg_loss=0.07419]
[2018-11-23 03:47:08.314]  Step 253909  [20.627 sec/step, loss=0.07557, avg_loss=0.07426]
[2018-11-23 03:47:28.415]  Step 253910  [20.619 sec/step, loss=0.07516, avg_loss=0.07425]
[2018-11-23 03:47:52.758]  Step 253911  [20.638 sec/step, loss=0.07619, avg_loss=0.07425]
[2018-11-23 03:48:14.735]  Step 253912  [20.687 sec/step, loss=0.07553, avg_loss=0.07426]
[2018-11-23 03:48:23.416]  Step 253913  [20.616 sec/step, loss=0.05656, avg_loss=0.07410]
[2018-11-23 03:48:37.187]  Step 253914  [20.507 sec/step, loss=0.07287, avg_loss=0.07407]
[2018-11-23 03:48:52.918]  Step 253915  [20.471 sec/step, loss=0.07238, avg_loss=0.07404]
[2018-11-23 03:49:08.219]  Step 253916  [20.414 sec/step, loss=0.07300, avg_loss=0.07401]
[2018-11-23 03:49:28.857]  Step 253917  [20.405 sec/step, loss=0.07633, avg_loss=0.07401]
[2018-11-23 03:49:41.724]  Generated 32 batches of size 32 in 12.069 sec
[2018-11-23 03:50:13.519]  Step 253918  [20.671 sec/step, loss=0.06737, avg_loss=0.07393]
[2018-11-23 03:50:36.694]  Step 253919  [20.669 sec/step, loss=0.07590, avg_loss=0.07393]
[2018-11-23 03:51:01.720]  Step 253920  [20.649 sec/step, loss=0.07646, avg_loss=0.07394]
[2018-11-23 03:51:24.430]  Step 253921  [20.754 sec/step, loss=0.07605, avg_loss=0.07398]
[2018-11-23 03:51:48.985]  Step 253922  [20.816 sec/step, loss=0.07563, avg_loss=0.07397]
[2018-11-23 03:52:10.668]  Step 253923  [20.817 sec/step, loss=0.07561, avg_loss=0.07397]
[2018-11-23 03:52:28.422]  Step 253924  [20.731 sec/step, loss=0.07442, avg_loss=0.07395]
[2018-11-23 03:52:45.783]  Step 253925  [20.690 sec/step, loss=0.07498, avg_loss=0.07394]
[2018-11-23 03:53:05.222]  Step 253926  [20.744 sec/step, loss=0.07521, avg_loss=0.07396]
[2018-11-23 03:53:13.982]  Step 253927  [20.633 sec/step, loss=0.05573, avg_loss=0.07377]
[2018-11-23 03:53:37.306]  Step 253928  [20.628 sec/step, loss=0.07624, avg_loss=0.07377]
[2018-11-23 03:53:56.793]  Step 253929  [20.738 sec/step, loss=0.07503, avg_loss=0.07397]
[2018-11-23 03:54:19.343]  Step 253930  [20.584 sec/step, loss=0.07615, avg_loss=0.07406]
[2018-11-23 03:54:40.904]  Step 253931  [20.608 sec/step, loss=0.07622, avg_loss=0.07407]
[2018-11-23 03:55:05.834]  Step 253932  [20.613 sec/step, loss=0.07620, avg_loss=0.07407]
[2018-11-23 03:55:20.869]  Step 253933  [20.575 sec/step, loss=0.07238, avg_loss=0.07404]
[2018-11-23 03:55:45.432]  Step 253934  [20.633 sec/step, loss=0.07550, avg_loss=0.07404]
[2018-11-23 03:56:08.892]  Step 253935  [20.622 sec/step, loss=0.07642, avg_loss=0.07405]
[2018-11-23 03:56:25.042]  Step 253936  [20.614 sec/step, loss=0.07339, avg_loss=0.07403]
[2018-11-23 03:56:43.510]  Step 253937  [20.593 sec/step, loss=0.07551, avg_loss=0.07403]
[2018-11-23 03:57:05.990]  Step 253938  [20.603 sec/step, loss=0.07621, avg_loss=0.07403]
[2018-11-23 03:57:30.509]  Step 253939  [20.663 sec/step, loss=0.07626, avg_loss=0.07405]
[2018-11-23 03:57:54.920]  Step 253940  [20.689 sec/step, loss=0.07530, avg_loss=0.07405]
[2018-11-23 03:58:17.487]  Step 253941  [20.688 sec/step, loss=0.07563, avg_loss=0.07404]
[2018-11-23 03:58:39.979]  Step 253942  [20.672 sec/step, loss=0.07562, avg_loss=0.07404]
[2018-11-23 03:59:05.966]  Step 253943  [20.698 sec/step, loss=0.07592, avg_loss=0.07404]
[2018-11-23 03:59:31.904]  Step 253944  [20.802 sec/step, loss=0.07568, avg_loss=0.07407]
[2018-11-23 04:00:07.889]  Step 253945  [20.922 sec/step, loss=0.06722, avg_loss=0.07397]
[2018-11-23 04:00:30.173]  Step 253946  [20.927 sec/step, loss=0.07521, avg_loss=0.07397]
[2018-11-23 04:00:49.365]  Step 253947  [20.904 sec/step, loss=0.07540, avg_loss=0.07396]
[2018-11-23 04:01:07.459]  Step 253948  [20.859 sec/step, loss=0.07471, avg_loss=0.07395]
[2018-11-23 04:01:28.033]  Step 253949  [20.901 sec/step, loss=0.07564, avg_loss=0.07399]
[2018-11-23 04:01:37.588]  Generated 32 batches of size 32 in 8.839 sec
[2018-11-23 04:01:47.396]  Step 253950  [20.970 sec/step, loss=0.07439, avg_loss=0.07402]
[2018-11-23 04:01:47.396]  Writing summary at step: 253950
[2018-11-23 04:02:22.504]  Step 253951  [20.996 sec/step, loss=0.07640, avg_loss=0.07403]
[2018-11-23 04:02:36.037]  Step 253952  [20.878 sec/step, loss=0.07345, avg_loss=0.07400]
[2018-11-23 04:02:55.066]  Step 253953  [20.933 sec/step, loss=0.07563, avg_loss=0.07402]
[2018-11-23 04:03:05.370]  Step 253954  [20.951 sec/step, loss=0.06823, avg_loss=0.07412]
[2018-11-23 04:03:29.372]  Step 253955  [20.979 sec/step, loss=0.07614, avg_loss=0.07412]
[2018-11-23 04:03:50.592]  Step 253956  [20.946 sec/step, loss=0.07573, avg_loss=0.07412]
[2018-11-23 04:04:10.396]  Step 253957  [20.970 sec/step, loss=0.07598, avg_loss=0.07413]
[2018-11-23 04:04:34.426]  Step 253958  [21.107 sec/step, loss=0.07577, avg_loss=0.07421]
[2018-11-23 04:04:49.905]  Step 253959  [21.035 sec/step, loss=0.07270, avg_loss=0.07417]
[2018-11-23 04:05:15.737]  Step 253960  [21.099 sec/step, loss=0.07647, avg_loss=0.07418]
[2018-11-23 04:05:38.976]  Step 253961  [21.093 sec/step, loss=0.07547, avg_loss=0.07418]
[2018-11-23 04:06:02.277]  Step 253962  [21.109 sec/step, loss=0.07608, avg_loss=0.07418]
[2018-11-23 04:06:40.148]  Step 253963  [21.101 sec/step, loss=0.06692, avg_loss=0.07418]
[2018-11-23 04:07:03.899]  Step 253964  [21.141 sec/step, loss=0.07637, avg_loss=0.07420]
[2018-11-23 04:07:26.182]  Step 253965  [21.229 sec/step, loss=0.07598, avg_loss=0.07423]
[2018-11-23 04:07:40.253]  Step 253966  [21.121 sec/step, loss=0.07282, avg_loss=0.07420]
[2018-11-23 04:07:49.236]  Step 253967  [20.978 sec/step, loss=0.05542, avg_loss=0.07400]
[2018-11-23 04:08:10.761]  Step 253968  [21.011 sec/step, loss=0.07582, avg_loss=0.07400]
[2018-11-23 04:08:35.781]  Step 253969  [21.141 sec/step, loss=0.07637, avg_loss=0.07406]
[2018-11-23 04:08:47.938]  Step 253970  [21.024 sec/step, loss=0.07138, avg_loss=0.07401]
[2018-11-23 04:09:06.690]  Step 253971  [20.999 sec/step, loss=0.07506, avg_loss=0.07401]
[2018-11-23 04:09:24.961]  Step 253972  [20.954 sec/step, loss=0.07444, avg_loss=0.07400]
[2018-11-23 04:09:41.710]  Step 253973  [20.901 sec/step, loss=0.07472, avg_loss=0.07399]
[2018-11-23 04:10:03.202]  Step 253974  [21.032 sec/step, loss=0.07636, avg_loss=0.07419]
[2018-11-23 04:10:29.155]  Step 253975  [21.032 sec/step, loss=0.07547, avg_loss=0.07419]
[2018-11-23 04:10:53.316]  Step 253976  [21.031 sec/step, loss=0.07639, avg_loss=0.07419]
[2018-11-23 04:11:17.148]  Step 253977  [21.015 sec/step, loss=0.07523, avg_loss=0.07418]
[2018-11-23 04:11:36.630]  Step 253978  [21.105 sec/step, loss=0.07491, avg_loss=0.07426]
[2018-11-23 04:11:58.095]  Step 253979  [21.142 sec/step, loss=0.07506, avg_loss=0.07426]
[2018-11-23 04:12:19.324]  Step 253980  [21.154 sec/step, loss=0.07514, avg_loss=0.07425]
[2018-11-23 04:12:28.714]  Generated 32 batches of size 32 in 8.553 sec
[2018-11-23 04:12:42.647]  Step 253981  [21.198 sec/step, loss=0.07567, avg_loss=0.07425]
[2018-11-23 04:12:58.680]  Step 253982  [21.139 sec/step, loss=0.07176, avg_loss=0.07421]
[2018-11-23 04:13:17.193]  Step 253983  [20.943 sec/step, loss=0.07537, avg_loss=0.07429]
[2018-11-23 04:13:35.911]  Step 253984  [20.928 sec/step, loss=0.07563, avg_loss=0.07429]
[2018-11-23 04:13:46.458]  Step 253985  [20.865 sec/step, loss=0.06845, avg_loss=0.07423]
[2018-11-23 04:14:08.152]  Step 253986  [20.928 sec/step, loss=0.07543, avg_loss=0.07426]
[2018-11-23 04:14:28.261]  Step 253987  [20.877 sec/step, loss=0.07562, avg_loss=0.07425]
[2018-11-23 04:14:52.748]  Step 253988  [20.906 sec/step, loss=0.07556, avg_loss=0.07424]
[2018-11-23 04:15:17.299]  Step 253989  [20.917 sec/step, loss=0.07617, avg_loss=0.07424]
[2018-11-23 04:15:38.638]  Step 253990  [20.919 sec/step, loss=0.07588, avg_loss=0.07424]
[2018-11-23 04:16:05.868]  Step 253991  [20.973 sec/step, loss=0.07492, avg_loss=0.07423]
[2018-11-23 04:16:28.030]  Step 253992  [21.037 sec/step, loss=0.07585, avg_loss=0.07427]
[2018-11-23 04:16:47.953]  Step 253993  [21.002 sec/step, loss=0.07454, avg_loss=0.07425]
[2018-11-23 04:17:11.649]  Step 253994  [21.052 sec/step, loss=0.07621, avg_loss=0.07425]
[2018-11-23 04:17:30.301]  Step 253995  [21.024 sec/step, loss=0.07492, avg_loss=0.07425]
[2018-11-23 04:17:52.276]  Step 253996  [21.124 sec/step, loss=0.07510, avg_loss=0.07429]
[2018-11-23 04:18:10.159]  Step 253997  [21.040 sec/step, loss=0.07413, avg_loss=0.07427]
[2018-11-23 04:18:27.181]  Step 253998  [21.026 sec/step, loss=0.07490, avg_loss=0.07426]
[2018-11-23 04:18:37.661]  Step 253999  [20.933 sec/step, loss=0.06703, avg_loss=0.07417]
[2018-11-23 04:18:58.494]  Step 254000  [21.038 sec/step, loss=0.07567, avg_loss=0.07425]
[2018-11-23 04:18:58.494]  Writing summary at step: 254000
[2018-11-23 04:19:39.786]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-254000
[2018-11-23 04:19:42.801]  Saving audio and alignment...
[2018-11-23 04:19:58.053]  Input: not soon enough, however; the volume was flung, it hit me, and i fell, striking my head against the door and cutting it. the cut bled, the pain was sharp: my terror had passed its climax; other feelings succeeded.~
[2018-11-23 04:20:19.202]  Step 254001  [21.016 sec/step, loss=0.07550, avg_loss=0.07425]
[2018-11-23 04:20:43.944]  Step 254002  [21.024 sec/step, loss=0.07653, avg_loss=0.07426]
[2018-11-23 04:21:05.490]  Step 254003  [20.995 sec/step, loss=0.07637, avg_loss=0.07426]
[2018-11-23 04:21:27.966]  Step 254004  [20.973 sec/step, loss=0.07524, avg_loss=0.07425]
[2018-11-23 04:21:43.671]  Step 254005  [20.912 sec/step, loss=0.07193, avg_loss=0.07421]
[2018-11-23 04:22:03.949]  Step 254006  [20.907 sec/step, loss=0.07643, avg_loss=0.07421]
[2018-11-23 04:22:27.252]  Step 254007  [20.922 sec/step, loss=0.07572, avg_loss=0.07421]
[2018-11-23 04:22:52.514]  Step 254008  [20.953 sec/step, loss=0.07620, avg_loss=0.07422]
[2018-11-23 04:23:15.344]  Step 254009  [20.953 sec/step, loss=0.07579, avg_loss=0.07422]
[2018-11-23 04:23:30.765]  Step 254010  [20.906 sec/step, loss=0.07352, avg_loss=0.07420]
[2018-11-23 04:23:42.113]  Generated 32 batches of size 32 in 10.479 sec
[2018-11-23 04:23:58.637]  Step 254011  [20.941 sec/step, loss=0.07572, avg_loss=0.07420]
[2018-11-23 04:24:10.713]  Step 254012  [20.842 sec/step, loss=0.07172, avg_loss=0.07416]
[2018-11-23 04:24:29.130]  Step 254013  [20.940 sec/step, loss=0.07608, avg_loss=0.07436]
[2018-11-23 04:24:37.485]  Step 254014  [20.885 sec/step, loss=0.05687, avg_loss=0.07420]
[2018-11-23 04:24:51.750]  Step 254015  [20.871 sec/step, loss=0.07198, avg_loss=0.07419]
[2018-11-23 04:25:15.952]  Step 254016  [20.960 sec/step, loss=0.07635, avg_loss=0.07423]
[2018-11-23 04:25:40.403]  Step 254017  [20.998 sec/step, loss=0.07560, avg_loss=0.07422]
[2018-11-23 04:26:00.427]  Step 254018  [20.752 sec/step, loss=0.07516, avg_loss=0.07430]
[2018-11-23 04:26:22.077]  Step 254019  [20.736 sec/step, loss=0.07540, avg_loss=0.07429]
[2018-11-23 04:26:34.130]  Step 254020  [20.607 sec/step, loss=0.07198, avg_loss=0.07425]
[2018-11-23 04:26:57.367]  Step 254021  [20.612 sec/step, loss=0.07622, avg_loss=0.07425]
[2018-11-23 04:27:23.204]  Step 254022  [20.625 sec/step, loss=0.07537, avg_loss=0.07425]
[2018-11-23 04:27:42.199]  Step 254023  [20.598 sec/step, loss=0.07522, avg_loss=0.07424]
[2018-11-23 04:27:59.060]  Step 254024  [20.589 sec/step, loss=0.07448, avg_loss=0.07424]
[2018-11-23 04:28:16.825]  Step 254025  [20.593 sec/step, loss=0.07431, avg_loss=0.07424]
[2018-11-23 04:28:40.777]  Step 254026  [20.638 sec/step, loss=0.07557, avg_loss=0.07424]
[2018-11-23 04:29:03.404]  Step 254027  [20.777 sec/step, loss=0.07597, avg_loss=0.07444]
[2018-11-23 04:29:26.677]  Step 254028  [20.776 sec/step, loss=0.07532, avg_loss=0.07443]
[2018-11-23 04:29:46.377]  Step 254029  [20.778 sec/step, loss=0.07474, avg_loss=0.07443]
[2018-11-23 04:30:07.739]  Step 254030  [20.766 sec/step, loss=0.07536, avg_loss=0.07442]
[2018-11-23 04:30:32.091]  Step 254031  [20.794 sec/step, loss=0.07677, avg_loss=0.07443]
[2018-11-23 04:30:53.131]  Step 254032  [20.755 sec/step, loss=0.07584, avg_loss=0.07442]
[2018-11-23 04:31:18.339]  Step 254033  [20.857 sec/step, loss=0.07569, avg_loss=0.07446]
[2018-11-23 04:31:39.753]  Step 254034  [20.826 sec/step, loss=0.07590, avg_loss=0.07446]
[2018-11-23 04:32:01.233]  Step 254035  [20.806 sec/step, loss=0.07596, avg_loss=0.07446]
[2018-11-23 04:32:26.226]  Step 254036  [20.894 sec/step, loss=0.07596, avg_loss=0.07448]
[2018-11-23 04:32:46.718]  Step 254037  [20.915 sec/step, loss=0.07563, avg_loss=0.07448]
[2018-11-23 04:33:08.234]  Step 254038  [20.905 sec/step, loss=0.07598, avg_loss=0.07448]
[2018-11-23 04:33:30.134]  Step 254039  [20.879 sec/step, loss=0.07533, avg_loss=0.07447]
[2018-11-23 04:33:49.936]  Step 254040  [20.833 sec/step, loss=0.07502, avg_loss=0.07447]
[2018-11-23 04:34:08.519]  Step 254041  [20.793 sec/step, loss=0.07482, avg_loss=0.07446]
[2018-11-23 04:34:33.156]  Step 254042  [20.814 sec/step, loss=0.07586, avg_loss=0.07446]
[2018-11-23 04:34:42.633]  Generated 32 batches of size 32 in 8.624 sec
[2018-11-23 04:34:50.186]  Step 254043  [20.725 sec/step, loss=0.07187, avg_loss=0.07442]
[2018-11-23 04:35:04.076]  Step 254044  [20.604 sec/step, loss=0.07334, avg_loss=0.07440]
[2018-11-23 04:35:19.471]  Step 254045  [20.398 sec/step, loss=0.07333, avg_loss=0.07446]
[2018-11-23 04:36:03.015]  Step 254046  [20.611 sec/step, loss=0.06724, avg_loss=0.07438]
[2018-11-23 04:36:27.368]  Step 254047  [20.663 sec/step, loss=0.07640, avg_loss=0.07439]
[2018-11-23 04:36:50.321]  Step 254048  [20.711 sec/step, loss=0.07603, avg_loss=0.07440]
[2018-11-23 04:37:00.632]  Step 254049  [20.608 sec/step, loss=0.06846, avg_loss=0.07433]
[2018-11-23 04:37:09.454]  Step 254050  [20.503 sec/step, loss=0.05547, avg_loss=0.07414]
[2018-11-23 04:37:09.454]  Writing summary at step: 254050
[2018-11-23 04:37:42.000]  Step 254051  [20.412 sec/step, loss=0.07271, avg_loss=0.07411]
[2018-11-23 04:38:03.404]  Step 254052  [20.491 sec/step, loss=0.07586, avg_loss=0.07413]
[2018-11-23 04:38:28.000]  Step 254053  [20.546 sec/step, loss=0.07558, avg_loss=0.07413]
[2018-11-23 04:38:46.940]  Step 254054  [20.633 sec/step, loss=0.07487, avg_loss=0.07420]
[2018-11-23 04:39:08.083]  Step 254055  [20.604 sec/step, loss=0.07589, avg_loss=0.07419]
[2018-11-23 04:39:33.000]  Step 254056  [20.641 sec/step, loss=0.07661, avg_loss=0.07420]
[2018-11-23 04:39:48.713]  Step 254057  [20.600 sec/step, loss=0.07353, avg_loss=0.07418]
[2018-11-23 04:40:10.581]  Step 254058  [20.578 sec/step, loss=0.07564, avg_loss=0.07418]
[2018-11-23 04:40:22.848]  Step 254059  [20.546 sec/step, loss=0.07132, avg_loss=0.07416]
[2018-11-23 04:40:47.274]  Step 254060  [20.532 sec/step, loss=0.07680, avg_loss=0.07417]
[2018-11-23 04:40:55.713]  Step 254061  [20.384 sec/step, loss=0.05706, avg_loss=0.07398]
[2018-11-23 04:41:14.334]  Step 254062  [20.337 sec/step, loss=0.07562, avg_loss=0.07398]
[2018-11-23 04:41:40.365]  Step 254063  [20.219 sec/step, loss=0.07541, avg_loss=0.07406]
[2018-11-23 04:42:18.368]  Step 254064  [20.362 sec/step, loss=0.06700, avg_loss=0.07397]
[2018-11-23 04:42:39.840]  Step 254065  [20.354 sec/step, loss=0.07607, avg_loss=0.07397]
[2018-11-23 04:43:01.811]  Step 254066  [20.432 sec/step, loss=0.07598, avg_loss=0.07400]
[2018-11-23 04:43:21.397]  Step 254067  [20.539 sec/step, loss=0.07494, avg_loss=0.07420]
[2018-11-23 04:43:39.045]  Step 254068  [20.500 sec/step, loss=0.07402, avg_loss=0.07418]
[2018-11-23 04:43:59.125]  Step 254069  [20.450 sec/step, loss=0.07547, avg_loss=0.07417]
[2018-11-23 04:44:09.729]  Step 254070  [20.435 sec/step, loss=0.06761, avg_loss=0.07413]
[2018-11-23 04:44:32.550]  Step 254071  [20.476 sec/step, loss=0.07525, avg_loss=0.07413]
[2018-11-23 04:44:53.548]  Step 254072  [20.503 sec/step, loss=0.07555, avg_loss=0.07414]
[2018-11-23 04:45:16.632]  Step 254073  [20.566 sec/step, loss=0.07558, avg_loss=0.07415]
[2018-11-23 04:45:26.010]  Generated 32 batches of size 32 in 8.579 sec
[2018-11-23 04:45:42.286]  Step 254074  [20.608 sec/step, loss=0.07597, avg_loss=0.07415]
[2018-11-23 04:46:00.939]  Step 254075  [20.535 sec/step, loss=0.07478, avg_loss=0.07414]
[2018-11-23 04:46:17.459]  Step 254076  [20.458 sec/step, loss=0.07546, avg_loss=0.07413]
[2018-11-23 04:46:40.724]  Step 254077  [20.453 sec/step, loss=0.07531, avg_loss=0.07413]
[2018-11-23 04:47:04.416]  Step 254078  [20.495 sec/step, loss=0.07573, avg_loss=0.07414]
[2018-11-23 04:47:27.486]  Step 254079  [20.511 sec/step, loss=0.07620, avg_loss=0.07415]
[2018-11-23 04:47:42.976]  Step 254080  [20.453 sec/step, loss=0.07255, avg_loss=0.07413]
[2018-11-23 04:48:06.910]  Step 254081  [20.460 sec/step, loss=0.07637, avg_loss=0.07413]
[2018-11-23 04:48:26.822]  Step 254082  [20.498 sec/step, loss=0.07593, avg_loss=0.07418]
[2018-11-23 04:48:48.327]  Step 254083  [20.528 sec/step, loss=0.07521, avg_loss=0.07417]
[2018-11-23 04:49:07.647]  Step 254084  [20.534 sec/step, loss=0.07443, avg_loss=0.07416]
[2018-11-23 04:49:31.443]  Step 254085  [20.667 sec/step, loss=0.07564, avg_loss=0.07423]
[2018-11-23 04:49:54.071]  Step 254086  [20.676 sec/step, loss=0.07569, avg_loss=0.07424]
[2018-11-23 04:50:17.855]  Step 254087  [20.713 sec/step, loss=0.07558, avg_loss=0.07424]
[2018-11-23 04:50:40.455]  Step 254088  [20.694 sec/step, loss=0.07524, avg_loss=0.07423]
[2018-11-23 04:50:58.206]  Step 254089  [20.626 sec/step, loss=0.07452, avg_loss=0.07422]
[2018-11-23 04:51:14.485]  Step 254090  [20.575 sec/step, loss=0.07321, avg_loss=0.07419]
[2018-11-23 04:51:24.884]  Step 254091  [20.407 sec/step, loss=0.06653, avg_loss=0.07411]
[2018-11-23 04:51:48.223]  Step 254092  [20.419 sec/step, loss=0.07527, avg_loss=0.07410]
[2018-11-23 04:51:56.499]  Step 254093  [20.302 sec/step, loss=0.05745, avg_loss=0.07393]
[2018-11-23 04:52:22.771]  Step 254094  [20.328 sec/step, loss=0.07567, avg_loss=0.07392]
[2018-11-23 04:52:44.003]  Step 254095  [20.354 sec/step, loss=0.07581, avg_loss=0.07393]
[2018-11-23 04:53:05.295]  Step 254096  [20.347 sec/step, loss=0.07601, avg_loss=0.07394]
[2018-11-23 04:53:28.727]  Step 254097  [20.403 sec/step, loss=0.07543, avg_loss=0.07396]
[2018-11-23 04:53:47.378]  Step 254098  [20.419 sec/step, loss=0.07509, avg_loss=0.07396]
[2018-11-23 04:54:09.649]  Step 254099  [20.537 sec/step, loss=0.07580, avg_loss=0.07404]
[2018-11-23 04:54:29.613]  Step 254100  [20.528 sec/step, loss=0.07577, avg_loss=0.07405]
[2018-11-23 04:54:29.613]  Writing summary at step: 254100
[2018-11-23 04:55:02.094]  Step 254101  [20.451 sec/step, loss=0.07309, avg_loss=0.07402]
[2018-11-23 04:55:42.333]  Step 254102  [20.606 sec/step, loss=0.06759, avg_loss=0.07393]
[2018-11-23 04:56:04.037]  Step 254103  [20.608 sec/step, loss=0.07588, avg_loss=0.07393]
[2018-11-23 04:56:28.452]  Step 254104  [20.627 sec/step, loss=0.07583, avg_loss=0.07393]
[2018-11-23 04:56:38.164]  Generated 32 batches of size 32 in 8.751 sec
[2018-11-23 04:56:54.864]  Step 254105  [20.734 sec/step, loss=0.07492, avg_loss=0.07396]
[2018-11-23 04:57:16.691]  Step 254106  [20.750 sec/step, loss=0.07533, avg_loss=0.07395]
[2018-11-23 04:57:40.659]  Step 254107  [20.757 sec/step, loss=0.07647, avg_loss=0.07396]
[2018-11-23 04:57:57.853]  Step 254108  [20.676 sec/step, loss=0.07473, avg_loss=0.07395]
[2018-11-23 04:58:09.280]  Step 254109  [20.562 sec/step, loss=0.07124, avg_loss=0.07390]
[2018-11-23 04:58:24.689]  Step 254110  [20.562 sec/step, loss=0.07185, avg_loss=0.07388]
[2018-11-23 04:58:50.681]  Step 254111  [20.543 sec/step, loss=0.07582, avg_loss=0.07388]
[2018-11-23 04:59:09.727]  Step 254112  [20.613 sec/step, loss=0.07560, avg_loss=0.07392]
[2018-11-23 04:59:29.972]  Step 254113  [20.631 sec/step, loss=0.07540, avg_loss=0.07392]
[2018-11-23 04:59:40.689]  Step 254114  [20.655 sec/step, loss=0.06746, avg_loss=0.07402]
[2018-11-23 05:00:04.589]  Step 254115  [20.751 sec/step, loss=0.07572, avg_loss=0.07406]
[2018-11-23 05:00:25.734]  Step 254116  [20.720 sec/step, loss=0.07559, avg_loss=0.07405]
[2018-11-23 05:00:51.175]  Step 254117  [20.730 sec/step, loss=0.07584, avg_loss=0.07405]
[2018-11-23 05:01:04.459]  Step 254118  [20.663 sec/step, loss=0.07079, avg_loss=0.07401]
[2018-11-23 05:01:22.984]  Step 254119  [20.632 sec/step, loss=0.07600, avg_loss=0.07402]
[2018-11-23 05:01:44.281]  Step 254120  [20.724 sec/step, loss=0.07555, avg_loss=0.07405]
[2018-11-23 05:02:07.683]  Step 254121  [20.726 sec/step, loss=0.07650, avg_loss=0.07405]
[2018-11-23 05:02:27.826]  Step 254122  [20.669 sec/step, loss=0.07565, avg_loss=0.07406]
[2018-11-23 05:02:45.721]  Step 254123  [20.658 sec/step, loss=0.07432, avg_loss=0.07405]
[2018-11-23 05:03:04.939]  Step 254124  [20.681 sec/step, loss=0.07506, avg_loss=0.07405]
[2018-11-23 05:03:26.466]  Step 254125  [20.719 sec/step, loss=0.07571, avg_loss=0.07407]
[2018-11-23 05:03:48.340]  Step 254126  [20.698 sec/step, loss=0.07575, avg_loss=0.07407]
[2018-11-23 05:03:56.986]  Step 254127  [20.558 sec/step, loss=0.05554, avg_loss=0.07387]
[2018-11-23 05:04:23.342]  Step 254128  [20.589 sec/step, loss=0.07532, avg_loss=0.07387]
[2018-11-23 05:04:45.927]  Step 254129  [20.618 sec/step, loss=0.07573, avg_loss=0.07388]
[2018-11-23 05:05:06.137]  Step 254130  [20.606 sec/step, loss=0.07484, avg_loss=0.07387]
[2018-11-23 05:05:20.077]  Step 254131  [20.502 sec/step, loss=0.07299, avg_loss=0.07383]
[2018-11-23 05:05:39.737]  Step 254132  [20.489 sec/step, loss=0.07498, avg_loss=0.07382]
[2018-11-23 05:05:55.941]  Step 254133  [20.399 sec/step, loss=0.07379, avg_loss=0.07381]
[2018-11-23 05:06:19.573]  Step 254134  [20.421 sec/step, loss=0.07526, avg_loss=0.07380]
[2018-11-23 05:06:46.760]  Step 254135  [20.478 sec/step, loss=0.07557, avg_loss=0.07379]
[2018-11-23 05:07:25.570]  Step 254136  [20.616 sec/step, loss=0.06713, avg_loss=0.07371]
[2018-11-23 05:07:35.329]  Generated 32 batches of size 32 in 8.712 sec
[2018-11-23 05:07:42.815]  Step 254137  [20.583 sec/step, loss=0.07300, avg_loss=0.07368]
[2018-11-23 05:08:07.196]  Step 254138  [20.612 sec/step, loss=0.07537, avg_loss=0.07367]
[2018-11-23 05:08:26.877]  Step 254139  [20.590 sec/step, loss=0.07499, avg_loss=0.07367]
[2018-11-23 05:08:43.838]  Step 254140  [20.562 sec/step, loss=0.07523, avg_loss=0.07367]
[2018-11-23 05:09:05.374]  Step 254141  [20.591 sec/step, loss=0.07597, avg_loss=0.07368]
[2018-11-23 05:09:29.952]  Step 254142  [20.590 sec/step, loss=0.07583, avg_loss=0.07368]
[2018-11-23 05:09:53.654]  Step 254143  [20.657 sec/step, loss=0.07608, avg_loss=0.07373]
[2018-11-23 05:10:15.554]  Step 254144  [20.737 sec/step, loss=0.07559, avg_loss=0.07375]
[2018-11-23 05:10:39.703]  Step 254145  [20.825 sec/step, loss=0.07536, avg_loss=0.07377]
[2018-11-23 05:11:05.833]  Step 254146  [20.651 sec/step, loss=0.07496, avg_loss=0.07385]
[2018-11-23 05:11:27.951]  Step 254147  [20.628 sec/step, loss=0.07639, avg_loss=0.07385]
[2018-11-23 05:11:48.032]  Step 254148  [20.600 sec/step, loss=0.07469, avg_loss=0.07383]
[2018-11-23 05:12:09.424]  Step 254149  [20.710 sec/step, loss=0.07557, avg_loss=0.07390]
[2018-11-23 05:12:25.518]  Step 254150  [20.783 sec/step, loss=0.07446, avg_loss=0.07409]
[2018-11-23 05:12:25.518]  Writing summary at step: 254150
[2018-11-23 05:13:13.298]  Step 254151  [20.732 sec/step, loss=0.05640, avg_loss=0.07393]
[2018-11-23 05:13:27.603]  Step 254152  [20.661 sec/step, loss=0.07220, avg_loss=0.07389]
[2018-11-23 05:13:51.848]  Step 254153  [20.658 sec/step, loss=0.07544, avg_loss=0.07389]
[2018-11-23 05:14:11.216]  Step 254154  [20.662 sec/step, loss=0.07513, avg_loss=0.07390]
[2018-11-23 05:14:29.931]  Step 254155  [20.638 sec/step, loss=0.07491, avg_loss=0.07389]
[2018-11-23 05:14:53.573]  Step 254156  [20.625 sec/step, loss=0.07620, avg_loss=0.07388]
[2018-11-23 05:15:14.624]  Step 254157  [20.678 sec/step, loss=0.07563, avg_loss=0.07390]
[2018-11-23 05:15:37.278]  Step 254158  [20.686 sec/step, loss=0.07561, avg_loss=0.07390]
[2018-11-23 05:15:54.255]  Step 254159  [20.733 sec/step, loss=0.07366, avg_loss=0.07393]
[2018-11-23 05:16:11.433]  Step 254160  [20.661 sec/step, loss=0.07461, avg_loss=0.07390]
[2018-11-23 05:16:34.789]  Step 254161  [20.810 sec/step, loss=0.07526, avg_loss=0.07409]
[2018-11-23 05:16:58.147]  Step 254162  [20.857 sec/step, loss=0.07591, avg_loss=0.07409]
[2018-11-23 05:17:19.897]  Step 254163  [20.815 sec/step, loss=0.07573, avg_loss=0.07409]
[2018-11-23 05:17:41.739]  Step 254164  [20.653 sec/step, loss=0.07515, avg_loss=0.07417]
[2018-11-23 05:17:52.894]  Step 254165  [20.550 sec/step, loss=0.07226, avg_loss=0.07414]
[2018-11-23 05:18:05.728]  Step 254166  [20.459 sec/step, loss=0.07267, avg_loss=0.07410]
[2018-11-23 05:18:29.613]  Step 254167  [20.502 sec/step, loss=0.07559, avg_loss=0.07411]
[2018-11-23 05:18:40.593]  Generated 32 batches of size 32 in 10.139 sec
[2018-11-23 05:18:57.409]  Step 254168  [20.603 sec/step, loss=0.07616, avg_loss=0.07413]
[2018-11-23 05:19:16.197]  Step 254169  [20.590 sec/step, loss=0.07643, avg_loss=0.07414]
[2018-11-23 05:19:36.328]  Step 254170  [20.685 sec/step, loss=0.07545, avg_loss=0.07422]
[2018-11-23 05:19:46.628]  Step 254171  [20.560 sec/step, loss=0.06753, avg_loss=0.07414]
[2018-11-23 05:20:10.798]  Step 254172  [20.592 sec/step, loss=0.07643, avg_loss=0.07415]
[2018-11-23 05:20:28.954]  Step 254173  [20.543 sec/step, loss=0.07488, avg_loss=0.07414]
[2018-11-23 05:20:50.733]  Step 254174  [20.504 sec/step, loss=0.07596, avg_loss=0.07414]
[2018-11-23 05:21:15.006]  Step 254175  [20.560 sec/step, loss=0.07601, avg_loss=0.07415]
[2018-11-23 05:21:37.373]  Step 254176  [20.618 sec/step, loss=0.07641, avg_loss=0.07416]
[2018-11-23 05:21:59.314]  Step 254177  [20.605 sec/step, loss=0.07511, avg_loss=0.07416]
[2018-11-23 05:22:22.938]  Step 254178  [20.605 sec/step, loss=0.07554, avg_loss=0.07416]
[2018-11-23 05:22:40.638]  Step 254179  [20.551 sec/step, loss=0.07410, avg_loss=0.07414]
[2018-11-23 05:22:59.451]  Step 254180  [20.584 sec/step, loss=0.07427, avg_loss=0.07416]
[2018-11-23 05:23:21.169]  Step 254181  [20.562 sec/step, loss=0.07556, avg_loss=0.07415]
[2018-11-23 05:23:29.748]  Step 254182  [20.449 sec/step, loss=0.05518, avg_loss=0.07394]
[2018-11-23 05:23:51.192]  Step 254183  [20.448 sec/step, loss=0.07519, avg_loss=0.07394]
[2018-11-23 05:24:14.730]  Step 254184  [20.490 sec/step, loss=0.07586, avg_loss=0.07395]
[2018-11-23 05:24:30.263]  Step 254185  [20.408 sec/step, loss=0.07294, avg_loss=0.07393]
[2018-11-23 05:24:47.388]  Step 254186  [20.353 sec/step, loss=0.07488, avg_loss=0.07392]
[2018-11-23 05:25:07.654]  Step 254187  [20.317 sec/step, loss=0.07503, avg_loss=0.07391]
[2018-11-23 05:25:27.596]  Step 254188  [20.291 sec/step, loss=0.07471, avg_loss=0.07391]
[2018-11-23 05:25:47.310]  Step 254189  [20.310 sec/step, loss=0.07471, avg_loss=0.07391]
[2018-11-23 05:26:10.382]  Step 254190  [20.378 sec/step, loss=0.07542, avg_loss=0.07393]
[2018-11-23 05:26:35.123]  Step 254191  [20.522 sec/step, loss=0.07534, avg_loss=0.07402]
[2018-11-23 05:26:59.338]  Step 254192  [20.531 sec/step, loss=0.07616, avg_loss=0.07403]
[2018-11-23 05:27:22.895]  Step 254193  [20.683 sec/step, loss=0.07548, avg_loss=0.07421]
[2018-11-23 05:27:38.597]  Step 254194  [20.578 sec/step, loss=0.07196, avg_loss=0.07417]
[2018-11-23 05:28:01.134]  Step 254195  [20.591 sec/step, loss=0.07534, avg_loss=0.07417]
[2018-11-23 05:28:22.897]  Step 254196  [20.595 sec/step, loss=0.07596, avg_loss=0.07417]
[2018-11-23 05:28:34.909]  Step 254197  [20.481 sec/step, loss=0.07116, avg_loss=0.07413]
[2018-11-23 05:29:01.072]  Step 254198  [20.556 sec/step, loss=0.07554, avg_loss=0.07413]
[2018-11-23 05:29:23.511]  Step 254199  [20.558 sec/step, loss=0.07540, avg_loss=0.07413]
[2018-11-23 05:29:34.086]  Generated 32 batches of size 32 in 9.717 sec
[2018-11-23 05:29:49.178]  Step 254200  [20.615 sec/step, loss=0.07522, avg_loss=0.07412]
[2018-11-23 05:29:49.178]  Writing summary at step: 254200
[2018-11-23 05:30:20.007]  Step 254201  [20.585 sec/step, loss=0.06801, avg_loss=0.07407]
[2018-11-23 05:30:38.139]  Step 254202  [20.363 sec/step, loss=0.07612, avg_loss=0.07416]
[2018-11-23 05:30:59.342]  Step 254203  [20.358 sec/step, loss=0.07589, avg_loss=0.07416]
[2018-11-23 05:31:23.479]  Step 254204  [20.356 sec/step, loss=0.07611, avg_loss=0.07416]
[2018-11-23 05:31:37.411]  Step 254205  [20.231 sec/step, loss=0.07242, avg_loss=0.07413]
[2018-11-23 05:32:02.504]  Step 254206  [20.264 sec/step, loss=0.07613, avg_loss=0.07414]
[2018-11-23 05:32:44.819]  Step 254207  [20.447 sec/step, loss=0.06704, avg_loss=0.07405]
[2018-11-23 05:33:07.226]  Step 254208  [20.499 sec/step, loss=0.07526, avg_loss=0.07405]
[2018-11-23 05:33:23.094]  Step 254209  [20.544 sec/step, loss=0.07140, avg_loss=0.07405]
[2018-11-23 05:33:44.973]  Step 254210  [20.608 sec/step, loss=0.07513, avg_loss=0.07409]
[2018-11-23 05:34:00.541]  Step 254211  [20.504 sec/step, loss=0.07280, avg_loss=0.07406]
[2018-11-23 05:34:35.999]  Step 254212  [20.668 sec/step, loss=0.06659, avg_loss=0.07397]
[2018-11-23 05:34:49.785]  Step 254213  [20.603 sec/step, loss=0.07314, avg_loss=0.07394]
[2018-11-23 05:35:12.810]  Step 254214  [20.727 sec/step, loss=0.07491, avg_loss=0.07402]
[2018-11-23 05:35:36.268]  Step 254215  [20.722 sec/step, loss=0.07541, avg_loss=0.07401]
[2018-11-23 05:35:53.842]  Step 254216  [20.686 sec/step, loss=0.07467, avg_loss=0.07401]
[2018-11-23 05:36:14.932]  Step 254217  [20.643 sec/step, loss=0.07583, avg_loss=0.07401]
[2018-11-23 05:36:23.505]  Step 254218  [20.596 sec/step, loss=0.05573, avg_loss=0.07385]
[2018-11-23 05:36:45.710]  Step 254219  [20.633 sec/step, loss=0.07493, avg_loss=0.07384]
[2018-11-23 05:37:10.654]  Step 254220  [20.669 sec/step, loss=0.07504, avg_loss=0.07384]
[2018-11-23 05:37:22.945]  Step 254221  [20.558 sec/step, loss=0.07133, avg_loss=0.07379]
[2018-11-23 05:37:42.623]  Step 254222  [20.553 sec/step, loss=0.07423, avg_loss=0.07377]
[2018-11-23 05:38:07.704]  Step 254223  [20.625 sec/step, loss=0.07558, avg_loss=0.07379]
[2018-11-23 05:38:28.909]  Step 254224  [20.645 sec/step, loss=0.07548, avg_loss=0.07379]
[2018-11-23 05:38:53.051]  Step 254225  [20.671 sec/step, loss=0.07616, avg_loss=0.07379]
[2018-11-23 05:39:12.323]  Step 254226  [20.645 sec/step, loss=0.07535, avg_loss=0.07379]
[2018-11-23 05:39:22.866]  Step 254227  [20.664 sec/step, loss=0.06723, avg_loss=0.07391]
[2018-11-23 05:39:41.680]  Step 254228  [20.589 sec/step, loss=0.07509, avg_loss=0.07391]
[2018-11-23 05:40:05.893]  Step 254229  [20.605 sec/step, loss=0.07539, avg_loss=0.07390]
[2018-11-23 05:40:30.019]  Step 254230  [20.644 sec/step, loss=0.07560, avg_loss=0.07391]
[2018-11-23 05:40:39.396]  Generated 32 batches of size 32 in 8.609 sec
[2018-11-23 05:40:49.851]  Step 254231  [20.703 sec/step, loss=0.07553, avg_loss=0.07393]
[2018-11-23 05:41:11.183]  Step 254232  [20.720 sec/step, loss=0.07485, avg_loss=0.07393]
[2018-11-23 05:41:31.336]  Step 254233  [20.759 sec/step, loss=0.07527, avg_loss=0.07395]
[2018-11-23 05:41:53.042]  Step 254234  [20.740 sec/step, loss=0.07543, avg_loss=0.07395]
[2018-11-23 05:42:19.087]  Step 254235  [20.729 sec/step, loss=0.07531, avg_loss=0.07395]
[2018-11-23 05:42:41.796]  Step 254236  [20.568 sec/step, loss=0.07561, avg_loss=0.07403]
[2018-11-23 05:43:05.410]  Step 254237  [20.631 sec/step, loss=0.07595, avg_loss=0.07406]
[2018-11-23 05:43:22.546]  Step 254238  [20.559 sec/step, loss=0.07429, avg_loss=0.07405]
[2018-11-23 05:43:42.646]  Step 254239  [20.563 sec/step, loss=0.07575, avg_loss=0.07406]
[2018-11-23 05:44:06.345]  Step 254240  [20.630 sec/step, loss=0.07490, avg_loss=0.07406]
[2018-11-23 05:44:21.578]  Step 254241  [20.567 sec/step, loss=0.07271, avg_loss=0.07402]
[2018-11-23 05:44:40.395]  Step 254242  [20.510 sec/step, loss=0.07468, avg_loss=0.07401]
[2018-11-23 05:45:02.223]  Step 254243  [20.491 sec/step, loss=0.07469, avg_loss=0.07400]
[2018-11-23 05:45:12.845]  Step 254244  [20.378 sec/step, loss=0.06683, avg_loss=0.07391]
[2018-11-23 05:45:37.467]  Step 254245  [20.383 sec/step, loss=0.07575, avg_loss=0.07391]
[2018-11-23 05:46:02.389]  Step 254246  [20.371 sec/step, loss=0.07520, avg_loss=0.07392]
[2018-11-23 05:46:24.767]  Step 254247  [20.374 sec/step, loss=0.07619, avg_loss=0.07391]
[2018-11-23 05:46:43.112]  Step 254248  [20.356 sec/step, loss=0.07523, avg_loss=0.07392]
[2018-11-23 05:47:05.638]  Step 254249  [20.368 sec/step, loss=0.07561, avg_loss=0.07392]
[2018-11-23 05:47:31.473]  Step 254250  [20.465 sec/step, loss=0.07486, avg_loss=0.07392]
[2018-11-23 05:47:31.473]  Writing summary at step: 254250
[2018-11-23 05:48:14.178]  Step 254251  [20.594 sec/step, loss=0.07592, avg_loss=0.07412]
[2018-11-23 05:48:51.438]  Step 254252  [20.823 sec/step, loss=0.06689, avg_loss=0.07407]
[2018-11-23 05:49:08.851]  Step 254253  [20.755 sec/step, loss=0.07423, avg_loss=0.07405]
[2018-11-23 05:49:31.730]  Step 254254  [20.790 sec/step, loss=0.07547, avg_loss=0.07406]
[2018-11-23 05:49:56.274]  Step 254255  [20.848 sec/step, loss=0.07540, avg_loss=0.07406]
[2018-11-23 05:50:17.685]  Step 254256  [20.826 sec/step, loss=0.07541, avg_loss=0.07405]
[2018-11-23 05:50:37.149]  Step 254257  [20.810 sec/step, loss=0.07418, avg_loss=0.07404]
[2018-11-23 05:50:56.532]  Step 254258  [20.777 sec/step, loss=0.07502, avg_loss=0.07403]
[2018-11-23 05:51:18.028]  Step 254259  [20.822 sec/step, loss=0.07462, avg_loss=0.07404]
[2018-11-23 05:51:29.449]  Step 254260  [20.765 sec/step, loss=0.07172, avg_loss=0.07401]
[2018-11-23 05:51:50.197]  Step 254261  [20.739 sec/step, loss=0.07494, avg_loss=0.07401]
[2018-11-23 05:51:59.453]  Generated 32 batches of size 32 in 8.329 sec
[2018-11-23 05:52:15.349]  Step 254262  [20.757 sec/step, loss=0.07527, avg_loss=0.07400]
[2018-11-23 05:52:39.367]  Step 254263  [20.779 sec/step, loss=0.07577, avg_loss=0.07400]
[2018-11-23 05:52:59.381]  Step 254264  [20.761 sec/step, loss=0.07565, avg_loss=0.07401]
[2018-11-23 05:53:15.160]  Step 254265  [20.807 sec/step, loss=0.07137, avg_loss=0.07400]
[2018-11-23 05:53:23.620]  Step 254266  [20.764 sec/step, loss=0.05641, avg_loss=0.07384]
[2018-11-23 05:53:40.454]  Step 254267  [20.693 sec/step, loss=0.07411, avg_loss=0.07382]
[2018-11-23 05:53:54.058]  Step 254268  [20.551 sec/step, loss=0.07245, avg_loss=0.07379]
[2018-11-23 05:54:16.204]  Step 254269  [20.585 sec/step, loss=0.07536, avg_loss=0.07378]
[2018-11-23 05:54:38.014]  Step 254270  [20.602 sec/step, loss=0.07528, avg_loss=0.07377]
[2018-11-23 05:55:02.295]  Step 254271  [20.741 sec/step, loss=0.07536, avg_loss=0.07385]
[2018-11-23 05:55:25.011]  Step 254272  [20.727 sec/step, loss=0.07540, avg_loss=0.07384]
[2018-11-23 05:55:50.143]  Step 254273  [20.797 sec/step, loss=0.07576, avg_loss=0.07385]
[2018-11-23 05:56:10.518]  Step 254274  [20.783 sec/step, loss=0.07502, avg_loss=0.07384]
[2018-11-23 05:56:25.757]  Step 254275  [20.692 sec/step, loss=0.07265, avg_loss=0.07381]
[2018-11-23 05:56:49.966]  Step 254276  [20.711 sec/step, loss=0.07565, avg_loss=0.07380]
[2018-11-23 05:57:14.789]  Step 254277  [20.739 sec/step, loss=0.07565, avg_loss=0.07381]
[2018-11-23 05:57:35.630]  Step 254278  [20.712 sec/step, loss=0.07516, avg_loss=0.07380]
[2018-11-23 05:57:54.487]  Step 254279  [20.723 sec/step, loss=0.07485, avg_loss=0.07381]
[2018-11-23 05:58:10.025]  Step 254280  [20.690 sec/step, loss=0.07306, avg_loss=0.07380]
[2018-11-23 05:58:20.609]  Step 254281  [20.579 sec/step, loss=0.06714, avg_loss=0.07371]
[2018-11-23 05:58:47.969]  Step 254282  [20.767 sec/step, loss=0.07515, avg_loss=0.07391]
[2018-11-23 05:59:06.907]  Step 254283  [20.742 sec/step, loss=0.07400, avg_loss=0.07390]
[2018-11-23 05:59:27.441]  Step 254284  [20.712 sec/step, loss=0.07479, avg_loss=0.07389]
[2018-11-23 05:59:46.075]  Step 254285  [20.743 sec/step, loss=0.07489, avg_loss=0.07391]
[2018-11-23 06:00:05.869]  Step 254286  [20.770 sec/step, loss=0.07411, avg_loss=0.07390]
[2018-11-23 06:00:25.650]  Step 254287  [20.765 sec/step, loss=0.07540, avg_loss=0.07391]
[2018-11-23 06:00:49.441]  Step 254288  [20.803 sec/step, loss=0.07583, avg_loss=0.07392]
[2018-11-23 06:01:11.333]  Step 254289  [20.825 sec/step, loss=0.07521, avg_loss=0.07392]
[2018-11-23 06:01:33.448]  Step 254290  [20.815 sec/step, loss=0.07586, avg_loss=0.07393]
[2018-11-23 06:01:51.840]  Step 254291  [20.752 sec/step, loss=0.07496, avg_loss=0.07392]
[2018-11-23 06:02:13.204]  Step 254292  [20.723 sec/step, loss=0.07570, avg_loss=0.07392]
[2018-11-23 06:02:36.879]  Step 254293  [20.725 sec/step, loss=0.07527, avg_loss=0.07392]
[2018-11-23 06:02:46.834]  Generated 32 batches of size 32 in 9.219 sec
[2018-11-23 06:03:03.421]  Step 254294  [20.833 sec/step, loss=0.07551, avg_loss=0.07395]
[2018-11-23 06:03:17.430]  Step 254295  [20.748 sec/step, loss=0.07276, avg_loss=0.07393]
[2018-11-23 06:03:38.921]  Step 254296  [20.745 sec/step, loss=0.07518, avg_loss=0.07392]
[2018-11-23 06:03:56.105]  Step 254297  [20.797 sec/step, loss=0.07444, avg_loss=0.07395]
[2018-11-23 06:04:20.063]  Step 254298  [20.775 sec/step, loss=0.07492, avg_loss=0.07394]
[2018-11-23 06:04:42.124]  Step 254299  [20.771 sec/step, loss=0.07524, avg_loss=0.07394]
[2018-11-23 06:05:19.333]  Step 254300  [20.886 sec/step, loss=0.06692, avg_loss=0.07386]
[2018-11-23 06:05:19.334]  Writing summary at step: 254300
[2018-11-23 06:05:40.941]  Step 254301  [20.872 sec/step, loss=0.05530, avg_loss=0.07373]
[2018-11-23 06:06:04.897]  Step 254302  [20.930 sec/step, loss=0.07607, avg_loss=0.07373]
[2018-11-23 06:06:29.258]  Step 254303  [20.962 sec/step, loss=0.07507, avg_loss=0.07372]
[2018-11-23 06:06:51.939]  Step 254304  [20.947 sec/step, loss=0.07503, avg_loss=0.07371]
[2018-11-23 06:07:04.240]  Step 254305  [20.931 sec/step, loss=0.06621, avg_loss=0.07365]
[2018-11-23 06:07:14.318]  Step 254306  [20.781 sec/step, loss=0.05667, avg_loss=0.07346]
[2018-11-23 06:07:40.092]  Step 254307  [20.615 sec/step, loss=0.07605, avg_loss=0.07355]
[2018-11-23 06:07:58.601]  Step 254308  [20.576 sec/step, loss=0.07593, avg_loss=0.07355]
[2018-11-23 06:08:20.510]  Step 254309  [20.637 sec/step, loss=0.07514, avg_loss=0.07359]
[2018-11-23 06:08:45.575]  Step 254310  [20.668 sec/step, loss=0.07600, avg_loss=0.07360]
[2018-11-23 06:08:59.648]  Step 254311  [20.653 sec/step, loss=0.07171, avg_loss=0.07359]
[2018-11-23 06:09:19.481]  Step 254312  [20.497 sec/step, loss=0.07431, avg_loss=0.07367]
[2018-11-23 06:09:40.258]  Step 254313  [20.567 sec/step, loss=0.07480, avg_loss=0.07368]
[2018-11-23 06:10:02.192]  Step 254314  [20.556 sec/step, loss=0.07534, avg_loss=0.07369]
[2018-11-23 06:10:22.192]  Step 254315  [20.522 sec/step, loss=0.07501, avg_loss=0.07368]
[2018-11-23 06:10:40.617]  Step 254316  [20.530 sec/step, loss=0.07416, avg_loss=0.07368]
[2018-11-23 06:11:07.920]  Step 254317  [20.592 sec/step, loss=0.07503, avg_loss=0.07367]
[2018-11-23 06:11:29.585]  Step 254318  [20.723 sec/step, loss=0.07604, avg_loss=0.07387]
[2018-11-23 06:12:06.266]  Step 254319  [20.868 sec/step, loss=0.06673, avg_loss=0.07379]
[2018-11-23 06:12:17.924]  Step 254320  [20.735 sec/step, loss=0.07086, avg_loss=0.07375]
[2018-11-23 06:12:42.299]  Step 254321  [20.856 sec/step, loss=0.07491, avg_loss=0.07378]
[2018-11-23 06:13:01.321]  Step 254322  [20.849 sec/step, loss=0.07462, avg_loss=0.07379]
[2018-11-23 06:13:23.910]  Step 254323  [20.824 sec/step, loss=0.07527, avg_loss=0.07378]
[2018-11-23 06:13:50.138]  Step 254324  [20.875 sec/step, loss=0.07510, avg_loss=0.07378]
[2018-11-23 06:13:59.340]  Generated 32 batches of size 32 in 8.437 sec
[2018-11-23 06:14:13.400]  Step 254325  [20.866 sec/step, loss=0.07548, avg_loss=0.07377]
[2018-11-23 06:14:36.670]  Step 254326  [20.906 sec/step, loss=0.07534, avg_loss=0.07377]
[2018-11-23 06:14:56.865]  Step 254327  [21.002 sec/step, loss=0.07505, avg_loss=0.07385]
[2018-11-23 06:15:19.552]  Step 254328  [21.041 sec/step, loss=0.07434, avg_loss=0.07384]
[2018-11-23 06:15:34.707]  Step 254329  [20.951 sec/step, loss=0.07137, avg_loss=0.07380]
[2018-11-23 06:15:58.966]  Step 254330  [20.952 sec/step, loss=0.07560, avg_loss=0.07380]
[2018-11-23 06:16:22.995]  Step 254331  [20.994 sec/step, loss=0.07508, avg_loss=0.07380]
[2018-11-23 06:16:40.116]  Step 254332  [20.952 sec/step, loss=0.07435, avg_loss=0.07380]
[2018-11-23 06:16:56.291]  Step 254333  [20.912 sec/step, loss=0.07262, avg_loss=0.07377]
[2018-11-23 06:17:19.448]  Step 254334  [20.926 sec/step, loss=0.07518, avg_loss=0.07377]
[2018-11-23 06:17:43.002]  Step 254335  [20.902 sec/step, loss=0.07568, avg_loss=0.07377]
[2018-11-23 06:17:58.689]  Step 254336  [20.831 sec/step, loss=0.07120, avg_loss=0.07373]
[2018-11-23 06:18:23.703]  Step 254337  [20.845 sec/step, loss=0.07560, avg_loss=0.07372]
[2018-11-23 06:18:47.551]  Step 254338  [20.912 sec/step, loss=0.07486, avg_loss=0.07373]
[2018-11-23 06:19:11.075]  Step 254339  [20.947 sec/step, loss=0.07439, avg_loss=0.07371]
[2018-11-23 06:19:28.182]  Step 254340  [20.881 sec/step, loss=0.07409, avg_loss=0.07371]
[2018-11-23 06:19:49.926]  Step 254341  [20.946 sec/step, loss=0.07427, avg_loss=0.07372]
[2018-11-23 06:20:09.409]  Step 254342  [20.953 sec/step, loss=0.07413, avg_loss=0.07372]
[2018-11-23 06:20:47.689]  Step 254343  [21.117 sec/step, loss=0.06661, avg_loss=0.07364]
[2018-11-23 06:21:05.257]  Step 254344  [21.187 sec/step, loss=0.07399, avg_loss=0.07371]
[2018-11-23 06:21:24.683]  Step 254345  [21.135 sec/step, loss=0.07517, avg_loss=0.07370]
[2018-11-23 06:21:46.307]  Step 254346  [21.102 sec/step, loss=0.07484, avg_loss=0.07370]
[2018-11-23 06:22:10.559]  Step 254347  [21.120 sec/step, loss=0.07517, avg_loss=0.07369]
[2018-11-23 06:22:31.239]  Step 254348  [21.144 sec/step, loss=0.07491, avg_loss=0.07368]
[2018-11-23 06:22:46.850]  Step 254349  [21.075 sec/step, loss=0.07271, avg_loss=0.07366]
[2018-11-23 06:23:10.572]  Step 254350  [21.053 sec/step, loss=0.07557, avg_loss=0.07366]
[2018-11-23 06:23:10.572]  Writing summary at step: 254350
[2018-11-23 06:23:50.966]  Step 254351  [20.976 sec/step, loss=0.07271, avg_loss=0.07363]
[2018-11-23 06:24:12.682]  Step 254352  [20.820 sec/step, loss=0.07479, avg_loss=0.07371]
[2018-11-23 06:24:23.155]  Step 254353  [20.751 sec/step, loss=0.06753, avg_loss=0.07364]
[2018-11-23 06:24:31.791]  Step 254354  [20.608 sec/step, loss=0.05492, avg_loss=0.07344]
[2018-11-23 06:24:51.962]  Step 254355  [20.565 sec/step, loss=0.07537, avg_loss=0.07344]
[2018-11-23 06:25:01.009]  Generated 32 batches of size 32 in 8.239 sec
[2018-11-23 06:25:14.375]  Step 254356  [20.575 sec/step, loss=0.07549, avg_loss=0.07344]
[2018-11-23 06:25:37.414]  Step 254357  [20.610 sec/step, loss=0.07570, avg_loss=0.07345]
[2018-11-23 06:26:01.994]  Step 254358  [20.662 sec/step, loss=0.07518, avg_loss=0.07345]
[2018-11-23 06:26:25.079]  Step 254359  [20.678 sec/step, loss=0.07554, avg_loss=0.07346]
[2018-11-23 06:26:45.533]  Step 254360  [20.769 sec/step, loss=0.07479, avg_loss=0.07349]
[2018-11-23 06:26:57.719]  Step 254361  [20.683 sec/step, loss=0.07085, avg_loss=0.07345]
[2018-11-23 06:27:16.345]  Step 254362  [20.618 sec/step, loss=0.07478, avg_loss=0.07345]
[2018-11-23 06:27:34.700]  Step 254363  [20.561 sec/step, loss=0.07505, avg_loss=0.07344]
[2018-11-23 06:27:55.914]  Step 254364  [20.573 sec/step, loss=0.07565, avg_loss=0.07344]
[2018-11-23 06:28:17.270]  Step 254365  [20.629 sec/step, loss=0.07510, avg_loss=0.07348]
[2018-11-23 06:28:35.745]  Step 254366  [20.729 sec/step, loss=0.07447, avg_loss=0.07366]
[2018-11-23 06:28:57.154]  Step 254367  [20.775 sec/step, loss=0.07480, avg_loss=0.07367]
[2018-11-23 06:29:05.777]  Step 254368  [20.725 sec/step, loss=0.05645, avg_loss=0.07351]
[2018-11-23 06:29:25.508]  Step 254369  [20.701 sec/step, loss=0.07555, avg_loss=0.07351]
[2018-11-23 06:29:48.125]  Step 254370  [20.709 sec/step, loss=0.07528, avg_loss=0.07351]
[2018-11-23 06:30:12.153]  Step 254371  [20.706 sec/step, loss=0.07522, avg_loss=0.07351]
[2018-11-23 06:30:36.093]  Step 254372  [20.719 sec/step, loss=0.07641, avg_loss=0.07352]
[2018-11-23 06:30:57.747]  Step 254373  [20.684 sec/step, loss=0.07573, avg_loss=0.07352]
[2018-11-23 06:31:17.787]  Step 254374  [20.680 sec/step, loss=0.07528, avg_loss=0.07352]
[2018-11-23 06:31:39.512]  Step 254375  [20.745 sec/step, loss=0.07525, avg_loss=0.07354]
[2018-11-23 06:31:59.133]  Step 254376  [20.699 sec/step, loss=0.07445, avg_loss=0.07353]
[2018-11-23 06:32:21.283]  Step 254377  [20.673 sec/step, loss=0.07508, avg_loss=0.07353]
[2018-11-23 06:32:43.412]  Step 254378  [20.686 sec/step, loss=0.07488, avg_loss=0.07352]
[2018-11-23 06:32:55.400]  Step 254379  [20.617 sec/step, loss=0.07127, avg_loss=0.07349]
[2018-11-23 06:33:19.244]  Step 254380  [20.700 sec/step, loss=0.07608, avg_loss=0.07352]
[2018-11-23 06:33:38.712]  Step 254381  [20.789 sec/step, loss=0.07438, avg_loss=0.07359]
[2018-11-23 06:33:56.929]  Step 254382  [20.697 sec/step, loss=0.07580, avg_loss=0.07360]
[2018-11-23 06:34:14.436]  Step 254383  [20.683 sec/step, loss=0.07381, avg_loss=0.07360]
[2018-11-23 06:34:31.273]  Step 254384  [20.646 sec/step, loss=0.07445, avg_loss=0.07359]
[2018-11-23 06:34:54.570]  Step 254385  [20.693 sec/step, loss=0.07512, avg_loss=0.07359]
[2018-11-23 06:35:20.200]  Step 254386  [20.751 sec/step, loss=0.07490, avg_loss=0.07360]
[2018-11-23 06:35:35.828]  Step 254387  [20.710 sec/step, loss=0.07166, avg_loss=0.07356]
[2018-11-23 06:35:45.779]  Generated 32 batches of size 32 in 9.215 sec
[2018-11-23 06:36:02.215]  Step 254388  [20.735 sec/step, loss=0.07566, avg_loss=0.07356]
[2018-11-23 06:36:16.036]  Step 254389  [20.655 sec/step, loss=0.07222, avg_loss=0.07353]
[2018-11-23 06:36:39.416]  Step 254390  [20.667 sec/step, loss=0.07534, avg_loss=0.07353]
[2018-11-23 06:37:03.358]  Step 254391  [20.723 sec/step, loss=0.07511, avg_loss=0.07353]
[2018-11-23 06:37:19.559]  Step 254392  [20.671 sec/step, loss=0.07264, avg_loss=0.07350]
[2018-11-23 06:37:41.158]  Step 254393  [20.651 sec/step, loss=0.07576, avg_loss=0.07350]
[2018-11-23 06:37:51.425]  Step 254394  [20.488 sec/step, loss=0.06839, avg_loss=0.07343]
[2018-11-23 06:38:16.387]  Step 254395  [20.597 sec/step, loss=0.07627, avg_loss=0.07347]
[2018-11-23 06:38:57.936]  Step 254396  [20.798 sec/step, loss=0.06650, avg_loss=0.07338]
[2018-11-23 06:39:16.273]  Step 254397  [20.809 sec/step, loss=0.07466, avg_loss=0.07338]
[2018-11-23 06:39:39.250]  Step 254398  [20.800 sec/step, loss=0.07550, avg_loss=0.07339]
[2018-11-23 06:40:03.535]  Step 254399  [20.822 sec/step, loss=0.07551, avg_loss=0.07339]
[2018-11-23 06:40:24.074]  Step 254400  [20.655 sec/step, loss=0.07442, avg_loss=0.07347]
[2018-11-23 06:40:24.074]  Writing summary at step: 254400
[2018-11-23 06:41:05.101]  Step 254401  [20.838 sec/step, loss=0.07479, avg_loss=0.07366]
[2018-11-23 06:41:27.037]  Step 254402  [20.817 sec/step, loss=0.07558, avg_loss=0.07366]
[2018-11-23 06:41:48.741]  Step 254403  [20.791 sec/step, loss=0.07452, avg_loss=0.07365]
[2018-11-23 06:42:09.018]  Step 254404  [20.767 sec/step, loss=0.07511, avg_loss=0.07365]
[2018-11-23 06:42:19.413]  Step 254405  [20.748 sec/step, loss=0.06644, avg_loss=0.07365]
[2018-11-23 06:42:57.820]  Step 254406  [21.031 sec/step, loss=0.06647, avg_loss=0.07375]
[2018-11-23 06:43:21.310]  Step 254407  [21.008 sec/step, loss=0.07471, avg_loss=0.07374]
[2018-11-23 06:43:33.038]  Step 254408  [20.940 sec/step, loss=0.07047, avg_loss=0.07368]
[2018-11-23 06:43:55.612]  Step 254409  [20.947 sec/step, loss=0.07582, avg_loss=0.07369]
[2018-11-23 06:44:13.101]  Step 254410  [20.871 sec/step, loss=0.07398, avg_loss=0.07367]
[2018-11-23 06:44:28.529]  Step 254411  [20.885 sec/step, loss=0.07152, avg_loss=0.07367]
[2018-11-23 06:44:50.530]  Step 254412  [20.907 sec/step, loss=0.07486, avg_loss=0.07367]
[2018-11-23 06:45:10.246]  Step 254413  [20.896 sec/step, loss=0.07437, avg_loss=0.07367]
[2018-11-23 06:45:28.909]  Step 254414  [20.863 sec/step, loss=0.07467, avg_loss=0.07366]
[2018-11-23 06:45:45.455]  Step 254415  [20.829 sec/step, loss=0.07271, avg_loss=0.07364]
[2018-11-23 06:46:09.399]  Step 254416  [20.884 sec/step, loss=0.07491, avg_loss=0.07365]
[2018-11-23 06:46:30.801]  Step 254417  [20.825 sec/step, loss=0.07595, avg_loss=0.07366]
[2018-11-23 06:46:39.212]  Step 254418  [20.692 sec/step, loss=0.05609, avg_loss=0.07346]
[2018-11-23 06:46:48.750]  Generated 32 batches of size 32 in 8.669 sec
[2018-11-23 06:47:05.400]  Step 254419  [20.587 sec/step, loss=0.07585, avg_loss=0.07355]
[2018-11-23 06:47:27.943]  Step 254420  [20.696 sec/step, loss=0.07551, avg_loss=0.07360]
[2018-11-23 06:47:49.674]  Step 254421  [20.670 sec/step, loss=0.07538, avg_loss=0.07360]
[2018-11-23 06:48:11.305]  Step 254422  [20.696 sec/step, loss=0.07547, avg_loss=0.07361]
[2018-11-23 06:48:35.707]  Step 254423  [20.714 sec/step, loss=0.07522, avg_loss=0.07361]
[2018-11-23 06:48:55.886]  Step 254424  [20.654 sec/step, loss=0.07560, avg_loss=0.07361]
[2018-11-23 06:49:18.592]  Step 254425  [20.648 sec/step, loss=0.07538, avg_loss=0.07361]
[2018-11-23 06:49:42.541]  Step 254426  [20.655 sec/step, loss=0.07621, avg_loss=0.07362]
[2018-11-23 06:50:01.231]  Step 254427  [20.640 sec/step, loss=0.07546, avg_loss=0.07362]
[2018-11-23 06:50:26.283]  Step 254428  [20.663 sec/step, loss=0.07560, avg_loss=0.07364]
[2018-11-23 06:50:42.503]  Step 254429  [20.674 sec/step, loss=0.07164, avg_loss=0.07364]
[2018-11-23 06:50:59.972]  Step 254430  [20.606 sec/step, loss=0.07479, avg_loss=0.07363]
[2018-11-23 06:51:19.489]  Step 254431  [20.561 sec/step, loss=0.07425, avg_loss=0.07362]
[2018-11-23 06:51:40.184]  Step 254432  [20.597 sec/step, loss=0.07527, avg_loss=0.07363]
[2018-11-23 06:52:02.712]  Step 254433  [20.660 sec/step, loss=0.07578, avg_loss=0.07366]
[2018-11-23 06:52:28.367]  Step 254434  [20.685 sec/step, loss=0.07573, avg_loss=0.07367]
[2018-11-23 06:52:49.992]  Step 254435  [20.666 sec/step, loss=0.07543, avg_loss=0.07367]
[2018-11-23 06:53:13.541]  Step 254436  [20.745 sec/step, loss=0.07479, avg_loss=0.07370]
[2018-11-23 06:53:36.715]  Step 254437  [20.726 sec/step, loss=0.07678, avg_loss=0.07372]
[2018-11-23 06:53:59.957]  Step 254438  [20.720 sec/step, loss=0.07550, avg_loss=0.07372]
[2018-11-23 06:54:23.475]  Step 254439  [20.720 sec/step, loss=0.07572, avg_loss=0.07374]
[2018-11-23 06:54:47.434]  Step 254440  [20.789 sec/step, loss=0.07561, avg_loss=0.07375]
[2018-11-23 06:55:11.915]  Step 254441  [20.816 sec/step, loss=0.07510, avg_loss=0.07376]
[2018-11-23 06:55:27.295]  Step 254442  [20.775 sec/step, loss=0.07279, avg_loss=0.07375]
[2018-11-23 06:55:45.894]  Step 254443  [20.578 sec/step, loss=0.07560, avg_loss=0.07384]
[2018-11-23 06:56:09.431]  Step 254444  [20.638 sec/step, loss=0.07573, avg_loss=0.07385]
[2018-11-23 06:56:31.042]  Step 254445  [20.660 sec/step, loss=0.07542, avg_loss=0.07386]
[2018-11-23 06:56:51.419]  Step 254446  [20.647 sec/step, loss=0.07468, avg_loss=0.07385]
[2018-11-23 06:57:12.873]  Step 254447  [20.619 sec/step, loss=0.07505, avg_loss=0.07385]
[2018-11-23 06:57:35.707]  Step 254448  [20.641 sec/step, loss=0.07485, avg_loss=0.07385]
[2018-11-23 06:57:46.185]  Step 254449  [20.589 sec/step, loss=0.06642, avg_loss=0.07379]
[2018-11-23 06:58:06.567]  Step 254450  [20.556 sec/step, loss=0.07496, avg_loss=0.07378]
[2018-11-23 06:58:06.567]  Writing summary at step: 254450
[2018-11-23 06:58:17.316]  Generated 32 batches of size 32 in 9.861 sec
[2018-11-23 06:59:12.899]  Step 254451  [20.612 sec/step, loss=0.07448, avg_loss=0.07380]
[2018-11-23 06:59:31.136]  Step 254452  [20.577 sec/step, loss=0.07376, avg_loss=0.07379]
[2018-11-23 06:59:53.799]  Step 254453  [20.699 sec/step, loss=0.07468, avg_loss=0.07386]
[2018-11-23 07:00:17.986]  Step 254454  [20.855 sec/step, loss=0.07574, avg_loss=0.07407]
[2018-11-23 07:00:26.460]  Step 254455  [20.738 sec/step, loss=0.05706, avg_loss=0.07389]
[2018-11-23 07:00:40.825]  Step 254456  [20.657 sec/step, loss=0.07252, avg_loss=0.07386]
[2018-11-23 07:01:01.502]  Step 254457  [20.634 sec/step, loss=0.07567, avg_loss=0.07386]
[2018-11-23 07:01:14.425]  Step 254458  [20.517 sec/step, loss=0.07081, avg_loss=0.07381]
[2018-11-23 07:01:34.999]  Step 254459  [20.492 sec/step, loss=0.07458, avg_loss=0.07380]
[2018-11-23 07:01:52.116]  Step 254460  [20.459 sec/step, loss=0.07430, avg_loss=0.07380]
[2018-11-23 07:02:12.488]  Step 254461  [20.541 sec/step, loss=0.07567, avg_loss=0.07385]
[2018-11-23 07:02:35.807]  Step 254462  [20.588 sec/step, loss=0.07592, avg_loss=0.07386]
[2018-11-23 07:02:46.372]  Step 254463  [20.510 sec/step, loss=0.06895, avg_loss=0.07380]
[2018-11-23 07:03:09.038]  Step 254464  [20.524 sec/step, loss=0.07557, avg_loss=0.07380]
[2018-11-23 07:03:33.327]  Step 254465  [20.554 sec/step, loss=0.07526, avg_loss=0.07380]
[2018-11-23 07:04:10.631]  Step 254466  [20.742 sec/step, loss=0.06638, avg_loss=0.07372]
[2018-11-23 07:04:35.021]  Step 254467  [20.772 sec/step, loss=0.07511, avg_loss=0.07372]
[2018-11-23 07:04:57.791]  Step 254468  [20.913 sec/step, loss=0.07479, avg_loss=0.07390]
[2018-11-23 07:05:17.670]  Step 254469  [20.915 sec/step, loss=0.07438, avg_loss=0.07389]
[2018-11-23 07:05:38.560]  Step 254470  [20.897 sec/step, loss=0.07552, avg_loss=0.07389]
[2018-11-23 07:05:58.060]  Step 254471  [20.852 sec/step, loss=0.07486, avg_loss=0.07389]
[2018-11-23 07:06:16.769]  Step 254472  [20.800 sec/step, loss=0.07506, avg_loss=0.07388]
[2018-11-23 07:06:32.289]  Step 254473  [20.738 sec/step, loss=0.07277, avg_loss=0.07385]
[2018-11-23 07:06:57.708]  Step 254474  [20.792 sec/step, loss=0.07590, avg_loss=0.07385]
[2018-11-23 07:07:20.837]  Step 254475  [20.806 sec/step, loss=0.07497, avg_loss=0.07385]
[2018-11-23 07:07:34.825]  Step 254476  [20.750 sec/step, loss=0.07208, avg_loss=0.07383]
[2018-11-23 07:07:47.332]  Step 254477  [20.653 sec/step, loss=0.07104, avg_loss=0.07379]
[2018-11-23 07:08:14.203]  Step 254478  [20.701 sec/step, loss=0.07578, avg_loss=0.07380]
[2018-11-23 07:08:35.747]  Step 254479  [20.796 sec/step, loss=0.07492, avg_loss=0.07383]
[2018-11-23 07:09:00.215]  Step 254480  [20.803 sec/step, loss=0.07492, avg_loss=0.07382]
[2018-11-23 07:09:22.640]  Step 254481  [20.832 sec/step, loss=0.07457, avg_loss=0.07382]
[2018-11-23 07:09:31.676]  Generated 32 batches of size 32 in 8.351 sec
[2018-11-23 07:09:45.279]  Step 254482  [20.876 sec/step, loss=0.07562, avg_loss=0.07382]
[2018-11-23 07:10:08.737]  Step 254483  [20.936 sec/step, loss=0.07479, avg_loss=0.07383]
[2018-11-23 07:10:32.810]  Step 254484  [21.008 sec/step, loss=0.07567, avg_loss=0.07384]
[2018-11-23 07:10:51.705]  Step 254485  [20.964 sec/step, loss=0.07412, avg_loss=0.07383]
[2018-11-23 07:11:11.091]  Step 254486  [20.902 sec/step, loss=0.07439, avg_loss=0.07383]
[2018-11-23 07:11:37.082]  Step 254487  [21.006 sec/step, loss=0.07463, avg_loss=0.07386]
[2018-11-23 07:11:58.676]  Step 254488  [20.958 sec/step, loss=0.07536, avg_loss=0.07385]
[2018-11-23 07:12:14.475]  Step 254489  [20.977 sec/step, loss=0.07172, avg_loss=0.07385]
[2018-11-23 07:12:23.149]  Step 254490  [20.830 sec/step, loss=0.05571, avg_loss=0.07365]
[2018-11-23 07:12:42.372]  Step 254491  [20.783 sec/step, loss=0.07500, avg_loss=0.07365]
[2018-11-23 07:13:05.529]  Step 254492  [20.853 sec/step, loss=0.07541, avg_loss=0.07368]
[2018-11-23 07:13:29.193]  Step 254493  [20.873 sec/step, loss=0.07466, avg_loss=0.07367]
[2018-11-23 07:13:53.313]  Step 254494  [21.012 sec/step, loss=0.07553, avg_loss=0.07374]
[2018-11-23 07:14:29.636]  Step 254495  [21.125 sec/step, loss=0.06634, avg_loss=0.07364]
[2018-11-23 07:14:52.178]  Step 254496  [20.935 sec/step, loss=0.07424, avg_loss=0.07372]
[2018-11-23 07:15:02.516]  Step 254497  [20.855 sec/step, loss=0.06570, avg_loss=0.07363]
[2018-11-23 07:15:20.921]  Step 254498  [20.810 sec/step, loss=0.07497, avg_loss=0.07362]
[2018-11-23 07:15:32.988]  Step 254499  [20.687 sec/step, loss=0.07059, avg_loss=0.07357]
[2018-11-23 07:15:54.722]  Step 254500  [20.699 sec/step, loss=0.07488, avg_loss=0.07358]
[2018-11-23 07:15:54.722]  Writing summary at step: 254500
[2018-11-23 07:16:19.487]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-254500
[2018-11-23 07:16:22.442]  Saving audio and alignment...
[2018-11-23 07:16:33.677]  Input: his recognition that {JH EY1 N} eyre was {K EH1 R IH0 K T ER0 AY2 Z D} by reality - deep, significant reality {T AH1 CH T} charlotte bronte to the quick.~_______________________________________________
[2018-11-23 07:16:58.246]  Step 254501  [20.673 sec/step, loss=0.07502, avg_loss=0.07358]
[2018-11-23 07:17:06.487]  Step 254502  [20.536 sec/step, loss=0.05628, avg_loss=0.07339]
[2018-11-23 07:17:23.720]  Step 254503  [20.491 sec/step, loss=0.07444, avg_loss=0.07339]
[2018-11-23 07:17:45.773]  Step 254504  [20.509 sec/step, loss=0.07473, avg_loss=0.07338]
[2018-11-23 07:18:01.377]  Step 254505  [20.561 sec/step, loss=0.07297, avg_loss=0.07345]
[2018-11-23 07:18:21.852]  Step 254506  [20.382 sec/step, loss=0.07518, avg_loss=0.07354]
[2018-11-23 07:18:35.425]  Step 254507  [20.282 sec/step, loss=0.07205, avg_loss=0.07351]
[2018-11-23 07:18:57.668]  Step 254508  [20.388 sec/step, loss=0.07578, avg_loss=0.07356]
[2018-11-23 07:19:19.864]  Step 254509  [20.384 sec/step, loss=0.07538, avg_loss=0.07356]
[2018-11-23 07:19:44.014]  Step 254510  [20.450 sec/step, loss=0.07570, avg_loss=0.07358]
[2018-11-23 07:20:03.868]  Step 254511  [20.495 sec/step, loss=0.07414, avg_loss=0.07360]
[2018-11-23 07:20:15.327]  Generated 32 batches of size 32 in 10.495 sec
[2018-11-23 07:20:31.843]  Step 254512  [20.554 sec/step, loss=0.07585, avg_loss=0.07361]
[2018-11-23 07:20:54.289]  Step 254513  [20.582 sec/step, loss=0.07503, avg_loss=0.07362]
[2018-11-23 07:21:12.903]  Step 254514  [20.581 sec/step, loss=0.07396, avg_loss=0.07361]
[2018-11-23 07:21:35.233]  Step 254515  [20.639 sec/step, loss=0.07524, avg_loss=0.07364]
[2018-11-23 07:22:01.658]  Step 254516  [20.664 sec/step, loss=0.07478, avg_loss=0.07364]
[2018-11-23 07:22:21.661]  Step 254517  [20.650 sec/step, loss=0.07511, avg_loss=0.07363]
[2018-11-23 07:22:42.431]  Step 254518  [20.774 sec/step, loss=0.07509, avg_loss=0.07382]
[2018-11-23 07:23:06.513]  Step 254519  [20.752 sec/step, loss=0.07530, avg_loss=0.07381]
[2018-11-23 07:23:25.339]  Step 254520  [20.715 sec/step, loss=0.07481, avg_loss=0.07380]
[2018-11-23 07:23:45.727]  Step 254521  [20.702 sec/step, loss=0.07433, avg_loss=0.07379]
[2018-11-23 07:24:09.260]  Step 254522  [20.721 sec/step, loss=0.07429, avg_loss=0.07378]
[2018-11-23 07:24:29.370]  Step 254523  [20.678 sec/step, loss=0.07455, avg_loss=0.07378]
[2018-11-23 07:24:55.491]  Step 254524  [20.737 sec/step, loss=0.07481, avg_loss=0.07377]
[2018-11-23 07:25:19.651]  Step 254525  [20.752 sec/step, loss=0.07532, avg_loss=0.07377]
[2018-11-23 07:25:40.748]  Step 254526  [20.723 sec/step, loss=0.07479, avg_loss=0.07375]
[2018-11-23 07:26:02.704]  Step 254527  [20.756 sec/step, loss=0.07438, avg_loss=0.07374]
[2018-11-23 07:26:24.924]  Step 254528  [20.728 sec/step, loss=0.07455, avg_loss=0.07373]
[2018-11-23 07:26:46.688]  Step 254529  [20.783 sec/step, loss=0.07524, avg_loss=0.07377]
[2018-11-23 07:27:10.858]  Step 254530  [20.850 sec/step, loss=0.07547, avg_loss=0.07377]
[2018-11-23 07:27:26.582]  Step 254531  [20.812 sec/step, loss=0.07168, avg_loss=0.07375]
[2018-11-23 07:27:35.272]  Step 254532  [20.692 sec/step, loss=0.05558, avg_loss=0.07355]
[2018-11-23 07:27:54.485]  Step 254533  [20.659 sec/step, loss=0.07474, avg_loss=0.07354]
[2018-11-23 07:28:13.315]  Step 254534  [20.591 sec/step, loss=0.07453, avg_loss=0.07353]
[2018-11-23 07:28:37.487]  Step 254535  [20.616 sec/step, loss=0.07491, avg_loss=0.07352]
[2018-11-23 07:29:00.330]  Step 254536  [20.609 sec/step, loss=0.07537, avg_loss=0.07353]
[2018-11-23 07:29:15.785]  Step 254537  [20.532 sec/step, loss=0.07259, avg_loss=0.07349]
[2018-11-23 07:29:40.237]  Step 254538  [20.544 sec/step, loss=0.07550, avg_loss=0.07349]
[2018-11-23 07:29:50.685]  Step 254539  [20.413 sec/step, loss=0.06892, avg_loss=0.07342]
[2018-11-23 07:30:13.081]  Step 254540  [20.398 sec/step, loss=0.07524, avg_loss=0.07342]
[2018-11-23 07:30:38.658]  Step 254541  [20.409 sec/step, loss=0.07596, avg_loss=0.07342]
[2018-11-23 07:30:57.678]  Step 254542  [20.445 sec/step, loss=0.07434, avg_loss=0.07344]
[2018-11-23 07:31:19.453]  Step 254543  [20.477 sec/step, loss=0.07565, avg_loss=0.07344]
[2018-11-23 07:31:28.950]  Generated 32 batches of size 32 in 8.708 sec
[2018-11-23 07:31:33.070]  Step 254544  [20.378 sec/step, loss=0.07135, avg_loss=0.07340]
[2018-11-23 07:31:56.308]  Step 254545  [20.394 sec/step, loss=0.07579, avg_loss=0.07340]
[2018-11-23 07:32:41.104]  Step 254546  [20.638 sec/step, loss=0.06723, avg_loss=0.07333]
[2018-11-23 07:33:00.970]  Step 254547  [20.622 sec/step, loss=0.07404, avg_loss=0.07332]
[2018-11-23 07:33:18.778]  Step 254548  [20.572 sec/step, loss=0.07374, avg_loss=0.07330]
[2018-11-23 07:33:33.823]  Step 254549  [20.618 sec/step, loss=0.07238, avg_loss=0.07336]
[2018-11-23 07:33:58.772]  Step 254550  [20.663 sec/step, loss=0.07494, avg_loss=0.07336]
[2018-11-23 07:33:58.772]  Writing summary at step: 254550
[2018-11-23 07:34:39.704]  Step 254551  [20.688 sec/step, loss=0.07484, avg_loss=0.07337]
[2018-11-23 07:34:57.355]  Step 254552  [20.682 sec/step, loss=0.07338, avg_loss=0.07336]
[2018-11-23 07:35:17.748]  Step 254553  [20.659 sec/step, loss=0.07485, avg_loss=0.07337]
[2018-11-23 07:35:43.128]  Step 254554  [20.671 sec/step, loss=0.07558, avg_loss=0.07336]
[2018-11-23 07:36:07.415]  Step 254555  [20.829 sec/step, loss=0.07485, avg_loss=0.07354]
[2018-11-23 07:36:33.574]  Step 254556  [20.947 sec/step, loss=0.07442, avg_loss=0.07356]
[2018-11-23 07:36:57.308]  Step 254557  [20.978 sec/step, loss=0.07560, avg_loss=0.07356]
[2018-11-23 07:37:17.413]  Step 254558  [21.050 sec/step, loss=0.07518, avg_loss=0.07360]
[2018-11-23 07:37:41.985]  Step 254559  [21.090 sec/step, loss=0.07512, avg_loss=0.07361]
[2018-11-23 07:37:50.801]  Step 254560  [21.006 sec/step, loss=0.05495, avg_loss=0.07342]
[2018-11-23 07:38:01.244]  Step 254561  [20.907 sec/step, loss=0.06563, avg_loss=0.07332]
[2018-11-23 07:38:24.673]  Step 254562  [20.908 sec/step, loss=0.07453, avg_loss=0.07330]
[2018-11-23 07:38:44.175]  Step 254563  [20.998 sec/step, loss=0.07485, avg_loss=0.07336]
[2018-11-23 07:39:03.866]  Step 254564  [20.968 sec/step, loss=0.07358, avg_loss=0.07334]
[2018-11-23 07:39:25.247]  Step 254565  [20.939 sec/step, loss=0.07506, avg_loss=0.07334]
[2018-11-23 07:39:39.371]  Step 254566  [20.707 sec/step, loss=0.07139, avg_loss=0.07339]
[2018-11-23 07:40:01.138]  Step 254567  [20.681 sec/step, loss=0.07476, avg_loss=0.07338]
[2018-11-23 07:40:20.076]  Step 254568  [20.642 sec/step, loss=0.07397, avg_loss=0.07338]
[2018-11-23 07:40:45.191]  Step 254569  [20.695 sec/step, loss=0.07514, avg_loss=0.07338]
[2018-11-23 07:41:02.371]  Step 254570  [20.658 sec/step, loss=0.07387, avg_loss=0.07337]
[2018-11-23 07:41:14.558]  Step 254571  [20.585 sec/step, loss=0.07044, avg_loss=0.07332]
[2018-11-23 07:41:37.383]  Step 254572  [20.626 sec/step, loss=0.07518, avg_loss=0.07332]
[2018-11-23 07:41:52.901]  Step 254573  [20.626 sec/step, loss=0.07260, avg_loss=0.07332]
[2018-11-23 07:42:15.156]  Step 254574  [20.594 sec/step, loss=0.07424, avg_loss=0.07331]
[2018-11-23 07:42:24.634]  Generated 32 batches of size 32 in 8.697 sec
[2018-11-23 07:42:38.284]  Step 254575  [20.594 sec/step, loss=0.07515, avg_loss=0.07331]
[2018-11-23 07:42:59.288]  Step 254576  [20.664 sec/step, loss=0.07523, avg_loss=0.07334]
[2018-11-23 07:43:17.934]  Step 254577  [20.726 sec/step, loss=0.07512, avg_loss=0.07338]
[2018-11-23 07:43:58.058]  Step 254578  [20.858 sec/step, loss=0.06641, avg_loss=0.07329]
[2018-11-23 07:44:21.848]  Step 254579  [20.881 sec/step, loss=0.07553, avg_loss=0.07329]
[2018-11-23 07:44:43.293]  Step 254580  [20.850 sec/step, loss=0.07453, avg_loss=0.07329]
[2018-11-23 07:44:59.015]  Step 254581  [20.783 sec/step, loss=0.07107, avg_loss=0.07325]
[2018-11-23 07:45:21.540]  Step 254582  [20.782 sec/step, loss=0.07526, avg_loss=0.07325]
[2018-11-23 07:45:45.454]  Step 254583  [20.787 sec/step, loss=0.07621, avg_loss=0.07326]
[2018-11-23 07:46:08.716]  Step 254584  [20.779 sec/step, loss=0.07444, avg_loss=0.07325]
[2018-11-23 07:46:30.497]  Step 254585  [20.808 sec/step, loss=0.07463, avg_loss=0.07326]
[2018-11-23 07:46:56.909]  Step 254586  [20.878 sec/step, loss=0.07523, avg_loss=0.07327]
[2018-11-23 07:47:17.249]  Step 254587  [20.821 sec/step, loss=0.07466, avg_loss=0.07327]
[2018-11-23 07:47:41.291]  Step 254588  [20.846 sec/step, loss=0.07535, avg_loss=0.07327]
[2018-11-23 07:48:03.652]  Step 254589  [20.911 sec/step, loss=0.07508, avg_loss=0.07330]
[2018-11-23 07:48:29.040]  Step 254590  [21.079 sec/step, loss=0.07585, avg_loss=0.07350]
[2018-11-23 07:48:49.193]  Step 254591  [21.088 sec/step, loss=0.07415, avg_loss=0.07349]
[2018-11-23 07:48:59.578]  Step 254592  [20.960 sec/step, loss=0.06742, avg_loss=0.07341]
[2018-11-23 07:49:22.152]  Step 254593  [20.949 sec/step, loss=0.07490, avg_loss=0.07342]
[2018-11-23 07:49:38.124]  Step 254594  [20.868 sec/step, loss=0.07222, avg_loss=0.07338]
[2018-11-23 07:50:15.314]  Step 254595  [20.876 sec/step, loss=0.06641, avg_loss=0.07338]
[2018-11-23 07:50:30.314]  Step 254596  [20.801 sec/step, loss=0.07098, avg_loss=0.07335]
[2018-11-23 07:50:48.763]  Step 254597  [20.882 sec/step, loss=0.07458, avg_loss=0.07344]
[2018-11-23 07:51:13.064]  Step 254598  [20.941 sec/step, loss=0.07562, avg_loss=0.07345]
[2018-11-23 07:51:35.053]  Step 254599  [21.040 sec/step, loss=0.07432, avg_loss=0.07348]
[2018-11-23 07:51:59.798]  Step 254600  [21.070 sec/step, loss=0.07492, avg_loss=0.07348]
[2018-11-23 07:51:59.798]  Writing summary at step: 254600
[2018-11-23 07:52:26.703]  Step 254601  [21.001 sec/step, loss=0.07395, avg_loss=0.07347]
[2018-11-23 07:52:50.383]  Step 254602  [21.155 sec/step, loss=0.07551, avg_loss=0.07366]
[2018-11-23 07:53:09.606]  Step 254603  [21.175 sec/step, loss=0.07391, avg_loss=0.07366]
[2018-11-23 07:53:29.600]  Step 254604  [21.154 sec/step, loss=0.07456, avg_loss=0.07366]
[2018-11-23 07:53:50.507]  Step 254605  [21.207 sec/step, loss=0.07440, avg_loss=0.07367]
[2018-11-23 07:53:59.722]  Generated 32 batches of size 32 in 8.347 sec
[2018-11-23 07:54:13.229]  Step 254606  [21.230 sec/step, loss=0.07441, avg_loss=0.07366]
[2018-11-23 07:54:24.793]  Step 254607  [21.210 sec/step, loss=0.07165, avg_loss=0.07366]
[2018-11-23 07:54:48.995]  Step 254608  [21.229 sec/step, loss=0.07523, avg_loss=0.07365]
[2018-11-23 07:55:07.370]  Step 254609  [21.191 sec/step, loss=0.07439, avg_loss=0.07364]
[2018-11-23 07:55:25.821]  Step 254610  [21.134 sec/step, loss=0.07532, avg_loss=0.07364]
[2018-11-23 07:55:47.674]  Step 254611  [21.154 sec/step, loss=0.07528, avg_loss=0.07365]
[2018-11-23 07:56:08.857]  Step 254612  [21.086 sec/step, loss=0.07529, avg_loss=0.07365]
[2018-11-23 07:56:22.378]  Step 254613  [20.997 sec/step, loss=0.07318, avg_loss=0.07363]
[2018-11-23 07:56:46.080]  Step 254614  [21.048 sec/step, loss=0.07482, avg_loss=0.07364]
[2018-11-23 07:57:01.831]  Step 254615  [20.982 sec/step, loss=0.07184, avg_loss=0.07360]
[2018-11-23 07:57:23.225]  Step 254616  [20.932 sec/step, loss=0.07504, avg_loss=0.07361]
[2018-11-23 07:57:47.299]  Step 254617  [20.973 sec/step, loss=0.07570, avg_loss=0.07361]
[2018-11-23 07:58:01.094]  Step 254618  [20.903 sec/step, loss=0.07205, avg_loss=0.07358]
[2018-11-23 07:58:21.488]  Step 254619  [20.866 sec/step, loss=0.07458, avg_loss=0.07357]
[2018-11-23 07:58:46.158]  Step 254620  [20.924 sec/step, loss=0.07469, avg_loss=0.07357]
[2018-11-23 07:59:04.111]  Step 254621  [20.900 sec/step, loss=0.07443, avg_loss=0.07357]
[2018-11-23 07:59:23.291]  Step 254622  [20.856 sec/step, loss=0.07406, avg_loss=0.07357]
[2018-11-23 07:59:49.426]  Step 254623  [20.917 sec/step, loss=0.07498, avg_loss=0.07358]
[2018-11-23 08:00:12.660]  Step 254624  [20.888 sec/step, loss=0.07443, avg_loss=0.07357]
[2018-11-23 08:00:29.723]  Step 254625  [20.817 sec/step, loss=0.07336, avg_loss=0.07355]
[2018-11-23 08:00:49.804]  Step 254626  [20.807 sec/step, loss=0.07410, avg_loss=0.07355]
[2018-11-23 08:01:13.133]  Step 254627  [20.820 sec/step, loss=0.07519, avg_loss=0.07355]
[2018-11-23 08:01:23.502]  Step 254628  [20.702 sec/step, loss=0.06731, avg_loss=0.07348]
[2018-11-23 08:01:45.197]  Step 254629  [20.701 sec/step, loss=0.07460, avg_loss=0.07347]
[2018-11-23 08:02:05.769]  Step 254630  [20.665 sec/step, loss=0.07537, avg_loss=0.07347]
[2018-11-23 08:02:29.592]  Step 254631  [20.746 sec/step, loss=0.07532, avg_loss=0.07351]
[2018-11-23 08:02:51.821]  Step 254632  [20.882 sec/step, loss=0.07457, avg_loss=0.07370]
[2018-11-23 08:03:13.197]  Step 254633  [20.903 sec/step, loss=0.07519, avg_loss=0.07370]
[2018-11-23 08:03:29.202]  Step 254634  [20.875 sec/step, loss=0.07277, avg_loss=0.07369]
[2018-11-23 08:03:53.027]  Step 254635  [20.872 sec/step, loss=0.07464, avg_loss=0.07368]
[2018-11-23 08:04:14.525]  Step 254636  [20.858 sec/step, loss=0.07469, avg_loss=0.07368]
[2018-11-23 08:04:34.353]  Step 254637  [20.902 sec/step, loss=0.07487, avg_loss=0.07370]
[2018-11-23 08:04:49.149]  Generated 32 batches of size 32 in 13.989 sec
[2018-11-23 08:05:20.065]  Step 254638  [21.114 sec/step, loss=0.06657, avg_loss=0.07361]
[2018-11-23 08:05:28.555]  Step 254639  [21.095 sec/step, loss=0.05625, avg_loss=0.07348]
[2018-11-23 08:05:51.945]  Step 254640  [21.105 sec/step, loss=0.07536, avg_loss=0.07349]
[2018-11-23 08:06:16.234]  Step 254641  [21.092 sec/step, loss=0.07533, avg_loss=0.07348]
[2018-11-23 08:06:34.613]  Step 254642  [21.085 sec/step, loss=0.07569, avg_loss=0.07349]
[2018-11-23 08:06:59.866]  Step 254643  [21.120 sec/step, loss=0.07537, avg_loss=0.07349]
[2018-11-23 08:07:19.054]  Step 254644  [21.176 sec/step, loss=0.07359, avg_loss=0.07351]
[2018-11-23 08:07:31.168]  Step 254645  [21.065 sec/step, loss=0.07061, avg_loss=0.07346]
[2018-11-23 08:07:56.062]  Step 254646  [20.866 sec/step, loss=0.07519, avg_loss=0.07354]
[2018-11-23 08:08:08.606]  Step 254647  [20.792 sec/step, loss=0.07088, avg_loss=0.07351]
[2018-11-23 08:08:31.585]  Step 254648  [20.844 sec/step, loss=0.07432, avg_loss=0.07351]
[2018-11-23 08:08:54.914]  Step 254649  [20.927 sec/step, loss=0.07356, avg_loss=0.07353]
[2018-11-23 08:09:19.049]  Step 254650  [20.919 sec/step, loss=0.07452, avg_loss=0.07352]
[2018-11-23 08:09:19.049]  Writing summary at step: 254650
[2018-11-23 08:10:03.735]  Step 254651  [20.933 sec/step, loss=0.07434, avg_loss=0.07352]
[2018-11-23 08:10:30.344]  Step 254652  [21.023 sec/step, loss=0.07459, avg_loss=0.07353]
[2018-11-23 08:10:41.170]  Step 254653  [20.927 sec/step, loss=0.06790, avg_loss=0.07346]
[2018-11-23 08:11:05.868]  Step 254654  [20.921 sec/step, loss=0.07472, avg_loss=0.07345]
[2018-11-23 08:11:23.160]  Step 254655  [20.851 sec/step, loss=0.07389, avg_loss=0.07344]
[2018-11-23 08:11:58.453]  Step 254656  [20.942 sec/step, loss=0.06617, avg_loss=0.07336]
[2018-11-23 08:12:23.527]  Step 254657  [20.955 sec/step, loss=0.07550, avg_loss=0.07336]
[2018-11-23 08:12:47.787]  Step 254658  [20.997 sec/step, loss=0.07542, avg_loss=0.07336]
[2018-11-23 08:13:12.127]  Step 254659  [20.995 sec/step, loss=0.07496, avg_loss=0.07336]
[2018-11-23 08:13:36.274]  Step 254660  [21.148 sec/step, loss=0.07445, avg_loss=0.07355]
[2018-11-23 08:13:58.300]  Step 254661  [21.264 sec/step, loss=0.07414, avg_loss=0.07364]
[2018-11-23 08:14:17.596]  Step 254662  [21.222 sec/step, loss=0.07452, avg_loss=0.07364]
[2018-11-23 08:14:37.971]  Step 254663  [21.231 sec/step, loss=0.07490, avg_loss=0.07364]
[2018-11-23 08:14:51.873]  Step 254664  [21.173 sec/step, loss=0.07246, avg_loss=0.07363]
[2018-11-23 08:15:10.344]  Step 254665  [21.144 sec/step, loss=0.07488, avg_loss=0.07363]
[2018-11-23 08:15:26.086]  Step 254666  [21.160 sec/step, loss=0.07142, avg_loss=0.07363]
[2018-11-23 08:15:50.869]  Step 254667  [21.190 sec/step, loss=0.07490, avg_loss=0.07363]
[2018-11-23 08:16:08.830]  Step 254668  [21.181 sec/step, loss=0.07372, avg_loss=0.07363]
[2018-11-23 08:16:18.464]  Generated 32 batches of size 32 in 8.750 sec
[2018-11-23 08:16:32.316]  Step 254669  [21.164 sec/step, loss=0.07426, avg_loss=0.07362]
[2018-11-23 08:16:55.437]  Step 254670  [21.224 sec/step, loss=0.07526, avg_loss=0.07363]
[2018-11-23 08:17:15.275]  Step 254671  [21.300 sec/step, loss=0.07473, avg_loss=0.07367]
[2018-11-23 08:17:30.705]  Step 254672  [21.226 sec/step, loss=0.07211, avg_loss=0.07364]
[2018-11-23 08:17:51.765]  Step 254673  [21.282 sec/step, loss=0.07528, avg_loss=0.07367]
[2018-11-23 08:18:14.233]  Step 254674  [21.284 sec/step, loss=0.07524, avg_loss=0.07368]
[2018-11-23 08:18:36.105]  Step 254675  [21.271 sec/step, loss=0.07512, avg_loss=0.07368]
[2018-11-23 08:18:44.623]  Step 254676  [21.147 sec/step, loss=0.05440, avg_loss=0.07347]
[2018-11-23 08:19:03.813]  Step 254677  [21.152 sec/step, loss=0.07404, avg_loss=0.07346]
[2018-11-23 08:19:27.532]  Step 254678  [20.988 sec/step, loss=0.07490, avg_loss=0.07354]
[2018-11-23 08:19:51.034]  Step 254679  [20.985 sec/step, loss=0.07485, avg_loss=0.07354]
[2018-11-23 08:20:13.580]  Step 254680  [20.996 sec/step, loss=0.07472, avg_loss=0.07354]
[2018-11-23 08:20:51.230]  Step 254681  [21.215 sec/step, loss=0.06618, avg_loss=0.07349]
[2018-11-23 08:21:06.776]  Step 254682  [21.146 sec/step, loss=0.07071, avg_loss=0.07345]
[2018-11-23 08:21:28.605]  Step 254683  [21.125 sec/step, loss=0.07449, avg_loss=0.07343]
[2018-11-23 08:21:50.479]  Step 254684  [21.111 sec/step, loss=0.07446, avg_loss=0.07343]
[2018-11-23 08:22:09.491]  Step 254685  [21.083 sec/step, loss=0.07465, avg_loss=0.07343]
[2018-11-23 08:22:27.153]  Step 254686  [20.996 sec/step, loss=0.07324, avg_loss=0.07341]
[2018-11-23 08:22:41.063]  Step 254687  [20.931 sec/step, loss=0.07163, avg_loss=0.07338]
[2018-11-23 08:23:02.484]  Step 254688  [20.905 sec/step, loss=0.07513, avg_loss=0.07338]
[2018-11-23 08:23:22.749]  Step 254689  [20.884 sec/step, loss=0.07395, avg_loss=0.07337]
[2018-11-23 08:23:45.849]  Step 254690  [20.861 sec/step, loss=0.07420, avg_loss=0.07335]
[2018-11-23 08:24:05.262]  Step 254691  [20.854 sec/step, loss=0.07364, avg_loss=0.07334]
[2018-11-23 08:24:13.893]  Step 254692  [20.836 sec/step, loss=0.05621, avg_loss=0.07323]
[2018-11-23 08:24:39.864]  Step 254693  [20.870 sec/step, loss=0.07481, avg_loss=0.07323]
[2018-11-23 08:24:58.520]  Step 254694  [20.897 sec/step, loss=0.07410, avg_loss=0.07325]
[2018-11-23 08:25:16.733]  Step 254695  [20.707 sec/step, loss=0.07448, avg_loss=0.07333]
[2018-11-23 08:25:27.056]  Step 254696  [20.661 sec/step, loss=0.06718, avg_loss=0.07329]
[2018-11-23 08:25:51.949]  Step 254697  [20.725 sec/step, loss=0.07471, avg_loss=0.07329]
[2018-11-23 08:26:12.160]  Step 254698  [20.684 sec/step, loss=0.07438, avg_loss=0.07328]
[2018-11-23 08:26:36.370]  Step 254699  [20.706 sec/step, loss=0.07464, avg_loss=0.07328]
[2018-11-23 08:26:59.913]  Step 254700  [20.694 sec/step, loss=0.07509, avg_loss=0.07329]
[2018-11-23 08:26:59.914]  Writing summary at step: 254700
[2018-11-23 08:27:09.512]  Generated 32 batches of size 32 in 8.693 sec
[2018-11-23 08:27:37.660]  Step 254701  [20.724 sec/step, loss=0.07462, avg_loss=0.07329]
[2018-11-23 08:27:58.956]  Step 254702  [20.700 sec/step, loss=0.07486, avg_loss=0.07329]
[2018-11-23 08:28:10.860]  Step 254703  [20.627 sec/step, loss=0.07055, avg_loss=0.07325]
[2018-11-23 08:28:34.797]  Step 254704  [20.666 sec/step, loss=0.07552, avg_loss=0.07326]
[2018-11-23 08:28:52.239]  Step 254705  [20.632 sec/step, loss=0.07424, avg_loss=0.07326]
[2018-11-23 08:29:13.853]  Step 254706  [20.621 sec/step, loss=0.07452, avg_loss=0.07326]
[2018-11-23 08:29:39.358]  Step 254707  [20.760 sec/step, loss=0.07518, avg_loss=0.07330]
[2018-11-23 08:30:01.427]  Step 254708  [20.739 sec/step, loss=0.07482, avg_loss=0.07329]
[2018-11-23 08:30:13.004]  Step 254709  [20.671 sec/step, loss=0.07021, avg_loss=0.07325]
[2018-11-23 08:30:36.776]  Step 254710  [20.724 sec/step, loss=0.07472, avg_loss=0.07325]
[2018-11-23 08:30:55.353]  Step 254711  [20.691 sec/step, loss=0.07492, avg_loss=0.07324]
[2018-11-23 08:31:15.201]  Step 254712  [20.678 sec/step, loss=0.07476, avg_loss=0.07324]
[2018-11-23 08:31:34.516]  Step 254713  [20.736 sec/step, loss=0.07340, avg_loss=0.07324]
[2018-11-23 08:31:55.739]  Step 254714  [20.711 sec/step, loss=0.07425, avg_loss=0.07323]
[2018-11-23 08:32:05.828]  Step 254715  [20.654 sec/step, loss=0.06710, avg_loss=0.07319]
[2018-11-23 08:32:24.758]  Step 254716  [20.630 sec/step, loss=0.07468, avg_loss=0.07318]
[2018-11-23 08:32:46.975]  Step 254717  [20.611 sec/step, loss=0.07454, avg_loss=0.07317]
[2018-11-23 08:33:10.239]  Step 254718  [20.706 sec/step, loss=0.07525, avg_loss=0.07320]
[2018-11-23 08:33:34.399]  Step 254719  [20.743 sec/step, loss=0.07468, avg_loss=0.07320]
[2018-11-23 08:33:48.228]  Step 254720  [20.635 sec/step, loss=0.07138, avg_loss=0.07317]
[2018-11-23 08:34:08.436]  Step 254721  [20.658 sec/step, loss=0.07481, avg_loss=0.07317]
[2018-11-23 08:34:29.096]  Step 254722  [20.672 sec/step, loss=0.07493, avg_loss=0.07318]
[2018-11-23 08:34:51.831]  Step 254723  [20.638 sec/step, loss=0.07436, avg_loss=0.07318]
[2018-11-23 08:35:00.548]  Step 254724  [20.493 sec/step, loss=0.05563, avg_loss=0.07299]
[2018-11-23 08:35:24.017]  Step 254725  [20.557 sec/step, loss=0.07522, avg_loss=0.07301]
[2018-11-23 08:35:48.836]  Step 254726  [20.605 sec/step, loss=0.07484, avg_loss=0.07301]
[2018-11-23 08:36:03.921]  Step 254727  [20.522 sec/step, loss=0.07219, avg_loss=0.07298]
[2018-11-23 08:36:29.418]  Step 254728  [20.674 sec/step, loss=0.07554, avg_loss=0.07307]
[2018-11-23 08:36:52.843]  Step 254729  [20.691 sec/step, loss=0.07449, avg_loss=0.07307]
[2018-11-23 08:37:15.764]  Step 254730  [20.714 sec/step, loss=0.07486, avg_loss=0.07306]
[2018-11-23 08:37:58.554]  Step 254731  [20.904 sec/step, loss=0.06628, avg_loss=0.07297]
[2018-11-23 08:38:08.431]  Generated 32 batches of size 32 in 8.728 sec
[2018-11-23 08:38:22.361]  Step 254732  [20.920 sec/step, loss=0.07401, avg_loss=0.07296]
[2018-11-23 08:38:48.455]  Step 254733  [20.967 sec/step, loss=0.07422, avg_loss=0.07296]
[2018-11-23 08:39:05.435]  Step 254734  [20.977 sec/step, loss=0.07403, avg_loss=0.07297]
[2018-11-23 08:39:28.639]  Step 254735  [20.970 sec/step, loss=0.07443, avg_loss=0.07297]
[2018-11-23 08:39:46.151]  Step 254736  [20.931 sec/step, loss=0.07347, avg_loss=0.07295]
[2018-11-23 08:40:04.763]  Step 254737  [20.918 sec/step, loss=0.07381, avg_loss=0.07294]
[2018-11-23 08:40:20.548]  Step 254738  [20.619 sec/step, loss=0.07056, avg_loss=0.07298]
[2018-11-23 08:40:44.936]  Step 254739  [20.778 sec/step, loss=0.07579, avg_loss=0.07318]
[2018-11-23 08:41:06.866]  Step 254740  [20.764 sec/step, loss=0.07483, avg_loss=0.07317]
[2018-11-23 08:41:30.820]  Step 254741  [20.760 sec/step, loss=0.07492, avg_loss=0.07317]
[2018-11-23 08:41:54.678]  Step 254742  [20.815 sec/step, loss=0.07459, avg_loss=0.07316]
[2018-11-23 08:42:15.254]  Step 254743  [20.768 sec/step, loss=0.07467, avg_loss=0.07315]
[2018-11-23 08:42:29.076]  Step 254744  [20.715 sec/step, loss=0.07178, avg_loss=0.07313]
[2018-11-23 08:42:50.665]  Step 254745  [20.809 sec/step, loss=0.07471, avg_loss=0.07317]
[2018-11-23 08:43:07.426]  Step 254746  [20.728 sec/step, loss=0.07368, avg_loss=0.07316]
[2018-11-23 08:43:31.654]  Step 254747  [20.845 sec/step, loss=0.07431, avg_loss=0.07319]
[2018-11-23 08:43:53.279]  Step 254748  [20.831 sec/step, loss=0.07448, avg_loss=0.07319]
[2018-11-23 08:44:12.365]  Step 254749  [20.789 sec/step, loss=0.07440, avg_loss=0.07320]
[2018-11-23 08:44:22.650]  Step 254750  [20.650 sec/step, loss=0.06708, avg_loss=0.07313]
[2018-11-23 08:44:22.650]  Writing summary at step: 254750
[2018-11-23 08:45:03.557]  Step 254751  [20.594 sec/step, loss=0.07332, avg_loss=0.07312]
[2018-11-23 08:45:25.277]  Step 254752  [20.545 sec/step, loss=0.07443, avg_loss=0.07312]
[2018-11-23 08:45:44.281]  Step 254753  [20.626 sec/step, loss=0.07488, avg_loss=0.07319]
[2018-11-23 08:45:59.888]  Step 254754  [20.535 sec/step, loss=0.07262, avg_loss=0.07317]
[2018-11-23 08:46:23.482]  Step 254755  [20.598 sec/step, loss=0.07458, avg_loss=0.07317]
[2018-11-23 08:46:38.936]  Step 254756  [20.400 sec/step, loss=0.07136, avg_loss=0.07322]
[2018-11-23 08:47:17.339]  Step 254757  [20.533 sec/step, loss=0.06596, avg_loss=0.07313]
[2018-11-23 08:47:35.421]  Step 254758  [20.472 sec/step, loss=0.07394, avg_loss=0.07311]
[2018-11-23 08:47:55.949]  Step 254759  [20.433 sec/step, loss=0.07478, avg_loss=0.07311]
[2018-11-23 08:48:07.964]  Step 254760  [20.312 sec/step, loss=0.07073, avg_loss=0.07307]
[2018-11-23 08:48:27.460]  Step 254761  [20.287 sec/step, loss=0.07373, avg_loss=0.07307]
[2018-11-23 08:48:37.005]  Step 254762  [20.189 sec/step, loss=0.05360, avg_loss=0.07286]
[2018-11-23 08:48:49.035]  Generated 32 batches of size 32 in 10.862 sec
[2018-11-23 08:49:04.628]  Step 254763  [20.262 sec/step, loss=0.07481, avg_loss=0.07286]
[2018-11-23 08:49:25.115]  Step 254764  [20.328 sec/step, loss=0.07389, avg_loss=0.07287]
[2018-11-23 08:49:49.318]  Step 254765  [20.385 sec/step, loss=0.07543, avg_loss=0.07288]
[2018-11-23 08:50:15.284]  Step 254766  [20.487 sec/step, loss=0.07469, avg_loss=0.07291]
[2018-11-23 08:50:37.423]  Step 254767  [20.461 sec/step, loss=0.07479, avg_loss=0.07291]
[2018-11-23 08:51:01.643]  Step 254768  [20.523 sec/step, loss=0.07448, avg_loss=0.07292]
[2018-11-23 08:51:23.850]  Step 254769  [20.511 sec/step, loss=0.07393, avg_loss=0.07292]
[2018-11-23 08:51:48.320]  Step 254770  [20.524 sec/step, loss=0.07526, avg_loss=0.07292]
[2018-11-23 08:52:09.803]  Step 254771  [20.541 sec/step, loss=0.07494, avg_loss=0.07292]
[2018-11-23 08:52:30.178]  Step 254772  [20.590 sec/step, loss=0.07445, avg_loss=0.07294]
[2018-11-23 08:52:54.652]  Step 254773  [20.624 sec/step, loss=0.07424, avg_loss=0.07293]
[2018-11-23 08:53:18.880]  Step 254774  [20.642 sec/step, loss=0.07520, avg_loss=0.07293]
[2018-11-23 08:53:37.086]  Step 254775  [20.605 sec/step, loss=0.07441, avg_loss=0.07292]
[2018-11-23 08:53:54.586]  Step 254776  [20.695 sec/step, loss=0.07325, avg_loss=0.07311]
[2018-11-23 08:54:16.561]  Step 254777  [20.723 sec/step, loss=0.07405, avg_loss=0.07311]
[2018-11-23 08:54:36.624]  Step 254778  [20.686 sec/step, loss=0.07420, avg_loss=0.07311]
[2018-11-23 08:55:03.306]  Step 254779  [20.718 sec/step, loss=0.07513, avg_loss=0.07311]
[2018-11-23 08:55:26.719]  Step 254780  [20.727 sec/step, loss=0.07502, avg_loss=0.07311]
[2018-11-23 08:55:51.077]  Step 254781  [20.594 sec/step, loss=0.07507, avg_loss=0.07320]
[2018-11-23 08:55:59.832]  Step 254782  [20.526 sec/step, loss=0.05567, avg_loss=0.07305]
[2018-11-23 08:56:21.759]  Step 254783  [20.527 sec/step, loss=0.07411, avg_loss=0.07305]
[2018-11-23 08:56:42.020]  Step 254784  [20.511 sec/step, loss=0.07474, avg_loss=0.07305]
[2018-11-23 08:57:01.289]  Step 254785  [20.513 sec/step, loss=0.07446, avg_loss=0.07305]
[2018-11-23 08:57:25.380]  Step 254786  [20.578 sec/step, loss=0.07435, avg_loss=0.07306]
[2018-11-23 08:57:46.931]  Step 254787  [20.654 sec/step, loss=0.07481, avg_loss=0.07309]
[2018-11-23 08:58:11.594]  Step 254788  [20.686 sec/step, loss=0.07443, avg_loss=0.07308]
[2018-11-23 08:58:52.300]  Step 254789  [20.891 sec/step, loss=0.06645, avg_loss=0.07301]
[2018-11-23 08:59:17.046]  Step 254790  [20.907 sec/step, loss=0.07460, avg_loss=0.07301]
[2018-11-23 08:59:39.417]  Step 254791  [20.937 sec/step, loss=0.07468, avg_loss=0.07302]
[2018-11-23 08:59:55.135]  Step 254792  [21.008 sec/step, loss=0.07093, avg_loss=0.07317]
[2018-11-23 09:00:10.721]  Step 254793  [20.904 sec/step, loss=0.07211, avg_loss=0.07314]
[2018-11-23 09:00:30.651]  Step 254794  [20.917 sec/step, loss=0.07395, avg_loss=0.07314]
[2018-11-23 09:00:40.018]  Generated 32 batches of size 32 in 8.510 sec
[2018-11-23 09:00:53.820]  Step 254795  [20.966 sec/step, loss=0.07529, avg_loss=0.07315]
[2018-11-23 09:01:05.876]  Step 254796  [20.983 sec/step, loss=0.06996, avg_loss=0.07318]
[2018-11-23 09:01:32.385]  Step 254797  [21.000 sec/step, loss=0.07524, avg_loss=0.07318]
[2018-11-23 09:01:49.734]  Step 254798  [20.971 sec/step, loss=0.07384, avg_loss=0.07318]
[2018-11-23 09:02:12.442]  Step 254799  [20.956 sec/step, loss=0.07468, avg_loss=0.07318]
[2018-11-23 09:02:31.291]  Step 254800  [20.909 sec/step, loss=0.07409, avg_loss=0.07317]
[2018-11-23 09:02:31.291]  Writing summary at step: 254800
[2018-11-23 09:03:07.546]  Step 254801  [20.923 sec/step, loss=0.07419, avg_loss=0.07316]
[2018-11-23 09:03:18.070]  Step 254802  [20.815 sec/step, loss=0.06615, avg_loss=0.07308]
[2018-11-23 09:03:40.098]  Step 254803  [20.916 sec/step, loss=0.07400, avg_loss=0.07311]
[2018-11-23 09:03:51.619]  Step 254804  [20.792 sec/step, loss=0.07030, avg_loss=0.07306]
[2018-11-23 09:04:00.227]  Step 254805  [20.704 sec/step, loss=0.05475, avg_loss=0.07286]
[2018-11-23 09:04:23.684]  Step 254806  [20.722 sec/step, loss=0.07427, avg_loss=0.07286]
[2018-11-23 09:05:07.095]  Step 254807  [20.901 sec/step, loss=0.06562, avg_loss=0.07276]
[2018-11-23 09:05:28.082]  Step 254808  [20.890 sec/step, loss=0.07464, avg_loss=0.07276]
[2018-11-23 09:05:53.939]  Step 254809  [21.033 sec/step, loss=0.07520, avg_loss=0.07281]
[2018-11-23 09:06:17.390]  Step 254810  [21.030 sec/step, loss=0.07513, avg_loss=0.07282]
[2018-11-23 09:06:42.442]  Step 254811  [21.095 sec/step, loss=0.07527, avg_loss=0.07282]
[2018-11-23 09:07:06.591]  Step 254812  [21.138 sec/step, loss=0.07479, avg_loss=0.07282]
[2018-11-23 09:07:28.390]  Step 254813  [21.162 sec/step, loss=0.07466, avg_loss=0.07283]
[2018-11-23 09:07:48.109]  Step 254814  [21.147 sec/step, loss=0.07350, avg_loss=0.07283]
[2018-11-23 09:08:10.018]  Step 254815  [21.266 sec/step, loss=0.07495, avg_loss=0.07290]
[2018-11-23 09:08:35.817]  Step 254816  [21.334 sec/step, loss=0.07527, avg_loss=0.07291]
[2018-11-23 09:08:58.314]  Step 254817  [21.337 sec/step, loss=0.07471, avg_loss=0.07291]
[2018-11-23 09:09:08.858]  Step 254818  [21.210 sec/step, loss=0.06623, avg_loss=0.07282]
[2018-11-23 09:09:24.081]  Step 254819  [21.121 sec/step, loss=0.07139, avg_loss=0.07279]
[2018-11-23 09:09:48.563]  Step 254820  [21.227 sec/step, loss=0.07437, avg_loss=0.07282]
[2018-11-23 09:10:15.638]  Step 254821  [21.296 sec/step, loss=0.07515, avg_loss=0.07282]
[2018-11-23 09:10:30.119]  Step 254822  [21.234 sec/step, loss=0.07090, avg_loss=0.07278]
[2018-11-23 09:10:50.267]  Step 254823  [21.208 sec/step, loss=0.07458, avg_loss=0.07278]
[2018-11-23 09:11:06.929]  Step 254824  [21.288 sec/step, loss=0.07219, avg_loss=0.07295]
[2018-11-23 09:11:30.281]  Step 254825  [21.286 sec/step, loss=0.07493, avg_loss=0.07295]
[2018-11-23 09:11:42.869]  Generated 32 batches of size 32 in 11.693 sec
[2018-11-23 09:12:01.399]  Step 254826  [21.349 sec/step, loss=0.07377, avg_loss=0.07294]
[2018-11-23 09:12:22.557]  Step 254827  [21.410 sec/step, loss=0.07483, avg_loss=0.07296]
[2018-11-23 09:12:41.123]  Step 254828  [21.341 sec/step, loss=0.07428, avg_loss=0.07295]
[2018-11-23 09:12:58.570]  Step 254829  [21.281 sec/step, loss=0.07352, avg_loss=0.07294]
[2018-11-23 09:13:16.991]  Step 254830  [21.236 sec/step, loss=0.07406, avg_loss=0.07293]
[2018-11-23 09:13:34.780]  Step 254831  [20.986 sec/step, loss=0.07339, avg_loss=0.07300]
[2018-11-23 09:13:59.070]  Step 254832  [20.991 sec/step, loss=0.07478, avg_loss=0.07301]
[2018-11-23 09:14:23.574]  Step 254833  [20.975 sec/step, loss=0.07489, avg_loss=0.07302]
[2018-11-23 09:14:45.294]  Step 254834  [21.022 sec/step, loss=0.07413, avg_loss=0.07302]
[2018-11-23 09:15:06.301]  Step 254835  [21.000 sec/step, loss=0.07477, avg_loss=0.07302]
[2018-11-23 09:15:22.223]  Step 254836  [20.984 sec/step, loss=0.07129, avg_loss=0.07300]
[2018-11-23 09:15:45.412]  Step 254837  [21.030 sec/step, loss=0.07514, avg_loss=0.07301]
[2018-11-23 09:15:59.596]  Step 254838  [21.014 sec/step, loss=0.07172, avg_loss=0.07302]
[2018-11-23 09:16:23.652]  Step 254839  [21.011 sec/step, loss=0.07417, avg_loss=0.07301]
[2018-11-23 09:16:41.225]  Step 254840  [20.967 sec/step, loss=0.07371, avg_loss=0.07300]
[2018-11-23 09:17:03.731]  Step 254841  [20.953 sec/step, loss=0.07424, avg_loss=0.07299]
[2018-11-23 09:17:21.517]  Step 254842  [20.892 sec/step, loss=0.07342, avg_loss=0.07298]
[2018-11-23 09:17:40.491]  Step 254843  [20.876 sec/step, loss=0.07475, avg_loss=0.07298]
[2018-11-23 09:18:17.959]  Step 254844  [21.113 sec/step, loss=0.06595, avg_loss=0.07292]
[2018-11-23 09:18:40.531]  Step 254845  [21.122 sec/step, loss=0.07441, avg_loss=0.07292]
[2018-11-23 09:19:04.658]  Step 254846  [21.196 sec/step, loss=0.07466, avg_loss=0.07293]
[2018-11-23 09:19:24.059]  Step 254847  [21.148 sec/step, loss=0.07436, avg_loss=0.07293]
[2018-11-23 09:19:34.375]  Step 254848  [21.035 sec/step, loss=0.06780, avg_loss=0.07286]
[2018-11-23 09:19:54.813]  Step 254849  [21.048 sec/step, loss=0.07503, avg_loss=0.07287]
[2018-11-23 09:20:15.791]  Step 254850  [21.155 sec/step, loss=0.07414, avg_loss=0.07294]
[2018-11-23 09:20:15.791]  Writing summary at step: 254850
[2018-11-23 09:21:02.338]  Step 254851  [21.238 sec/step, loss=0.07543, avg_loss=0.07296]
[2018-11-23 09:21:24.061]  Step 254852  [21.238 sec/step, loss=0.07410, avg_loss=0.07296]
[2018-11-23 09:21:46.438]  Step 254853  [21.272 sec/step, loss=0.07453, avg_loss=0.07295]
[2018-11-23 09:22:09.402]  Step 254854  [21.345 sec/step, loss=0.07489, avg_loss=0.07298]
[2018-11-23 09:22:35.953]  Step 254855  [21.375 sec/step, loss=0.07439, avg_loss=0.07297]
[2018-11-23 09:22:44.777]  Step 254856  [21.309 sec/step, loss=0.05587, avg_loss=0.07282]
[2018-11-23 09:22:54.522]  Generated 32 batches of size 32 in 9.015 sec
[2018-11-23 09:23:05.412]  Step 254857  [21.131 sec/step, loss=0.07378, avg_loss=0.07290]
[2018-11-23 09:23:26.729]  Step 254858  [21.163 sec/step, loss=0.07503, avg_loss=0.07291]
[2018-11-23 09:23:50.785]  Step 254859  [21.199 sec/step, loss=0.07521, avg_loss=0.07291]
[2018-11-23 09:24:06.034]  Step 254860  [21.231 sec/step, loss=0.07281, avg_loss=0.07293]
[2018-11-23 09:24:29.524]  Step 254861  [21.271 sec/step, loss=0.07477, avg_loss=0.07294]
[2018-11-23 09:24:54.574]  Step 254862  [21.426 sec/step, loss=0.07545, avg_loss=0.07316]
[2018-11-23 09:25:15.689]  Step 254863  [21.361 sec/step, loss=0.07495, avg_loss=0.07316]
[2018-11-23 09:25:40.138]  Step 254864  [21.401 sec/step, loss=0.07475, avg_loss=0.07317]
[2018-11-23 09:25:52.349]  Step 254865  [21.281 sec/step, loss=0.07068, avg_loss=0.07312]
[2018-11-23 09:26:14.742]  Step 254866  [21.245 sec/step, loss=0.07451, avg_loss=0.07312]
[2018-11-23 09:26:28.652]  Step 254867  [21.163 sec/step, loss=0.07143, avg_loss=0.07309]
[2018-11-23 09:26:52.824]  Step 254868  [21.162 sec/step, loss=0.07515, avg_loss=0.07310]
[2018-11-23 09:27:16.622]  Step 254869  [21.178 sec/step, loss=0.07499, avg_loss=0.07311]
[2018-11-23 09:27:34.991]  Step 254870  [21.117 sec/step, loss=0.07525, avg_loss=0.07311]
[2018-11-23 09:27:56.964]  Step 254871  [21.122 sec/step, loss=0.07499, avg_loss=0.07311]
[2018-11-23 09:28:08.642]  Step 254872  [21.035 sec/step, loss=0.07072, avg_loss=0.07307]
[2018-11-23 09:28:27.931]  Step 254873  [20.983 sec/step, loss=0.07404, avg_loss=0.07307]
[2018-11-23 09:28:48.301]  Step 254874  [20.944 sec/step, loss=0.07399, avg_loss=0.07306]
[2018-11-23 09:29:27.977]  Step 254875  [21.159 sec/step, loss=0.06707, avg_loss=0.07298]
[2018-11-23 09:29:52.437]  Step 254876  [21.229 sec/step, loss=0.07438, avg_loss=0.07299]
[2018-11-23 09:30:16.170]  Step 254877  [21.246 sec/step, loss=0.07493, avg_loss=0.07300]
[2018-11-23 09:30:34.809]  Step 254878  [21.232 sec/step, loss=0.07399, avg_loss=0.07300]
[2018-11-23 09:30:44.449]  Step 254879  [21.062 sec/step, loss=0.05486, avg_loss=0.07280]
[2018-11-23 09:31:04.885]  Step 254880  [21.032 sec/step, loss=0.07489, avg_loss=0.07280]
[2018-11-23 09:31:26.524]  Step 254881  [21.005 sec/step, loss=0.07475, avg_loss=0.07279]
[2018-11-23 09:31:46.251]  Step 254882  [21.114 sec/step, loss=0.07422, avg_loss=0.07298]
[2018-11-23 09:32:08.035]  Step 254883  [21.113 sec/step, loss=0.07461, avg_loss=0.07298]
[2018-11-23 09:32:25.023]  Step 254884  [21.080 sec/step, loss=0.07392, avg_loss=0.07298]
[2018-11-23 09:32:35.301]  Step 254885  [20.990 sec/step, loss=0.06859, avg_loss=0.07292]
[2018-11-23 09:32:58.081]  Step 254886  [20.977 sec/step, loss=0.07476, avg_loss=0.07292]
[2018-11-23 09:33:13.753]  Step 254887  [20.918 sec/step, loss=0.07109, avg_loss=0.07288]
[2018-11-23 09:33:40.270]  Step 254888  [20.937 sec/step, loss=0.07539, avg_loss=0.07289]
[2018-11-23 09:33:49.812]  Generated 32 batches of size 32 in 8.640 sec
[2018-11-23 09:33:57.270]  Step 254889  [20.700 sec/step, loss=0.07187, avg_loss=0.07295]
[2018-11-23 09:34:22.302]  Step 254890  [20.703 sec/step, loss=0.07516, avg_loss=0.07295]
[2018-11-23 09:34:45.620]  Step 254891  [20.712 sec/step, loss=0.07490, avg_loss=0.07296]
[2018-11-23 09:35:09.008]  Step 254892  [20.789 sec/step, loss=0.07630, avg_loss=0.07301]
[2018-11-23 09:35:30.567]  Step 254893  [20.849 sec/step, loss=0.07485, avg_loss=0.07304]
[2018-11-23 09:35:48.483]  Step 254894  [20.829 sec/step, loss=0.07331, avg_loss=0.07303]
[2018-11-23 09:36:12.462]  Step 254895  [20.837 sec/step, loss=0.07567, avg_loss=0.07303]
[2018-11-23 09:36:35.002]  Step 254896  [20.942 sec/step, loss=0.07510, avg_loss=0.07308]
[2018-11-23 09:36:55.612]  Step 254897  [20.883 sec/step, loss=0.07567, avg_loss=0.07309]
[2018-11-23 09:37:19.217]  Step 254898  [20.945 sec/step, loss=0.07440, avg_loss=0.07309]
[2018-11-23 09:37:39.312]  Step 254899  [20.919 sec/step, loss=0.07406, avg_loss=0.07309]
[2018-11-23 09:37:56.170]  Step 254900  [20.899 sec/step, loss=0.07327, avg_loss=0.07308]
[2018-11-23 09:37:56.170]  Writing summary at step: 254900
[2018-11-23 09:38:42.059]  Step 254901  [20.922 sec/step, loss=0.07505, avg_loss=0.07309]
[2018-11-23 09:39:08.148]  Step 254902  [21.078 sec/step, loss=0.07539, avg_loss=0.07318]
[2018-11-23 09:39:30.774]  Step 254903  [21.084 sec/step, loss=0.07481, avg_loss=0.07319]
[2018-11-23 09:39:52.573]  Step 254904  [21.187 sec/step, loss=0.07480, avg_loss=0.07323]
[2018-11-23 09:40:15.068]  Step 254905  [21.326 sec/step, loss=0.07514, avg_loss=0.07344]
[2018-11-23 09:40:36.386]  Step 254906  [21.304 sec/step, loss=0.07428, avg_loss=0.07344]
[2018-11-23 09:40:59.550]  Step 254907  [21.102 sec/step, loss=0.07469, avg_loss=0.07353]
[2018-11-23 09:41:11.876]  Step 254908  [21.015 sec/step, loss=0.06997, avg_loss=0.07348]
[2018-11-23 09:41:32.107]  Step 254909  [20.959 sec/step, loss=0.07393, avg_loss=0.07347]
[2018-11-23 09:42:01.680]  Step 254910  [21.020 sec/step, loss=0.07437, avg_loss=0.07346]
[2018-11-23 09:42:26.760]  Step 254911  [21.020 sec/step, loss=0.07530, avg_loss=0.07346]
[2018-11-23 09:42:54.666]  Step 254912  [21.058 sec/step, loss=0.07383, avg_loss=0.07345]
[2018-11-23 09:43:31.974]  Step 254913  [21.213 sec/step, loss=0.06582, avg_loss=0.07336]
[2018-11-23 09:43:53.383]  Step 254914  [21.230 sec/step, loss=0.07398, avg_loss=0.07337]
[2018-11-23 09:44:20.780]  Step 254915  [21.285 sec/step, loss=0.07423, avg_loss=0.07336]
[2018-11-23 09:44:41.237]  Step 254916  [21.231 sec/step, loss=0.07478, avg_loss=0.07336]
[2018-11-23 09:45:06.658]  Step 254917  [21.261 sec/step, loss=0.07338, avg_loss=0.07334]
[2018-11-23 09:45:24.697]  Step 254918  [21.336 sec/step, loss=0.07090, avg_loss=0.07339]
[2018-11-23 09:45:49.115]  Step 254919  [21.427 sec/step, loss=0.07463, avg_loss=0.07342]
[2018-11-23 09:46:00.134]  Generated 32 batches of size 32 in 10.004 sec
[2018-11-23 09:46:12.603]  Step 254920  [21.418 sec/step, loss=0.07394, avg_loss=0.07342]
[2018-11-23 09:46:20.155]  Step 254921  [21.222 sec/step, loss=0.05729, avg_loss=0.07324]
[2018-11-23 09:46:44.739]  Step 254922  [21.323 sec/step, loss=0.07552, avg_loss=0.07329]
[2018-11-23 09:46:55.288]  Step 254923  [21.227 sec/step, loss=0.06534, avg_loss=0.07319]
[2018-11-23 09:47:20.486]  Step 254924  [21.313 sec/step, loss=0.07460, avg_loss=0.07322]
[2018-11-23 09:47:20.489]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-254924 (requested by user)
[2018-11-23 09:47:44.401]  Step 254925  [21.285 sec/step, loss=0.07488, avg_loss=0.07322]
[2018-11-23 09:48:03.278]  Step 254926  [21.163 sec/step, loss=0.07278, avg_loss=0.07321]
[2018-11-23 09:48:28.422]  Step 254927  [21.202 sec/step, loss=0.07483, avg_loss=0.07321]
[2018-11-23 09:48:44.603]  Step 254928  [21.179 sec/step, loss=0.07222, avg_loss=0.07319]
[2018-11-23 09:49:15.094]  Step 254929  [21.309 sec/step, loss=0.07458, avg_loss=0.07320]
[2018-11-23 09:49:51.083]  Step 254930  [21.485 sec/step, loss=0.07426, avg_loss=0.07320]
[2018-11-23 09:50:25.745]  Step 254931  [21.653 sec/step, loss=0.07462, avg_loss=0.07321]
[2018-11-23 09:50:56.435]  Step 254932  [21.717 sec/step, loss=0.07381, avg_loss=0.07320]
[2018-11-23 09:51:25.634]  Step 254933  [21.764 sec/step, loss=0.07455, avg_loss=0.07320]
[2018-11-23 09:51:36.999]  Step 254934  [21.661 sec/step, loss=0.05530, avg_loss=0.07301]
[2018-11-23 09:52:13.529]  Step 254935  [21.816 sec/step, loss=0.07461, avg_loss=0.07301]
[2018-11-23 09:52:50.067]  Step 254936  [22.022 sec/step, loss=0.07438, avg_loss=0.07304]
[2018-11-23 09:53:19.348]  Step 254937  [22.083 sec/step, loss=0.07335, avg_loss=0.07302]
[2018-11-23 09:53:57.856]  Step 254938  [22.326 sec/step, loss=0.07454, avg_loss=0.07305]
[2018-11-23 09:54:41.018]  Step 254939  [22.517 sec/step, loss=0.07559, avg_loss=0.07306]
[2018-11-23 09:54:59.769]  Step 254940  [22.529 sec/step, loss=0.07048, avg_loss=0.07303]

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2018-11-23 10:25:13.874]  Devices available to tensorflow: [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 4899331060286566552
]
[2018-11-23 10:25:13.874]  Checkpoint path: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt
[2018-11-23 10:25:13.874]  Loading training data from: /Users/Aaron/Desktop/Code/tacotron/training/train.txt
[2018-11-23 10:25:13.874]  Using model: tacotron
[2018-11-23 10:25:13.874]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: english_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: True
[2018-11-23 10:25:13.879]  Loaded metadata for 398 examples (1.06 hours)
[2018-11-23 10:25:14.651]  Loaded CMUDict with 116869 unambiguous entries
[2018-11-23 10:25:18.194]  Initialized Tacotron model. Dimensions: 
[2018-11-23 10:25:18.194]    embedding:               256
[2018-11-23 10:25:18.194]    prenet out:              128
[2018-11-23 10:25:18.194]    encoder out:             256
[2018-11-23 10:25:18.194]    attention out:           256
[2018-11-23 10:25:18.195]    concat attn & out:       512
[2018-11-23 10:25:18.195]    decoder cell out:        256
[2018-11-23 10:25:18.195]    decoder out (5 frames):  400
[2018-11-23 10:25:18.195]    decoder out (1 frame):   80
[2018-11-23 10:25:18.195]    postnet out:             256
[2018-11-23 10:25:18.196]    linear out:              1025
[2018-11-23 10:25:34.783]  Resuming from checkpoint: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-254924 at commit: None
[2018-11-23 10:25:42.978]  Generated 32 batches of size 32 in 8.194 sec
[2018-11-23 10:26:16.944]  Step 254925  [42.160 sec/step, loss=0.07487, avg_loss=0.07487]
[2018-11-23 10:26:43.145]  Step 254926  [34.180 sec/step, loss=0.07486, avg_loss=0.07486]
[2018-11-23 10:27:04.688]  Step 254927  [29.967 sec/step, loss=0.07376, avg_loss=0.07450]
[2018-11-23 10:27:15.409]  Step 254928  [25.156 sec/step, loss=0.05570, avg_loss=0.06980]
[2018-11-23 10:27:40.492]  Step 254929  [25.141 sec/step, loss=0.07381, avg_loss=0.07060]
[2018-11-23 10:28:02.448]  Step 254930  [24.610 sec/step, loss=0.07457, avg_loss=0.07126]
[2018-11-23 10:28:24.839]  Step 254931  [24.293 sec/step, loss=0.07511, avg_loss=0.07181]
[2018-11-23 10:28:47.939]  Step 254932  [24.144 sec/step, loss=0.07507, avg_loss=0.07222]
[2018-11-23 10:29:11.939]  Step 254933  [24.128 sec/step, loss=0.07472, avg_loss=0.07250]
[2018-11-23 10:29:36.449]  Step 254934  [24.166 sec/step, loss=0.07427, avg_loss=0.07267]
[2018-11-23 10:29:52.732]  Step 254935  [23.449 sec/step, loss=0.07165, avg_loss=0.07258]
[2018-11-23 10:30:32.883]  Step 254936  [24.841 sec/step, loss=0.06607, avg_loss=0.07204]
[2018-11-23 10:30:51.278]  Step 254937  [24.345 sec/step, loss=0.07356, avg_loss=0.07215]
[2018-11-23 10:31:01.984]  Step 254938  [23.371 sec/step, loss=0.06772, avg_loss=0.07184]
[2018-11-23 10:31:27.243]  Step 254939  [23.497 sec/step, loss=0.07482, avg_loss=0.07204]
[2018-11-23 10:31:40.080]  Step 254940  [22.831 sec/step, loss=0.07094, avg_loss=0.07197]
[2018-11-23 10:32:02.591]  Step 254941  [22.812 sec/step, loss=0.07478, avg_loss=0.07213]
[2018-11-23 10:32:22.504]  Step 254942  [22.651 sec/step, loss=0.07393, avg_loss=0.07223]
[2018-11-23 10:32:39.104]  Step 254943  [22.332 sec/step, loss=0.07238, avg_loss=0.07224]
[2018-11-23 10:33:04.478]  Step 254944  [22.484 sec/step, loss=0.07443, avg_loss=0.07235]
[2018-11-23 10:33:23.934]  Step 254945  [22.340 sec/step, loss=0.07373, avg_loss=0.07242]
[2018-11-23 10:33:49.046]  Step 254946  [22.466 sec/step, loss=0.07445, avg_loss=0.07251]
[2018-11-23 10:34:03.286]  Step 254947  [22.109 sec/step, loss=0.07239, avg_loss=0.07250]
[2018-11-23 10:34:13.611]  Generated 32 batches of size 32 in 9.478 sec
[2018-11-23 10:34:27.151]  Step 254948  [22.182 sec/step, loss=0.07454, avg_loss=0.07259]
[2018-11-23 10:34:53.085]  Step 254949  [22.332 sec/step, loss=0.07512, avg_loss=0.07269]
[2018-11-23 10:35:11.608]  Step 254950  [22.185 sec/step, loss=0.07458, avg_loss=0.07276]
[2018-11-23 10:35:11.608]  Writing summary at step: 254950
[2018-11-23 10:36:03.652]  Step 254951  [22.162 sec/step, loss=0.07511, avg_loss=0.07285]
[2018-11-23 10:36:21.424]  Step 254952  [22.005 sec/step, loss=0.07312, avg_loss=0.07286]
[2018-11-23 10:36:45.938]  Step 254953  [22.092 sec/step, loss=0.07555, avg_loss=0.07295]
[2018-11-23 10:37:06.395]  Step 254954  [22.037 sec/step, loss=0.07409, avg_loss=0.07299]
[2018-11-23 10:37:34.825]  Step 254955  [22.244 sec/step, loss=0.07401, avg_loss=0.07302]
[2018-11-23 10:37:56.360]  Step 254956  [22.221 sec/step, loss=0.07412, avg_loss=0.07306]
[2018-11-23 10:38:15.572]  Step 254957  [22.130 sec/step, loss=0.07322, avg_loss=0.07306]
[2018-11-23 10:38:57.618]  Step 254958  [22.716 sec/step, loss=0.06622, avg_loss=0.07286]
[2018-11-23 10:39:22.719]  Step 254959  [22.784 sec/step, loss=0.07497, avg_loss=0.07292]
[2018-11-23 10:39:45.363]  Step 254960  [22.780 sec/step, loss=0.07432, avg_loss=0.07296]
[2018-11-23 10:40:08.293]  Step 254961  [22.784 sec/step, loss=0.07436, avg_loss=0.07300]
[2018-11-23 10:40:18.629]  Step 254962  [22.457 sec/step, loss=0.06754, avg_loss=0.07285]
[2018-11-23 10:40:41.222]  Step 254963  [22.460 sec/step, loss=0.07455, avg_loss=0.07290]
[2018-11-23 10:41:07.917]  Step 254964  [22.566 sec/step, loss=0.07440, avg_loss=0.07294]
[2018-11-23 10:41:21.746]  Step 254965  [22.353 sec/step, loss=0.07205, avg_loss=0.07291]
[2018-11-23 10:41:46.024]  Step 254966  [22.399 sec/step, loss=0.07482, avg_loss=0.07296]
[2018-11-23 10:42:07.576]  Step 254967  [22.379 sec/step, loss=0.07465, avg_loss=0.07300]
[2018-11-23 10:42:30.607]  Step 254968  [22.394 sec/step, loss=0.07464, avg_loss=0.07304]
[2018-11-23 10:42:51.550]  Step 254969  [22.362 sec/step, loss=0.07461, avg_loss=0.07307]
[2018-11-23 10:43:12.694]  Step 254970  [22.335 sec/step, loss=0.07457, avg_loss=0.07310]
[2018-11-23 10:43:27.964]  Step 254971  [22.185 sec/step, loss=0.07093, avg_loss=0.07306]
[2018-11-23 10:43:52.210]  Step 254972  [22.228 sec/step, loss=0.07479, avg_loss=0.07309]
[2018-11-23 10:44:16.392]  Step 254973  [22.268 sec/step, loss=0.07434, avg_loss=0.07312]
[2018-11-23 10:44:34.195]  Step 254974  [22.178 sec/step, loss=0.07352, avg_loss=0.07313]
[2018-11-23 10:44:53.968]  Step 254975  [22.131 sec/step, loss=0.07438, avg_loss=0.07315]
[2018-11-23 10:45:19.421]  Step 254976  [22.195 sec/step, loss=0.07530, avg_loss=0.07319]
[2018-11-23 10:45:39.411]  Step 254977  [22.153 sec/step, loss=0.07362, avg_loss=0.07320]
[2018-11-23 10:45:55.979]  Step 254978  [22.050 sec/step, loss=0.07211, avg_loss=0.07318]
[2018-11-23 10:46:05.648]  Generated 32 batches of size 32 in 8.823 sec
[2018-11-23 10:46:14.616]  Step 254979  [21.988 sec/step, loss=0.07360, avg_loss=0.07319]
[2018-11-23 10:46:38.599]  Step 254980  [22.024 sec/step, loss=0.07511, avg_loss=0.07322]
[2018-11-23 10:47:00.897]  Step 254981  [22.028 sec/step, loss=0.07399, avg_loss=0.07324]
[2018-11-23 10:47:22.472]  Step 254982  [22.021 sec/step, loss=0.07444, avg_loss=0.07326]
[2018-11-23 10:47:33.834]  Step 254983  [21.840 sec/step, loss=0.07082, avg_loss=0.07322]
[2018-11-23 10:47:52.274]  Step 254984  [21.783 sec/step, loss=0.07464, avg_loss=0.07324]
[2018-11-23 10:48:15.929]  Step 254985  [21.814 sec/step, loss=0.07568, avg_loss=0.07328]
[2018-11-23 10:48:24.316]  Step 254986  [21.597 sec/step, loss=0.05550, avg_loss=0.07299]
[2018-11-23 10:48:48.980]  Step 254987  [21.646 sec/step, loss=0.07452, avg_loss=0.07302]
[2018-11-23 10:49:10.001]  Step 254988  [21.636 sec/step, loss=0.07449, avg_loss=0.07304]
[2018-11-23 10:49:34.777]  Step 254989  [21.685 sec/step, loss=0.07472, avg_loss=0.07307]
[2018-11-23 10:49:55.207]  Step 254990  [21.666 sec/step, loss=0.07420, avg_loss=0.07308]
[2018-11-23 10:50:16.858]  Step 254991  [21.665 sec/step, loss=0.07487, avg_loss=0.07311]
[2018-11-23 10:50:35.296]  Step 254992  [21.618 sec/step, loss=0.07394, avg_loss=0.07312]
[2018-11-23 10:50:56.092]  Step 254993  [21.606 sec/step, loss=0.07367, avg_loss=0.07313]
[2018-11-23 10:51:20.305]  Step 254994  [21.643 sec/step, loss=0.07489, avg_loss=0.07315]
[2018-11-23 10:51:42.937]  Step 254995  [21.657 sec/step, loss=0.07430, avg_loss=0.07317]
[2018-11-23 10:51:58.506]  Step 254996  [21.573 sec/step, loss=0.07069, avg_loss=0.07314]
[2018-11-23 10:52:14.121]  Step 254997  [21.491 sec/step, loss=0.07217, avg_loss=0.07312]
[2018-11-23 10:52:54.338]  Step 254998  [21.744 sec/step, loss=0.06668, avg_loss=0.07304]
[2018-11-23 10:53:17.905]  Step 254999  [21.768 sec/step, loss=0.07494, avg_loss=0.07306]
[2018-11-23 10:53:35.202]  Step 255000  [21.709 sec/step, loss=0.07310, avg_loss=0.07306]
[2018-11-23 10:53:35.202]  Writing summary at step: 255000
[2018-11-23 10:53:49.590]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-255000
[2018-11-23 10:53:52.551]  Saving audio and alignment...
[2018-11-23 10:54:08.382]  Input: to the moods of the most minor scenes: in the winter lane near thornfield, the little brown birds, which stirred occasionally in the hedge, looked like single russet leaves that had forgotten to drop (chapter seven).~__________
[2018-11-23 10:54:20.654]  Step 255001  [21.587 sec/step, loss=0.06971, avg_loss=0.07302]
[2018-11-23 10:54:47.512]  Step 255002  [21.654 sec/step, loss=0.07459, avg_loss=0.07304]
[2018-11-23 10:55:11.687]  Step 255003  [21.686 sec/step, loss=0.07481, avg_loss=0.07306]
[2018-11-23 10:55:28.674]  Step 255004  [21.628 sec/step, loss=0.07342, avg_loss=0.07307]
[2018-11-23 10:55:53.418]  Step 255005  [21.666 sec/step, loss=0.07511, avg_loss=0.07309]
[2018-11-23 10:56:13.870]  Step 255006  [21.651 sec/step, loss=0.07446, avg_loss=0.07311]
[2018-11-23 10:56:38.636]  Step 255007  [21.689 sec/step, loss=0.07403, avg_loss=0.07312]
[2018-11-23 10:57:00.335]  Step 255008  [21.689 sec/step, loss=0.07402, avg_loss=0.07313]
[2018-11-23 10:57:11.462]  Generated 32 batches of size 32 in 10.280 sec
[2018-11-23 10:57:26.759]  Step 255009  [21.745 sec/step, loss=0.07486, avg_loss=0.07315]
[2018-11-23 10:57:49.039]  Step 255010  [21.751 sec/step, loss=0.07420, avg_loss=0.07316]
[2018-11-23 10:58:11.726]  Step 255011  [21.762 sec/step, loss=0.07488, avg_loss=0.07318]
[2018-11-23 10:58:22.179]  Step 255012  [21.633 sec/step, loss=0.06665, avg_loss=0.07311]
[2018-11-23 10:58:46.034]  Step 255013  [21.658 sec/step, loss=0.07432, avg_loss=0.07312]
[2018-11-23 10:58:54.405]  Step 255014  [21.510 sec/step, loss=0.05604, avg_loss=0.07293]
[2018-11-23 10:59:15.819]  Step 255015  [21.509 sec/step, loss=0.07482, avg_loss=0.07295]
[2018-11-23 10:59:34.889]  Step 255016  [21.483 sec/step, loss=0.07503, avg_loss=0.07297]
[2018-11-23 10:59:55.899]  Step 255017  [21.478 sec/step, loss=0.07403, avg_loss=0.07299]
[2018-11-23 11:00:17.580]  Step 255018  [21.480 sec/step, loss=0.07503, avg_loss=0.07301]
[2018-11-23 11:00:39.630]  Step 255019  [21.486 sec/step, loss=0.07503, avg_loss=0.07303]
[2018-11-23 11:00:59.937]  Step 255020  [21.474 sec/step, loss=0.07484, avg_loss=0.07305]
[2018-11-23 11:01:40.614]  Step 255021  [21.672 sec/step, loss=0.06607, avg_loss=0.07298]
[2018-11-23 11:02:05.123]  Step 255022  [21.701 sec/step, loss=0.07456, avg_loss=0.07299]
[2018-11-23 11:02:29.573]  Step 255023  [21.728 sec/step, loss=0.07516, avg_loss=0.07301]
[2018-11-23 11:02:54.015]  Step 255024  [21.755 sec/step, loss=0.07523, avg_loss=0.07304]
[2018-11-23 11:03:15.816]  Step 255025  [21.552 sec/step, loss=0.07373, avg_loss=0.07302]
[2018-11-23 11:03:26.285]  Step 255026  [21.395 sec/step, loss=0.06726, avg_loss=0.07295]
[2018-11-23 11:03:42.399]  Step 255027  [21.340 sec/step, loss=0.07047, avg_loss=0.07292]
[2018-11-23 11:03:54.709]  Step 255028  [21.356 sec/step, loss=0.07022, avg_loss=0.07306]
[2018-11-23 11:04:13.329]  Step 255029  [21.292 sec/step, loss=0.07466, avg_loss=0.07307]
[2018-11-23 11:04:35.814]  Step 255030  [21.297 sec/step, loss=0.07431, avg_loss=0.07307]
[2018-11-23 11:05:00.537]  Step 255031  [21.320 sec/step, loss=0.07428, avg_loss=0.07306]
[2018-11-23 11:05:20.760]  Step 255032  [21.291 sec/step, loss=0.07385, avg_loss=0.07305]
[2018-11-23 11:05:29.489]  Step 255033  [21.139 sec/step, loss=0.05581, avg_loss=0.07286]
[2018-11-23 11:05:51.807]  Step 255034  [21.117 sec/step, loss=0.07472, avg_loss=0.07286]
[2018-11-23 11:06:14.349]  Step 255035  [21.179 sec/step, loss=0.07348, avg_loss=0.07288]
[2018-11-23 11:06:34.177]  Step 255036  [20.976 sec/step, loss=0.07397, avg_loss=0.07296]
[2018-11-23 11:06:57.766]  Step 255037  [21.028 sec/step, loss=0.07498, avg_loss=0.07297]
[2018-11-23 11:07:15.371]  Step 255038  [21.097 sec/step, loss=0.07372, avg_loss=0.07303]
[2018-11-23 11:07:33.579]  Step 255039  [21.027 sec/step, loss=0.07319, avg_loss=0.07302]
[2018-11-23 11:07:54.201]  Step 255040  [21.104 sec/step, loss=0.07447, avg_loss=0.07305]
[2018-11-23 11:08:03.581]  Generated 32 batches of size 32 in 8.637 sec
[2018-11-23 11:08:11.512]  Step 255041  [21.052 sec/step, loss=0.07227, avg_loss=0.07303]
[2018-11-23 11:08:25.365]  Step 255042  [20.992 sec/step, loss=0.07228, avg_loss=0.07301]
[2018-11-23 11:08:47.642]  Step 255043  [21.049 sec/step, loss=0.07449, avg_loss=0.07303]
[2018-11-23 11:09:09.385]  Step 255044  [21.012 sec/step, loss=0.07477, avg_loss=0.07303]
[2018-11-23 11:09:35.701]  Step 255045  [21.081 sec/step, loss=0.07419, avg_loss=0.07304]
[2018-11-23 11:09:54.561]  Step 255046  [21.018 sec/step, loss=0.07348, avg_loss=0.07303]
[2018-11-23 11:10:18.366]  Step 255047  [21.114 sec/step, loss=0.07425, avg_loss=0.07305]
[2018-11-23 11:10:48.619]  Step 255048  [21.178 sec/step, loss=0.07544, avg_loss=0.07306]
[2018-11-23 11:11:20.285]  Step 255049  [21.235 sec/step, loss=0.07437, avg_loss=0.07305]
[2018-11-23 11:11:42.608]  Step 255050  [21.273 sec/step, loss=0.07395, avg_loss=0.07304]
[2018-11-23 11:11:42.608]  Writing summary at step: 255050
[2018-11-23 11:12:26.718]  Step 255051  [21.283 sec/step, loss=0.07404, avg_loss=0.07303]
[2018-11-23 11:12:50.521]  Step 255052  [21.343 sec/step, loss=0.07473, avg_loss=0.07305]
[2018-11-23 11:13:10.424]  Step 255053  [21.297 sec/step, loss=0.07333, avg_loss=0.07303]
[2018-11-23 11:13:28.918]  Step 255054  [21.278 sec/step, loss=0.07441, avg_loss=0.07303]
[2018-11-23 11:13:49.499]  Step 255055  [21.199 sec/step, loss=0.07437, avg_loss=0.07303]
[2018-11-23 11:14:00.040]  Step 255056  [21.089 sec/step, loss=0.06635, avg_loss=0.07296]
[2018-11-23 11:14:25.520]  Step 255057  [21.152 sec/step, loss=0.07501, avg_loss=0.07297]
[2018-11-23 11:14:43.685]  Step 255058  [20.913 sec/step, loss=0.07311, avg_loss=0.07304]
[2018-11-23 11:14:52.409]  Step 255059  [20.749 sec/step, loss=0.05297, avg_loss=0.07282]
[2018-11-23 11:15:14.881]  Step 255060  [20.748 sec/step, loss=0.07420, avg_loss=0.07282]
[2018-11-23 11:15:37.704]  Step 255061  [20.747 sec/step, loss=0.07441, avg_loss=0.07282]
[2018-11-23 11:16:01.973]  Step 255062  [20.886 sec/step, loss=0.07526, avg_loss=0.07290]
[2018-11-23 11:16:19.808]  Step 255063  [20.838 sec/step, loss=0.07364, avg_loss=0.07289]
[2018-11-23 11:16:35.712]  Step 255064  [20.730 sec/step, loss=0.07054, avg_loss=0.07285]
[2018-11-23 11:17:18.666]  Step 255065  [21.022 sec/step, loss=0.06620, avg_loss=0.07279]
[2018-11-23 11:17:44.949]  Step 255066  [21.042 sec/step, loss=0.07398, avg_loss=0.07278]
[2018-11-23 11:18:05.453]  Step 255067  [21.031 sec/step, loss=0.07426, avg_loss=0.07278]
[2018-11-23 11:18:30.042]  Step 255068  [21.047 sec/step, loss=0.07540, avg_loss=0.07279]
[2018-11-23 11:18:52.043]  Step 255069  [21.057 sec/step, loss=0.07468, avg_loss=0.07279]
[2018-11-23 11:19:11.522]  Step 255070  [21.041 sec/step, loss=0.07448, avg_loss=0.07279]
[2018-11-23 11:19:35.672]  Step 255071  [21.130 sec/step, loss=0.07434, avg_loss=0.07282]
[2018-11-23 11:19:45.379]  Generated 32 batches of size 32 in 8.741 sec
[2018-11-23 11:20:01.186]  Step 255072  [21.142 sec/step, loss=0.07514, avg_loss=0.07283]
[2018-11-23 11:20:25.604]  Step 255073  [21.145 sec/step, loss=0.07456, avg_loss=0.07283]
[2018-11-23 11:20:48.149]  Step 255074  [21.192 sec/step, loss=0.07470, avg_loss=0.07284]
[2018-11-23 11:21:03.546]  Step 255075  [21.148 sec/step, loss=0.07213, avg_loss=0.07282]
[2018-11-23 11:21:22.188]  Step 255076  [21.080 sec/step, loss=0.07381, avg_loss=0.07280]
[2018-11-23 11:21:46.223]  Step 255077  [21.121 sec/step, loss=0.07428, avg_loss=0.07281]
[2018-11-23 11:21:58.031]  Step 255078  [21.073 sec/step, loss=0.07050, avg_loss=0.07279]
[2018-11-23 11:22:20.805]  Step 255079  [21.114 sec/step, loss=0.07478, avg_loss=0.07280]
[2018-11-23 11:22:34.753]  Step 255080  [21.014 sec/step, loss=0.07140, avg_loss=0.07277]
[2018-11-23 11:22:46.910]  Step 255081  [20.913 sec/step, loss=0.06989, avg_loss=0.07273]
[2018-11-23 11:23:09.763]  Step 255082  [20.925 sec/step, loss=0.07496, avg_loss=0.07273]
[2018-11-23 11:23:46.412]  Step 255083  [21.178 sec/step, loss=0.06590, avg_loss=0.07268]
[2018-11-23 11:24:07.877]  Step 255084  [21.209 sec/step, loss=0.07419, avg_loss=0.07268]
[2018-11-23 11:24:33.996]  Step 255085  [21.233 sec/step, loss=0.07410, avg_loss=0.07266]
[2018-11-23 11:24:56.136]  Step 255086  [21.371 sec/step, loss=0.07404, avg_loss=0.07285]
[2018-11-23 11:25:11.851]  Step 255087  [21.281 sec/step, loss=0.07043, avg_loss=0.07281]
[2018-11-23 11:25:33.371]  Step 255088  [21.286 sec/step, loss=0.07424, avg_loss=0.07280]
[2018-11-23 11:25:58.483]  Step 255089  [21.290 sec/step, loss=0.07439, avg_loss=0.07280]
[2018-11-23 11:26:19.279]  Step 255090  [21.293 sec/step, loss=0.07456, avg_loss=0.07280]
[2018-11-23 11:26:39.606]  Step 255091  [21.280 sec/step, loss=0.07438, avg_loss=0.07280]
[2018-11-23 11:26:58.698]  Step 255092  [21.287 sec/step, loss=0.07346, avg_loss=0.07279]
[2018-11-23 11:27:21.617]  Step 255093  [21.308 sec/step, loss=0.07506, avg_loss=0.07281]
[2018-11-23 11:27:45.823]  Step 255094  [21.308 sec/step, loss=0.07474, avg_loss=0.07281]
[2018-11-23 11:27:59.456]  Step 255095  [21.218 sec/step, loss=0.07191, avg_loss=0.07278]
[2018-11-23 11:28:18.596]  Step 255096  [21.253 sec/step, loss=0.07357, avg_loss=0.07281]
[2018-11-23 11:28:42.340]  Step 255097  [21.335 sec/step, loss=0.07410, avg_loss=0.07283]
[2018-11-23 11:28:59.985]  Step 255098  [21.109 sec/step, loss=0.07303, avg_loss=0.07289]
[2018-11-23 11:29:24.177]  Step 255099  [21.115 sec/step, loss=0.07494, avg_loss=0.07289]
[2018-11-23 11:29:42.106]  Step 255100  [21.122 sec/step, loss=0.07321, avg_loss=0.07290]
[2018-11-23 11:29:42.106]  Writing summary at step: 255100
[2018-11-23 11:30:14.985]  Step 255101  [21.101 sec/step, loss=0.06666, avg_loss=0.07287]
[2018-11-23 11:30:37.705]  Step 255102  [21.060 sec/step, loss=0.07502, avg_loss=0.07287]
[2018-11-23 11:30:48.187]  Generated 32 batches of size 32 in 9.453 sec
[2018-11-23 11:30:55.821]  Step 255103  [20.999 sec/step, loss=0.07194, avg_loss=0.07284]
[2018-11-23 11:31:19.802]  Step 255104  [21.069 sec/step, loss=0.07433, avg_loss=0.07285]
[2018-11-23 11:31:40.551]  Step 255105  [21.029 sec/step, loss=0.07477, avg_loss=0.07285]
[2018-11-23 11:31:59.113]  Step 255106  [21.010 sec/step, loss=0.07447, avg_loss=0.07285]
[2018-11-23 11:32:19.146]  Step 255107  [20.963 sec/step, loss=0.07420, avg_loss=0.07285]
[2018-11-23 11:32:27.488]  Step 255108  [20.830 sec/step, loss=0.05617, avg_loss=0.07267]
[2018-11-23 11:32:49.593]  Step 255109  [20.786 sec/step, loss=0.07477, avg_loss=0.07267]
[2018-11-23 11:33:14.596]  Step 255110  [20.814 sec/step, loss=0.07499, avg_loss=0.07268]
[2018-11-23 11:33:38.679]  Step 255111  [20.828 sec/step, loss=0.07480, avg_loss=0.07268]
[2018-11-23 11:33:54.163]  Step 255112  [20.878 sec/step, loss=0.07182, avg_loss=0.07273]
[2018-11-23 11:34:11.854]  Step 255113  [20.816 sec/step, loss=0.07296, avg_loss=0.07272]
[2018-11-23 11:34:30.578]  Step 255114  [20.920 sec/step, loss=0.07389, avg_loss=0.07289]
[2018-11-23 11:34:50.106]  Step 255115  [20.901 sec/step, loss=0.07406, avg_loss=0.07289]
[2018-11-23 11:35:12.355]  Step 255116  [20.933 sec/step, loss=0.07457, avg_loss=0.07288]
[2018-11-23 11:35:33.176]  Step 255117  [20.931 sec/step, loss=0.07429, avg_loss=0.07288]
[2018-11-23 11:35:50.131]  Step 255118  [20.884 sec/step, loss=0.07330, avg_loss=0.07287]
[2018-11-23 11:35:58.724]  Step 255119  [20.749 sec/step, loss=0.05540, avg_loss=0.07267]
[2018-11-23 11:36:19.210]  Step 255120  [20.751 sec/step, loss=0.07405, avg_loss=0.07266]
[2018-11-23 11:36:41.531]  Step 255121  [20.567 sec/step, loss=0.07371, avg_loss=0.07274]
[2018-11-23 11:37:05.228]  Step 255122  [20.559 sec/step, loss=0.07416, avg_loss=0.07273]
[2018-11-23 11:37:26.931]  Step 255123  [20.532 sec/step, loss=0.07449, avg_loss=0.07273]
[2018-11-23 11:37:50.012]  Step 255124  [20.518 sec/step, loss=0.07453, avg_loss=0.07272]
[2018-11-23 11:38:13.761]  Step 255125  [20.537 sec/step, loss=0.07411, avg_loss=0.07272]
[2018-11-23 11:38:28.153]  Step 255126  [20.577 sec/step, loss=0.07181, avg_loss=0.07277]
[2018-11-23 11:38:52.887]  Step 255127  [20.663 sec/step, loss=0.07550, avg_loss=0.07282]
[2018-11-23 11:39:08.867]  Step 255128  [20.700 sec/step, loss=0.07058, avg_loss=0.07282]
[2018-11-23 11:39:34.891]  Step 255129  [20.774 sec/step, loss=0.07428, avg_loss=0.07282]
[2018-11-23 11:39:55.177]  Step 255130  [20.752 sec/step, loss=0.07488, avg_loss=0.07283]
[2018-11-23 11:40:14.750]  Step 255131  [20.700 sec/step, loss=0.07345, avg_loss=0.07282]
[2018-11-23 11:40:39.555]  Step 255132  [20.746 sec/step, loss=0.07494, avg_loss=0.07283]
[2018-11-23 11:40:58.675]  Step 255133  [20.850 sec/step, loss=0.07430, avg_loss=0.07301]
[2018-11-23 11:41:09.112]  Step 255134  [20.731 sec/step, loss=0.06651, avg_loss=0.07293]
[2018-11-23 11:41:18.861]  Generated 32 batches of size 32 in 8.966 sec
[2018-11-23 11:41:32.727]  Step 255135  [20.742 sec/step, loss=0.07472, avg_loss=0.07294]
[2018-11-23 11:41:54.565]  Step 255136  [20.762 sec/step, loss=0.07469, avg_loss=0.07295]
[2018-11-23 11:42:36.665]  Step 255137  [20.947 sec/step, loss=0.06587, avg_loss=0.07286]
[2018-11-23 11:43:01.292]  Step 255138  [21.017 sec/step, loss=0.07451, avg_loss=0.07287]
[2018-11-23 11:43:25.735]  Step 255139  [21.080 sec/step, loss=0.07451, avg_loss=0.07288]
[2018-11-23 11:43:37.802]  Step 255140  [20.994 sec/step, loss=0.06955, avg_loss=0.07283]
[2018-11-23 11:44:00.935]  Step 255141  [21.052 sec/step, loss=0.07459, avg_loss=0.07286]
[2018-11-23 11:44:25.582]  Step 255142  [21.160 sec/step, loss=0.07548, avg_loss=0.07289]
[2018-11-23 11:44:49.926]  Step 255143  [21.181 sec/step, loss=0.07487, avg_loss=0.07289]
[2018-11-23 11:45:12.232]  Step 255144  [21.186 sec/step, loss=0.07444, avg_loss=0.07289]
[2018-11-23 11:45:34.312]  Step 255145  [21.144 sec/step, loss=0.07399, avg_loss=0.07289]
[2018-11-23 11:45:59.067]  Step 255146  [21.203 sec/step, loss=0.07458, avg_loss=0.07290]
[2018-11-23 11:46:24.226]  Step 255147  [21.217 sec/step, loss=0.07527, avg_loss=0.07291]
[2018-11-23 11:46:42.853]  Step 255148  [21.100 sec/step, loss=0.07391, avg_loss=0.07289]
[2018-11-23 11:46:53.376]  Step 255149  [20.889 sec/step, loss=0.06552, avg_loss=0.07280]
[2018-11-23 11:47:10.867]  Step 255150  [20.841 sec/step, loss=0.07416, avg_loss=0.07281]
[2018-11-23 11:47:10.867]  Writing summary at step: 255150
[2018-11-23 11:47:58.825]  Step 255151  [20.848 sec/step, loss=0.07430, avg_loss=0.07281]
[2018-11-23 11:48:16.984]  Step 255152  [20.792 sec/step, loss=0.07277, avg_loss=0.07279]
[2018-11-23 11:48:41.416]  Step 255153  [20.837 sec/step, loss=0.07514, avg_loss=0.07281]
[2018-11-23 11:49:01.134]  Step 255154  [20.849 sec/step, loss=0.07438, avg_loss=0.07281]
[2018-11-23 11:49:21.221]  Step 255155  [20.844 sec/step, loss=0.07376, avg_loss=0.07280]
[2018-11-23 11:49:29.656]  Step 255156  [20.823 sec/step, loss=0.05596, avg_loss=0.07270]
[2018-11-23 11:49:48.251]  Step 255157  [20.754 sec/step, loss=0.07397, avg_loss=0.07269]
[2018-11-23 11:50:02.412]  Step 255158  [20.714 sec/step, loss=0.07101, avg_loss=0.07266]
[2018-11-23 11:50:14.630]  Step 255159  [20.749 sec/step, loss=0.06930, avg_loss=0.07283]
[2018-11-23 11:50:37.468]  Step 255160  [20.753 sec/step, loss=0.07509, avg_loss=0.07284]
[2018-11-23 11:50:55.168]  Step 255161  [20.702 sec/step, loss=0.07224, avg_loss=0.07282]
[2018-11-23 11:51:20.102]  Step 255162  [20.708 sec/step, loss=0.07429, avg_loss=0.07281]
[2018-11-23 11:51:41.756]  Step 255163  [20.746 sec/step, loss=0.07507, avg_loss=0.07282]
[2018-11-23 11:51:57.552]  Step 255164  [20.745 sec/step, loss=0.07041, avg_loss=0.07282]
[2018-11-23 11:52:18.026]  Step 255165  [20.520 sec/step, loss=0.07457, avg_loss=0.07290]
[2018-11-23 11:52:27.100]  Generated 32 batches of size 32 in 8.336 sec
[2018-11-23 11:52:40.539]  Step 255166  [20.483 sec/step, loss=0.07437, avg_loss=0.07291]
[2018-11-23 11:53:04.088]  Step 255167  [20.513 sec/step, loss=0.07439, avg_loss=0.07291]
[2018-11-23 11:53:26.949]  Step 255168  [20.496 sec/step, loss=0.07463, avg_loss=0.07290]
[2018-11-23 11:53:49.960]  Step 255169  [20.506 sec/step, loss=0.07479, avg_loss=0.07290]
[2018-11-23 11:54:16.138]  Step 255170  [20.573 sec/step, loss=0.07425, avg_loss=0.07290]
[2018-11-23 11:54:40.491]  Step 255171  [20.575 sec/step, loss=0.07467, avg_loss=0.07290]
[2018-11-23 11:55:21.438]  Step 255172  [20.729 sec/step, loss=0.06608, avg_loss=0.07281]
[2018-11-23 11:55:41.861]  Step 255173  [20.689 sec/step, loss=0.07443, avg_loss=0.07281]
[2018-11-23 11:56:03.497]  Step 255174  [20.680 sec/step, loss=0.07390, avg_loss=0.07280]
[2018-11-23 11:56:21.206]  Step 255175  [20.703 sec/step, loss=0.07328, avg_loss=0.07281]
[2018-11-23 11:56:44.729]  Step 255176  [20.752 sec/step, loss=0.07428, avg_loss=0.07282]
[2018-11-23 11:57:03.385]  Step 255177  [20.699 sec/step, loss=0.07506, avg_loss=0.07283]
[2018-11-23 11:57:15.706]  Step 255178  [20.704 sec/step, loss=0.07030, avg_loss=0.07282]
[2018-11-23 11:57:37.630]  Step 255179  [20.695 sec/step, loss=0.07471, avg_loss=0.07282]
[2018-11-23 11:57:57.698]  Step 255180  [20.756 sec/step, loss=0.07364, avg_loss=0.07285]
[2018-11-23 11:58:18.730]  Step 255181  [20.845 sec/step, loss=0.07510, avg_loss=0.07290]
[2018-11-23 11:58:29.205]  Step 255182  [20.721 sec/step, loss=0.06710, avg_loss=0.07282]
[2018-11-23 11:58:51.320]  Step 255183  [20.576 sec/step, loss=0.07437, avg_loss=0.07290]
[2018-11-23 11:59:10.649]  Step 255184  [20.555 sec/step, loss=0.07376, avg_loss=0.07290]
[2018-11-23 11:59:29.260]  Step 255185  [20.480 sec/step, loss=0.07339, avg_loss=0.07289]
[2018-11-23 11:59:53.596]  Step 255186  [20.501 sec/step, loss=0.07460, avg_loss=0.07290]
[2018-11-23 12:00:18.506]  Step 255187  [20.593 sec/step, loss=0.07523, avg_loss=0.07295]
[2018-11-23 12:00:43.506]  Step 255188  [20.628 sec/step, loss=0.07376, avg_loss=0.07294]
[2018-11-23 12:01:01.140]  Step 255189  [20.553 sec/step, loss=0.07343, avg_loss=0.07293]
[2018-11-23 12:01:42.101]  Step 255190  [20.755 sec/step, loss=0.06545, avg_loss=0.07284]
[2018-11-23 12:02:05.745]  Step 255191  [20.788 sec/step, loss=0.07412, avg_loss=0.07284]
[2018-11-23 12:02:31.382]  Step 255192  [20.854 sec/step, loss=0.07439, avg_loss=0.07285]
[2018-11-23 12:02:56.272]  Step 255193  [20.873 sec/step, loss=0.07449, avg_loss=0.07284]
[2018-11-23 12:03:16.828]  Step 255194  [20.837 sec/step, loss=0.07366, avg_loss=0.07283]
[2018-11-23 12:03:25.705]  Step 255195  [20.789 sec/step, loss=0.05356, avg_loss=0.07265]
[2018-11-23 12:03:39.980]  Step 255196  [20.741 sec/step, loss=0.07128, avg_loss=0.07262]
[2018-11-23 12:04:00.676]  Step 255197  [20.710 sec/step, loss=0.07485, avg_loss=0.07263]
[2018-11-23 12:04:12.947]  Generated 32 batches of size 32 in 11.336 sec
[2018-11-23 12:04:28.172]  Step 255198  [20.809 sec/step, loss=0.07544, avg_loss=0.07266]
[2018-11-23 12:04:43.796]  Step 255199  [20.723 sec/step, loss=0.07147, avg_loss=0.07262]
[2018-11-23 12:05:07.752]  Step 255200  [20.783 sec/step, loss=0.07483, avg_loss=0.07264]
[2018-11-23 12:05:07.752]  Writing summary at step: 255200
[2018-11-23 12:06:01.920]  Step 255201  [20.956 sec/step, loss=0.07433, avg_loss=0.07271]
[2018-11-23 12:06:23.770]  Step 255202  [20.947 sec/step, loss=0.07461, avg_loss=0.07271]
[2018-11-23 12:06:48.111]  Step 255203  [21.009 sec/step, loss=0.07456, avg_loss=0.07274]
[2018-11-23 12:07:04.033]  Step 255204  [20.929 sec/step, loss=0.07210, avg_loss=0.07271]
[2018-11-23 12:07:29.605]  Step 255205  [20.977 sec/step, loss=0.07509, avg_loss=0.07272]
[2018-11-23 12:07:45.097]  Step 255206  [20.946 sec/step, loss=0.07033, avg_loss=0.07268]
[2018-11-23 12:08:03.694]  Step 255207  [20.932 sec/step, loss=0.07388, avg_loss=0.07267]
[2018-11-23 12:08:25.109]  Step 255208  [21.062 sec/step, loss=0.07462, avg_loss=0.07286]
[2018-11-23 12:08:48.920]  Step 255209  [21.080 sec/step, loss=0.07375, avg_loss=0.07285]
[2018-11-23 12:09:11.661]  Step 255210  [21.057 sec/step, loss=0.07451, avg_loss=0.07284]
[2018-11-23 12:09:34.941]  Step 255211  [21.049 sec/step, loss=0.07443, avg_loss=0.07284]
[2018-11-23 12:09:51.365]  Step 255212  [21.058 sec/step, loss=0.07166, avg_loss=0.07284]
[2018-11-23 12:10:09.062]  Step 255213  [21.058 sec/step, loss=0.07282, avg_loss=0.07283]
[2018-11-23 12:10:26.420]  Step 255214  [21.045 sec/step, loss=0.07333, avg_loss=0.07283]
[2018-11-23 12:10:49.040]  Step 255215  [21.076 sec/step, loss=0.07447, avg_loss=0.07283]
[2018-11-23 12:11:39.522]  Step 255216  [21.358 sec/step, loss=0.06609, avg_loss=0.07275]
[2018-11-23 12:12:04.303]  Step 255217  [21.398 sec/step, loss=0.07388, avg_loss=0.07274]
[2018-11-23 12:12:13.001]  Step 255218  [21.315 sec/step, loss=0.05389, avg_loss=0.07255]
[2018-11-23 12:12:33.716]  Step 255219  [21.436 sec/step, loss=0.07421, avg_loss=0.07274]
[2018-11-23 12:12:56.901]  Step 255220  [21.463 sec/step, loss=0.07475, avg_loss=0.07275]
[2018-11-23 12:13:21.572]  Step 255221  [21.487 sec/step, loss=0.07444, avg_loss=0.07275]
[2018-11-23 12:13:32.342]  Step 255222  [21.357 sec/step, loss=0.06715, avg_loss=0.07268]
[2018-11-23 12:13:56.768]  Step 255223  [21.385 sec/step, loss=0.07439, avg_loss=0.07268]
[2018-11-23 12:14:23.386]  Step 255224  [21.420 sec/step, loss=0.07408, avg_loss=0.07268]
[2018-11-23 12:14:43.761]  Step 255225  [21.386 sec/step, loss=0.07422, avg_loss=0.07268]
[2018-11-23 12:15:02.785]  Step 255226  [21.433 sec/step, loss=0.07422, avg_loss=0.07270]
[2018-11-23 12:15:22.925]  Step 255227  [21.387 sec/step, loss=0.07374, avg_loss=0.07268]
[2018-11-23 12:15:45.540]  Step 255228  [21.453 sec/step, loss=0.07385, avg_loss=0.07272]
[2018-11-23 12:15:54.789]  Generated 32 batches of size 32 in 8.354 sec
[2018-11-23 12:16:07.941]  Step 255229  [21.417 sec/step, loss=0.07401, avg_loss=0.07271]
[2018-11-23 12:16:26.814]  Step 255230  [21.403 sec/step, loss=0.07389, avg_loss=0.07270]
[2018-11-23 12:16:51.747]  Step 255231  [21.456 sec/step, loss=0.07424, avg_loss=0.07271]
[2018-11-23 12:17:16.452]  Step 255232  [21.455 sec/step, loss=0.07492, avg_loss=0.07271]
[2018-11-23 12:17:30.468]  Step 255233  [21.404 sec/step, loss=0.07094, avg_loss=0.07268]
[2018-11-23 12:17:42.418]  Step 255234  [21.419 sec/step, loss=0.07067, avg_loss=0.07272]
[2018-11-23 12:18:04.419]  Step 255235  [21.403 sec/step, loss=0.07424, avg_loss=0.07272]
[2018-11-23 12:18:29.543]  Step 255236  [21.436 sec/step, loss=0.07456, avg_loss=0.07271]
[2018-11-23 12:18:52.027]  Step 255237  [21.240 sec/step, loss=0.07493, avg_loss=0.07281]
[2018-11-23 12:19:11.068]  Step 255238  [21.184 sec/step, loss=0.07421, avg_loss=0.07280]
[2018-11-23 12:19:51.864]  Step 255239  [21.348 sec/step, loss=0.06561, avg_loss=0.07271]
[2018-11-23 12:20:07.329]  Step 255240  [21.382 sec/step, loss=0.07208, avg_loss=0.07274]
[2018-11-23 12:20:31.981]  Step 255241  [21.397 sec/step, loss=0.07470, avg_loss=0.07274]
[2018-11-23 12:20:52.643]  Step 255242  [21.357 sec/step, loss=0.07400, avg_loss=0.07272]
[2018-11-23 12:21:13.040]  Step 255243  [21.317 sec/step, loss=0.07425, avg_loss=0.07272]
[2018-11-23 12:21:35.249]  Step 255244  [21.316 sec/step, loss=0.07373, avg_loss=0.07271]
[2018-11-23 12:21:55.084]  Step 255245  [21.294 sec/step, loss=0.07314, avg_loss=0.07270]
[2018-11-23 12:22:12.054]  Step 255246  [21.216 sec/step, loss=0.07387, avg_loss=0.07270]
[2018-11-23 12:22:36.818]  Step 255247  [21.212 sec/step, loss=0.07481, avg_loss=0.07269]
[2018-11-23 12:23:01.406]  Step 255248  [21.272 sec/step, loss=0.07423, avg_loss=0.07269]
[2018-11-23 12:23:26.480]  Step 255249  [21.417 sec/step, loss=0.07483, avg_loss=0.07279]
[2018-11-23 12:23:48.274]  Step 255250  [21.460 sec/step, loss=0.07378, avg_loss=0.07278]
[2018-11-23 12:23:48.274]  Writing summary at step: 255250
[2018-11-23 12:24:28.481]  Step 255251  [21.365 sec/step, loss=0.07095, avg_loss=0.07275]
[2018-11-23 12:24:51.565]  Step 255252  [21.414 sec/step, loss=0.07404, avg_loss=0.07276]
[2018-11-23 12:25:12.965]  Step 255253  [21.384 sec/step, loss=0.07445, avg_loss=0.07276]
[2018-11-23 12:25:37.828]  Step 255254  [21.435 sec/step, loss=0.07446, avg_loss=0.07276]
[2018-11-23 12:25:47.435]  Step 255255  [21.331 sec/step, loss=0.05518, avg_loss=0.07257]
[2018-11-23 12:26:10.728]  Step 255256  [21.479 sec/step, loss=0.07423, avg_loss=0.07275]
[2018-11-23 12:26:33.983]  Step 255257  [21.526 sec/step, loss=0.07481, avg_loss=0.07276]
[2018-11-23 12:26:56.887]  Step 255258  [21.613 sec/step, loss=0.07497, avg_loss=0.07280]
[2018-11-23 12:27:07.282]  Step 255259  [21.595 sec/step, loss=0.06646, avg_loss=0.07277]
[2018-11-23 12:27:18.354]  Generated 32 batches of size 32 in 10.271 sec
[2018-11-23 12:27:33.848]  Step 255260  [21.632 sec/step, loss=0.07387, avg_loss=0.07276]
[2018-11-23 12:27:56.476]  Step 255261  [21.682 sec/step, loss=0.07472, avg_loss=0.07279]
[2018-11-23 12:28:20.909]  Step 255262  [21.677 sec/step, loss=0.07436, avg_loss=0.07279]
[2018-11-23 12:28:39.870]  Step 255263  [21.650 sec/step, loss=0.07358, avg_loss=0.07277]
[2018-11-23 12:28:52.284]  Step 255264  [21.616 sec/step, loss=0.06961, avg_loss=0.07276]
[2018-11-23 12:29:10.704]  Step 255265  [21.595 sec/step, loss=0.07379, avg_loss=0.07276]
[2018-11-23 12:29:26.231]  Step 255266  [21.525 sec/step, loss=0.07038, avg_loss=0.07272]
[2018-11-23 12:29:44.230]  Step 255267  [21.470 sec/step, loss=0.07292, avg_loss=0.07270]
[2018-11-23 12:30:04.850]  Step 255268  [21.448 sec/step, loss=0.07469, avg_loss=0.07270]
[2018-11-23 12:30:49.173]  Step 255269  [21.661 sec/step, loss=0.06566, avg_loss=0.07261]
[2018-11-23 12:31:11.717]  Step 255270  [21.624 sec/step, loss=0.07438, avg_loss=0.07261]
[2018-11-23 12:31:24.245]  Step 255271  [21.506 sec/step, loss=0.06975, avg_loss=0.07256]
[2018-11-23 12:31:33.147]  Step 255272  [21.186 sec/step, loss=0.05533, avg_loss=0.07246]
[2018-11-23 12:31:56.476]  Step 255273  [21.215 sec/step, loss=0.07412, avg_loss=0.07245]
[2018-11-23 12:32:18.329]  Step 255274  [21.217 sec/step, loss=0.07420, avg_loss=0.07246]
[2018-11-23 12:32:36.665]  Step 255275  [21.223 sec/step, loss=0.07437, avg_loss=0.07247]
[2018-11-23 12:32:51.181]  Step 255276  [21.133 sec/step, loss=0.07201, avg_loss=0.07244]
[2018-11-23 12:33:08.311]  Step 255277  [21.118 sec/step, loss=0.07319, avg_loss=0.07242]
[2018-11-23 12:33:32.672]  Step 255278  [21.238 sec/step, loss=0.07481, avg_loss=0.07247]
[2018-11-23 12:33:54.459]  Step 255279  [21.237 sec/step, loss=0.07416, avg_loss=0.07246]
[2018-11-23 12:34:17.056]  Step 255280  [21.262 sec/step, loss=0.07419, avg_loss=0.07247]
[2018-11-23 12:34:35.066]  Step 255281  [21.232 sec/step, loss=0.07270, avg_loss=0.07245]
[2018-11-23 12:34:56.098]  Step 255282  [21.337 sec/step, loss=0.07415, avg_loss=0.07252]
[2018-11-23 12:35:18.321]  Step 255283  [21.339 sec/step, loss=0.07366, avg_loss=0.07251]
[2018-11-23 12:35:42.891]  Step 255284  [21.391 sec/step, loss=0.07444, avg_loss=0.07252]
[2018-11-23 12:36:02.198]  Step 255285  [21.398 sec/step, loss=0.07340, avg_loss=0.07252]
[2018-11-23 12:36:27.799]  Step 255286  [21.411 sec/step, loss=0.07508, avg_loss=0.07252]
[2018-11-23 12:36:46.371]  Step 255287  [21.347 sec/step, loss=0.07238, avg_loss=0.07249]
[2018-11-23 12:37:12.952]  Step 255288  [21.363 sec/step, loss=0.07427, avg_loss=0.07250]
[2018-11-23 12:37:23.389]  Step 255289  [21.291 sec/step, loss=0.06630, avg_loss=0.07243]
[2018-11-23 12:37:46.554]  Step 255290  [21.113 sec/step, loss=0.07459, avg_loss=0.07252]
[2018-11-23 12:38:11.280]  Step 255291  [21.124 sec/step, loss=0.07414, avg_loss=0.07252]
[2018-11-23 12:38:20.232]  Generated 32 batches of size 32 in 8.155 sec
[2018-11-23 12:38:32.549]  Step 255292  [21.080 sec/step, loss=0.07359, avg_loss=0.07251]
[2018-11-23 12:38:57.693]  Step 255293  [21.083 sec/step, loss=0.07524, avg_loss=0.07252]
[2018-11-23 12:39:18.015]  Step 255294  [21.080 sec/step, loss=0.07371, avg_loss=0.07252]
[2018-11-23 12:39:37.280]  Step 255295  [21.184 sec/step, loss=0.07379, avg_loss=0.07272]
[2018-11-23 12:40:00.462]  Step 255296  [21.273 sec/step, loss=0.07429, avg_loss=0.07275]
[2018-11-23 12:40:21.199]  Step 255297  [21.274 sec/step, loss=0.07458, avg_loss=0.07275]
[2018-11-23 12:40:46.371]  Step 255298  [21.251 sec/step, loss=0.07402, avg_loss=0.07273]
[2018-11-23 12:41:02.323]  Step 255299  [21.254 sec/step, loss=0.07131, avg_loss=0.07273]
[2018-11-23 12:41:23.912]  Step 255300  [21.230 sec/step, loss=0.07436, avg_loss=0.07273]
[2018-11-23 12:41:23.912]  Writing summary at step: 255300
[2018-11-23 12:42:05.110]  Step 255301  [21.146 sec/step, loss=0.07347, avg_loss=0.07272]
[2018-11-23 12:42:23.788]  Step 255302  [21.115 sec/step, loss=0.07374, avg_loss=0.07271]
[2018-11-23 12:42:49.032]  Step 255303  [21.124 sec/step, loss=0.07475, avg_loss=0.07271]
[2018-11-23 12:43:13.409]  Step 255304  [21.208 sec/step, loss=0.07480, avg_loss=0.07274]
[2018-11-23 12:43:32.911]  Step 255305  [21.148 sec/step, loss=0.07333, avg_loss=0.07272]
[2018-11-23 12:43:45.163]  Step 255306  [21.115 sec/step, loss=0.06976, avg_loss=0.07272]
[2018-11-23 12:44:08.312]  Step 255307  [21.161 sec/step, loss=0.07490, avg_loss=0.07273]
[2018-11-23 12:44:24.138]  Step 255308  [21.105 sec/step, loss=0.07174, avg_loss=0.07270]
[2018-11-23 12:44:44.605]  Step 255309  [21.071 sec/step, loss=0.07404, avg_loss=0.07270]
[2018-11-23 12:45:07.429]  Step 255310  [21.072 sec/step, loss=0.07463, avg_loss=0.07270]
[2018-11-23 12:45:25.084]  Step 255311  [21.016 sec/step, loss=0.07321, avg_loss=0.07269]
[2018-11-23 12:46:09.718]  Step 255312  [21.298 sec/step, loss=0.06566, avg_loss=0.07263]
[2018-11-23 12:46:25.400]  Step 255313  [21.278 sec/step, loss=0.06998, avg_loss=0.07260]
[2018-11-23 12:46:51.475]  Step 255314  [21.365 sec/step, loss=0.07398, avg_loss=0.07261]
[2018-11-23 12:47:15.661]  Step 255315  [21.381 sec/step, loss=0.07373, avg_loss=0.07260]
[2018-11-23 12:47:39.089]  Step 255316  [21.110 sec/step, loss=0.07443, avg_loss=0.07268]
[2018-11-23 12:48:02.091]  Step 255317  [21.092 sec/step, loss=0.07404, avg_loss=0.07268]
[2018-11-23 12:48:23.930]  Step 255318  [21.224 sec/step, loss=0.07366, avg_loss=0.07288]
[2018-11-23 12:48:43.082]  Step 255319  [21.208 sec/step, loss=0.07313, avg_loss=0.07287]
[2018-11-23 12:49:03.207]  Step 255320  [21.178 sec/step, loss=0.07377, avg_loss=0.07286]
[2018-11-23 12:49:25.798]  Step 255321  [21.157 sec/step, loss=0.07335, avg_loss=0.07285]
[2018-11-23 12:49:34.587]  Step 255322  [21.137 sec/step, loss=0.05387, avg_loss=0.07272]
[2018-11-23 12:49:44.627]  Generated 32 batches of size 32 in 9.018 sec
[2018-11-23 12:49:59.976]  Step 255323  [21.147 sec/step, loss=0.07429, avg_loss=0.07272]
[2018-11-23 12:50:24.399]  Step 255324  [21.125 sec/step, loss=0.07474, avg_loss=0.07272]
[2018-11-23 12:50:38.573]  Step 255325  [21.063 sec/step, loss=0.07126, avg_loss=0.07269]
[2018-11-23 12:51:03.521]  Step 255326  [21.122 sec/step, loss=0.07464, avg_loss=0.07270]
[2018-11-23 12:51:28.601]  Step 255327  [21.171 sec/step, loss=0.07472, avg_loss=0.07271]
[2018-11-23 12:51:50.315]  Step 255328  [21.162 sec/step, loss=0.07367, avg_loss=0.07271]
[2018-11-23 12:52:01.014]  Step 255329  [21.045 sec/step, loss=0.06674, avg_loss=0.07263]
[2018-11-23 12:52:26.223]  Step 255330  [21.109 sec/step, loss=0.07428, avg_loss=0.07264]
[2018-11-23 12:52:45.812]  Step 255331  [21.055 sec/step, loss=0.07417, avg_loss=0.07264]
[2018-11-23 12:53:05.459]  Step 255332  [21.005 sec/step, loss=0.07320, avg_loss=0.07262]
[2018-11-23 12:53:22.848]  Step 255333  [21.038 sec/step, loss=0.07281, avg_loss=0.07264]
[2018-11-23 12:53:36.812]  Step 255334  [21.059 sec/step, loss=0.07074, avg_loss=0.07264]
[2018-11-23 12:53:57.186]  Step 255335  [21.042 sec/step, loss=0.07386, avg_loss=0.07264]
[2018-11-23 12:54:18.872]  Step 255336  [21.008 sec/step, loss=0.07445, avg_loss=0.07263]
[2018-11-23 12:54:41.395]  Step 255337  [21.008 sec/step, loss=0.07368, avg_loss=0.07262]
[2018-11-23 12:55:05.220]  Step 255338  [21.056 sec/step, loss=0.07422, avg_loss=0.07262]
[2018-11-23 12:55:16.202]  Step 255339  [20.758 sec/step, loss=0.06637, avg_loss=0.07263]
[2018-11-23 12:55:40.843]  Step 255340  [20.850 sec/step, loss=0.07373, avg_loss=0.07265]
[2018-11-23 12:56:05.645]  Step 255341  [20.851 sec/step, loss=0.07520, avg_loss=0.07265]
[2018-11-23 12:56:32.105]  Step 255342  [20.909 sec/step, loss=0.07429, avg_loss=0.07265]
[2018-11-23 12:56:48.296]  Step 255343  [20.867 sec/step, loss=0.07037, avg_loss=0.07261]
[2018-11-23 12:57:08.546]  Step 255344  [20.848 sec/step, loss=0.07321, avg_loss=0.07261]
[2018-11-23 12:57:23.932]  Step 255345  [20.803 sec/step, loss=0.07170, avg_loss=0.07260]
[2018-11-23 12:57:41.760]  Step 255346  [20.812 sec/step, loss=0.07288, avg_loss=0.07259]
[2018-11-23 12:57:50.633]  Step 255347  [20.653 sec/step, loss=0.05503, avg_loss=0.07239]
[2018-11-23 12:58:15.601]  Step 255348  [20.657 sec/step, loss=0.07438, avg_loss=0.07239]
[2018-11-23 12:58:40.970]  Step 255349  [20.659 sec/step, loss=0.07502, avg_loss=0.07239]
[2018-11-23 12:59:04.532]  Step 255350  [20.677 sec/step, loss=0.07424, avg_loss=0.07240]
[2018-11-23 12:59:04.533]  Writing summary at step: 255350
[2018-11-23 12:59:54.891]  Step 255351  [20.792 sec/step, loss=0.07374, avg_loss=0.07242]
[2018-11-23 13:00:22.177]  Step 255352  [20.834 sec/step, loss=0.07448, avg_loss=0.07243]
[2018-11-23 13:00:49.428]  Step 255353  [20.893 sec/step, loss=0.07377, avg_loss=0.07242]
[2018-11-23 13:01:00.808]  Generated 32 batches of size 32 in 10.221 sec
[2018-11-23 13:01:14.606]  Step 255354  [20.896 sec/step, loss=0.07449, avg_loss=0.07242]
[2018-11-23 13:01:33.680]  Step 255355  [20.991 sec/step, loss=0.07308, avg_loss=0.07260]
[2018-11-23 13:01:57.409]  Step 255356  [20.995 sec/step, loss=0.07429, avg_loss=0.07260]
[2018-11-23 13:02:21.439]  Step 255357  [21.003 sec/step, loss=0.07394, avg_loss=0.07259]
[2018-11-23 13:03:03.385]  Step 255358  [21.193 sec/step, loss=0.06602, avg_loss=0.07250]
[2018-11-23 13:03:23.743]  Step 255359  [21.293 sec/step, loss=0.07448, avg_loss=0.07258]
[2018-11-23 13:03:42.442]  Step 255360  [21.214 sec/step, loss=0.07429, avg_loss=0.07259]
[2018-11-23 13:04:03.754]  Step 255361  [21.201 sec/step, loss=0.07419, avg_loss=0.07258]
[2018-11-23 13:04:16.122]  Step 255362  [21.080 sec/step, loss=0.06995, avg_loss=0.07254]
[2018-11-23 13:04:39.705]  Step 255363  [21.127 sec/step, loss=0.07377, avg_loss=0.07254]
[2018-11-23 13:05:02.170]  Step 255364  [21.227 sec/step, loss=0.07404, avg_loss=0.07258]
[2018-11-23 13:05:18.245]  Step 255365  [21.204 sec/step, loss=0.07173, avg_loss=0.07256]
[2018-11-23 13:05:45.776]  Step 255366  [21.324 sec/step, loss=0.07358, avg_loss=0.07260]
[2018-11-23 13:06:06.509]  Step 255367  [21.351 sec/step, loss=0.07295, avg_loss=0.07260]
[2018-11-23 13:06:32.353]  Step 255368  [21.403 sec/step, loss=0.07432, avg_loss=0.07259]
[2018-11-23 13:06:43.628]  Step 255369  [21.073 sec/step, loss=0.06543, avg_loss=0.07259]
[2018-11-23 13:06:55.606]  Step 255370  [20.967 sec/step, loss=0.06958, avg_loss=0.07254]
[2018-11-23 13:07:18.140]  Step 255371  [21.067 sec/step, loss=0.07329, avg_loss=0.07258]
[2018-11-23 13:07:40.463]  Step 255372  [21.201 sec/step, loss=0.07443, avg_loss=0.07277]
[2018-11-23 13:08:02.438]  Step 255373  [21.188 sec/step, loss=0.07312, avg_loss=0.07276]
[2018-11-23 13:08:19.801]  Step 255374  [21.143 sec/step, loss=0.07303, avg_loss=0.07275]
[2018-11-23 13:08:45.473]  Step 255375  [21.216 sec/step, loss=0.07414, avg_loss=0.07274]
[2018-11-23 13:09:32.823]  Step 255376  [21.545 sec/step, loss=0.06545, avg_loss=0.07268]
[2018-11-23 13:09:58.928]  Step 255377  [21.634 sec/step, loss=0.07499, avg_loss=0.07270]
[2018-11-23 13:10:23.728]  Step 255378  [21.639 sec/step, loss=0.07410, avg_loss=0.07269]
[2018-11-23 13:10:48.041]  Step 255379  [21.664 sec/step, loss=0.07386, avg_loss=0.07269]
[2018-11-23 13:11:04.371]  Step 255380  [21.601 sec/step, loss=0.07027, avg_loss=0.07265]
[2018-11-23 13:11:25.442]  Step 255381  [21.632 sec/step, loss=0.07307, avg_loss=0.07265]
[2018-11-23 13:11:50.479]  Step 255382  [21.672 sec/step, loss=0.07395, avg_loss=0.07265]
[2018-11-23 13:12:12.026]  Step 255383  [21.665 sec/step, loss=0.07389, avg_loss=0.07265]
[2018-11-23 13:12:32.384]  Step 255384  [21.623 sec/step, loss=0.07397, avg_loss=0.07265]
[2018-11-23 13:12:41.606]  Step 255385  [21.522 sec/step, loss=0.05488, avg_loss=0.07246]
[2018-11-23 13:12:51.515]  Generated 32 batches of size 32 in 9.125 sec
[2018-11-23 13:13:02.048]  Step 255386  [21.471 sec/step, loss=0.07289, avg_loss=0.07244]
[2018-11-23 13:13:22.272]  Step 255387  [21.487 sec/step, loss=0.07403, avg_loss=0.07246]
[2018-11-23 13:13:46.810]  Step 255388  [21.467 sec/step, loss=0.07472, avg_loss=0.07246]
[2018-11-23 13:14:07.619]  Step 255389  [21.571 sec/step, loss=0.07417, avg_loss=0.07254]
[2018-11-23 13:14:28.169]  Step 255390  [21.544 sec/step, loss=0.07416, avg_loss=0.07253]
[2018-11-23 13:14:52.233]  Step 255391  [21.538 sec/step, loss=0.07443, avg_loss=0.07254]
[2018-11-23 13:15:15.179]  Step 255392  [21.555 sec/step, loss=0.07412, avg_loss=0.07254]
[2018-11-23 13:15:29.381]  Step 255393  [21.445 sec/step, loss=0.07125, avg_loss=0.07250]
[2018-11-23 13:15:54.220]  Step 255394  [21.490 sec/step, loss=0.07505, avg_loss=0.07252]
[2018-11-23 13:16:18.229]  Step 255395  [21.538 sec/step, loss=0.07441, avg_loss=0.07252]
[2018-11-23 13:16:40.251]  Step 255396  [21.526 sec/step, loss=0.07454, avg_loss=0.07252]
[2018-11-23 13:17:07.191]  Step 255397  [21.588 sec/step, loss=0.07434, avg_loss=0.07252]
[2018-11-23 13:17:50.675]  Step 255398  [21.771 sec/step, loss=0.06577, avg_loss=0.07244]
[2018-11-23 13:18:13.140]  Step 255399  [21.836 sec/step, loss=0.07429, avg_loss=0.07247]
[2018-11-23 13:18:36.448]  Step 255400  [21.854 sec/step, loss=0.07420, avg_loss=0.07247]
[2018-11-23 13:18:36.448]  Writing summary at step: 255400
[2018-11-23 13:19:24.817]  Step 255401  [21.892 sec/step, loss=0.07402, avg_loss=0.07247]
[2018-11-23 13:19:50.787]  Step 255402  [21.965 sec/step, loss=0.07360, avg_loss=0.07247]
[2018-11-23 13:20:17.555]  Step 255403  [21.981 sec/step, loss=0.07421, avg_loss=0.07247]
[2018-11-23 13:20:35.220]  Step 255404  [21.913 sec/step, loss=0.07304, avg_loss=0.07245]
[2018-11-23 13:20:58.275]  Step 255405  [21.949 sec/step, loss=0.07427, avg_loss=0.07246]
[2018-11-23 13:21:18.260]  Step 255406  [22.026 sec/step, loss=0.07371, avg_loss=0.07250]
[2018-11-23 13:21:38.337]  Step 255407  [21.996 sec/step, loss=0.07316, avg_loss=0.07248]
[2018-11-23 13:21:54.141]  Step 255408  [21.995 sec/step, loss=0.07206, avg_loss=0.07248]
[2018-11-23 13:22:02.980]  Step 255409  [21.879 sec/step, loss=0.05337, avg_loss=0.07228]
[2018-11-23 13:22:19.171]  Step 255410  [21.813 sec/step, loss=0.07080, avg_loss=0.07224]
[2018-11-23 13:22:31.659]  Step 255411  [21.761 sec/step, loss=0.07084, avg_loss=0.07222]
[2018-11-23 13:22:53.880]  Step 255412  [21.537 sec/step, loss=0.07449, avg_loss=0.07230]
[2018-11-23 13:23:17.801]  Step 255413  [21.619 sec/step, loss=0.07387, avg_loss=0.07234]
[2018-11-23 13:23:42.414]  Step 255414  [21.605 sec/step, loss=0.07447, avg_loss=0.07235]
[2018-11-23 13:23:56.860]  Step 255415  [21.507 sec/step, loss=0.07144, avg_loss=0.07232]
[2018-11-23 13:24:16.176]  Step 255416  [21.466 sec/step, loss=0.07475, avg_loss=0.07233]
[2018-11-23 13:24:26.329]  Generated 32 batches of size 32 in 9.057 sec
[2018-11-23 13:24:29.192]  Step 255417  [21.366 sec/step, loss=0.06539, avg_loss=0.07224]
[2018-11-23 13:24:51.365]  Step 255418  [21.370 sec/step, loss=0.07379, avg_loss=0.07224]
[2018-11-23 13:25:17.085]  Step 255419  [21.435 sec/step, loss=0.07416, avg_loss=0.07225]
[2018-11-23 13:25:36.488]  Step 255420  [21.428 sec/step, loss=0.07326, avg_loss=0.07225]
[2018-11-23 13:25:59.972]  Step 255421  [21.437 sec/step, loss=0.07427, avg_loss=0.07226]
[2018-11-23 13:26:24.707]  Step 255422  [21.597 sec/step, loss=0.07516, avg_loss=0.07247]
[2018-11-23 13:26:42.901]  Step 255423  [21.525 sec/step, loss=0.07308, avg_loss=0.07246]
[2018-11-23 13:27:06.162]  Step 255424  [21.513 sec/step, loss=0.07436, avg_loss=0.07245]
[2018-11-23 13:27:28.467]  Step 255425  [21.594 sec/step, loss=0.07389, avg_loss=0.07248]
[2018-11-23 13:27:51.488]  Step 255426  [21.575 sec/step, loss=0.07417, avg_loss=0.07248]
[2018-11-23 13:28:10.332]  Step 255427  [21.513 sec/step, loss=0.07321, avg_loss=0.07246]
[2018-11-23 13:28:28.544]  Step 255428  [21.478 sec/step, loss=0.07252, avg_loss=0.07245]
[2018-11-23 13:28:51.317]  Step 255429  [21.598 sec/step, loss=0.07340, avg_loss=0.07252]
[2018-11-23 13:29:16.910]  Step 255430  [21.602 sec/step, loss=0.07442, avg_loss=0.07252]
[2018-11-23 13:29:25.687]  Step 255431  [21.494 sec/step, loss=0.05514, avg_loss=0.07233]
[2018-11-23 13:29:50.607]  Step 255432  [21.547 sec/step, loss=0.07472, avg_loss=0.07234]
[2018-11-23 13:30:15.303]  Step 255433  [21.620 sec/step, loss=0.07361, avg_loss=0.07235]
[2018-11-23 13:30:38.760]  Step 255434  [21.715 sec/step, loss=0.07442, avg_loss=0.07239]
[2018-11-23 13:31:05.429]  Step 255435  [21.778 sec/step, loss=0.07442, avg_loss=0.07239]
[2018-11-23 13:31:21.790]  Step 255436  [21.725 sec/step, loss=0.07019, avg_loss=0.07235]
[2018-11-23 13:31:46.068]  Step 255437  [21.742 sec/step, loss=0.07426, avg_loss=0.07236]
[2018-11-23 13:32:27.675]  Step 255438  [21.920 sec/step, loss=0.06590, avg_loss=0.07227]
[2018-11-23 13:32:41.893]  Step 255439  [21.952 sec/step, loss=0.07121, avg_loss=0.07232]
[2018-11-23 13:33:06.708]  Step 255440  [21.954 sec/step, loss=0.07383, avg_loss=0.07232]
[2018-11-23 13:33:28.704]  Step 255441  [21.926 sec/step, loss=0.07335, avg_loss=0.07230]
[2018-11-23 13:33:52.303]  Step 255442  [21.897 sec/step, loss=0.07451, avg_loss=0.07231]
[2018-11-23 13:34:13.834]  Step 255443  [21.951 sec/step, loss=0.07422, avg_loss=0.07234]
[2018-11-23 13:34:40.433]  Step 255444  [22.014 sec/step, loss=0.07370, avg_loss=0.07235]
[2018-11-23 13:34:56.221]  Step 255445  [22.018 sec/step, loss=0.07127, avg_loss=0.07234]
[2018-11-23 13:35:08.729]  Step 255446  [21.965 sec/step, loss=0.06972, avg_loss=0.07231]
[2018-11-23 13:35:31.100]  Step 255447  [22.100 sec/step, loss=0.07395, avg_loss=0.07250]
[2018-11-23 13:35:53.901]  Step 255448  [22.078 sec/step, loss=0.07463, avg_loss=0.07250]
[2018-11-23 13:36:03.562]  Generated 32 batches of size 32 in 8.701 sec
[2018-11-23 13:36:12.947]  Step 255449  [22.015 sec/step, loss=0.07348, avg_loss=0.07249]
[2018-11-23 13:36:33.202]  Step 255450  [21.982 sec/step, loss=0.07363, avg_loss=0.07248]
[2018-11-23 13:36:33.202]  Writing summary at step: 255450
[2018-11-23 13:37:04.761]  Step 255451  [21.833 sec/step, loss=0.06697, avg_loss=0.07242]
[2018-11-23 13:37:27.375]  Step 255452  [21.786 sec/step, loss=0.07406, avg_loss=0.07241]
[2018-11-23 13:37:48.575]  Step 255453  [21.726 sec/step, loss=0.07313, avg_loss=0.07240]
[2018-11-23 13:38:08.634]  Step 255454  [21.674 sec/step, loss=0.07375, avg_loss=0.07240]
[2018-11-23 13:38:27.649]  Step 255455  [21.674 sec/step, loss=0.07350, avg_loss=0.07240]
[2018-11-23 13:38:51.962]  Step 255456  [21.680 sec/step, loss=0.07423, avg_loss=0.07240]
[2018-11-23 13:39:17.088]  Step 255457  [21.691 sec/step, loss=0.07388, avg_loss=0.07240]
[2018-11-23 13:39:36.545]  Step 255458  [21.466 sec/step, loss=0.07325, avg_loss=0.07247]
[2018-11-23 13:40:02.964]  Step 255459  [21.526 sec/step, loss=0.07396, avg_loss=0.07247]
[2018-11-23 13:40:18.706]  Step 255460  [21.497 sec/step, loss=0.07053, avg_loss=0.07243]
[2018-11-23 13:40:27.133]  Step 255461  [21.368 sec/step, loss=0.05282, avg_loss=0.07222]
[2018-11-23 13:40:48.730]  Step 255462  [21.460 sec/step, loss=0.07432, avg_loss=0.07226]
[2018-11-23 13:41:11.044]  Step 255463  [21.447 sec/step, loss=0.07388, avg_loss=0.07226]
[2018-11-23 13:41:27.165]  Step 255464  [21.384 sec/step, loss=0.07229, avg_loss=0.07224]
[2018-11-23 13:41:44.979]  Step 255465  [21.401 sec/step, loss=0.07265, avg_loss=0.07225]
[2018-11-23 13:42:26.368]  Step 255466  [21.540 sec/step, loss=0.06528, avg_loss=0.07217]
[2018-11-23 13:42:50.387]  Step 255467  [21.573 sec/step, loss=0.07530, avg_loss=0.07219]
[2018-11-23 13:43:09.003]  Step 255468  [21.501 sec/step, loss=0.07477, avg_loss=0.07220]
[2018-11-23 13:43:30.439]  Step 255469  [21.602 sec/step, loss=0.07455, avg_loss=0.07229]
[2018-11-23 13:43:52.666]  Step 255470  [21.705 sec/step, loss=0.07390, avg_loss=0.07233]
[2018-11-23 13:44:16.666]  Step 255471  [21.719 sec/step, loss=0.07415, avg_loss=0.07234]
[2018-11-23 13:44:40.613]  Step 255472  [21.736 sec/step, loss=0.07457, avg_loss=0.07234]
[2018-11-23 13:44:51.420]  Step 255473  [21.624 sec/step, loss=0.06582, avg_loss=0.07227]
[2018-11-23 13:45:15.714]  Step 255474  [21.693 sec/step, loss=0.07480, avg_loss=0.07229]
[2018-11-23 13:45:34.945]  Step 255475  [21.629 sec/step, loss=0.07298, avg_loss=0.07227]
[2018-11-23 13:45:56.488]  Step 255476  [21.371 sec/step, loss=0.07376, avg_loss=0.07236]
[2018-11-23 13:46:20.383]  Step 255477  [21.349 sec/step, loss=0.07388, avg_loss=0.07235]
[2018-11-23 13:46:43.237]  Step 255478  [21.329 sec/step, loss=0.07402, avg_loss=0.07235]
[2018-11-23 13:46:55.454]  Step 255479  [21.208 sec/step, loss=0.06951, avg_loss=0.07230]
[2018-11-23 13:47:05.091]  Generated 32 batches of size 32 in 8.834 sec
[2018-11-23 13:47:14.320]  Step 255480  [21.234 sec/step, loss=0.07355, avg_loss=0.07234]
[2018-11-23 13:47:38.104]  Step 255481  [21.261 sec/step, loss=0.07391, avg_loss=0.07234]
[2018-11-23 13:47:59.896]  Step 255482  [21.228 sec/step, loss=0.07419, avg_loss=0.07235]
[2018-11-23 13:48:19.693]  Step 255483  [21.211 sec/step, loss=0.07335, avg_loss=0.07234]
[2018-11-23 13:48:41.414]  Step 255484  [21.224 sec/step, loss=0.07426, avg_loss=0.07234]
[2018-11-23 13:49:06.769]  Step 255485  [21.386 sec/step, loss=0.07474, avg_loss=0.07254]
[2018-11-23 13:49:30.745]  Step 255486  [21.421 sec/step, loss=0.07430, avg_loss=0.07256]
[2018-11-23 13:49:46.126]  Step 255487  [21.373 sec/step, loss=0.07077, avg_loss=0.07252]
[2018-11-23 13:50:07.988]  Step 255488  [21.346 sec/step, loss=0.07393, avg_loss=0.07252]
[2018-11-23 13:50:31.557]  Step 255489  [21.373 sec/step, loss=0.07394, avg_loss=0.07251]
[2018-11-23 13:50:51.877]  Step 255490  [21.371 sec/step, loss=0.07289, avg_loss=0.07250]
[2018-11-23 13:51:12.909]  Step 255491  [21.341 sec/step, loss=0.07349, avg_loss=0.07249]
[2018-11-23 13:51:34.952]  Step 255492  [21.332 sec/step, loss=0.07330, avg_loss=0.07248]
[2018-11-23 13:51:48.798]  Step 255493  [21.328 sec/step, loss=0.07133, avg_loss=0.07248]
[2018-11-23 13:52:11.034]  Step 255494  [21.302 sec/step, loss=0.07391, avg_loss=0.07247]
[2018-11-23 13:52:19.769]  Step 255495  [21.149 sec/step, loss=0.05627, avg_loss=0.07229]
[2018-11-23 13:52:34.940]  Step 255496  [21.081 sec/step, loss=0.07026, avg_loss=0.07225]
[2018-11-23 13:52:59.531]  Step 255497  [21.057 sec/step, loss=0.07471, avg_loss=0.07225]
[2018-11-23 13:53:17.446]  Step 255498  [20.802 sec/step, loss=0.07249, avg_loss=0.07232]
[2018-11-23 13:53:39.794]  Step 255499  [20.801 sec/step, loss=0.07414, avg_loss=0.07232]
[2018-11-23 13:54:03.605]  Step 255500  [20.806 sec/step, loss=0.07361, avg_loss=0.07231]
[2018-11-23 13:54:03.605]  Writing summary at step: 255500
[2018-11-23 13:54:28.870]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-255500
[2018-11-23 13:54:31.961]  Saving audio and alignment...
[2018-11-23 13:54:47.672]  Input: and the beautiful puritan plain style - the pure and simple english adopted by seventeenth-century puritans - with its premium on veracity and its suspicion of surfaces. it~_____________________________________________________________
[2018-11-23 13:55:04.394]  Step 255501  [20.743 sec/step, loss=0.07151, avg_loss=0.07229]
[2018-11-23 13:55:23.151]  Step 255502  [20.671 sec/step, loss=0.07342, avg_loss=0.07229]
[2018-11-23 13:55:46.522]  Step 255503  [20.637 sec/step, loss=0.07340, avg_loss=0.07228]
[2018-11-23 13:56:31.173]  Step 255504  [20.907 sec/step, loss=0.06582, avg_loss=0.07220]
[2018-11-23 13:56:56.039]  Step 255505  [20.925 sec/step, loss=0.07406, avg_loss=0.07220]
[2018-11-23 13:57:15.345]  Step 255506  [20.918 sec/step, loss=0.07460, avg_loss=0.07221]
[2018-11-23 13:57:36.491]  Step 255507  [20.929 sec/step, loss=0.07394, avg_loss=0.07222]
[2018-11-23 13:58:03.180]  Step 255508  [21.038 sec/step, loss=0.07400, avg_loss=0.07224]
[2018-11-23 13:58:25.460]  Step 255509  [21.172 sec/step, loss=0.07404, avg_loss=0.07245]
[2018-11-23 13:58:35.949]  Generated 32 batches of size 32 in 9.367 sec
[2018-11-23 13:58:52.564]  Step 255510  [21.281 sec/step, loss=0.07390, avg_loss=0.07248]
[2018-11-23 13:59:14.613]  Step 255511  [21.377 sec/step, loss=0.07461, avg_loss=0.07251]
[2018-11-23 13:59:38.916]  Step 255512  [21.397 sec/step, loss=0.07384, avg_loss=0.07251]
[2018-11-23 14:00:00.792]  Step 255513  [21.377 sec/step, loss=0.07335, avg_loss=0.07250]
[2018-11-23 14:00:11.409]  Step 255514  [21.237 sec/step, loss=0.06576, avg_loss=0.07242]
[2018-11-23 14:00:32.029]  Step 255515  [21.299 sec/step, loss=0.07406, avg_loss=0.07244]
[2018-11-23 14:00:44.048]  Step 255516  [21.226 sec/step, loss=0.07021, avg_loss=0.07240]
[2018-11-23 14:01:08.459]  Step 255517  [21.340 sec/step, loss=0.07427, avg_loss=0.07248]
[2018-11-23 14:01:27.946]  Step 255518  [21.313 sec/step, loss=0.07351, avg_loss=0.07248]
[2018-11-23 14:01:48.964]  Step 255519  [21.266 sec/step, loss=0.07432, avg_loss=0.07248]
[2018-11-23 14:02:12.743]  Step 255520  [21.310 sec/step, loss=0.07359, avg_loss=0.07249]
[2018-11-23 14:02:34.999]  Step 255521  [21.297 sec/step, loss=0.07342, avg_loss=0.07248]
[2018-11-23 14:02:55.906]  Step 255522  [21.259 sec/step, loss=0.07420, avg_loss=0.07247]
[2018-11-23 14:03:17.672]  Step 255523  [21.295 sec/step, loss=0.07411, avg_loss=0.07248]
[2018-11-23 14:03:41.635]  Step 255524  [21.302 sec/step, loss=0.07441, avg_loss=0.07248]
[2018-11-23 14:04:05.342]  Step 255525  [21.316 sec/step, loss=0.07367, avg_loss=0.07248]
[2018-11-23 14:04:18.131]  Step 255526  [21.214 sec/step, loss=0.06950, avg_loss=0.07243]
[2018-11-23 14:04:37.058]  Step 255527  [21.214 sec/step, loss=0.07284, avg_loss=0.07243]
[2018-11-23 14:05:03.842]  Step 255528  [21.300 sec/step, loss=0.07454, avg_loss=0.07245]
[2018-11-23 14:05:23.409]  Step 255529  [21.268 sec/step, loss=0.07331, avg_loss=0.07245]
[2018-11-23 14:05:47.667]  Step 255530  [21.255 sec/step, loss=0.07505, avg_loss=0.07245]
[2018-11-23 14:06:10.751]  Step 255531  [21.398 sec/step, loss=0.07403, avg_loss=0.07264]
[2018-11-23 14:06:19.760]  Step 255532  [21.239 sec/step, loss=0.05432, avg_loss=0.07244]
[2018-11-23 14:06:35.897]  Step 255533  [21.153 sec/step, loss=0.07213, avg_loss=0.07242]
[2018-11-23 14:06:58.137]  Step 255534  [21.141 sec/step, loss=0.07425, avg_loss=0.07242]
[2018-11-23 14:07:17.059]  Step 255535  [21.063 sec/step, loss=0.07422, avg_loss=0.07242]
[2018-11-23 14:07:39.936]  Step 255536  [21.129 sec/step, loss=0.07439, avg_loss=0.07246]
[2018-11-23 14:08:04.826]  Step 255537  [21.135 sec/step, loss=0.07419, avg_loss=0.07246]
[2018-11-23 14:08:19.169]  Step 255538  [20.862 sec/step, loss=0.07157, avg_loss=0.07252]
[2018-11-23 14:08:39.400]  Step 255539  [20.922 sec/step, loss=0.07355, avg_loss=0.07254]
[2018-11-23 14:08:56.902]  Step 255540  [20.849 sec/step, loss=0.07292, avg_loss=0.07253]
[2018-11-23 14:09:12.874]  Step 255541  [20.789 sec/step, loss=0.07144, avg_loss=0.07251]
[2018-11-23 14:09:25.693]  Generated 32 batches of size 32 in 11.943 sec
[2018-11-23 14:09:43.352]  Step 255542  [20.858 sec/step, loss=0.07443, avg_loss=0.07251]
[2018-11-23 14:10:19.726]  Step 255543  [21.006 sec/step, loss=0.06557, avg_loss=0.07242]
[2018-11-23 14:10:30.620]  Step 255544  [20.849 sec/step, loss=0.06607, avg_loss=0.07235]
[2018-11-23 14:10:54.514]  Step 255545  [20.930 sec/step, loss=0.07391, avg_loss=0.07238]
[2018-11-23 14:11:12.472]  Step 255546  [20.985 sec/step, loss=0.07290, avg_loss=0.07241]
[2018-11-23 14:11:34.615]  Step 255547  [20.982 sec/step, loss=0.07425, avg_loss=0.07241]
[2018-11-23 14:11:56.955]  Step 255548  [20.978 sec/step, loss=0.07407, avg_loss=0.07240]
[2018-11-23 14:12:24.167]  Step 255549  [21.059 sec/step, loss=0.07396, avg_loss=0.07241]
[2018-11-23 14:12:49.273]  Step 255550  [21.108 sec/step, loss=0.07382, avg_loss=0.07241]
[2018-11-23 14:12:49.274]  Writing summary at step: 255550
[2018-11-23 14:13:26.952]  Step 255551  [21.225 sec/step, loss=0.07270, avg_loss=0.07247]
[2018-11-23 14:13:47.279]  Step 255552  [21.202 sec/step, loss=0.07302, avg_loss=0.07246]
[2018-11-23 14:14:11.576]  Step 255553  [21.233 sec/step, loss=0.07440, avg_loss=0.07247]
[2018-11-23 14:14:32.907]  Step 255554  [21.246 sec/step, loss=0.07390, avg_loss=0.07247]
[2018-11-23 14:14:52.150]  Step 255555  [21.248 sec/step, loss=0.07327, avg_loss=0.07247]
[2018-11-23 14:15:03.666]  Step 255556  [21.120 sec/step, loss=0.07018, avg_loss=0.07243]
[2018-11-23 14:15:25.537]  Step 255557  [21.087 sec/step, loss=0.07409, avg_loss=0.07243]
[2018-11-23 14:15:44.907]  Step 255558  [21.087 sec/step, loss=0.07342, avg_loss=0.07243]
[2018-11-23 14:16:09.623]  Step 255559  [21.069 sec/step, loss=0.07376, avg_loss=0.07243]
[2018-11-23 14:16:24.786]  Step 255560  [21.064 sec/step, loss=0.07033, avg_loss=0.07243]
[2018-11-23 14:16:48.815]  Step 255561  [21.220 sec/step, loss=0.07342, avg_loss=0.07264]
[2018-11-23 14:17:11.904]  Step 255562  [21.235 sec/step, loss=0.07431, avg_loss=0.07264]
[2018-11-23 14:17:36.479]  Step 255563  [21.257 sec/step, loss=0.07478, avg_loss=0.07264]
[2018-11-23 14:17:53.354]  Step 255564  [21.265 sec/step, loss=0.07137, avg_loss=0.07263]
[2018-11-23 14:18:16.383]  Step 255565  [21.317 sec/step, loss=0.07443, avg_loss=0.07265]
[2018-11-23 14:18:57.436]  Step 255566  [21.314 sec/step, loss=0.06542, avg_loss=0.07265]
[2018-11-23 14:19:19.233]  Step 255567  [21.291 sec/step, loss=0.07380, avg_loss=0.07264]
[2018-11-23 14:19:44.935]  Step 255568  [21.362 sec/step, loss=0.07487, avg_loss=0.07264]
[2018-11-23 14:20:07.457]  Step 255569  [21.373 sec/step, loss=0.07368, avg_loss=0.07263]
[2018-11-23 14:20:28.012]  Step 255570  [21.356 sec/step, loss=0.07426, avg_loss=0.07263]
[2018-11-23 14:20:53.837]  Step 255571  [21.375 sec/step, loss=0.07389, avg_loss=0.07263]
[2018-11-23 14:21:20.359]  Step 255572  [21.400 sec/step, loss=0.07340, avg_loss=0.07262]
[2018-11-23 14:21:29.387]  Step 255573  [21.383 sec/step, loss=0.05621, avg_loss=0.07252]
[2018-11-23 14:21:29.788]  Generated 32 batches of size 32 in 8.534 sec
[2018-11-23 14:21:52.032]  Step 255574  [21.366 sec/step, loss=0.07412, avg_loss=0.07252]
[2018-11-23 14:22:14.913]  Step 255575  [21.403 sec/step, loss=0.07474, avg_loss=0.07254]
[2018-11-23 14:22:39.072]  Step 255576  [21.429 sec/step, loss=0.07463, avg_loss=0.07254]
[2018-11-23 14:22:49.605]  Step 255577  [21.295 sec/step, loss=0.06473, avg_loss=0.07245]
[2018-11-23 14:23:08.551]  Step 255578  [21.256 sec/step, loss=0.07431, avg_loss=0.07246]
[2018-11-23 14:23:30.261]  Step 255579  [21.351 sec/step, loss=0.07451, avg_loss=0.07251]
[2018-11-23 14:23:48.147]  Step 255580  [21.341 sec/step, loss=0.07254, avg_loss=0.07250]
[2018-11-23 14:24:07.825]  Step 255581  [21.300 sec/step, loss=0.07325, avg_loss=0.07249]
[2018-11-23 14:24:34.156]  Step 255582  [21.345 sec/step, loss=0.07407, avg_loss=0.07249]
[2018-11-23 14:24:59.310]  Step 255583  [21.399 sec/step, loss=0.07436, avg_loss=0.07250]
[2018-11-23 14:25:15.156]  Step 255584  [21.340 sec/step, loss=0.07026, avg_loss=0.07246]
[2018-11-23 14:25:23.544]  Step 255585  [21.171 sec/step, loss=0.05530, avg_loss=0.07226]
[2018-11-23 14:25:48.184]  Step 255586  [21.177 sec/step, loss=0.07419, avg_loss=0.07226]
[2018-11-23 14:26:07.408]  Step 255587  [21.216 sec/step, loss=0.07349, avg_loss=0.07229]
[2018-11-23 14:26:21.498]  Step 255588  [21.138 sec/step, loss=0.07090, avg_loss=0.07226]
[2018-11-23 14:26:43.799]  Step 255589  [21.125 sec/step, loss=0.07343, avg_loss=0.07225]
[2018-11-23 14:27:03.293]  Step 255590  [21.117 sec/step, loss=0.07355, avg_loss=0.07226]
[2018-11-23 14:27:25.860]  Step 255591  [21.132 sec/step, loss=0.07460, avg_loss=0.07227]
[2018-11-23 14:28:10.888]  Step 255592  [21.362 sec/step, loss=0.06572, avg_loss=0.07220]
[2018-11-23 14:28:31.887]  Step 255593  [21.434 sec/step, loss=0.07380, avg_loss=0.07222]
[2018-11-23 14:28:56.132]  Step 255594  [21.454 sec/step, loss=0.07442, avg_loss=0.07223]
[2018-11-23 14:29:20.880]  Step 255595  [21.614 sec/step, loss=0.07437, avg_loss=0.07241]
[2018-11-23 14:29:47.117]  Step 255596  [21.725 sec/step, loss=0.07355, avg_loss=0.07244]
[2018-11-23 14:30:06.915]  Step 255597  [21.677 sec/step, loss=0.07340, avg_loss=0.07243]
[2018-11-23 14:30:21.550]  Step 255598  [21.644 sec/step, loss=0.06989, avg_loss=0.07240]
[2018-11-23 14:30:45.014]  Step 255599  [21.655 sec/step, loss=0.07423, avg_loss=0.07240]
[2018-11-23 14:31:07.431]  Step 255600  [21.641 sec/step, loss=0.07351, avg_loss=0.07240]
[2018-11-23 14:31:07.431]  Writing summary at step: 255600
[2018-11-23 14:31:52.536]  Step 255601  [21.719 sec/step, loss=0.07399, avg_loss=0.07242]
[2018-11-23 14:32:14.394]  Step 255602  [21.750 sec/step, loss=0.07419, avg_loss=0.07243]
[2018-11-23 14:32:30.057]  Step 255603  [21.673 sec/step, loss=0.07188, avg_loss=0.07242]
[2018-11-23 14:32:42.439]  Generated 32 batches of size 32 in 11.397 sec
[2018-11-23 14:32:59.972]  Step 255604  [21.526 sec/step, loss=0.07466, avg_loss=0.07251]
[2018-11-23 14:33:18.452]  Step 255605  [21.462 sec/step, loss=0.07356, avg_loss=0.07250]
[2018-11-23 14:33:39.045]  Step 255606  [21.475 sec/step, loss=0.07384, avg_loss=0.07249]
[2018-11-23 14:34:01.820]  Step 255607  [21.491 sec/step, loss=0.07442, avg_loss=0.07250]
[2018-11-23 14:34:24.102]  Step 255608  [21.447 sec/step, loss=0.07358, avg_loss=0.07249]
[2018-11-23 14:34:45.461]  Step 255609  [21.438 sec/step, loss=0.07374, avg_loss=0.07249]
[2018-11-23 14:34:56.013]  Step 255610  [21.272 sec/step, loss=0.06588, avg_loss=0.07241]
[2018-11-23 14:35:13.610]  Step 255611  [21.228 sec/step, loss=0.07281, avg_loss=0.07239]
[2018-11-23 14:35:40.210]  Step 255612  [21.251 sec/step, loss=0.07373, avg_loss=0.07239]
[2018-11-23 14:36:02.423]  Step 255613  [21.254 sec/step, loss=0.07358, avg_loss=0.07239]
[2018-11-23 14:36:12.740]  Step 255614  [21.251 sec/step, loss=0.05366, avg_loss=0.07227]
[2018-11-23 14:36:35.079]  Step 255615  [21.268 sec/step, loss=0.07314, avg_loss=0.07226]
[2018-11-23 14:36:56.770]  Step 255616  [21.365 sec/step, loss=0.07426, avg_loss=0.07230]
[2018-11-23 14:37:19.811]  Step 255617  [21.351 sec/step, loss=0.07358, avg_loss=0.07230]
[2018-11-23 14:37:33.693]  Step 255618  [21.295 sec/step, loss=0.07122, avg_loss=0.07227]
[2018-11-23 14:37:53.242]  Step 255619  [21.280 sec/step, loss=0.07395, avg_loss=0.07227]
[2018-11-23 14:38:16.049]  Step 255620  [21.271 sec/step, loss=0.07414, avg_loss=0.07228]
[2018-11-23 14:38:40.338]  Step 255621  [21.291 sec/step, loss=0.07384, avg_loss=0.07228]
[2018-11-23 14:38:59.331]  Step 255622  [21.272 sec/step, loss=0.07358, avg_loss=0.07227]
[2018-11-23 14:39:24.357]  Step 255623  [21.305 sec/step, loss=0.07395, avg_loss=0.07227]
[2018-11-23 14:39:46.764]  Step 255624  [21.289 sec/step, loss=0.07432, avg_loss=0.07227]
[2018-11-23 14:39:59.162]  Step 255625  [21.176 sec/step, loss=0.06963, avg_loss=0.07223]
[2018-11-23 14:40:09.869]  Step 255626  [21.155 sec/step, loss=0.06681, avg_loss=0.07220]
[2018-11-23 14:40:31.594]  Step 255627  [21.183 sec/step, loss=0.07359, avg_loss=0.07221]
[2018-11-23 14:40:49.882]  Step 255628  [21.098 sec/step, loss=0.07271, avg_loss=0.07219]
[2018-11-23 14:41:21.625]  Step 255629  [21.220 sec/step, loss=0.07387, avg_loss=0.07220]
[2018-11-23 14:41:41.782]  Step 255630  [21.179 sec/step, loss=0.07305, avg_loss=0.07218]
[2018-11-23 14:41:58.440]  Step 255631  [21.115 sec/step, loss=0.07147, avg_loss=0.07215]
[2018-11-23 14:42:21.685]  Step 255632  [21.257 sec/step, loss=0.07407, avg_loss=0.07235]
[2018-11-23 14:42:40.875]  Step 255633  [21.287 sec/step, loss=0.07355, avg_loss=0.07237]
[2018-11-23 14:42:57.880]  Step 255634  [21.235 sec/step, loss=0.07331, avg_loss=0.07236]
[2018-11-23 14:43:18.521]  Step 255635  [21.252 sec/step, loss=0.07393, avg_loss=0.07235]
[2018-11-23 14:43:29.209]  Generated 32 batches of size 32 in 9.905 sec
[2018-11-23 14:43:45.168]  Step 255636  [21.290 sec/step, loss=0.07466, avg_loss=0.07236]
[2018-11-23 14:44:22.447]  Step 255637  [21.414 sec/step, loss=0.06555, avg_loss=0.07227]
[2018-11-23 14:44:38.381]  Step 255638  [21.430 sec/step, loss=0.07008, avg_loss=0.07225]
[2018-11-23 14:45:02.556]  Step 255639  [21.469 sec/step, loss=0.07419, avg_loss=0.07226]
[2018-11-23 14:45:27.155]  Step 255640  [21.540 sec/step, loss=0.07466, avg_loss=0.07228]
[2018-11-23 14:45:49.408]  Step 255641  [21.603 sec/step, loss=0.07377, avg_loss=0.07230]
[2018-11-23 14:46:10.121]  Step 255642  [21.505 sec/step, loss=0.07393, avg_loss=0.07230]
[2018-11-23 14:46:34.731]  Step 255643  [21.388 sec/step, loss=0.07480, avg_loss=0.07239]
[2018-11-23 14:46:58.511]  Step 255644  [21.517 sec/step, loss=0.07424, avg_loss=0.07247]
[2018-11-23 14:47:21.079]  Step 255645  [21.503 sec/step, loss=0.07349, avg_loss=0.07247]
[2018-11-23 14:47:42.142]  Step 255646  [21.534 sec/step, loss=0.07393, avg_loss=0.07248]
[2018-11-23 14:48:07.338]  Step 255647  [21.565 sec/step, loss=0.07364, avg_loss=0.07247]
[2018-11-23 14:48:28.539]  Step 255648  [21.554 sec/step, loss=0.07413, avg_loss=0.07247]
[2018-11-23 14:48:48.527]  Step 255649  [21.481 sec/step, loss=0.07297, avg_loss=0.07246]
[2018-11-23 14:49:04.351]  Step 255650  [21.388 sec/step, loss=0.07124, avg_loss=0.07244]
[2018-11-23 14:49:04.351]  Writing summary at step: 255650
[2018-11-23 14:49:50.571]  Step 255651  [21.369 sec/step, loss=0.07380, avg_loss=0.07245]
[2018-11-23 14:50:08.039]  Step 255652  [21.340 sec/step, loss=0.07304, avg_loss=0.07245]
[2018-11-23 14:50:23.929]  Step 255653  [21.256 sec/step, loss=0.07029, avg_loss=0.07241]
[2018-11-23 14:50:36.581]  Step 255654  [21.169 sec/step, loss=0.06985, avg_loss=0.07236]
[2018-11-23 14:50:48.518]  Step 255655  [21.096 sec/step, loss=0.06589, avg_loss=0.07229]
[2018-11-23 14:51:11.137]  Step 255656  [21.207 sec/step, loss=0.07448, avg_loss=0.07233]
[2018-11-23 14:51:49.334]  Step 255657  [21.370 sec/step, loss=0.06506, avg_loss=0.07224]
[2018-11-23 14:52:11.241]  Step 255658  [21.396 sec/step, loss=0.07408, avg_loss=0.07225]
[2018-11-23 14:52:25.524]  Step 255659  [21.292 sec/step, loss=0.07122, avg_loss=0.07223]
[2018-11-23 14:52:34.078]  Step 255660  [21.225 sec/step, loss=0.05491, avg_loss=0.07207]
[2018-11-23 14:52:58.436]  Step 255661  [21.229 sec/step, loss=0.07464, avg_loss=0.07208]
[2018-11-23 14:53:17.672]  Step 255662  [21.190 sec/step, loss=0.07313, avg_loss=0.07207]
[2018-11-23 14:53:42.008]  Step 255663  [21.188 sec/step, loss=0.07410, avg_loss=0.07206]
[2018-11-23 14:54:08.857]  Step 255664  [21.288 sec/step, loss=0.07388, avg_loss=0.07209]
[2018-11-23 14:54:27.984]  Step 255665  [21.249 sec/step, loss=0.07407, avg_loss=0.07209]
[2018-11-23 14:54:50.281]  Step 255666  [21.061 sec/step, loss=0.07444, avg_loss=0.07218]
[2018-11-23 14:54:59.290]  Generated 32 batches of size 32 in 8.169 sec
[2018-11-23 14:55:14.225]  Step 255667  [21.082 sec/step, loss=0.07425, avg_loss=0.07218]
[2018-11-23 14:55:31.950]  Step 255668  [21.003 sec/step, loss=0.07266, avg_loss=0.07216]
[2018-11-23 14:55:52.126]  Step 255669  [20.979 sec/step, loss=0.07388, avg_loss=0.07216]
[2018-11-23 14:56:14.357]  Step 255670  [20.996 sec/step, loss=0.07365, avg_loss=0.07215]
[2018-11-23 14:56:37.615]  Step 255671  [20.970 sec/step, loss=0.07411, avg_loss=0.07216]
[2018-11-23 14:57:01.938]  Step 255672  [20.948 sec/step, loss=0.07460, avg_loss=0.07217]
[2018-11-23 14:57:25.937]  Step 255673  [21.098 sec/step, loss=0.07358, avg_loss=0.07234]
[2018-11-23 14:57:47.140]  Step 255674  [21.084 sec/step, loss=0.07377, avg_loss=0.07234]
[2018-11-23 14:58:11.253]  Step 255675  [21.096 sec/step, loss=0.07399, avg_loss=0.07233]
[2018-11-23 14:58:35.436]  Step 255676  [21.096 sec/step, loss=0.07402, avg_loss=0.07233]
[2018-11-23 14:58:59.251]  Step 255677  [21.229 sec/step, loss=0.07441, avg_loss=0.07242]
[2018-11-23 14:59:41.490]  Step 255678  [21.462 sec/step, loss=0.06594, avg_loss=0.07234]
[2018-11-23 15:00:04.255]  Step 255679  [21.472 sec/step, loss=0.07349, avg_loss=0.07233]
[2018-11-23 15:00:27.663]  Step 255680  [21.528 sec/step, loss=0.07358, avg_loss=0.07234]
[2018-11-23 15:00:53.432]  Step 255681  [21.589 sec/step, loss=0.07420, avg_loss=0.07235]
[2018-11-23 15:01:13.801]  Step 255682  [21.529 sec/step, loss=0.07324, avg_loss=0.07234]
[2018-11-23 15:01:24.196]  Step 255683  [21.381 sec/step, loss=0.06605, avg_loss=0.07226]
[2018-11-23 15:01:44.132]  Step 255684  [21.422 sec/step, loss=0.07313, avg_loss=0.07229]
[2018-11-23 15:02:00.302]  Step 255685  [21.500 sec/step, loss=0.07137, avg_loss=0.07245]
[2018-11-23 15:02:18.339]  Step 255686  [21.434 sec/step, loss=0.07271, avg_loss=0.07243]
[2018-11-23 15:02:40.801]  Step 255687  [21.466 sec/step, loss=0.07327, avg_loss=0.07243]
[2018-11-23 15:03:01.698]  Step 255688  [21.534 sec/step, loss=0.07413, avg_loss=0.07246]
[2018-11-23 15:03:13.814]  Step 255689  [21.433 sec/step, loss=0.06937, avg_loss=0.07242]
[2018-11-23 15:03:30.926]  Step 255690  [21.409 sec/step, loss=0.07302, avg_loss=0.07242]
[2018-11-23 15:03:52.532]  Step 255691  [21.399 sec/step, loss=0.07393, avg_loss=0.07241]
[2018-11-23 15:04:01.175]  Step 255692  [21.035 sec/step, loss=0.05404, avg_loss=0.07229]
[2018-11-23 15:04:27.940]  Step 255693  [21.093 sec/step, loss=0.07414, avg_loss=0.07230]
[2018-11-23 15:04:46.704]  Step 255694  [21.038 sec/step, loss=0.07372, avg_loss=0.07229]
[2018-11-23 15:05:06.090]  Step 255695  [20.985 sec/step, loss=0.07318, avg_loss=0.07228]
[2018-11-23 15:05:20.039]  Step 255696  [20.862 sec/step, loss=0.07120, avg_loss=0.07225]
[2018-11-23 15:05:43.254]  Step 255697  [20.896 sec/step, loss=0.07433, avg_loss=0.07226]
[2018-11-23 15:06:08.309]  Step 255698  [21.000 sec/step, loss=0.07493, avg_loss=0.07231]
[2018-11-23 15:06:17.862]  Generated 32 batches of size 32 in 8.684 sec
[2018-11-23 15:06:32.304]  Step 255699  [21.005 sec/step, loss=0.07448, avg_loss=0.07232]
[2018-11-23 15:06:55.737]  Step 255700  [21.016 sec/step, loss=0.07380, avg_loss=0.07232]
[2018-11-23 15:06:55.737]  Writing summary at step: 255700
[2018-11-23 15:07:37.765]  Step 255701  [20.988 sec/step, loss=0.07463, avg_loss=0.07232]
[2018-11-23 15:08:02.124]  Step 255702  [21.013 sec/step, loss=0.07499, avg_loss=0.07233]
[2018-11-23 15:08:22.650]  Step 255703  [21.061 sec/step, loss=0.07413, avg_loss=0.07236]
[2018-11-23 15:08:38.650]  Step 255704  [20.922 sec/step, loss=0.07078, avg_loss=0.07232]
[2018-11-23 15:09:03.443]  Step 255705  [20.985 sec/step, loss=0.07398, avg_loss=0.07232]
[2018-11-23 15:09:26.116]  Step 255706  [21.006 sec/step, loss=0.07386, avg_loss=0.07232]
[2018-11-23 15:09:50.436]  Step 255707  [21.021 sec/step, loss=0.07421, avg_loss=0.07232]
[2018-11-23 15:10:10.127]  Step 255708  [20.996 sec/step, loss=0.07301, avg_loss=0.07231]
[2018-11-23 15:10:31.867]  Step 255709  [20.999 sec/step, loss=0.07405, avg_loss=0.07232]
[2018-11-23 15:10:52.673]  Step 255710  [21.102 sec/step, loss=0.07400, avg_loss=0.07240]
[2018-11-23 15:11:18.299]  Step 255711  [21.182 sec/step, loss=0.07299, avg_loss=0.07240]
[2018-11-23 15:11:39.877]  Step 255712  [21.132 sec/step, loss=0.07457, avg_loss=0.07241]
[2018-11-23 15:12:01.955]  Step 255713  [21.131 sec/step, loss=0.07314, avg_loss=0.07240]
[2018-11-23 15:12:24.154]  Step 255714  [21.249 sec/step, loss=0.07363, avg_loss=0.07260]
[2018-11-23 15:12:46.657]  Step 255715  [21.251 sec/step, loss=0.07315, avg_loss=0.07260]
[2018-11-23 15:13:09.938]  Step 255716  [21.267 sec/step, loss=0.07424, avg_loss=0.07260]
[2018-11-23 15:13:25.603]  Step 255717  [21.193 sec/step, loss=0.07038, avg_loss=0.07257]
[2018-11-23 15:13:51.104]  Step 255718  [21.309 sec/step, loss=0.07475, avg_loss=0.07261]
[2018-11-23 15:14:06.460]  Step 255719  [21.267 sec/step, loss=0.07112, avg_loss=0.07258]
[2018-11-23 15:14:18.603]  Step 255720  [21.161 sec/step, loss=0.06978, avg_loss=0.07253]
[2018-11-23 15:14:45.687]  Step 255721  [21.189 sec/step, loss=0.07363, avg_loss=0.07253]
[2018-11-23 15:14:59.645]  Step 255722  [21.138 sec/step, loss=0.07103, avg_loss=0.07251]
[2018-11-23 15:15:21.538]  Step 255723  [21.107 sec/step, loss=0.07404, avg_loss=0.07251]
[2018-11-23 15:15:45.905]  Step 255724  [21.127 sec/step, loss=0.07351, avg_loss=0.07250]
[2018-11-23 15:15:55.146]  Step 255725  [21.095 sec/step, loss=0.05484, avg_loss=0.07235]
[2018-11-23 15:16:19.799]  Step 255726  [21.235 sec/step, loss=0.07388, avg_loss=0.07242]
[2018-11-23 15:16:44.190]  Step 255727  [21.261 sec/step, loss=0.07410, avg_loss=0.07243]
[2018-11-23 15:16:54.811]  Step 255728  [21.185 sec/step, loss=0.06659, avg_loss=0.07237]
[2018-11-23 15:17:20.601]  Step 255729  [21.125 sec/step, loss=0.07397, avg_loss=0.07237]
[2018-11-23 15:17:30.473]  Generated 32 batches of size 32 in 8.938 sec
[2018-11-23 15:17:39.582]  Step 255730  [21.113 sec/step, loss=0.07319, avg_loss=0.07237]
[2018-11-23 15:18:03.719]  Step 255731  [21.188 sec/step, loss=0.07422, avg_loss=0.07240]
[2018-11-23 15:18:26.713]  Step 255732  [21.186 sec/step, loss=0.07402, avg_loss=0.07240]
[2018-11-23 15:19:11.644]  Step 255733  [21.443 sec/step, loss=0.06548, avg_loss=0.07231]
[2018-11-23 15:19:32.353]  Step 255734  [21.480 sec/step, loss=0.07390, avg_loss=0.07232]
[2018-11-23 15:19:51.825]  Step 255735  [21.468 sec/step, loss=0.07375, avg_loss=0.07232]
[2018-11-23 15:20:10.714]  Step 255736  [21.391 sec/step, loss=0.07318, avg_loss=0.07230]
[2018-11-23 15:20:33.838]  Step 255737  [21.249 sec/step, loss=0.07391, avg_loss=0.07239]
[2018-11-23 15:20:55.338]  Step 255738  [21.305 sec/step, loss=0.07386, avg_loss=0.07243]
[2018-11-23 15:21:18.622]  Step 255739  [21.296 sec/step, loss=0.07382, avg_loss=0.07242]
[2018-11-23 15:21:43.161]  Step 255740  [21.295 sec/step, loss=0.07491, avg_loss=0.07242]
[2018-11-23 15:22:07.997]  Step 255741  [21.321 sec/step, loss=0.07395, avg_loss=0.07243]
[2018-11-23 15:22:31.723]  Step 255742  [21.351 sec/step, loss=0.07352, avg_loss=0.07242]
[2018-11-23 15:22:50.454]  Step 255743  [21.293 sec/step, loss=0.07287, avg_loss=0.07240]
[2018-11-23 15:23:07.681]  Step 255744  [21.227 sec/step, loss=0.07105, avg_loss=0.07237]
[2018-11-23 15:23:26.529]  Step 255745  [21.190 sec/step, loss=0.07304, avg_loss=0.07237]
[2018-11-23 15:23:45.559]  Step 255746  [21.169 sec/step, loss=0.07400, avg_loss=0.07237]
[2018-11-23 15:24:07.553]  Step 255747  [21.137 sec/step, loss=0.07412, avg_loss=0.07237]
[2018-11-23 15:24:25.775]  Step 255748  [21.108 sec/step, loss=0.07233, avg_loss=0.07235]
[2018-11-23 15:24:36.788]  Step 255749  [21.018 sec/step, loss=0.06567, avg_loss=0.07228]
[2018-11-23 15:24:53.153]  Step 255750  [21.023 sec/step, loss=0.07169, avg_loss=0.07229]
[2018-11-23 15:24:53.153]  Writing summary at step: 255750
[2018-11-23 15:25:36.687]  Step 255751  [21.051 sec/step, loss=0.07350, avg_loss=0.07228]
[2018-11-23 15:26:01.391]  Step 255752  [21.124 sec/step, loss=0.07349, avg_loss=0.07229]
[2018-11-23 15:26:24.000]  Step 255753  [21.191 sec/step, loss=0.07315, avg_loss=0.07232]
[2018-11-23 15:26:44.664]  Step 255754  [21.271 sec/step, loss=0.07397, avg_loss=0.07236]
[2018-11-23 15:26:53.807]  Step 255755  [21.243 sec/step, loss=0.05440, avg_loss=0.07224]
[2018-11-23 15:27:17.932]  Step 255756  [21.258 sec/step, loss=0.07445, avg_loss=0.07224]
[2018-11-23 15:27:56.777]  Step 255757  [21.265 sec/step, loss=0.06545, avg_loss=0.07225]
[2018-11-23 15:28:18.726]  Step 255758  [21.265 sec/step, loss=0.07381, avg_loss=0.07224]
[2018-11-23 15:28:45.575]  Step 255759  [21.391 sec/step, loss=0.07340, avg_loss=0.07226]
[2018-11-23 15:28:58.402]  Step 255760  [21.433 sec/step, loss=0.07011, avg_loss=0.07242]
[2018-11-23 15:29:07.602]  Generated 32 batches of size 32 in 8.436 sec
[2018-11-23 15:29:22.550]  Step 255761  [21.431 sec/step, loss=0.07352, avg_loss=0.07241]
[2018-11-23 15:29:44.443]  Step 255762  [21.458 sec/step, loss=0.07409, avg_loss=0.07241]
[2018-11-23 15:30:09.920]  Step 255763  [21.469 sec/step, loss=0.07481, avg_loss=0.07242]
[2018-11-23 15:30:34.517]  Step 255764  [21.447 sec/step, loss=0.07381, avg_loss=0.07242]
[2018-11-23 15:30:55.806]  Step 255765  [21.468 sec/step, loss=0.07378, avg_loss=0.07242]
[2018-11-23 15:31:15.589]  Step 255766  [21.443 sec/step, loss=0.07366, avg_loss=0.07241]
[2018-11-23 15:31:30.049]  Step 255767  [21.348 sec/step, loss=0.07133, avg_loss=0.07238]
[2018-11-23 15:31:55.612]  Step 255768  [21.427 sec/step, loss=0.07403, avg_loss=0.07239]
[2018-11-23 15:32:18.240]  Step 255769  [21.451 sec/step, loss=0.07395, avg_loss=0.07240]
[2018-11-23 15:32:36.868]  Step 255770  [21.415 sec/step, loss=0.07320, avg_loss=0.07239]
[2018-11-23 15:33:00.239]  Step 255771  [21.416 sec/step, loss=0.07395, avg_loss=0.07239]
[2018-11-23 15:33:08.777]  Step 255772  [21.259 sec/step, loss=0.05526, avg_loss=0.07220]
[2018-11-23 15:33:29.587]  Step 255773  [21.227 sec/step, loss=0.07362, avg_loss=0.07220]
[2018-11-23 15:33:54.147]  Step 255774  [21.260 sec/step, loss=0.07391, avg_loss=0.07220]
[2018-11-23 15:34:04.344]  Step 255775  [21.121 sec/step, loss=0.06574, avg_loss=0.07212]
[2018-11-23 15:34:25.991]  Step 255776  [21.096 sec/step, loss=0.07420, avg_loss=0.07212]
[2018-11-23 15:34:51.395]  Step 255777  [21.112 sec/step, loss=0.07383, avg_loss=0.07211]
[2018-11-23 15:35:13.990]  Step 255778  [20.915 sec/step, loss=0.07354, avg_loss=0.07219]
[2018-11-23 15:35:31.736]  Step 255779  [20.865 sec/step, loss=0.07228, avg_loss=0.07218]
[2018-11-23 15:35:52.548]  Step 255780  [20.839 sec/step, loss=0.07296, avg_loss=0.07217]
[2018-11-23 15:36:17.118]  Step 255781  [20.827 sec/step, loss=0.07343, avg_loss=0.07216]
[2018-11-23 15:36:39.778]  Step 255782  [20.850 sec/step, loss=0.07406, avg_loss=0.07217]
[2018-11-23 15:37:00.836]  Step 255783  [20.957 sec/step, loss=0.07326, avg_loss=0.07224]
[2018-11-23 15:37:20.919]  Step 255784  [20.958 sec/step, loss=0.07368, avg_loss=0.07225]
[2018-11-23 15:37:42.425]  Step 255785  [21.011 sec/step, loss=0.07301, avg_loss=0.07226]
[2018-11-23 15:38:06.505]  Step 255786  [21.072 sec/step, loss=0.07337, avg_loss=0.07227]
[2018-11-23 15:38:22.684]  Step 255787  [21.009 sec/step, loss=0.07100, avg_loss=0.07225]
[2018-11-23 15:38:48.030]  Step 255788  [21.054 sec/step, loss=0.07445, avg_loss=0.07225]
[2018-11-23 15:39:27.619]  Step 255789  [21.328 sec/step, loss=0.06507, avg_loss=0.07221]
[2018-11-23 15:39:51.728]  Step 255790  [21.398 sec/step, loss=0.07358, avg_loss=0.07221]
[2018-11-23 15:40:10.957]  Step 255791  [21.374 sec/step, loss=0.07348, avg_loss=0.07221]
[2018-11-23 15:40:24.119]  Step 255792  [21.420 sec/step, loss=0.07156, avg_loss=0.07238]
[2018-11-23 15:40:33.667]  Generated 32 batches of size 32 in 8.608 sec
[2018-11-23 15:40:40.969]  Step 255793  [21.321 sec/step, loss=0.06969, avg_loss=0.07234]
[2018-11-23 15:40:52.555]  Step 255794  [21.249 sec/step, loss=0.06954, avg_loss=0.07230]
[2018-11-23 15:41:17.221]  Step 255795  [21.302 sec/step, loss=0.07413, avg_loss=0.07231]
[2018-11-23 15:41:40.253]  Step 255796  [21.392 sec/step, loss=0.07375, avg_loss=0.07233]
[2018-11-23 15:41:59.493]  Step 255797  [21.353 sec/step, loss=0.07357, avg_loss=0.07232]
[2018-11-23 15:42:22.480]  Step 255798  [21.332 sec/step, loss=0.07445, avg_loss=0.07232]
[2018-11-23 15:42:44.561]  Step 255799  [21.313 sec/step, loss=0.07342, avg_loss=0.07231]
[2018-11-23 15:43:10.808]  Step 255800  [21.341 sec/step, loss=0.07362, avg_loss=0.07231]
[2018-11-23 15:43:10.808]  Writing summary at step: 255800
[2018-11-23 15:43:44.498]  Step 255801  [21.279 sec/step, loss=0.07122, avg_loss=0.07227]
[2018-11-23 15:44:09.842]  Step 255802  [21.289 sec/step, loss=0.07417, avg_loss=0.07227]
[2018-11-23 15:44:34.122]  Step 255803  [21.326 sec/step, loss=0.07386, avg_loss=0.07226]
[2018-11-23 15:44:52.630]  Step 255804  [21.351 sec/step, loss=0.07351, avg_loss=0.07229]
[2018-11-23 15:45:11.963]  Step 255805  [21.297 sec/step, loss=0.07327, avg_loss=0.07228]
[2018-11-23 15:45:29.329]  Step 255806  [21.244 sec/step, loss=0.07273, avg_loss=0.07227]
[2018-11-23 15:45:47.667]  Step 255807  [21.184 sec/step, loss=0.07043, avg_loss=0.07223]
[2018-11-23 15:46:08.381]  Step 255808  [21.194 sec/step, loss=0.07358, avg_loss=0.07224]
[2018-11-23 15:46:33.697]  Step 255809  [21.230 sec/step, loss=0.07348, avg_loss=0.07223]
[2018-11-23 15:46:56.057]  Step 255810  [21.245 sec/step, loss=0.07322, avg_loss=0.07223]
[2018-11-23 15:47:13.316]  Step 255811  [21.162 sec/step, loss=0.07260, avg_loss=0.07222]
[2018-11-23 15:47:34.908]  Step 255812  [21.162 sec/step, loss=0.07404, avg_loss=0.07222]
[2018-11-23 15:47:55.081]  Step 255813  [21.143 sec/step, loss=0.07337, avg_loss=0.07222]
[2018-11-23 15:48:18.865]  Step 255814  [21.159 sec/step, loss=0.07380, avg_loss=0.07222]
[2018-11-23 15:48:41.495]  Step 255815  [21.160 sec/step, loss=0.07327, avg_loss=0.07222]
[2018-11-23 15:49:07.806]  Step 255816  [21.190 sec/step, loss=0.07310, avg_loss=0.07221]
[2018-11-23 15:49:18.238]  Step 255817  [21.138 sec/step, loss=0.06677, avg_loss=0.07217]
[2018-11-23 15:49:32.199]  Step 255818  [21.022 sec/step, loss=0.07072, avg_loss=0.07213]
[2018-11-23 15:50:11.588]  Step 255819  [21.263 sec/step, loss=0.06494, avg_loss=0.07207]
[2018-11-23 15:50:31.568]  Step 255820  [21.341 sec/step, loss=0.07280, avg_loss=0.07210]
[2018-11-23 15:50:55.995]  Step 255821  [21.315 sec/step, loss=0.07336, avg_loss=0.07210]
[2018-11-23 15:51:08.332]  Step 255822  [21.298 sec/step, loss=0.06923, avg_loss=0.07208]
[2018-11-23 15:51:30.533]  Step 255823  [21.301 sec/step, loss=0.07333, avg_loss=0.07207]
[2018-11-23 15:51:40.106]  Generated 32 batches of size 32 in 8.696 sec
[2018-11-23 15:51:53.401]  Step 255824  [21.286 sec/step, loss=0.07357, avg_loss=0.07208]
[2018-11-23 15:52:17.904]  Step 255825  [21.439 sec/step, loss=0.07441, avg_loss=0.07227]
[2018-11-23 15:52:40.889]  Step 255826  [21.422 sec/step, loss=0.07434, avg_loss=0.07228]
[2018-11-23 15:53:05.043]  Step 255827  [21.420 sec/step, loss=0.07343, avg_loss=0.07227]
[2018-11-23 15:53:27.766]  Step 255828  [21.541 sec/step, loss=0.07386, avg_loss=0.07234]
[2018-11-23 15:53:49.424]  Step 255829  [21.500 sec/step, loss=0.07381, avg_loss=0.07234]
[2018-11-23 15:54:08.821]  Step 255830  [21.504 sec/step, loss=0.07301, avg_loss=0.07234]
[2018-11-23 15:54:17.546]  Step 255831  [21.350 sec/step, loss=0.05516, avg_loss=0.07215]
[2018-11-23 15:54:41.218]  Step 255832  [21.357 sec/step, loss=0.07380, avg_loss=0.07215]
[2018-11-23 15:54:55.236]  Step 255833  [21.047 sec/step, loss=0.07059, avg_loss=0.07220]
[2018-11-23 15:55:10.935]  Step 255834  [20.997 sec/step, loss=0.07107, avg_loss=0.07217]
[2018-11-23 15:55:29.850]  Step 255835  [20.992 sec/step, loss=0.07245, avg_loss=0.07216]
[2018-11-23 15:55:55.891]  Step 255836  [21.063 sec/step, loss=0.07457, avg_loss=0.07217]
[2018-11-23 15:56:06.725]  Step 255837  [20.940 sec/step, loss=0.06596, avg_loss=0.07209]
[2018-11-23 15:56:30.531]  Step 255838  [20.963 sec/step, loss=0.07361, avg_loss=0.07209]
[2018-11-23 15:56:52.962]  Step 255839  [20.955 sec/step, loss=0.07330, avg_loss=0.07208]
[2018-11-23 15:57:17.562]  Step 255840  [20.955 sec/step, loss=0.07384, avg_loss=0.07207]
[2018-11-23 15:57:42.920]  Step 255841  [20.961 sec/step, loss=0.07433, avg_loss=0.07208]
[2018-11-23 15:58:04.598]  Step 255842  [20.940 sec/step, loss=0.07390, avg_loss=0.07208]
[2018-11-23 15:58:28.491]  Step 255843  [20.992 sec/step, loss=0.07334, avg_loss=0.07208]
[2018-11-23 15:58:52.672]  Step 255844  [21.061 sec/step, loss=0.07407, avg_loss=0.07211]
[2018-11-23 15:59:01.235]  Step 255845  [20.959 sec/step, loss=0.05338, avg_loss=0.07192]
[2018-11-23 15:59:21.937]  Step 255846  [20.975 sec/step, loss=0.07381, avg_loss=0.07192]
[2018-11-23 15:59:47.413]  Step 255847  [21.010 sec/step, loss=0.07455, avg_loss=0.07192]
[2018-11-23 16:00:14.315]  Step 255848  [21.097 sec/step, loss=0.07388, avg_loss=0.07194]
[2018-11-23 16:00:36.770]  Step 255849  [21.211 sec/step, loss=0.07299, avg_loss=0.07201]
[2018-11-23 16:00:55.464]  Step 255850  [21.235 sec/step, loss=0.07264, avg_loss=0.07202]
[2018-11-23 16:00:55.465]  Writing summary at step: 255850
[2018-11-23 16:01:31.302]  Step 255851  [21.167 sec/step, loss=0.06957, avg_loss=0.07198]
[2018-11-23 16:01:52.551]  Step 255852  [21.133 sec/step, loss=0.07375, avg_loss=0.07198]
[2018-11-23 16:02:09.290]  Step 255853  [21.074 sec/step, loss=0.07286, avg_loss=0.07198]
[2018-11-23 16:02:31.934]  Step 255854  [21.094 sec/step, loss=0.07408, avg_loss=0.07198]
[2018-11-23 16:02:41.499]  Generated 32 batches of size 32 in 8.714 sec
[2018-11-23 16:02:52.208]  Step 255855  [21.205 sec/step, loss=0.07403, avg_loss=0.07218]
[2018-11-23 16:03:14.853]  Step 255856  [21.190 sec/step, loss=0.07343, avg_loss=0.07217]
[2018-11-23 16:03:34.461]  Step 255857  [20.998 sec/step, loss=0.07296, avg_loss=0.07224]
[2018-11-23 16:03:58.250]  Step 255858  [21.016 sec/step, loss=0.07435, avg_loss=0.07225]
[2018-11-23 16:04:21.280]  Step 255859  [20.978 sec/step, loss=0.07404, avg_loss=0.07225]
[2018-11-23 16:04:33.320]  Step 255860  [20.970 sec/step, loss=0.06984, avg_loss=0.07225]
[2018-11-23 16:05:17.256]  Step 255861  [21.168 sec/step, loss=0.06590, avg_loss=0.07217]
[2018-11-23 16:05:38.053]  Step 255862  [21.157 sec/step, loss=0.07370, avg_loss=0.07217]
[2018-11-23 16:05:59.711]  Step 255863  [21.119 sec/step, loss=0.07425, avg_loss=0.07216]
[2018-11-23 16:06:22.143]  Step 255864  [21.097 sec/step, loss=0.07350, avg_loss=0.07216]
[2018-11-23 16:06:42.612]  Step 255865  [21.089 sec/step, loss=0.07347, avg_loss=0.07216]
[2018-11-23 16:06:53.069]  Step 255866  [20.996 sec/step, loss=0.06612, avg_loss=0.07208]
[2018-11-23 16:07:19.114]  Step 255867  [21.112 sec/step, loss=0.07430, avg_loss=0.07211]
[2018-11-23 16:07:43.590]  Step 255868  [21.101 sec/step, loss=0.07348, avg_loss=0.07211]
[2018-11-23 16:08:01.832]  Step 255869  [21.057 sec/step, loss=0.07235, avg_loss=0.07209]
[2018-11-23 16:08:24.001]  Step 255870  [21.092 sec/step, loss=0.07305, avg_loss=0.07209]
[2018-11-23 16:08:48.776]  Step 255871  [21.106 sec/step, loss=0.07394, avg_loss=0.07209]
[2018-11-23 16:09:11.228]  Step 255872  [21.245 sec/step, loss=0.07306, avg_loss=0.07227]
[2018-11-23 16:09:30.110]  Step 255873  [21.226 sec/step, loss=0.07306, avg_loss=0.07226]
[2018-11-23 16:10:07.268]  Step 255874  [21.352 sec/step, loss=0.06562, avg_loss=0.07218]
[2018-11-23 16:10:33.608]  Step 255875  [21.514 sec/step, loss=0.07395, avg_loss=0.07226]
[2018-11-23 16:10:48.789]  Step 255876  [21.449 sec/step, loss=0.07045, avg_loss=0.07222]
[2018-11-23 16:11:11.682]  Step 255877  [21.424 sec/step, loss=0.07405, avg_loss=0.07223]
[2018-11-23 16:11:31.590]  Step 255878  [21.397 sec/step, loss=0.07316, avg_loss=0.07222]
[2018-11-23 16:11:51.047]  Step 255879  [21.414 sec/step, loss=0.07359, avg_loss=0.07223]
[2018-11-23 16:12:15.445]  Step 255880  [21.450 sec/step, loss=0.07411, avg_loss=0.07225]
[2018-11-23 16:12:38.448]  Step 255881  [21.434 sec/step, loss=0.07394, avg_loss=0.07225]
[2018-11-23 16:12:50.746]  Step 255882  [21.331 sec/step, loss=0.06927, avg_loss=0.07220]
[2018-11-23 16:12:59.389]  Step 255883  [21.207 sec/step, loss=0.05455, avg_loss=0.07202]
[2018-11-23 16:13:24.658]  Step 255884  [21.258 sec/step, loss=0.07359, avg_loss=0.07202]
[2018-11-23 16:13:45.876]  Step 255885  [21.255 sec/step, loss=0.07376, avg_loss=0.07202]
[2018-11-23 16:14:03.321]  Step 255886  [21.189 sec/step, loss=0.07259, avg_loss=0.07202]
[2018-11-23 16:14:13.052]  Generated 32 batches of size 32 in 8.856 sec
[2018-11-23 16:14:31.474]  Step 255887  [21.309 sec/step, loss=0.07412, avg_loss=0.07205]
[2018-11-23 16:14:58.371]  Step 255888  [21.324 sec/step, loss=0.07409, avg_loss=0.07204]
[2018-11-23 16:15:13.965]  Step 255889  [21.084 sec/step, loss=0.07110, avg_loss=0.07210]
[2018-11-23 16:15:30.054]  Step 255890  [21.004 sec/step, loss=0.06997, avg_loss=0.07207]
[2018-11-23 16:15:55.897]  Step 255891  [21.070 sec/step, loss=0.07332, avg_loss=0.07207]
[2018-11-23 16:16:16.412]  Step 255892  [21.144 sec/step, loss=0.07367, avg_loss=0.07209]
[2018-11-23 16:16:35.150]  Step 255893  [21.163 sec/step, loss=0.07343, avg_loss=0.07212]
[2018-11-23 16:16:57.071]  Step 255894  [21.266 sec/step, loss=0.07335, avg_loss=0.07216]
[2018-11-23 16:17:18.953]  Step 255895  [21.238 sec/step, loss=0.07411, avg_loss=0.07216]
[2018-11-23 16:17:42.663]  Step 255896  [21.245 sec/step, loss=0.07316, avg_loss=0.07216]
[2018-11-23 16:18:04.245]  Step 255897  [21.269 sec/step, loss=0.07382, avg_loss=0.07216]
[2018-11-23 16:18:26.583]  Step 255898  [21.262 sec/step, loss=0.07328, avg_loss=0.07215]
[2018-11-23 16:18:43.856]  Step 255899  [21.214 sec/step, loss=0.07231, avg_loss=0.07214]
[2018-11-23 16:19:06.386]  Step 255900  [21.177 sec/step, loss=0.07374, avg_loss=0.07214]
[2018-11-23 16:19:06.386]  Writing summary at step: 255900
[2018-11-23 16:19:58.303]  Step 255901  [21.285 sec/step, loss=0.07267, avg_loss=0.07215]
[2018-11-23 16:20:39.549]  Step 255902  [21.444 sec/step, loss=0.06501, avg_loss=0.07206]
[2018-11-23 16:21:01.054]  Step 255903  [21.416 sec/step, loss=0.07346, avg_loss=0.07206]
[2018-11-23 16:21:19.705]  Step 255904  [21.418 sec/step, loss=0.07331, avg_loss=0.07205]
[2018-11-23 16:21:44.236]  Step 255905  [21.470 sec/step, loss=0.07367, avg_loss=0.07206]
[2018-11-23 16:21:59.638]  Step 255906  [21.450 sec/step, loss=0.07132, avg_loss=0.07204]
[2018-11-23 16:22:24.199]  Step 255907  [21.512 sec/step, loss=0.07432, avg_loss=0.07208]
[2018-11-23 16:22:44.734]  Step 255908  [21.510 sec/step, loss=0.07391, avg_loss=0.07209]
[2018-11-23 16:22:53.357]  Step 255909  [21.343 sec/step, loss=0.05477, avg_loss=0.07190]
[2018-11-23 16:23:11.396]  Step 255910  [21.300 sec/step, loss=0.07262, avg_loss=0.07189]
[2018-11-23 16:23:36.389]  Step 255911  [21.378 sec/step, loss=0.07382, avg_loss=0.07190]
[2018-11-23 16:24:00.602]  Step 255912  [21.404 sec/step, loss=0.07345, avg_loss=0.07190]
[2018-11-23 16:24:12.848]  Step 255913  [21.325 sec/step, loss=0.06977, avg_loss=0.07186]
[2018-11-23 16:24:33.656]  Step 255914  [21.295 sec/step, loss=0.07285, avg_loss=0.07185]
[2018-11-23 16:24:47.804]  Step 255915  [21.210 sec/step, loss=0.07089, avg_loss=0.07183]
[2018-11-23 16:25:11.756]  Step 255916  [21.186 sec/step, loss=0.07360, avg_loss=0.07183]
[2018-11-23 16:25:22.160]  Step 255917  [21.186 sec/step, loss=0.06573, avg_loss=0.07182]
[2018-11-23 16:25:31.627]  Generated 32 batches of size 32 in 8.529 sec
[2018-11-23 16:25:47.346]  Step 255918  [21.298 sec/step, loss=0.07370, avg_loss=0.07185]
[2018-11-23 16:26:09.259]  Step 255919  [21.124 sec/step, loss=0.07314, avg_loss=0.07194]
[2018-11-23 16:26:34.606]  Step 255920  [21.177 sec/step, loss=0.07455, avg_loss=0.07195]
[2018-11-23 16:26:55.947]  Step 255921  [21.146 sec/step, loss=0.07351, avg_loss=0.07195]
[2018-11-23 16:27:18.767]  Step 255922  [21.251 sec/step, loss=0.07368, avg_loss=0.07200]
[2018-11-23 16:27:38.021]  Step 255923  [21.222 sec/step, loss=0.07387, avg_loss=0.07200]
[2018-11-23 16:27:59.733]  Step 255924  [21.210 sec/step, loss=0.07291, avg_loss=0.07200]
[2018-11-23 16:28:18.563]  Step 255925  [21.153 sec/step, loss=0.07257, avg_loss=0.07198]
[2018-11-23 16:28:34.474]  Step 255926  [21.083 sec/step, loss=0.06961, avg_loss=0.07193]
[2018-11-23 16:28:56.537]  Step 255927  [21.062 sec/step, loss=0.07391, avg_loss=0.07194]
[2018-11-23 16:29:20.452]  Step 255928  [21.074 sec/step, loss=0.07318, avg_loss=0.07193]
[2018-11-23 16:29:40.964]  Step 255929  [21.062 sec/step, loss=0.07323, avg_loss=0.07192]
[2018-11-23 16:30:05.555]  Step 255930  [21.114 sec/step, loss=0.07369, avg_loss=0.07193]
[2018-11-23 16:30:29.695]  Step 255931  [21.268 sec/step, loss=0.07368, avg_loss=0.07212]
[2018-11-23 16:30:38.144]  Step 255932  [21.116 sec/step, loss=0.05561, avg_loss=0.07193]
[2018-11-23 16:30:50.397]  Step 255933  [21.098 sec/step, loss=0.06887, avg_loss=0.07192]
[2018-11-23 16:31:05.971]  Step 255934  [21.097 sec/step, loss=0.07099, avg_loss=0.07192]
[2018-11-23 16:31:30.621]  Step 255935  [21.155 sec/step, loss=0.07349, avg_loss=0.07193]
[2018-11-23 16:32:12.626]  Step 255936  [21.314 sec/step, loss=0.06502, avg_loss=0.07183]
[2018-11-23 16:32:35.233]  Step 255937  [21.432 sec/step, loss=0.07363, avg_loss=0.07191]
[2018-11-23 16:33:00.581]  Step 255938  [21.447 sec/step, loss=0.07439, avg_loss=0.07192]
[2018-11-23 16:33:24.647]  Step 255939  [21.464 sec/step, loss=0.07345, avg_loss=0.07192]
[2018-11-23 16:33:46.581]  Step 255940  [21.437 sec/step, loss=0.07407, avg_loss=0.07192]
[2018-11-23 16:34:04.571]  Step 255941  [21.363 sec/step, loss=0.07217, avg_loss=0.07190]
[2018-11-23 16:34:29.101]  Step 255942  [21.392 sec/step, loss=0.07410, avg_loss=0.07190]
[2018-11-23 16:34:48.001]  Step 255943  [21.342 sec/step, loss=0.07318, avg_loss=0.07190]
[2018-11-23 16:35:10.351]  Step 255944  [21.324 sec/step, loss=0.07297, avg_loss=0.07189]
[2018-11-23 16:35:27.673]  Step 255945  [21.411 sec/step, loss=0.07283, avg_loss=0.07208]
[2018-11-23 16:35:53.600]  Step 255946  [21.463 sec/step, loss=0.07410, avg_loss=0.07209]
[2018-11-23 16:36:09.438]  Step 255947  [21.367 sec/step, loss=0.06989, avg_loss=0.07204]
[2018-11-23 16:36:28.342]  Step 255948  [21.287 sec/step, loss=0.07352, avg_loss=0.07203]
[2018-11-23 16:36:50.455]  Step 255949  [21.284 sec/step, loss=0.07357, avg_loss=0.07204]
[2018-11-23 16:36:59.938]  Generated 32 batches of size 32 in 8.589 sec
[2018-11-23 16:37:13.330]  Step 255950  [21.326 sec/step, loss=0.07348, avg_loss=0.07205]
[2018-11-23 16:37:13.330]  Writing summary at step: 255950
[2018-11-23 16:37:55.762]  Step 255951  [21.360 sec/step, loss=0.07286, avg_loss=0.07208]
[2018-11-23 16:38:06.109]  Step 255952  [21.251 sec/step, loss=0.06531, avg_loss=0.07200]
[2018-11-23 16:38:19.864]  Step 255953  [21.221 sec/step, loss=0.07088, avg_loss=0.07198]
[2018-11-23 16:38:40.093]  Step 255954  [21.197 sec/step, loss=0.07324, avg_loss=0.07197]
[2018-11-23 16:38:59.360]  Step 255955  [21.187 sec/step, loss=0.07349, avg_loss=0.07196]
[2018-11-23 16:39:23.440]  Step 255956  [21.201 sec/step, loss=0.07425, avg_loss=0.07197]
[2018-11-23 16:39:49.612]  Step 255957  [21.267 sec/step, loss=0.07395, avg_loss=0.07198]
[2018-11-23 16:40:11.258]  Step 255958  [21.245 sec/step, loss=0.07375, avg_loss=0.07198]
[2018-11-23 16:40:30.442]  Step 255959  [21.207 sec/step, loss=0.07311, avg_loss=0.07197]
[2018-11-23 16:40:52.666]  Step 255960  [21.309 sec/step, loss=0.07284, avg_loss=0.07200]
[2018-11-23 16:41:15.054]  Step 255961  [21.093 sec/step, loss=0.07330, avg_loss=0.07207]
[2018-11-23 16:41:34.182]  Step 255962  [21.077 sec/step, loss=0.07267, avg_loss=0.07206]
[2018-11-23 16:41:56.256]  Step 255963  [21.081 sec/step, loss=0.07317, avg_loss=0.07205]
[2018-11-23 16:42:07.113]  Step 255964  [20.965 sec/step, loss=0.06515, avg_loss=0.07197]
[2018-11-23 16:42:31.580]  Step 255965  [21.005 sec/step, loss=0.07411, avg_loss=0.07197]
[2018-11-23 16:42:55.480]  Step 255966  [21.140 sec/step, loss=0.07387, avg_loss=0.07205]
[2018-11-23 16:43:12.637]  Step 255967  [21.051 sec/step, loss=0.07295, avg_loss=0.07204]
[2018-11-23 16:43:30.526]  Step 255968  [20.985 sec/step, loss=0.07275, avg_loss=0.07203]
[2018-11-23 16:43:54.168]  Step 255969  [21.039 sec/step, loss=0.07324, avg_loss=0.07204]
[2018-11-23 16:44:08.149]  Step 255970  [20.957 sec/step, loss=0.07094, avg_loss=0.07202]
[2018-11-23 16:44:23.863]  Step 255971  [20.866 sec/step, loss=0.06987, avg_loss=0.07198]
[2018-11-23 16:44:44.051]  Step 255972  [20.844 sec/step, loss=0.07349, avg_loss=0.07198]
[2018-11-23 16:45:10.495]  Step 255973  [20.919 sec/step, loss=0.07346, avg_loss=0.07198]
[2018-11-23 16:45:35.850]  Step 255974  [20.801 sec/step, loss=0.07459, avg_loss=0.07207]
[2018-11-23 16:45:44.909]  Step 255975  [20.629 sec/step, loss=0.05376, avg_loss=0.07187]
[2018-11-23 16:46:06.110]  Step 255976  [20.689 sec/step, loss=0.07318, avg_loss=0.07190]
[2018-11-23 16:46:51.477]  Step 255977  [20.913 sec/step, loss=0.06532, avg_loss=0.07181]
[2018-11-23 16:47:16.086]  Step 255978  [20.960 sec/step, loss=0.07408, avg_loss=0.07182]
[2018-11-23 16:47:39.446]  Step 255979  [20.999 sec/step, loss=0.07367, avg_loss=0.07182]
[2018-11-23 16:47:58.205]  Step 255980  [20.943 sec/step, loss=0.07369, avg_loss=0.07182]
[2018-11-23 16:48:08.103]  Generated 32 batches of size 32 in 8.732 sec
[2018-11-23 16:48:12.259]  Step 255981  [20.854 sec/step, loss=0.07047, avg_loss=0.07178]
[2018-11-23 16:48:31.461]  Step 255982  [20.923 sec/step, loss=0.07370, avg_loss=0.07183]
[2018-11-23 16:48:54.729]  Step 255983  [21.069 sec/step, loss=0.07374, avg_loss=0.07202]
[2018-11-23 16:49:19.482]  Step 255984  [21.064 sec/step, loss=0.07352, avg_loss=0.07202]
[2018-11-23 16:49:41.104]  Step 255985  [21.068 sec/step, loss=0.07382, avg_loss=0.07202]
[2018-11-23 16:50:05.303]  Step 255986  [21.135 sec/step, loss=0.07473, avg_loss=0.07204]
[2018-11-23 16:50:28.790]  Step 255987  [21.089 sec/step, loss=0.07366, avg_loss=0.07204]
[2018-11-23 16:50:45.090]  Step 255988  [20.983 sec/step, loss=0.07133, avg_loss=0.07201]
[2018-11-23 16:51:05.053]  Step 255989  [21.026 sec/step, loss=0.07361, avg_loss=0.07203]
[2018-11-23 16:51:30.137]  Step 255990  [21.116 sec/step, loss=0.07364, avg_loss=0.07207]
[2018-11-23 16:51:54.743]  Step 255991  [21.104 sec/step, loss=0.07355, avg_loss=0.07207]
[2018-11-23 16:52:16.283]  Step 255992  [21.114 sec/step, loss=0.07376, avg_loss=0.07207]
[2018-11-23 16:52:40.161]  Step 255993  [21.166 sec/step, loss=0.07300, avg_loss=0.07207]
[2018-11-23 16:52:57.996]  Step 255994  [21.125 sec/step, loss=0.07223, avg_loss=0.07206]
[2018-11-23 16:53:20.268]  Step 255995  [21.129 sec/step, loss=0.07350, avg_loss=0.07205]
[2018-11-23 16:53:36.115]  Step 255996  [21.050 sec/step, loss=0.07006, avg_loss=0.07202]
[2018-11-23 16:53:53.055]  Step 255997  [21.004 sec/step, loss=0.07244, avg_loss=0.07201]
[2018-11-23 16:54:13.573]  Step 255998  [20.985 sec/step, loss=0.07295, avg_loss=0.07200]
[2018-11-23 16:54:29.024]  Step 255999  [20.967 sec/step, loss=0.07114, avg_loss=0.07199]
[2018-11-23 16:54:51.908]  Step 256000  [20.971 sec/step, loss=0.07344, avg_loss=0.07199]
[2018-11-23 16:54:51.908]  Writing summary at step: 256000
[2018-11-23 16:55:11.313]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-256000
[2018-11-23 16:55:14.396]  Saving audio and alignment...
[2018-11-23 16:55:27.799]  Input: understanding and imperfect feelings, yet ever profoundly interesting: as interesting as the tales bessie sometimes narrated on winter evenings, when she chanced to be in good humour;~______
[2018-11-23 16:55:51.104]  Step 256001  [20.941 sec/step, loss=0.07362, avg_loss=0.07200]
[2018-11-23 16:56:31.309]  Step 256002  [20.930 sec/step, loss=0.06546, avg_loss=0.07200]
[2018-11-23 16:56:45.118]  Step 256003  [20.853 sec/step, loss=0.07084, avg_loss=0.07198]
[2018-11-23 16:56:55.404]  Step 256004  [20.770 sec/step, loss=0.06474, avg_loss=0.07189]
[2018-11-23 16:57:19.245]  Step 256005  [20.763 sec/step, loss=0.07385, avg_loss=0.07189]
[2018-11-23 16:57:45.426]  Step 256006  [20.870 sec/step, loss=0.07337, avg_loss=0.07191]
[2018-11-23 16:57:53.674]  Step 256007  [20.707 sec/step, loss=0.05547, avg_loss=0.07173]
[2018-11-23 16:58:05.993]  Step 256008  [20.625 sec/step, loss=0.06900, avg_loss=0.07168]
[2018-11-23 16:58:26.910]  Step 256009  [20.748 sec/step, loss=0.07432, avg_loss=0.07187]
[2018-11-23 16:58:47.175]  Step 256010  [20.770 sec/step, loss=0.07384, avg_loss=0.07188]
[2018-11-23 16:58:58.153]  Generated 32 batches of size 32 in 10.114 sec
[2018-11-23 16:59:14.807]  Step 256011  [20.797 sec/step, loss=0.07440, avg_loss=0.07189]
[2018-11-23 16:59:38.459]  Step 256012  [20.791 sec/step, loss=0.07395, avg_loss=0.07189]
[2018-11-23 17:00:04.204]  Step 256013  [20.926 sec/step, loss=0.07414, avg_loss=0.07194]
[2018-11-23 17:00:25.938]  Step 256014  [20.935 sec/step, loss=0.07348, avg_loss=0.07194]
[2018-11-23 17:00:45.686]  Step 256015  [20.991 sec/step, loss=0.07360, avg_loss=0.07197]
[2018-11-23 17:01:09.061]  Step 256016  [20.986 sec/step, loss=0.07423, avg_loss=0.07198]
[2018-11-23 17:01:27.610]  Step 256017  [21.067 sec/step, loss=0.07393, avg_loss=0.07206]
[2018-11-23 17:01:51.871]  Step 256018  [21.058 sec/step, loss=0.07444, avg_loss=0.07207]
[2018-11-23 17:02:13.462]  Step 256019  [21.055 sec/step, loss=0.07401, avg_loss=0.07208]
[2018-11-23 17:02:38.155]  Step 256020  [21.048 sec/step, loss=0.07376, avg_loss=0.07207]
[2018-11-23 17:03:00.853]  Step 256021  [21.062 sec/step, loss=0.07415, avg_loss=0.07207]
[2018-11-23 17:03:38.737]  Step 256022  [21.212 sec/step, loss=0.06503, avg_loss=0.07199]
[2018-11-23 17:03:50.142]  Step 256023  [21.134 sec/step, loss=0.06939, avg_loss=0.07194]
[2018-11-23 17:04:16.310]  Step 256024  [21.178 sec/step, loss=0.07326, avg_loss=0.07195]
[2018-11-23 17:04:36.576]  Step 256025  [21.193 sec/step, loss=0.07282, avg_loss=0.07195]
[2018-11-23 17:04:58.608]  Step 256026  [21.254 sec/step, loss=0.07332, avg_loss=0.07199]
[2018-11-23 17:05:06.134]  Step 256027  [21.109 sec/step, loss=0.05617, avg_loss=0.07181]
[2018-11-23 17:05:24.622]  Step 256028  [21.054 sec/step, loss=0.07308, avg_loss=0.07181]
[2018-11-23 17:05:49.137]  Step 256029  [21.094 sec/step, loss=0.07438, avg_loss=0.07182]
[2018-11-23 17:06:08.058]  Step 256030  [21.038 sec/step, loss=0.07383, avg_loss=0.07182]
[2018-11-23 17:06:24.309]  Step 256031  [20.959 sec/step, loss=0.07096, avg_loss=0.07179]
[2018-11-23 17:06:47.930]  Step 256032  [21.110 sec/step, loss=0.07409, avg_loss=0.07198]
[2018-11-23 17:07:12.361]  Step 256033  [21.232 sec/step, loss=0.07357, avg_loss=0.07203]
[2018-11-23 17:07:34.644]  Step 256034  [21.299 sec/step, loss=0.07323, avg_loss=0.07205]
[2018-11-23 17:07:56.444]  Step 256035  [21.271 sec/step, loss=0.07331, avg_loss=0.07205]
[2018-11-23 17:08:18.779]  Step 256036  [21.074 sec/step, loss=0.07374, avg_loss=0.07213]
[2018-11-23 17:08:41.731]  Step 256037  [21.078 sec/step, loss=0.07432, avg_loss=0.07214]
[2018-11-23 17:09:04.097]  Step 256038  [21.048 sec/step, loss=0.07398, avg_loss=0.07214]
[2018-11-23 17:09:24.458]  Step 256039  [21.011 sec/step, loss=0.07379, avg_loss=0.07214]
[2018-11-23 17:09:38.268]  Step 256040  [20.929 sec/step, loss=0.07202, avg_loss=0.07212]
[2018-11-23 17:10:01.028]  Step 256041  [20.977 sec/step, loss=0.07442, avg_loss=0.07214]
[2018-11-23 17:10:16.200]  Step 256042  [20.884 sec/step, loss=0.06996, avg_loss=0.07210]
[2018-11-23 17:10:26.789]  Generated 32 batches of size 32 in 9.876 sec
[2018-11-23 17:10:43.450]  Step 256043  [20.967 sec/step, loss=0.07399, avg_loss=0.07211]
[2018-11-23 17:11:09.112]  Step 256044  [21.000 sec/step, loss=0.07455, avg_loss=0.07212]
[2018-11-23 17:11:27.058]  Step 256045  [21.006 sec/step, loss=0.07275, avg_loss=0.07212]
[2018-11-23 17:11:37.559]  Step 256046  [20.852 sec/step, loss=0.06470, avg_loss=0.07203]
[2018-11-23 17:11:56.505]  Step 256047  [20.883 sec/step, loss=0.07331, avg_loss=0.07206]
[2018-11-23 17:12:17.514]  Step 256048  [20.904 sec/step, loss=0.07527, avg_loss=0.07208]
[2018-11-23 17:12:41.533]  Step 256049  [20.923 sec/step, loss=0.07349, avg_loss=0.07208]
[2018-11-23 17:13:01.122]  Step 256050  [20.890 sec/step, loss=0.07378, avg_loss=0.07208]
[2018-11-23 17:13:01.122]  Writing summary at step: 256050
[2018-11-23 17:13:49.364]  Step 256051  [20.929 sec/step, loss=0.07384, avg_loss=0.07209]
[2018-11-23 17:14:10.288]  Step 256052  [21.035 sec/step, loss=0.07350, avg_loss=0.07218]
[2018-11-23 17:14:35.072]  Step 256053  [21.145 sec/step, loss=0.07362, avg_loss=0.07220]
[2018-11-23 17:15:01.266]  Step 256054  [21.205 sec/step, loss=0.07403, avg_loss=0.07221]
[2018-11-23 17:15:24.104]  Step 256055  [21.241 sec/step, loss=0.07341, avg_loss=0.07221]
[2018-11-23 17:15:55.618]  Step 256056  [21.315 sec/step, loss=0.07464, avg_loss=0.07221]
[2018-11-23 17:16:17.689]  Step 256057  [21.274 sec/step, loss=0.07413, avg_loss=0.07222]
[2018-11-23 17:16:28.299]  Step 256058  [21.163 sec/step, loss=0.06698, avg_loss=0.07215]
[2018-11-23 17:16:42.751]  Step 256059  [21.116 sec/step, loss=0.07113, avg_loss=0.07213]
[2018-11-23 17:17:05.656]  Step 256060  [21.123 sec/step, loss=0.07341, avg_loss=0.07213]
[2018-11-23 17:17:26.705]  Step 256061  [21.110 sec/step, loss=0.07455, avg_loss=0.07215]
[2018-11-23 17:17:52.280]  Step 256062  [21.174 sec/step, loss=0.07454, avg_loss=0.07216]
[2018-11-23 17:18:14.126]  Step 256063  [21.172 sec/step, loss=0.07391, avg_loss=0.07217]
[2018-11-23 17:18:36.231]  Step 256064  [21.284 sec/step, loss=0.07423, avg_loss=0.07226]
[2018-11-23 17:18:59.537]  Step 256065  [21.273 sec/step, loss=0.07368, avg_loss=0.07226]
[2018-11-23 17:19:23.704]  Step 256066  [21.275 sec/step, loss=0.07416, avg_loss=0.07226]
[2018-11-23 17:19:33.000]  Step 256067  [21.197 sec/step, loss=0.05397, avg_loss=0.07207]
[2018-11-23 17:19:53.895]  Step 256068  [21.227 sec/step, loss=0.07395, avg_loss=0.07208]
[2018-11-23 17:20:13.819]  Step 256069  [21.190 sec/step, loss=0.07346, avg_loss=0.07209]
[2018-11-23 17:20:32.659]  Step 256070  [21.238 sec/step, loss=0.07301, avg_loss=0.07211]
[2018-11-23 17:20:58.162]  Step 256071  [21.336 sec/step, loss=0.07438, avg_loss=0.07215]
[2018-11-23 17:21:14.044]  Step 256072  [21.293 sec/step, loss=0.07127, avg_loss=0.07213]
[2018-11-23 17:21:38.453]  Step 256073  [21.273 sec/step, loss=0.07408, avg_loss=0.07214]
[2018-11-23 17:21:48.065]  Generated 32 batches of size 32 in 8.835 sec
[2018-11-23 17:21:52.613]  Step 256074  [21.161 sec/step, loss=0.06941, avg_loss=0.07208]
[2018-11-23 17:22:11.190]  Step 256075  [21.256 sec/step, loss=0.07422, avg_loss=0.07229]
[2018-11-23 17:22:33.215]  Step 256076  [21.264 sec/step, loss=0.07370, avg_loss=0.07229]
[2018-11-23 17:22:56.687]  Step 256077  [21.045 sec/step, loss=0.07360, avg_loss=0.07238]
[2018-11-23 17:23:15.534]  Step 256078  [20.988 sec/step, loss=0.07301, avg_loss=0.07237]
[2018-11-23 17:23:53.449]  Step 256079  [21.133 sec/step, loss=0.06614, avg_loss=0.07229]
[2018-11-23 17:24:15.413]  Step 256080  [21.165 sec/step, loss=0.07415, avg_loss=0.07229]
[2018-11-23 17:24:32.536]  Step 256081  [21.196 sec/step, loss=0.07283, avg_loss=0.07232]
[2018-11-23 17:24:49.113]  Step 256082  [21.170 sec/step, loss=0.07203, avg_loss=0.07230]
[2018-11-23 17:25:11.001]  Step 256083  [21.156 sec/step, loss=0.07336, avg_loss=0.07230]
[2018-11-23 17:25:34.278]  Step 256084  [21.141 sec/step, loss=0.07364, avg_loss=0.07230]
[2018-11-23 17:25:50.740]  Step 256085  [21.089 sec/step, loss=0.07114, avg_loss=0.07227]
[2018-11-23 17:26:03.035]  Step 256086  [20.970 sec/step, loss=0.06946, avg_loss=0.07222]
[2018-11-23 17:26:27.421]  Step 256087  [20.979 sec/step, loss=0.07441, avg_loss=0.07223]
[2018-11-23 17:26:52.874]  Step 256088  [21.071 sec/step, loss=0.07436, avg_loss=0.07226]
[2018-11-23 17:27:15.909]  Step 256089  [21.102 sec/step, loss=0.07422, avg_loss=0.07226]
[2018-11-23 17:27:34.255]  Step 256090  [21.034 sec/step, loss=0.07330, avg_loss=0.07226]
[2018-11-23 17:27:56.849]  Step 256091  [21.014 sec/step, loss=0.07380, avg_loss=0.07226]
[2018-11-23 17:28:07.298]  Step 256092  [20.903 sec/step, loss=0.06601, avg_loss=0.07218]
[2018-11-23 17:28:31.361]  Step 256093  [20.905 sec/step, loss=0.07385, avg_loss=0.07219]
[2018-11-23 17:28:51.736]  Step 256094  [20.930 sec/step, loss=0.07349, avg_loss=0.07221]
[2018-11-23 17:29:05.653]  Step 256095  [20.847 sec/step, loss=0.07154, avg_loss=0.07219]
[2018-11-23 17:29:28.495]  Step 256096  [20.917 sec/step, loss=0.07388, avg_loss=0.07222]
[2018-11-23 17:29:51.067]  Step 256097  [20.973 sec/step, loss=0.07330, avg_loss=0.07223]
[2018-11-23 17:30:12.268]  Step 256098  [20.980 sec/step, loss=0.07305, avg_loss=0.07223]
[2018-11-23 17:30:34.246]  Step 256099  [21.045 sec/step, loss=0.07408, avg_loss=0.07226]
[2018-11-23 17:30:59.870]  Step 256100  [21.073 sec/step, loss=0.07325, avg_loss=0.07226]
[2018-11-23 17:30:59.870]  Writing summary at step: 256100
[2018-11-23 17:31:58.335]  Step 256101  [21.244 sec/step, loss=0.06467, avg_loss=0.07217]
[2018-11-23 17:32:22.339]  Step 256102  [21.082 sec/step, loss=0.07374, avg_loss=0.07225]
[2018-11-23 17:32:42.732]  Step 256103  [21.148 sec/step, loss=0.07327, avg_loss=0.07228]
[2018-11-23 17:33:07.395]  Step 256104  [21.292 sec/step, loss=0.07371, avg_loss=0.07237]
[2018-11-23 17:33:16.959]  Generated 32 batches of size 32 in 8.682 sec
[2018-11-23 17:33:23.847]  Step 256105  [21.218 sec/step, loss=0.07042, avg_loss=0.07233]
[2018-11-23 17:33:50.042]  Step 256106  [21.218 sec/step, loss=0.07331, avg_loss=0.07233]
[2018-11-23 17:34:14.511]  Step 256107  [21.380 sec/step, loss=0.07339, avg_loss=0.07251]
[2018-11-23 17:34:31.822]  Step 256108  [21.430 sec/step, loss=0.07338, avg_loss=0.07256]
[2018-11-23 17:34:54.305]  Step 256109  [21.446 sec/step, loss=0.07329, avg_loss=0.07255]
[2018-11-23 17:35:13.196]  Step 256110  [21.432 sec/step, loss=0.07378, avg_loss=0.07255]
[2018-11-23 17:35:33.035]  Step 256111  [21.354 sec/step, loss=0.07295, avg_loss=0.07253]
[2018-11-23 17:35:52.420]  Step 256112  [21.312 sec/step, loss=0.07276, avg_loss=0.07252]
[2018-11-23 17:36:01.187]  Step 256113  [21.142 sec/step, loss=0.05360, avg_loss=0.07231]
[2018-11-23 17:36:23.881]  Step 256114  [21.151 sec/step, loss=0.07353, avg_loss=0.07231]
[2018-11-23 17:36:47.573]  Step 256115  [21.191 sec/step, loss=0.07322, avg_loss=0.07231]
[2018-11-23 17:37:12.882]  Step 256116  [21.210 sec/step, loss=0.07403, avg_loss=0.07231]
[2018-11-23 17:37:33.225]  Step 256117  [21.228 sec/step, loss=0.07356, avg_loss=0.07231]
[2018-11-23 17:37:57.402]  Step 256118  [21.227 sec/step, loss=0.07408, avg_loss=0.07230]
[2018-11-23 17:38:21.264]  Step 256119  [21.250 sec/step, loss=0.07312, avg_loss=0.07229]
[2018-11-23 17:38:33.447]  Step 256120  [21.125 sec/step, loss=0.06932, avg_loss=0.07225]
[2018-11-23 17:38:57.567]  Step 256121  [21.139 sec/step, loss=0.07337, avg_loss=0.07224]
[2018-11-23 17:39:15.538]  Step 256122  [20.940 sec/step, loss=0.07240, avg_loss=0.07231]
[2018-11-23 17:39:24.134]  Step 256123  [20.912 sec/step, loss=0.05523, avg_loss=0.07217]
[2018-11-23 17:39:44.991]  Step 256124  [20.859 sec/step, loss=0.07382, avg_loss=0.07218]
[2018-11-23 17:40:04.246]  Step 256125  [20.849 sec/step, loss=0.07310, avg_loss=0.07218]
[2018-11-23 17:40:19.952]  Step 256126  [20.785 sec/step, loss=0.07141, avg_loss=0.07216]
[2018-11-23 17:40:46.936]  Step 256127  [20.980 sec/step, loss=0.07282, avg_loss=0.07233]
[2018-11-23 17:41:10.760]  Step 256128  [21.033 sec/step, loss=0.07417, avg_loss=0.07234]
[2018-11-23 17:41:32.312]  Step 256129  [21.004 sec/step, loss=0.07415, avg_loss=0.07234]
[2018-11-23 17:41:54.054]  Step 256130  [21.032 sec/step, loss=0.07383, avg_loss=0.07234]
[2018-11-23 17:42:17.861]  Step 256131  [21.107 sec/step, loss=0.07358, avg_loss=0.07236]
[2018-11-23 17:42:33.552]  Step 256132  [21.028 sec/step, loss=0.07026, avg_loss=0.07232]
[2018-11-23 17:42:56.888]  Step 256133  [21.017 sec/step, loss=0.07463, avg_loss=0.07234]
[2018-11-23 17:43:19.882]  Step 256134  [21.024 sec/step, loss=0.07359, avg_loss=0.07234]
[2018-11-23 17:43:44.323]  Step 256135  [21.051 sec/step, loss=0.07353, avg_loss=0.07234]
[2018-11-23 17:44:21.604]  Step 256136  [21.200 sec/step, loss=0.06553, avg_loss=0.07226]
[2018-11-23 17:44:30.676]  Generated 32 batches of size 32 in 8.229 sec
[2018-11-23 17:44:44.754]  Step 256137  [21.202 sec/step, loss=0.07362, avg_loss=0.07225]
[2018-11-23 17:45:03.559]  Step 256138  [21.167 sec/step, loss=0.07272, avg_loss=0.07224]
[2018-11-23 17:45:26.056]  Step 256139  [21.188 sec/step, loss=0.07339, avg_loss=0.07224]
[2018-11-23 17:45:46.507]  Step 256140  [21.254 sec/step, loss=0.07327, avg_loss=0.07225]
[2018-11-23 17:46:04.988]  Step 256141  [21.212 sec/step, loss=0.07351, avg_loss=0.07224]
[2018-11-23 17:46:27.106]  Step 256142  [21.281 sec/step, loss=0.07314, avg_loss=0.07227]
[2018-11-23 17:46:37.524]  Step 256143  [21.113 sec/step, loss=0.06670, avg_loss=0.07220]
[2018-11-23 17:46:55.152]  Step 256144  [21.032 sec/step, loss=0.07262, avg_loss=0.07218]
[2018-11-23 17:47:09.390]  Step 256145  [20.995 sec/step, loss=0.07124, avg_loss=0.07216]
[2018-11-23 17:47:23.344]  Step 256146  [21.030 sec/step, loss=0.06993, avg_loss=0.07222]
[2018-11-23 17:47:33.699]  Step 256147  [20.944 sec/step, loss=0.06464, avg_loss=0.07213]
[2018-11-23 17:47:56.706]  Step 256148  [20.964 sec/step, loss=0.07364, avg_loss=0.07211]
[2018-11-23 17:48:35.144]  Step 256149  [21.108 sec/step, loss=0.06497, avg_loss=0.07203]
[2018-11-23 17:48:59.447]  Step 256150  [21.155 sec/step, loss=0.07334, avg_loss=0.07202]
[2018-11-23 17:48:59.447]  Writing summary at step: 256150
[2018-11-23 17:49:46.552]  Step 256151  [21.148 sec/step, loss=0.07364, avg_loss=0.07202]
[2018-11-23 17:49:58.146]  Step 256152  [21.055 sec/step, loss=0.06946, avg_loss=0.07198]
[2018-11-23 17:50:17.072]  Step 256153  [20.996 sec/step, loss=0.07295, avg_loss=0.07197]
[2018-11-23 17:50:44.360]  Step 256154  [21.007 sec/step, loss=0.07329, avg_loss=0.07197]
[2018-11-23 17:50:59.651]  Step 256155  [20.932 sec/step, loss=0.07133, avg_loss=0.07195]
[2018-11-23 17:51:22.530]  Step 256156  [20.845 sec/step, loss=0.07408, avg_loss=0.07194]
[2018-11-23 17:51:38.826]  Step 256157  [20.788 sec/step, loss=0.06940, avg_loss=0.07189]
[2018-11-23 17:52:00.633]  Step 256158  [20.900 sec/step, loss=0.07373, avg_loss=0.07196]
[2018-11-23 17:52:09.112]  Step 256159  [20.840 sec/step, loss=0.05543, avg_loss=0.07180]
[2018-11-23 17:52:29.665]  Step 256160  [20.816 sec/step, loss=0.07335, avg_loss=0.07180]
[2018-11-23 17:52:51.453]  Step 256161  [20.824 sec/step, loss=0.07416, avg_loss=0.07180]
[2018-11-23 17:53:16.043]  Step 256162  [20.814 sec/step, loss=0.07381, avg_loss=0.07179]
[2018-11-23 17:53:37.517]  Step 256163  [20.810 sec/step, loss=0.07347, avg_loss=0.07179]
[2018-11-23 17:53:55.943]  Step 256164  [20.773 sec/step, loss=0.07354, avg_loss=0.07178]
[2018-11-23 17:54:18.170]  Step 256165  [20.763 sec/step, loss=0.07288, avg_loss=0.07177]
[2018-11-23 17:54:38.761]  Step 256166  [20.727 sec/step, loss=0.07362, avg_loss=0.07177]
[2018-11-23 17:54:58.173]  Step 256167  [20.828 sec/step, loss=0.07374, avg_loss=0.07197]
[2018-11-23 17:55:09.144]  Generated 32 batches of size 32 in 10.169 sec
[2018-11-23 17:55:25.578]  Step 256168  [20.893 sec/step, loss=0.07373, avg_loss=0.07196]
[2018-11-23 17:55:43.611]  Step 256169  [20.874 sec/step, loss=0.07260, avg_loss=0.07195]
[2018-11-23 17:56:03.290]  Step 256170  [20.883 sec/step, loss=0.07303, avg_loss=0.07195]
[2018-11-23 17:56:26.827]  Step 256171  [20.863 sec/step, loss=0.07414, avg_loss=0.07195]
[2018-11-23 17:56:43.871]  Step 256172  [20.875 sec/step, loss=0.07267, avg_loss=0.07197]
[2018-11-23 17:57:09.450]  Step 256173  [20.886 sec/step, loss=0.07432, avg_loss=0.07197]
[2018-11-23 17:57:30.838]  Step 256174  [20.959 sec/step, loss=0.07313, avg_loss=0.07201]
[2018-11-23 17:57:53.357]  Step 256175  [20.998 sec/step, loss=0.07386, avg_loss=0.07200]
[2018-11-23 17:58:17.559]  Step 256176  [21.020 sec/step, loss=0.07400, avg_loss=0.07201]
[2018-11-23 17:58:42.195]  Step 256177  [21.031 sec/step, loss=0.07402, avg_loss=0.07201]
[2018-11-23 17:59:03.960]  Step 256178  [21.061 sec/step, loss=0.07363, avg_loss=0.07202]
[2018-11-23 17:59:47.134]  Step 256179  [21.113 sec/step, loss=0.06540, avg_loss=0.07201]
[2018-11-23 18:00:11.474]  Step 256180  [21.137 sec/step, loss=0.07296, avg_loss=0.07200]
[2018-11-23 18:00:31.559]  Step 256181  [21.167 sec/step, loss=0.07262, avg_loss=0.07199]
[2018-11-23 18:00:54.600]  Step 256182  [21.231 sec/step, loss=0.07323, avg_loss=0.07201]
[2018-11-23 18:01:05.486]  Step 256183  [21.121 sec/step, loss=0.06612, avg_loss=0.07193]
[2018-11-23 18:01:28.432]  Step 256184  [21.118 sec/step, loss=0.07330, avg_loss=0.07193]
[2018-11-23 18:01:42.437]  Step 256185  [21.093 sec/step, loss=0.07077, avg_loss=0.07193]
[2018-11-23 18:01:54.758]  Step 256186  [21.094 sec/step, loss=0.06840, avg_loss=0.07192]
[2018-11-23 18:02:14.222]  Step 256187  [21.044 sec/step, loss=0.07261, avg_loss=0.07190]
[2018-11-23 18:02:36.893]  Step 256188  [21.017 sec/step, loss=0.07283, avg_loss=0.07188]
[2018-11-23 18:03:00.768]  Step 256189  [21.025 sec/step, loss=0.07386, avg_loss=0.07188]
[2018-11-23 18:03:18.324]  Step 256190  [21.017 sec/step, loss=0.07283, avg_loss=0.07188]
[2018-11-23 18:03:43.032]  Step 256191  [21.038 sec/step, loss=0.07339, avg_loss=0.07187]
[2018-11-23 18:04:07.091]  Step 256192  [21.174 sec/step, loss=0.07394, avg_loss=0.07195]
[2018-11-23 18:04:15.850]  Step 256193  [21.021 sec/step, loss=0.05233, avg_loss=0.07174]
[2018-11-23 18:04:35.461]  Step 256194  [21.014 sec/step, loss=0.07292, avg_loss=0.07173]
[2018-11-23 18:04:59.383]  Step 256195  [21.114 sec/step, loss=0.07381, avg_loss=0.07175]
[2018-11-23 18:05:22.368]  Step 256196  [21.115 sec/step, loss=0.07376, avg_loss=0.07175]
[2018-11-23 18:05:42.825]  Step 256197  [21.094 sec/step, loss=0.07341, avg_loss=0.07175]
[2018-11-23 18:06:07.271]  Step 256198  [21.126 sec/step, loss=0.07356, avg_loss=0.07176]
[2018-11-23 18:06:25.105]  Step 256199  [21.085 sec/step, loss=0.07192, avg_loss=0.07174]
[2018-11-23 18:06:34.416]  Generated 32 batches of size 32 in 8.551 sec
[2018-11-23 18:06:42.460]  Step 256200  [21.002 sec/step, loss=0.07002, avg_loss=0.07170]
[2018-11-23 18:06:42.460]  Writing summary at step: 256200
[2018-11-23 18:07:25.883]  Step 256201  [20.819 sec/step, loss=0.07306, avg_loss=0.07179]
[2018-11-23 18:07:53.218]  Step 256202  [20.852 sec/step, loss=0.07346, avg_loss=0.07178]
[2018-11-23 18:08:18.286]  Step 256203  [20.899 sec/step, loss=0.07436, avg_loss=0.07180]
[2018-11-23 18:08:39.094]  Step 256204  [20.860 sec/step, loss=0.07365, avg_loss=0.07179]
[2018-11-23 18:08:57.976]  Step 256205  [20.885 sec/step, loss=0.07368, avg_loss=0.07183]
[2018-11-23 18:09:19.514]  Step 256206  [20.838 sec/step, loss=0.07369, avg_loss=0.07183]
[2018-11-23 18:09:35.052]  Step 256207  [20.749 sec/step, loss=0.07124, avg_loss=0.07181]
[2018-11-23 18:09:52.499]  Step 256208  [20.750 sec/step, loss=0.07211, avg_loss=0.07180]
[2018-11-23 18:10:07.873]  Step 256209  [20.679 sec/step, loss=0.07114, avg_loss=0.07178]
[2018-11-23 18:10:28.039]  Step 256210  [20.692 sec/step, loss=0.07224, avg_loss=0.07176]
[2018-11-23 18:10:48.684]  Step 256211  [20.700 sec/step, loss=0.07308, avg_loss=0.07176]
[2018-11-23 18:11:09.373]  Step 256212  [20.713 sec/step, loss=0.07352, avg_loss=0.07177]
[2018-11-23 18:11:32.636]  Step 256213  [20.858 sec/step, loss=0.07319, avg_loss=0.07197]
[2018-11-23 18:11:46.652]  Step 256214  [20.771 sec/step, loss=0.07028, avg_loss=0.07193]
[2018-11-23 18:12:08.980]  Step 256215  [20.757 sec/step, loss=0.07339, avg_loss=0.07193]
[2018-11-23 18:12:33.044]  Step 256216  [20.745 sec/step, loss=0.07456, avg_loss=0.07194]
[2018-11-23 18:13:00.450]  Step 256217  [20.815 sec/step, loss=0.07316, avg_loss=0.07194]
[2018-11-23 18:13:24.847]  Step 256218  [20.818 sec/step, loss=0.07340, avg_loss=0.07193]
[2018-11-23 18:13:33.396]  Step 256219  [20.665 sec/step, loss=0.05538, avg_loss=0.07175]
[2018-11-23 18:13:49.112]  Step 256220  [20.700 sec/step, loss=0.06951, avg_loss=0.07175]
[2018-11-23 18:14:14.166]  Step 256221  [20.709 sec/step, loss=0.07406, avg_loss=0.07176]
[2018-11-23 18:14:26.678]  Step 256222  [20.655 sec/step, loss=0.06903, avg_loss=0.07173]
[2018-11-23 18:14:49.113]  Step 256223  [20.793 sec/step, loss=0.07282, avg_loss=0.07190]
[2018-11-23 18:15:12.678]  Step 256224  [20.820 sec/step, loss=0.07338, avg_loss=0.07190]
[2018-11-23 18:15:32.284]  Step 256225  [20.824 sec/step, loss=0.07249, avg_loss=0.07189]
[2018-11-23 18:16:24.335]  Step 256226  [21.187 sec/step, loss=0.06525, avg_loss=0.07183]
[2018-11-23 18:16:49.538]  Step 256227  [21.169 sec/step, loss=0.07356, avg_loss=0.07184]
[2018-11-23 18:17:06.746]  Step 256228  [21.103 sec/step, loss=0.07220, avg_loss=0.07182]
[2018-11-23 18:17:28.844]  Step 256229  [21.109 sec/step, loss=0.07368, avg_loss=0.07181]
[2018-11-23 18:17:50.855]  Step 256230  [21.111 sec/step, loss=0.07334, avg_loss=0.07181]
[2018-11-23 18:18:00.992]  Generated 32 batches of size 32 in 9.017 sec
[2018-11-23 18:18:11.400]  Step 256231  [21.079 sec/step, loss=0.07275, avg_loss=0.07180]
[2018-11-23 18:18:33.809]  Step 256232  [21.146 sec/step, loss=0.07361, avg_loss=0.07183]
[2018-11-23 18:18:59.008]  Step 256233  [21.164 sec/step, loss=0.07400, avg_loss=0.07183]
[2018-11-23 18:19:23.682]  Step 256234  [21.181 sec/step, loss=0.07340, avg_loss=0.07183]
[2018-11-23 18:19:47.321]  Step 256235  [21.173 sec/step, loss=0.07352, avg_loss=0.07183]
[2018-11-23 18:19:57.957]  Step 256236  [20.907 sec/step, loss=0.06599, avg_loss=0.07183]
[2018-11-23 18:20:16.492]  Step 256237  [20.861 sec/step, loss=0.07349, avg_loss=0.07183]
[2018-11-23 18:20:37.709]  Step 256238  [20.885 sec/step, loss=0.07342, avg_loss=0.07184]
[2018-11-23 18:21:02.638]  Step 256239  [20.909 sec/step, loss=0.07363, avg_loss=0.07184]
[2018-11-23 18:21:26.511]  Step 256240  [20.943 sec/step, loss=0.07344, avg_loss=0.07184]
[2018-11-23 18:21:46.706]  Step 256241  [20.960 sec/step, loss=0.07313, avg_loss=0.07184]
[2018-11-23 18:22:10.158]  Step 256242  [20.974 sec/step, loss=0.07364, avg_loss=0.07184]
[2018-11-23 18:22:18.842]  Step 256243  [20.956 sec/step, loss=0.05396, avg_loss=0.07171]
[2018-11-23 18:22:39.376]  Step 256244  [20.985 sec/step, loss=0.07328, avg_loss=0.07172]
[2018-11-23 18:22:49.673]  Step 256245  [20.946 sec/step, loss=0.06602, avg_loss=0.07167]
[2018-11-23 18:23:03.549]  Step 256246  [20.945 sec/step, loss=0.07069, avg_loss=0.07168]
[2018-11-23 18:23:22.254]  Step 256247  [21.029 sec/step, loss=0.07275, avg_loss=0.07176]
[2018-11-23 18:24:02.887]  Step 256248  [21.205 sec/step, loss=0.06472, avg_loss=0.07167]
[2018-11-23 18:24:23.379]  Step 256249  [21.026 sec/step, loss=0.07275, avg_loss=0.07174]
[2018-11-23 18:24:46.857]  Step 256250  [21.017 sec/step, loss=0.07299, avg_loss=0.07174]
[2018-11-23 18:24:46.857]  Writing summary at step: 256250
[2018-11-23 18:25:30.384]  Step 256251  [21.011 sec/step, loss=0.07389, avg_loss=0.07174]
[2018-11-23 18:25:52.706]  Step 256252  [21.118 sec/step, loss=0.07314, avg_loss=0.07178]
[2018-11-23 18:26:16.975]  Step 256253  [21.172 sec/step, loss=0.07397, avg_loss=0.07179]
[2018-11-23 18:26:32.282]  Step 256254  [21.052 sec/step, loss=0.07150, avg_loss=0.07177]
[2018-11-23 18:26:54.261]  Step 256255  [21.119 sec/step, loss=0.07314, avg_loss=0.07179]
[2018-11-23 18:27:16.338]  Step 256256  [21.111 sec/step, loss=0.07367, avg_loss=0.07179]
[2018-11-23 18:27:34.792]  Step 256257  [21.132 sec/step, loss=0.07286, avg_loss=0.07182]
[2018-11-23 18:27:46.925]  Step 256258  [21.036 sec/step, loss=0.06904, avg_loss=0.07177]
[2018-11-23 18:28:02.771]  Step 256259  [21.109 sec/step, loss=0.06937, avg_loss=0.07191]
[2018-11-23 18:28:27.004]  Step 256260  [21.146 sec/step, loss=0.07377, avg_loss=0.07192]
[2018-11-23 18:28:44.154]  Step 256261  [21.100 sec/step, loss=0.07249, avg_loss=0.07190]
[2018-11-23 18:28:55.868]  Generated 32 batches of size 32 in 10.842 sec
[2018-11-23 18:29:14.516]  Step 256262  [21.157 sec/step, loss=0.07334, avg_loss=0.07190]
[2018-11-23 18:29:32.392]  Step 256263  [21.121 sec/step, loss=0.07258, avg_loss=0.07189]
[2018-11-23 18:29:55.415]  Step 256264  [21.167 sec/step, loss=0.07346, avg_loss=0.07189]
[2018-11-23 18:30:20.272]  Step 256265  [21.194 sec/step, loss=0.07312, avg_loss=0.07189]
[2018-11-23 18:30:43.287]  Step 256266  [21.218 sec/step, loss=0.07329, avg_loss=0.07189]
[2018-11-23 18:31:08.724]  Step 256267  [21.278 sec/step, loss=0.07448, avg_loss=0.07189]
[2018-11-23 18:31:33.682]  Step 256268  [21.254 sec/step, loss=0.07441, avg_loss=0.07190]
[2018-11-23 18:31:56.087]  Step 256269  [21.297 sec/step, loss=0.07321, avg_loss=0.07191]
[2018-11-23 18:32:15.439]  Step 256270  [21.294 sec/step, loss=0.07325, avg_loss=0.07191]
[2018-11-23 18:32:31.694]  Step 256271  [21.221 sec/step, loss=0.07073, avg_loss=0.07187]
[2018-11-23 18:32:56.259]  Step 256272  [21.297 sec/step, loss=0.07317, avg_loss=0.07188]
[2018-11-23 18:33:22.218]  Step 256273  [21.300 sec/step, loss=0.07282, avg_loss=0.07186]
[2018-11-23 18:33:35.939]  Step 256274  [21.224 sec/step, loss=0.07012, avg_loss=0.07183]
[2018-11-23 18:33:59.289]  Step 256275  [21.232 sec/step, loss=0.07322, avg_loss=0.07183]
[2018-11-23 18:34:21.076]  Step 256276  [21.208 sec/step, loss=0.07339, avg_loss=0.07182]
[2018-11-23 18:34:45.466]  Step 256277  [21.205 sec/step, loss=0.07347, avg_loss=0.07182]
[2018-11-23 18:35:09.899]  Step 256278  [21.232 sec/step, loss=0.07373, avg_loss=0.07182]
[2018-11-23 18:35:32.232]  Step 256279  [21.024 sec/step, loss=0.07332, avg_loss=0.07190]
[2018-11-23 18:35:40.750]  Step 256280  [20.865 sec/step, loss=0.05429, avg_loss=0.07171]
[2018-11-23 18:36:03.360]  Step 256281  [20.891 sec/step, loss=0.07323, avg_loss=0.07172]
[2018-11-23 18:36:24.165]  Step 256282  [20.868 sec/step, loss=0.07260, avg_loss=0.07171]
[2018-11-23 18:36:41.216]  Step 256283  [20.930 sec/step, loss=0.07216, avg_loss=0.07177]
[2018-11-23 18:36:56.852]  Step 256284  [20.857 sec/step, loss=0.06988, avg_loss=0.07174]
[2018-11-23 18:37:18.577]  Step 256285  [20.934 sec/step, loss=0.07359, avg_loss=0.07176]
[2018-11-23 18:37:42.870]  Step 256286  [21.054 sec/step, loss=0.07427, avg_loss=0.07182]
[2018-11-23 18:38:05.328]  Step 256287  [21.084 sec/step, loss=0.07291, avg_loss=0.07183]
[2018-11-23 18:38:26.963]  Step 256288  [21.073 sec/step, loss=0.07351, avg_loss=0.07183]
[2018-11-23 18:38:38.918]  Step 256289  [20.954 sec/step, loss=0.06870, avg_loss=0.07178]
[2018-11-23 18:39:02.491]  Step 256290  [21.014 sec/step, loss=0.07343, avg_loss=0.07179]
[2018-11-23 18:39:20.496]  Step 256291  [20.947 sec/step, loss=0.07245, avg_loss=0.07178]
[2018-11-23 18:39:40.070]  Step 256292  [20.903 sec/step, loss=0.07259, avg_loss=0.07176]
[2018-11-23 18:39:58.390]  Step 256293  [20.998 sec/step, loss=0.07330, avg_loss=0.07197]
[2018-11-23 18:40:08.742]  Generated 32 batches of size 32 in 9.551 sec
[2018-11-23 18:40:25.473]  Step 256294  [21.073 sec/step, loss=0.07408, avg_loss=0.07199]
[2018-11-23 18:40:50.325]  Step 256295  [21.082 sec/step, loss=0.07329, avg_loss=0.07198]
[2018-11-23 18:41:10.913]  Step 256296  [21.058 sec/step, loss=0.07319, avg_loss=0.07197]
[2018-11-23 18:41:31.514]  Step 256297  [21.060 sec/step, loss=0.07342, avg_loss=0.07198]
[2018-11-23 18:41:55.337]  Step 256298  [21.053 sec/step, loss=0.07335, avg_loss=0.07197]
[2018-11-23 18:42:14.162]  Step 256299  [21.063 sec/step, loss=0.07305, avg_loss=0.07198]
[2018-11-23 18:42:24.662]  Step 256300  [20.995 sec/step, loss=0.06522, avg_loss=0.07194]
[2018-11-23 18:42:24.663]  Writing summary at step: 256300
[2018-11-23 18:43:27.087]  Step 256301  [20.966 sec/step, loss=0.07320, avg_loss=0.07194]
[2018-11-23 18:43:47.755]  Step 256302  [20.899 sec/step, loss=0.07336, avg_loss=0.07194]
[2018-11-23 18:44:01.623]  Step 256303  [20.787 sec/step, loss=0.07068, avg_loss=0.07190]
[2018-11-23 18:44:21.786]  Step 256304  [20.781 sec/step, loss=0.07351, avg_loss=0.07190]
[2018-11-23 18:44:38.932]  Step 256305  [20.763 sec/step, loss=0.07255, avg_loss=0.07189]
[2018-11-23 18:45:03.642]  Step 256306  [20.795 sec/step, loss=0.07374, avg_loss=0.07189]
[2018-11-23 18:45:27.642]  Step 256307  [20.880 sec/step, loss=0.07406, avg_loss=0.07192]
[2018-11-23 18:45:49.346]  Step 256308  [20.922 sec/step, loss=0.07362, avg_loss=0.07193]
[2018-11-23 18:46:15.626]  Step 256309  [21.031 sec/step, loss=0.07316, avg_loss=0.07195]
[2018-11-23 18:46:34.020]  Step 256310  [21.014 sec/step, loss=0.07240, avg_loss=0.07195]
[2018-11-23 18:46:44.612]  Step 256311  [20.913 sec/step, loss=0.06591, avg_loss=0.07188]
[2018-11-23 18:47:05.252]  Step 256312  [20.913 sec/step, loss=0.07323, avg_loss=0.07188]
[2018-11-23 18:47:29.513]  Step 256313  [20.923 sec/step, loss=0.07370, avg_loss=0.07188]
[2018-11-23 18:47:49.457]  Step 256314  [20.982 sec/step, loss=0.07252, avg_loss=0.07191]
[2018-11-23 18:48:14.767]  Step 256315  [21.012 sec/step, loss=0.07421, avg_loss=0.07191]
[2018-11-23 18:48:39.262]  Step 256316  [21.016 sec/step, loss=0.07317, avg_loss=0.07190]
[2018-11-23 18:48:54.867]  Step 256317  [20.898 sec/step, loss=0.07126, avg_loss=0.07188]
[2018-11-23 18:49:19.105]  Step 256318  [20.896 sec/step, loss=0.07325, avg_loss=0.07188]
[2018-11-23 18:49:27.823]  Step 256319  [20.898 sec/step, loss=0.05461, avg_loss=0.07187]
[2018-11-23 18:49:52.422]  Step 256320  [20.987 sec/step, loss=0.07344, avg_loss=0.07191]
[2018-11-23 18:50:04.655]  Step 256321  [20.859 sec/step, loss=0.06932, avg_loss=0.07186]
[2018-11-23 18:50:24.427]  Step 256322  [20.931 sec/step, loss=0.07289, avg_loss=0.07190]
[2018-11-23 18:50:43.378]  Step 256323  [20.896 sec/step, loss=0.07189, avg_loss=0.07189]
[2018-11-23 18:51:06.418]  Step 256324  [20.891 sec/step, loss=0.07358, avg_loss=0.07189]
[2018-11-23 18:51:16.119]  Generated 32 batches of size 32 in 8.920 sec
[2018-11-23 18:51:31.044]  Step 256325  [20.941 sec/step, loss=0.07343, avg_loss=0.07190]
[2018-11-23 18:51:54.294]  Step 256326  [20.653 sec/step, loss=0.07292, avg_loss=0.07198]
[2018-11-23 18:52:16.323]  Step 256327  [20.622 sec/step, loss=0.07325, avg_loss=0.07198]
[2018-11-23 18:52:34.740]  Step 256328  [20.634 sec/step, loss=0.07377, avg_loss=0.07199]
[2018-11-23 18:52:56.710]  Step 256329  [20.632 sec/step, loss=0.07283, avg_loss=0.07198]
[2018-11-23 18:53:18.206]  Step 256330  [20.627 sec/step, loss=0.07346, avg_loss=0.07199]
[2018-11-23 18:53:56.061]  Step 256331  [20.800 sec/step, loss=0.06486, avg_loss=0.07191]
[2018-11-23 18:54:11.678]  Step 256332  [20.732 sec/step, loss=0.07062, avg_loss=0.07188]
[2018-11-23 18:54:33.717]  Step 256333  [20.701 sec/step, loss=0.07301, avg_loss=0.07187]
[2018-11-23 18:54:57.820]  Step 256334  [20.695 sec/step, loss=0.07298, avg_loss=0.07186]
[2018-11-23 18:55:23.853]  Step 256335  [20.719 sec/step, loss=0.07304, avg_loss=0.07186]
[2018-11-23 18:55:46.237]  Step 256336  [20.837 sec/step, loss=0.07261, avg_loss=0.07192]
[2018-11-23 18:56:09.988]  Step 256337  [20.889 sec/step, loss=0.07390, avg_loss=0.07193]
[2018-11-23 18:56:28.862]  Step 256338  [20.865 sec/step, loss=0.07255, avg_loss=0.07192]
[2018-11-23 18:56:49.035]  Step 256339  [20.818 sec/step, loss=0.07309, avg_loss=0.07191]
[2018-11-23 18:57:02.786]  Step 256340  [20.717 sec/step, loss=0.07058, avg_loss=0.07189]
[2018-11-23 18:57:26.248]  Step 256341  [20.749 sec/step, loss=0.07293, avg_loss=0.07188]
[2018-11-23 18:57:49.121]  Step 256342  [20.743 sec/step, loss=0.07384, avg_loss=0.07189]
[2018-11-23 18:58:01.828]  Step 256343  [20.784 sec/step, loss=0.06914, avg_loss=0.07204]
[2018-11-23 18:58:26.613]  Step 256344  [20.826 sec/step, loss=0.07368, avg_loss=0.07204]
[2018-11-23 18:59:04.794]  Step 256345  [21.105 sec/step, loss=0.06522, avg_loss=0.07203]
[2018-11-23 18:59:26.368]  Step 256346  [21.182 sec/step, loss=0.07362, avg_loss=0.07206]
[2018-11-23 18:59:47.035]  Step 256347  [21.202 sec/step, loss=0.07260, avg_loss=0.07206]
[2018-11-23 19:00:12.674]  Step 256348  [21.052 sec/step, loss=0.07392, avg_loss=0.07215]
[2018-11-23 19:00:35.702]  Step 256349  [21.077 sec/step, loss=0.07302, avg_loss=0.07216]
[2018-11-23 19:00:56.884]  Step 256350  [21.054 sec/step, loss=0.07339, avg_loss=0.07216]
[2018-11-23 19:00:56.884]  Writing summary at step: 256350
[2018-11-23 19:01:38.255]  Step 256351  [21.055 sec/step, loss=0.07276, avg_loss=0.07215]
[2018-11-23 19:02:02.673]  Step 256352  [21.076 sec/step, loss=0.07348, avg_loss=0.07215]
[2018-11-23 19:02:25.310]  Step 256353  [21.060 sec/step, loss=0.07353, avg_loss=0.07215]
[2018-11-23 19:02:35.708]  Step 256354  [21.011 sec/step, loss=0.06676, avg_loss=0.07210]
[2018-11-23 19:02:57.798]  Step 256355  [21.012 sec/step, loss=0.07335, avg_loss=0.07210]
[2018-11-23 19:03:07.097]  Generated 32 batches of size 32 in 8.491 sec
[2018-11-23 19:03:18.504]  Step 256356  [20.998 sec/step, loss=0.07309, avg_loss=0.07210]
[2018-11-23 19:03:36.100]  Step 256357  [20.990 sec/step, loss=0.07178, avg_loss=0.07209]
[2018-11-23 19:03:52.153]  Step 256358  [21.029 sec/step, loss=0.06963, avg_loss=0.07209]
[2018-11-23 19:04:00.861]  Step 256359  [20.957 sec/step, loss=0.05400, avg_loss=0.07194]
[2018-11-23 19:04:17.842]  Step 256360  [20.885 sec/step, loss=0.07240, avg_loss=0.07192]
[2018-11-23 19:04:38.684]  Step 256361  [20.922 sec/step, loss=0.07314, avg_loss=0.07193]
[2018-11-23 19:05:02.676]  Step 256362  [20.858 sec/step, loss=0.07321, avg_loss=0.07193]
[2018-11-23 19:05:23.835]  Step 256363  [20.891 sec/step, loss=0.07275, avg_loss=0.07193]
[2018-11-23 19:05:39.527]  Step 256364  [20.818 sec/step, loss=0.07088, avg_loss=0.07191]
[2018-11-23 19:05:49.829]  Step 256365  [20.672 sec/step, loss=0.06466, avg_loss=0.07182]
[2018-11-23 19:05:58.235]  Step 256366  [20.526 sec/step, loss=0.05360, avg_loss=0.07162]
[2018-11-23 19:06:20.498]  Step 256367  [20.494 sec/step, loss=0.07316, avg_loss=0.07161]
[2018-11-23 19:06:42.109]  Step 256368  [20.461 sec/step, loss=0.07356, avg_loss=0.07160]
[2018-11-23 19:07:06.711]  Step 256369  [20.483 sec/step, loss=0.07320, avg_loss=0.07160]
[2018-11-23 19:07:28.060]  Step 256370  [20.503 sec/step, loss=0.07271, avg_loss=0.07160]
[2018-11-23 19:07:45.048]  Step 256371  [20.510 sec/step, loss=0.07184, avg_loss=0.07161]
[2018-11-23 19:08:10.081]  Step 256372  [20.515 sec/step, loss=0.07389, avg_loss=0.07161]
[2018-11-23 19:08:25.861]  Step 256373  [20.413 sec/step, loss=0.07082, avg_loss=0.07159]
[2018-11-23 19:08:44.369]  Step 256374  [20.461 sec/step, loss=0.07286, avg_loss=0.07162]
[2018-11-23 19:09:07.241]  Step 256375  [20.456 sec/step, loss=0.07303, avg_loss=0.07162]
[2018-11-23 19:09:26.042]  Step 256376  [20.426 sec/step, loss=0.07308, avg_loss=0.07162]
[2018-11-23 19:09:41.345]  Step 256377  [20.335 sec/step, loss=0.06954, avg_loss=0.07158]
[2018-11-23 19:10:02.769]  Step 256378  [20.305 sec/step, loss=0.07378, avg_loss=0.07158]
[2018-11-23 19:10:22.593]  Step 256379  [20.280 sec/step, loss=0.07336, avg_loss=0.07158]
[2018-11-23 19:10:48.075]  Step 256380  [20.450 sec/step, loss=0.07434, avg_loss=0.07178]
[2018-11-23 19:11:00.199]  Step 256381  [20.345 sec/step, loss=0.06890, avg_loss=0.07174]
[2018-11-23 19:11:24.391]  Step 256382  [20.379 sec/step, loss=0.07354, avg_loss=0.07175]
[2018-11-23 19:11:51.089]  Step 256383  [20.475 sec/step, loss=0.07323, avg_loss=0.07176]
[2018-11-23 19:12:15.228]  Step 256384  [20.560 sec/step, loss=0.07313, avg_loss=0.07179]
[2018-11-23 19:12:37.300]  Step 256385  [20.564 sec/step, loss=0.07353, avg_loss=0.07179]
[2018-11-23 19:13:01.328]  Step 256386  [20.561 sec/step, loss=0.07355, avg_loss=0.07178]
[2018-11-23 19:13:26.017]  Step 256387  [20.583 sec/step, loss=0.07333, avg_loss=0.07178]
[2018-11-23 19:13:35.393]  Generated 32 batches of size 32 in 8.630 sec
[2018-11-23 19:13:41.026]  Step 256388  [20.517 sec/step, loss=0.06990, avg_loss=0.07175]
[2018-11-23 19:14:00.464]  Step 256389  [20.592 sec/step, loss=0.07308, avg_loss=0.07179]
[2018-11-23 19:14:43.174]  Step 256390  [20.783 sec/step, loss=0.06488, avg_loss=0.07171]
[2018-11-23 19:15:03.474]  Step 256391  [20.806 sec/step, loss=0.07251, avg_loss=0.07171]
[2018-11-23 19:15:23.587]  Step 256392  [20.812 sec/step, loss=0.07346, avg_loss=0.07172]
[2018-11-23 19:15:46.992]  Step 256393  [20.863 sec/step, loss=0.07298, avg_loss=0.07171]
[2018-11-23 19:16:04.693]  Step 256394  [20.769 sec/step, loss=0.07215, avg_loss=0.07169]
[2018-11-23 19:16:28.568]  Step 256395  [20.759 sec/step, loss=0.07329, avg_loss=0.07169]
[2018-11-23 19:16:49.812]  Step 256396  [20.765 sec/step, loss=0.07309, avg_loss=0.07169]
[2018-11-23 19:17:08.290]  Step 256397  [20.744 sec/step, loss=0.07189, avg_loss=0.07168]
[2018-11-23 19:17:31.983]  Step 256398  [20.743 sec/step, loss=0.07287, avg_loss=0.07167]
[2018-11-23 19:18:02.744]  Step 256399  [20.862 sec/step, loss=0.07353, avg_loss=0.07168]
[2018-11-23 19:18:16.795]  Step 256400  [20.898 sec/step, loss=0.07029, avg_loss=0.07173]
[2018-11-23 19:18:16.795]  Writing summary at step: 256400
[2018-11-23 19:18:59.257]  Step 256401  [20.893 sec/step, loss=0.07274, avg_loss=0.07172]
[2018-11-23 19:19:21.438]  Step 256402  [20.908 sec/step, loss=0.07279, avg_loss=0.07172]
[2018-11-23 19:19:41.195]  Step 256403  [20.967 sec/step, loss=0.07249, avg_loss=0.07174]
[2018-11-23 19:20:03.693]  Step 256404  [20.990 sec/step, loss=0.07293, avg_loss=0.07173]
[2018-11-23 19:20:30.552]  Step 256405  [21.087 sec/step, loss=0.07262, avg_loss=0.07173]
[2018-11-23 19:20:54.957]  Step 256406  [21.084 sec/step, loss=0.07346, avg_loss=0.07173]
[2018-11-23 19:21:17.397]  Step 256407  [21.068 sec/step, loss=0.07344, avg_loss=0.07172]
[2018-11-23 19:21:37.809]  Step 256408  [21.056 sec/step, loss=0.07300, avg_loss=0.07172]
[2018-11-23 19:21:58.792]  Step 256409  [21.003 sec/step, loss=0.07335, avg_loss=0.07172]
[2018-11-23 19:22:23.734]  Step 256410  [21.068 sec/step, loss=0.07328, avg_loss=0.07173]
[2018-11-23 19:22:42.809]  Step 256411  [21.153 sec/step, loss=0.07250, avg_loss=0.07179]
[2018-11-23 19:23:06.425]  Step 256412  [21.183 sec/step, loss=0.07383, avg_loss=0.07180]
[2018-11-23 19:23:44.235]  Step 256413  [21.318 sec/step, loss=0.06472, avg_loss=0.07171]
[2018-11-23 19:24:01.526]  Step 256414  [21.292 sec/step, loss=0.07196, avg_loss=0.07170]
[2018-11-23 19:24:11.782]  Step 256415  [21.141 sec/step, loss=0.06541, avg_loss=0.07162]
[2018-11-23 19:24:35.652]  Step 256416  [21.135 sec/step, loss=0.07288, avg_loss=0.07161]
[2018-11-23 19:25:00.255]  Step 256417  [21.225 sec/step, loss=0.07370, avg_loss=0.07164]
[2018-11-23 19:25:12.044]  Step 256418  [21.100 sec/step, loss=0.06966, avg_loss=0.07160]
[2018-11-23 19:25:21.303]  Generated 32 batches of size 32 in 8.508 sec
[2018-11-23 19:25:37.750]  Step 256419  [21.270 sec/step, loss=0.07366, avg_loss=0.07179]
[2018-11-23 19:25:59.962]  Step 256420  [21.246 sec/step, loss=0.07279, avg_loss=0.07178]
[2018-11-23 19:26:15.509]  Step 256421  [21.279 sec/step, loss=0.06907, avg_loss=0.07178]
[2018-11-23 19:26:39.982]  Step 256422  [21.326 sec/step, loss=0.07332, avg_loss=0.07179]
[2018-11-23 19:27:01.531]  Step 256423  [21.352 sec/step, loss=0.07309, avg_loss=0.07180]
[2018-11-23 19:27:24.121]  Step 256424  [21.348 sec/step, loss=0.07367, avg_loss=0.07180]
[2018-11-23 19:27:32.504]  Step 256425  [21.186 sec/step, loss=0.05429, avg_loss=0.07161]
[2018-11-23 19:27:52.044]  Step 256426  [21.148 sec/step, loss=0.07305, avg_loss=0.07161]
[2018-11-23 19:28:07.914]  Step 256427  [21.087 sec/step, loss=0.07067, avg_loss=0.07158]
[2018-11-23 19:28:29.288]  Step 256428  [21.116 sec/step, loss=0.07349, avg_loss=0.07158]
[2018-11-23 19:28:51.290]  Step 256429  [21.117 sec/step, loss=0.07308, avg_loss=0.07158]
[2018-11-23 19:29:16.102]  Step 256430  [21.150 sec/step, loss=0.07318, avg_loss=0.07158]
[2018-11-23 19:29:26.520]  Step 256431  [20.876 sec/step, loss=0.06756, avg_loss=0.07161]
[2018-11-23 19:29:35.191]  Step 256432  [20.806 sec/step, loss=0.05396, avg_loss=0.07144]
[2018-11-23 19:29:54.526]  Step 256433  [20.779 sec/step, loss=0.07300, avg_loss=0.07144]
[2018-11-23 19:30:16.274]  Step 256434  [20.755 sec/step, loss=0.07306, avg_loss=0.07144]
[2018-11-23 19:30:38.577]  Step 256435  [20.718 sec/step, loss=0.07300, avg_loss=0.07144]
[2018-11-23 19:30:53.555]  Step 256436  [20.644 sec/step, loss=0.07100, avg_loss=0.07142]
[2018-11-23 19:31:13.885]  Step 256437  [20.610 sec/step, loss=0.07323, avg_loss=0.07142]
[2018-11-23 19:31:37.850]  Step 256438  [20.661 sec/step, loss=0.07356, avg_loss=0.07143]
[2018-11-23 19:31:55.714]  Step 256439  [20.638 sec/step, loss=0.07228, avg_loss=0.07142]
[2018-11-23 19:32:21.979]  Step 256440  [20.763 sec/step, loss=0.07330, avg_loss=0.07145]
[2018-11-23 19:32:44.585]  Step 256441  [20.754 sec/step, loss=0.07326, avg_loss=0.07145]
[2018-11-23 19:33:08.535]  Step 256442  [20.765 sec/step, loss=0.07280, avg_loss=0.07144]
[2018-11-23 19:33:32.679]  Step 256443  [20.879 sec/step, loss=0.07342, avg_loss=0.07148]
[2018-11-23 19:33:56.915]  Step 256444  [20.874 sec/step, loss=0.07421, avg_loss=0.07149]
[2018-11-23 19:34:22.992]  Step 256445  [20.753 sec/step, loss=0.07373, avg_loss=0.07157]
[2018-11-23 19:34:43.886]  Step 256446  [20.746 sec/step, loss=0.07302, avg_loss=0.07157]
[2018-11-23 19:34:56.305]  Step 256447  [20.664 sec/step, loss=0.06812, avg_loss=0.07152]
[2018-11-23 19:35:36.081]  Step 256448  [20.805 sec/step, loss=0.06521, avg_loss=0.07144]
[2018-11-23 19:35:51.690]  Step 256449  [20.731 sec/step, loss=0.07109, avg_loss=0.07142]
[2018-11-23 19:36:16.343]  Step 256450  [20.766 sec/step, loss=0.07314, avg_loss=0.07141]
[2018-11-23 19:36:16.343]  Writing summary at step: 256450
[2018-11-23 19:36:26.073]  Generated 32 batches of size 32 in 8.807 sec
[2018-11-23 19:37:00.286]  Step 256451  [20.734 sec/step, loss=0.07352, avg_loss=0.07142]
[2018-11-23 19:37:24.249]  Step 256452  [20.729 sec/step, loss=0.07394, avg_loss=0.07143]
[2018-11-23 19:37:43.138]  Step 256453  [20.692 sec/step, loss=0.07239, avg_loss=0.07141]
[2018-11-23 19:38:00.076]  Step 256454  [20.757 sec/step, loss=0.07210, avg_loss=0.07147]
[2018-11-23 19:38:15.877]  Step 256455  [20.694 sec/step, loss=0.07032, avg_loss=0.07144]
[2018-11-23 19:38:35.802]  Step 256456  [20.686 sec/step, loss=0.07234, avg_loss=0.07143]
[2018-11-23 19:38:56.312]  Step 256457  [20.715 sec/step, loss=0.07345, avg_loss=0.07145]
[2018-11-23 19:39:18.086]  Step 256458  [20.773 sec/step, loss=0.07267, avg_loss=0.07148]
[2018-11-23 19:39:37.931]  Step 256459  [20.884 sec/step, loss=0.07212, avg_loss=0.07166]
[2018-11-23 19:39:59.739]  Step 256460  [20.932 sec/step, loss=0.07230, avg_loss=0.07166]
[2018-11-23 19:40:10.070]  Step 256461  [20.827 sec/step, loss=0.06457, avg_loss=0.07157]
[2018-11-23 19:40:34.780]  Step 256462  [20.834 sec/step, loss=0.07251, avg_loss=0.07157]
[2018-11-23 19:40:50.979]  Step 256463  [20.785 sec/step, loss=0.07089, avg_loss=0.07155]
[2018-11-23 19:41:04.782]  Step 256464  [20.766 sec/step, loss=0.06974, avg_loss=0.07154]
[2018-11-23 19:41:31.029]  Step 256465  [20.925 sec/step, loss=0.07317, avg_loss=0.07162]
[2018-11-23 19:41:52.366]  Step 256466  [21.055 sec/step, loss=0.07319, avg_loss=0.07182]
[2018-11-23 19:42:13.513]  Step 256467  [21.043 sec/step, loss=0.07332, avg_loss=0.07182]
[2018-11-23 19:42:35.973]  Step 256468  [21.052 sec/step, loss=0.07316, avg_loss=0.07181]
[2018-11-23 19:42:56.334]  Step 256469  [21.010 sec/step, loss=0.07310, avg_loss=0.07181]
[2018-11-23 19:43:20.767]  Step 256470  [21.040 sec/step, loss=0.07355, avg_loss=0.07182]
[2018-11-23 19:43:58.067]  Step 256471  [21.243 sec/step, loss=0.06515, avg_loss=0.07175]
[2018-11-23 19:44:16.718]  Step 256472  [21.180 sec/step, loss=0.07353, avg_loss=0.07175]
[2018-11-23 19:44:35.516]  Step 256473  [21.210 sec/step, loss=0.07246, avg_loss=0.07177]
[2018-11-23 19:44:52.548]  Step 256474  [21.195 sec/step, loss=0.07245, avg_loss=0.07176]
[2018-11-23 19:45:12.725]  Step 256475  [21.168 sec/step, loss=0.07332, avg_loss=0.07177]
[2018-11-23 19:45:36.464]  Step 256476  [21.217 sec/step, loss=0.07296, avg_loss=0.07176]
[2018-11-23 19:45:45.086]  Step 256477  [21.151 sec/step, loss=0.05475, avg_loss=0.07162]
[2018-11-23 19:46:10.225]  Step 256478  [21.188 sec/step, loss=0.07399, avg_loss=0.07162]
[2018-11-23 19:46:30.910]  Step 256479  [21.196 sec/step, loss=0.07301, avg_loss=0.07162]
[2018-11-23 19:46:53.116]  Step 256480  [21.164 sec/step, loss=0.07299, avg_loss=0.07160]
[2018-11-23 19:47:16.959]  Step 256481  [21.281 sec/step, loss=0.07331, avg_loss=0.07165]
[2018-11-23 19:47:26.699]  Generated 32 batches of size 32 in 8.940 sec
[2018-11-23 19:47:31.038]  Step 256482  [21.180 sec/step, loss=0.06857, avg_loss=0.07160]
[2018-11-23 19:47:50.568]  Step 256483  [21.108 sec/step, loss=0.07315, avg_loss=0.07160]
[2018-11-23 19:48:08.695]  Step 256484  [21.048 sec/step, loss=0.07179, avg_loss=0.07158]
[2018-11-23 19:48:32.664]  Step 256485  [21.067 sec/step, loss=0.07350, avg_loss=0.07158]
[2018-11-23 19:48:55.315]  Step 256486  [21.053 sec/step, loss=0.07345, avg_loss=0.07158]
[2018-11-23 19:49:11.359]  Step 256487  [20.967 sec/step, loss=0.06966, avg_loss=0.07154]
[2018-11-23 19:49:35.728]  Step 256488  [21.060 sec/step, loss=0.07410, avg_loss=0.07159]
[2018-11-23 19:49:59.207]  Step 256489  [21.101 sec/step, loss=0.07306, avg_loss=0.07159]
[2018-11-23 19:50:22.243]  Step 256490  [20.904 sec/step, loss=0.07330, avg_loss=0.07167]
[2018-11-23 19:50:46.610]  Step 256491  [20.945 sec/step, loss=0.07332, avg_loss=0.07168]
[2018-11-23 19:51:07.207]  Step 256492  [20.949 sec/step, loss=0.07264, avg_loss=0.07167]
[2018-11-23 19:51:25.920]  Step 256493  [20.903 sec/step, loss=0.07325, avg_loss=0.07167]
[2018-11-23 19:51:43.004]  Step 256494  [20.896 sec/step, loss=0.07207, avg_loss=0.07167]
[2018-11-23 19:52:06.973]  Step 256495  [20.897 sec/step, loss=0.07276, avg_loss=0.07167]
[2018-11-23 19:52:28.512]  Step 256496  [20.900 sec/step, loss=0.07354, avg_loss=0.07167]
[2018-11-23 19:52:52.211]  Step 256497  [20.952 sec/step, loss=0.07338, avg_loss=0.07169]
[2018-11-23 19:53:17.255]  Step 256498  [20.966 sec/step, loss=0.07354, avg_loss=0.07169]
[2018-11-23 19:53:36.497]  Step 256499  [20.851 sec/step, loss=0.07227, avg_loss=0.07168]
[2018-11-23 19:54:01.135]  Step 256500  [20.957 sec/step, loss=0.07372, avg_loss=0.07171]
[2018-11-23 19:54:01.135]  Writing summary at step: 256500
[2018-11-23 19:54:21.661]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-256500
[2018-11-23 19:54:25.948]  Saving audio and alignment...
[2018-11-23 19:54:40.921]  Input: and that the fiction concludes in a cosily {IH0 K S K L UW1 S IH0 V} {M EH1 R IH0 JH} with the land-owning gentry. an unquestioned ideology of {IH2 M P IH1 R IY0 AH0 L IH0 S T} axiomatics is {HH EH1 L D} to {IH2 N F AO1 R M} the~_________________________________________________________
[2018-11-23 19:55:02.568]  Step 256501  [20.986 sec/step, loss=0.07311, avg_loss=0.07172]
[2018-11-23 19:55:31.201]  Step 256502  [21.051 sec/step, loss=0.07280, avg_loss=0.07172]
[2018-11-23 19:56:13.193]  Step 256503  [21.273 sec/step, loss=0.06496, avg_loss=0.07164]
[2018-11-23 19:56:31.068]  Step 256504  [21.227 sec/step, loss=0.07197, avg_loss=0.07163]
[2018-11-23 19:56:53.645]  Step 256505  [21.184 sec/step, loss=0.07219, avg_loss=0.07163]
[2018-11-23 19:57:18.075]  Step 256506  [21.184 sec/step, loss=0.07276, avg_loss=0.07162]
[2018-11-23 19:57:39.793]  Step 256507  [21.177 sec/step, loss=0.07315, avg_loss=0.07162]
[2018-11-23 19:57:52.066]  Step 256508  [21.096 sec/step, loss=0.06862, avg_loss=0.07158]
[2018-11-23 19:58:14.808]  Step 256509  [21.113 sec/step, loss=0.07302, avg_loss=0.07157]
[2018-11-23 19:58:30.310]  Step 256510  [21.019 sec/step, loss=0.07082, avg_loss=0.07155]
[2018-11-23 19:58:51.968]  Step 256511  [21.045 sec/step, loss=0.07332, avg_loss=0.07156]
[2018-11-23 19:59:01.697]  Generated 32 batches of size 32 in 8.692 sec
[2018-11-23 19:59:15.898]  Step 256512  [21.048 sec/step, loss=0.07253, avg_loss=0.07154]
[2018-11-23 19:59:36.388]  Step 256513  [20.875 sec/step, loss=0.07279, avg_loss=0.07162]
[2018-11-23 19:59:54.116]  Step 256514  [20.879 sec/step, loss=0.06954, avg_loss=0.07160]
[2018-11-23 20:00:18.612]  Step 256515  [21.021 sec/step, loss=0.07335, avg_loss=0.07168]
[2018-11-23 20:00:43.695]  Step 256516  [21.034 sec/step, loss=0.07337, avg_loss=0.07168]
[2018-11-23 20:00:52.398]  Step 256517  [20.875 sec/step, loss=0.05292, avg_loss=0.07148]
[2018-11-23 20:01:06.087]  Step 256518  [20.894 sec/step, loss=0.07067, avg_loss=0.07149]
[2018-11-23 20:01:16.467]  Step 256519  [20.740 sec/step, loss=0.06671, avg_loss=0.07142]
[2018-11-23 20:01:35.842]  Step 256520  [20.712 sec/step, loss=0.07304, avg_loss=0.07142]
[2018-11-23 20:01:54.478]  Step 256521  [20.743 sec/step, loss=0.07309, avg_loss=0.07146]
[2018-11-23 20:02:15.428]  Step 256522  [20.708 sec/step, loss=0.07306, avg_loss=0.07146]
[2018-11-23 20:02:39.480]  Step 256523  [20.733 sec/step, loss=0.07401, avg_loss=0.07147]
[2018-11-23 20:02:57.132]  Step 256524  [20.683 sec/step, loss=0.07175, avg_loss=0.07145]
[2018-11-23 20:03:08.640]  Step 256525  [20.714 sec/step, loss=0.06918, avg_loss=0.07159]
[2018-11-23 20:03:22.433]  Step 256526  [20.657 sec/step, loss=0.06989, avg_loss=0.07156]
[2018-11-23 20:03:48.631]  Step 256527  [20.760 sec/step, loss=0.07299, avg_loss=0.07159]
[2018-11-23 20:04:10.506]  Step 256528  [20.765 sec/step, loss=0.07328, avg_loss=0.07158]
[2018-11-23 20:04:33.311]  Step 256529  [20.773 sec/step, loss=0.07311, avg_loss=0.07158]
[2018-11-23 20:04:53.280]  Step 256530  [20.725 sec/step, loss=0.07265, avg_loss=0.07158]
[2018-11-23 20:05:13.491]  Step 256531  [20.823 sec/step, loss=0.07358, avg_loss=0.07164]
[2018-11-23 20:05:54.110]  Step 256532  [21.142 sec/step, loss=0.06453, avg_loss=0.07175]
[2018-11-23 20:06:04.740]  Step 256533  [21.055 sec/step, loss=0.06496, avg_loss=0.07166]
[2018-11-23 20:06:20.059]  Step 256534  [20.991 sec/step, loss=0.07041, avg_loss=0.07164]
[2018-11-23 20:06:44.634]  Step 256535  [21.014 sec/step, loss=0.07415, avg_loss=0.07165]
[2018-11-23 20:07:06.781]  Step 256536  [21.085 sec/step, loss=0.07333, avg_loss=0.07167]
[2018-11-23 20:07:30.749]  Step 256537  [21.122 sec/step, loss=0.07328, avg_loss=0.07167]
[2018-11-23 20:07:54.166]  Step 256538  [21.116 sec/step, loss=0.07312, avg_loss=0.07167]
[2018-11-23 20:08:17.773]  Step 256539  [21.174 sec/step, loss=0.07370, avg_loss=0.07168]
[2018-11-23 20:08:34.554]  Step 256540  [21.079 sec/step, loss=0.07257, avg_loss=0.07168]
[2018-11-23 20:08:59.655]  Step 256541  [21.104 sec/step, loss=0.07294, avg_loss=0.07167]
[2018-11-23 20:09:21.270]  Step 256542  [21.080 sec/step, loss=0.07345, avg_loss=0.07168]
[2018-11-23 20:09:45.713]  Step 256543  [21.083 sec/step, loss=0.07355, avg_loss=0.07168]
[2018-11-23 20:09:55.576]  Generated 32 batches of size 32 in 8.851 sec
[2018-11-23 20:10:10.700]  Step 256544  [21.091 sec/step, loss=0.07346, avg_loss=0.07167]
[2018-11-23 20:10:26.299]  Step 256545  [20.986 sec/step, loss=0.06939, avg_loss=0.07163]
[2018-11-23 20:10:45.980]  Step 256546  [20.974 sec/step, loss=0.07251, avg_loss=0.07162]
[2018-11-23 20:11:07.482]  Step 256547  [21.065 sec/step, loss=0.07268, avg_loss=0.07167]
[2018-11-23 20:11:27.875]  Step 256548  [20.871 sec/step, loss=0.07262, avg_loss=0.07174]
[2018-11-23 20:11:50.092]  Step 256549  [20.937 sec/step, loss=0.07269, avg_loss=0.07176]
[2018-11-23 20:11:58.476]  Step 256550  [20.774 sec/step, loss=0.05499, avg_loss=0.07158]
[2018-11-23 20:11:58.476]  Writing summary at step: 256550
[2018-11-23 20:12:42.281]  Step 256551  [20.825 sec/step, loss=0.07331, avg_loss=0.07158]
[2018-11-23 20:13:04.070]  Step 256552  [20.803 sec/step, loss=0.07220, avg_loss=0.07156]
[2018-11-23 20:13:21.880]  Step 256553  [20.792 sec/step, loss=0.07215, avg_loss=0.07156]
[2018-11-23 20:13:45.243]  Step 256554  [20.857 sec/step, loss=0.07286, avg_loss=0.07156]
[2018-11-23 20:14:10.074]  Step 256555  [20.947 sec/step, loss=0.07420, avg_loss=0.07160]
[2018-11-23 20:14:25.582]  Step 256556  [20.903 sec/step, loss=0.06880, avg_loss=0.07157]
[2018-11-23 20:14:42.413]  Step 256557  [20.866 sec/step, loss=0.07201, avg_loss=0.07155]
[2018-11-23 20:15:02.771]  Step 256558  [20.852 sec/step, loss=0.07296, avg_loss=0.07156]
[2018-11-23 20:15:13.178]  Step 256559  [20.757 sec/step, loss=0.06564, avg_loss=0.07149]
[2018-11-23 20:15:32.689]  Step 256560  [20.734 sec/step, loss=0.07311, avg_loss=0.07150]
[2018-11-23 20:15:59.207]  Step 256561  [20.896 sec/step, loss=0.07273, avg_loss=0.07158]
[2018-11-23 20:16:21.001]  Step 256562  [20.867 sec/step, loss=0.07313, avg_loss=0.07159]
[2018-11-23 20:16:29.656]  Step 256563  [20.792 sec/step, loss=0.05292, avg_loss=0.07141]
[2018-11-23 20:16:49.899]  Step 256564  [20.856 sec/step, loss=0.07370, avg_loss=0.07145]
[2018-11-23 20:17:11.558]  Step 256565  [20.810 sec/step, loss=0.07329, avg_loss=0.07145]
[2018-11-23 20:17:30.709]  Step 256566  [20.788 sec/step, loss=0.07264, avg_loss=0.07144]
[2018-11-23 20:17:54.747]  Step 256567  [20.817 sec/step, loss=0.07343, avg_loss=0.07144]
[2018-11-23 20:18:24.552]  Step 256568  [20.891 sec/step, loss=0.07318, avg_loss=0.07144]
[2018-11-23 20:18:50.666]  Step 256569  [20.948 sec/step, loss=0.07322, avg_loss=0.07145]
[2018-11-23 20:19:12.081]  Step 256570  [20.918 sec/step, loss=0.07342, avg_loss=0.07144]
[2018-11-23 20:19:36.509]  Step 256571  [20.789 sec/step, loss=0.07378, avg_loss=0.07153]
[2018-11-23 20:19:52.166]  Step 256572  [20.759 sec/step, loss=0.07086, avg_loss=0.07150]
[2018-11-23 20:20:14.541]  Step 256573  [20.795 sec/step, loss=0.07302, avg_loss=0.07151]
[2018-11-23 20:20:28.636]  Step 256574  [20.766 sec/step, loss=0.07012, avg_loss=0.07149]
[2018-11-23 20:20:41.573]  Generated 32 batches of size 32 in 11.936 sec
[2018-11-23 20:21:00.784]  Step 256575  [20.885 sec/step, loss=0.07426, avg_loss=0.07150]
[2018-11-23 20:21:25.095]  Step 256576  [20.891 sec/step, loss=0.07336, avg_loss=0.07150]
[2018-11-23 20:21:44.072]  Step 256577  [20.995 sec/step, loss=0.07295, avg_loss=0.07168]
[2018-11-23 20:22:08.621]  Step 256578  [20.989 sec/step, loss=0.07320, avg_loss=0.07167]
[2018-11-23 20:22:20.683]  Step 256579  [20.903 sec/step, loss=0.06832, avg_loss=0.07163]
[2018-11-23 20:22:39.418]  Step 256580  [20.868 sec/step, loss=0.07276, avg_loss=0.07162]
[2018-11-23 20:23:02.430]  Step 256581  [20.860 sec/step, loss=0.07340, avg_loss=0.07163]
[2018-11-23 20:23:26.300]  Step 256582  [20.957 sec/step, loss=0.07302, avg_loss=0.07167]
[2018-11-23 20:24:01.890]  Step 256583  [21.118 sec/step, loss=0.06548, avg_loss=0.07159]
[2018-11-23 20:24:23.494]  Step 256584  [21.153 sec/step, loss=0.07312, avg_loss=0.07161]
[2018-11-23 20:24:42.982]  Step 256585  [21.108 sec/step, loss=0.07277, avg_loss=0.07160]
[2018-11-23 20:25:04.802]  Step 256586  [21.100 sec/step, loss=0.07292, avg_loss=0.07159]
[2018-11-23 20:25:31.244]  Step 256587  [21.204 sec/step, loss=0.07270, avg_loss=0.07162]
[2018-11-23 20:25:55.909]  Step 256588  [21.207 sec/step, loss=0.07422, avg_loss=0.07163]
[2018-11-23 20:26:15.698]  Step 256589  [21.170 sec/step, loss=0.07231, avg_loss=0.07162]
[2018-11-23 20:26:41.305]  Step 256590  [21.195 sec/step, loss=0.07381, avg_loss=0.07162]
[2018-11-23 20:27:06.014]  Step 256591  [21.199 sec/step, loss=0.07371, avg_loss=0.07163]
[2018-11-23 20:27:14.945]  Step 256592  [21.082 sec/step, loss=0.05405, avg_loss=0.07144]
[2018-11-23 20:27:39.194]  Step 256593  [21.138 sec/step, loss=0.07323, avg_loss=0.07144]
[2018-11-23 20:28:00.740]  Step 256594  [21.182 sec/step, loss=0.07343, avg_loss=0.07145]
[2018-11-23 20:28:21.804]  Step 256595  [21.153 sec/step, loss=0.07269, avg_loss=0.07145]
[2018-11-23 20:28:44.177]  Step 256596  [21.162 sec/step, loss=0.07257, avg_loss=0.07144]
[2018-11-23 20:28:59.988]  Step 256597  [21.083 sec/step, loss=0.06953, avg_loss=0.07141]
[2018-11-23 20:29:14.578]  Step 256598  [20.978 sec/step, loss=0.07008, avg_loss=0.07137]
[2018-11-23 20:29:32.314]  Step 256599  [20.963 sec/step, loss=0.07222, avg_loss=0.07137]
[2018-11-23 20:29:55.610]  Step 256600  [20.950 sec/step, loss=0.07334, avg_loss=0.07137]
[2018-11-23 20:29:55.610]  Writing summary at step: 256600
[2018-11-23 20:30:28.792]  Step 256601  [20.937 sec/step, loss=0.07301, avg_loss=0.07137]
[2018-11-23 20:30:52.759]  Step 256602  [20.891 sec/step, loss=0.07339, avg_loss=0.07137]
[2018-11-23 20:31:17.333]  Step 256603  [20.717 sec/step, loss=0.07326, avg_loss=0.07145]
[2018-11-23 20:31:37.624]  Step 256604  [20.741 sec/step, loss=0.07306, avg_loss=0.07147]
[2018-11-23 20:32:00.405]  Step 256605  [20.743 sec/step, loss=0.07298, avg_loss=0.07147]
[2018-11-23 20:32:13.911]  Generated 32 batches of size 32 in 12.716 sec
[2018-11-23 20:32:46.211]  Step 256606  [20.956 sec/step, loss=0.06465, avg_loss=0.07139]
[2018-11-23 20:33:01.730]  Step 256607  [20.894 sec/step, loss=0.07044, avg_loss=0.07137]
[2018-11-23 20:33:25.900]  Step 256608  [21.013 sec/step, loss=0.07302, avg_loss=0.07141]
[2018-11-23 20:33:42.908]  Step 256609  [20.956 sec/step, loss=0.07218, avg_loss=0.07140]
[2018-11-23 20:34:06.473]  Step 256610  [21.037 sec/step, loss=0.07308, avg_loss=0.07142]
[2018-11-23 20:34:24.994]  Step 256611  [21.005 sec/step, loss=0.07314, avg_loss=0.07142]
[2018-11-23 20:34:44.062]  Step 256612  [20.957 sec/step, loss=0.07234, avg_loss=0.07142]
[2018-11-23 20:34:54.575]  Step 256613  [20.857 sec/step, loss=0.06586, avg_loss=0.07135]
[2018-11-23 20:35:17.301]  Step 256614  [20.907 sec/step, loss=0.07324, avg_loss=0.07139]
[2018-11-23 20:35:42.060]  Step 256615  [20.910 sec/step, loss=0.07373, avg_loss=0.07139]
[2018-11-23 20:36:00.898]  Step 256616  [20.847 sec/step, loss=0.07284, avg_loss=0.07139]
[2018-11-23 20:36:20.481]  Step 256617  [20.956 sec/step, loss=0.07250, avg_loss=0.07158]
[2018-11-23 20:36:42.091]  Step 256618  [21.035 sec/step, loss=0.07258, avg_loss=0.07160]
[2018-11-23 20:37:05.626]  Step 256619  [21.167 sec/step, loss=0.07312, avg_loss=0.07167]
[2018-11-23 20:37:28.503]  Step 256620  [21.202 sec/step, loss=0.07295, avg_loss=0.07166]
[2018-11-23 20:37:42.641]  Step 256621  [21.157 sec/step, loss=0.07012, avg_loss=0.07163]
[2018-11-23 20:38:02.955]  Step 256622  [21.150 sec/step, loss=0.07332, avg_loss=0.07164]
[2018-11-23 20:38:39.849]  Step 256623  [21.279 sec/step, loss=0.06499, avg_loss=0.07155]
[2018-11-23 20:38:56.788]  Step 256624  [21.272 sec/step, loss=0.07210, avg_loss=0.07155]
[2018-11-23 20:39:20.496]  Step 256625  [21.394 sec/step, loss=0.07351, avg_loss=0.07159]
[2018-11-23 20:39:32.832]  Step 256626  [21.379 sec/step, loss=0.06841, avg_loss=0.07158]
[2018-11-23 20:39:58.014]  Step 256627  [21.369 sec/step, loss=0.07384, avg_loss=0.07159]
[2018-11-23 20:40:22.612]  Step 256628  [21.396 sec/step, loss=0.07299, avg_loss=0.07158]
[2018-11-23 20:40:40.851]  Step 256629  [21.351 sec/step, loss=0.07183, avg_loss=0.07157]
[2018-11-23 20:41:02.472]  Step 256630  [21.367 sec/step, loss=0.07369, avg_loss=0.07158]
[2018-11-23 20:41:27.036]  Step 256631  [21.411 sec/step, loss=0.07369, avg_loss=0.07158]
[2018-11-23 20:41:49.728]  Step 256632  [21.231 sec/step, loss=0.07326, avg_loss=0.07167]
[2018-11-23 20:42:09.050]  Step 256633  [21.318 sec/step, loss=0.07214, avg_loss=0.07174]
[2018-11-23 20:42:24.971]  Step 256634  [21.324 sec/step, loss=0.07151, avg_loss=0.07175]
[2018-11-23 20:42:48.969]  Step 256635  [21.318 sec/step, loss=0.07280, avg_loss=0.07174]
[2018-11-23 20:43:09.007]  Step 256636  [21.297 sec/step, loss=0.07266, avg_loss=0.07173]
[2018-11-23 20:43:32.721]  Step 256637  [21.295 sec/step, loss=0.07346, avg_loss=0.07173]
[2018-11-23 20:43:41.632]  Generated 32 batches of size 32 in 8.209 sec
[2018-11-23 20:43:54.560]  Step 256638  [21.279 sec/step, loss=0.07296, avg_loss=0.07173]
[2018-11-23 20:44:04.814]  Step 256639  [21.146 sec/step, loss=0.06601, avg_loss=0.07166]
[2018-11-23 20:44:28.427]  Step 256640  [21.214 sec/step, loss=0.07326, avg_loss=0.07166]
[2018-11-23 20:44:37.124]  Step 256641  [21.050 sec/step, loss=0.05454, avg_loss=0.07148]
[2018-11-23 20:44:52.730]  Step 256642  [20.990 sec/step, loss=0.07035, avg_loss=0.07145]
[2018-11-23 20:45:14.714]  Step 256643  [20.965 sec/step, loss=0.07304, avg_loss=0.07144]
[2018-11-23 20:45:39.145]  Step 256644  [20.960 sec/step, loss=0.07294, avg_loss=0.07144]
[2018-11-23 20:46:01.055]  Step 256645  [21.023 sec/step, loss=0.07280, avg_loss=0.07147]
[2018-11-23 20:46:27.124]  Step 256646  [21.087 sec/step, loss=0.07373, avg_loss=0.07148]
[2018-11-23 20:46:50.036]  Step 256647  [21.101 sec/step, loss=0.07309, avg_loss=0.07149]
[2018-11-23 20:47:15.914]  Step 256648  [21.155 sec/step, loss=0.07216, avg_loss=0.07148]
[2018-11-23 20:47:39.458]  Step 256649  [21.169 sec/step, loss=0.07315, avg_loss=0.07149]
[2018-11-23 20:48:04.723]  Step 256650  [21.338 sec/step, loss=0.07373, avg_loss=0.07168]
[2018-11-23 20:48:04.723]  Writing summary at step: 256650
[2018-11-23 20:48:50.474]  Step 256651  [21.469 sec/step, loss=0.06473, avg_loss=0.07159]
[2018-11-23 20:49:15.029]  Step 256652  [21.497 sec/step, loss=0.07276, avg_loss=0.07160]
[2018-11-23 20:49:37.718]  Step 256653  [21.546 sec/step, loss=0.07277, avg_loss=0.07160]
[2018-11-23 20:49:58.507]  Step 256654  [21.520 sec/step, loss=0.07312, avg_loss=0.07160]
[2018-11-23 20:50:22.585]  Step 256655  [21.513 sec/step, loss=0.07415, avg_loss=0.07160]
[2018-11-23 20:50:36.408]  Step 256656  [21.496 sec/step, loss=0.06984, avg_loss=0.07161]
[2018-11-23 20:50:47.997]  Step 256657  [21.443 sec/step, loss=0.06470, avg_loss=0.07154]
[2018-11-23 20:51:06.821]  Step 256658  [21.428 sec/step, loss=0.07284, avg_loss=0.07154]
[2018-11-23 20:51:30.309]  Step 256659  [21.559 sec/step, loss=0.07331, avg_loss=0.07162]
[2018-11-23 20:51:51.792]  Step 256660  [21.579 sec/step, loss=0.07320, avg_loss=0.07162]
[2018-11-23 20:52:08.635]  Step 256661  [21.482 sec/step, loss=0.07223, avg_loss=0.07161]
[2018-11-23 20:52:20.571]  Step 256662  [21.383 sec/step, loss=0.06874, avg_loss=0.07157]
[2018-11-23 20:52:42.646]  Step 256663  [21.517 sec/step, loss=0.07332, avg_loss=0.07177]
[2018-11-23 20:52:57.741]  Step 256664  [21.466 sec/step, loss=0.06956, avg_loss=0.07173]
[2018-11-23 20:53:19.111]  Step 256665  [21.463 sec/step, loss=0.07304, avg_loss=0.07173]
[2018-11-23 20:53:41.453]  Step 256666  [21.495 sec/step, loss=0.07383, avg_loss=0.07174]
[2018-11-23 20:54:05.085]  Step 256667  [21.491 sec/step, loss=0.07279, avg_loss=0.07173]
[2018-11-23 20:54:27.593]  Step 256668  [21.418 sec/step, loss=0.07189, avg_loss=0.07172]
[2018-11-23 20:54:37.295]  Generated 32 batches of size 32 in 8.945 sec
[2018-11-23 20:54:45.503]  Step 256669  [21.336 sec/step, loss=0.07060, avg_loss=0.07170]
[2018-11-23 20:55:05.746]  Step 256670  [21.324 sec/step, loss=0.07253, avg_loss=0.07169]
[2018-11-23 20:55:25.373]  Step 256671  [21.276 sec/step, loss=0.07204, avg_loss=0.07167]
[2018-11-23 20:55:44.815]  Step 256672  [21.314 sec/step, loss=0.07303, avg_loss=0.07169]
[2018-11-23 20:56:02.423]  Step 256673  [21.266 sec/step, loss=0.07194, avg_loss=0.07168]
[2018-11-23 20:56:26.220]  Step 256674  [21.363 sec/step, loss=0.07367, avg_loss=0.07172]
[2018-11-23 20:56:44.899]  Step 256675  [21.229 sec/step, loss=0.07314, avg_loss=0.07170]
[2018-11-23 20:57:06.738]  Step 256676  [21.204 sec/step, loss=0.07301, avg_loss=0.07170]
[2018-11-23 20:57:30.726]  Step 256677  [21.254 sec/step, loss=0.07312, avg_loss=0.07170]
[2018-11-23 20:57:54.885]  Step 256678  [21.250 sec/step, loss=0.07352, avg_loss=0.07171]
[2018-11-23 20:58:19.115]  Step 256679  [21.372 sec/step, loss=0.07325, avg_loss=0.07175]
[2018-11-23 20:58:31.334]  Step 256680  [21.307 sec/step, loss=0.06862, avg_loss=0.07171]
[2018-11-23 20:58:49.239]  Step 256681  [21.256 sec/step, loss=0.07160, avg_loss=0.07169]
[2018-11-23 20:59:06.206]  Step 256682  [21.187 sec/step, loss=0.07142, avg_loss=0.07168]
[2018-11-23 20:59:29.165]  Step 256683  [21.060 sec/step, loss=0.07299, avg_loss=0.07175]
[2018-11-23 20:59:53.869]  Step 256684  [21.091 sec/step, loss=0.07330, avg_loss=0.07176]
[2018-11-23 21:00:13.338]  Step 256685  [21.091 sec/step, loss=0.07196, avg_loss=0.07175]
[2018-11-23 21:00:34.772]  Step 256686  [21.087 sec/step, loss=0.07235, avg_loss=0.07174]
[2018-11-23 21:01:00.666]  Step 256687  [21.082 sec/step, loss=0.07342, avg_loss=0.07175]
[2018-11-23 21:01:09.514]  Step 256688  [20.924 sec/step, loss=0.05326, avg_loss=0.07154]
[2018-11-23 21:01:30.140]  Step 256689  [20.932 sec/step, loss=0.07315, avg_loss=0.07155]
[2018-11-23 21:01:53.772]  Step 256690  [20.912 sec/step, loss=0.07341, avg_loss=0.07154]
[2018-11-23 21:02:18.105]  Step 256691  [20.908 sec/step, loss=0.07320, avg_loss=0.07154]
[2018-11-23 21:02:31.700]  Step 256692  [20.955 sec/step, loss=0.07001, avg_loss=0.07170]
[2018-11-23 21:02:55.153]  Step 256693  [20.947 sec/step, loss=0.07276, avg_loss=0.07169]
[2018-11-23 21:03:17.104]  Step 256694  [20.951 sec/step, loss=0.07281, avg_loss=0.07169]
[2018-11-23 21:03:38.495]  Step 256695  [20.954 sec/step, loss=0.07359, avg_loss=0.07170]
[2018-11-23 21:04:01.250]  Step 256696  [20.958 sec/step, loss=0.07368, avg_loss=0.07171]
[2018-11-23 21:04:16.766]  Step 256697  [20.955 sec/step, loss=0.07047, avg_loss=0.07172]
[2018-11-23 21:04:38.849]  Step 256698  [21.030 sec/step, loss=0.07258, avg_loss=0.07174]
[2018-11-23 21:04:57.793]  Step 256699  [21.042 sec/step, loss=0.07251, avg_loss=0.07174]
[2018-11-23 21:05:18.270]  Step 256700  [21.014 sec/step, loss=0.07323, avg_loss=0.07174]
[2018-11-23 21:05:18.270]  Writing summary at step: 256700
[2018-11-23 21:05:27.682]  Generated 32 batches of size 32 in 8.538 sec
[2018-11-23 21:06:02.074]  Step 256701  [21.022 sec/step, loss=0.07322, avg_loss=0.07175]
[2018-11-23 21:06:20.469]  Step 256702  [20.966 sec/step, loss=0.07265, avg_loss=0.07174]
[2018-11-23 21:07:03.759]  Step 256703  [21.153 sec/step, loss=0.06490, avg_loss=0.07165]
[2018-11-23 21:07:14.426]  Step 256704  [21.057 sec/step, loss=0.06660, avg_loss=0.07159]
[2018-11-23 21:07:38.613]  Step 256705  [21.071 sec/step, loss=0.07300, avg_loss=0.07159]
[2018-11-23 21:07:57.876]  Step 256706  [20.806 sec/step, loss=0.07289, avg_loss=0.07167]
[2018-11-23 21:08:13.672]  Step 256707  [20.809 sec/step, loss=0.06966, avg_loss=0.07167]
[2018-11-23 21:08:39.838]  Step 256708  [20.829 sec/step, loss=0.07264, avg_loss=0.07166]
[2018-11-23 21:09:03.372]  Step 256709  [20.894 sec/step, loss=0.07308, avg_loss=0.07167]
[2018-11-23 21:09:23.334]  Step 256710  [20.858 sec/step, loss=0.07235, avg_loss=0.07166]
[2018-11-23 21:09:47.014]  Step 256711  [20.909 sec/step, loss=0.07292, avg_loss=0.07166]
[2018-11-23 21:09:55.342]  Step 256712  [20.802 sec/step, loss=0.05441, avg_loss=0.07148]
[2018-11-23 21:10:16.656]  Step 256713  [20.910 sec/step, loss=0.07304, avg_loss=0.07155]
[2018-11-23 21:10:35.577]  Step 256714  [20.872 sec/step, loss=0.07234, avg_loss=0.07154]
[2018-11-23 21:10:52.975]  Step 256715  [20.798 sec/step, loss=0.06863, avg_loss=0.07149]
[2018-11-23 21:11:30.314]  Step 256716  [20.983 sec/step, loss=0.06437, avg_loss=0.07141]
[2018-11-23 21:11:44.195]  Step 256717  [20.926 sec/step, loss=0.07009, avg_loss=0.07138]
[2018-11-23 21:12:03.791]  Step 256718  [20.906 sec/step, loss=0.07249, avg_loss=0.07138]
[2018-11-23 21:12:25.954]  Step 256719  [20.892 sec/step, loss=0.07214, avg_loss=0.07137]
[2018-11-23 21:12:50.626]  Step 256720  [20.910 sec/step, loss=0.07395, avg_loss=0.07138]
[2018-11-23 21:13:08.386]  Step 256721  [20.947 sec/step, loss=0.07151, avg_loss=0.07140]
[2018-11-23 21:13:28.902]  Step 256722  [20.949 sec/step, loss=0.07310, avg_loss=0.07140]
[2018-11-23 21:13:53.548]  Step 256723  [20.826 sec/step, loss=0.07310, avg_loss=0.07148]
[2018-11-23 21:14:15.344]  Step 256724  [20.875 sec/step, loss=0.07350, avg_loss=0.07149]
[2018-11-23 21:14:34.111]  Step 256725  [20.825 sec/step, loss=0.07329, avg_loss=0.07149]
[2018-11-23 21:14:56.161]  Step 256726  [20.922 sec/step, loss=0.07340, avg_loss=0.07154]
[2018-11-23 21:15:18.205]  Step 256727  [20.891 sec/step, loss=0.07240, avg_loss=0.07152]
[2018-11-23 21:15:43.848]  Step 256728  [20.901 sec/step, loss=0.07395, avg_loss=0.07153]
[2018-11-23 21:16:04.790]  Step 256729  [20.929 sec/step, loss=0.07313, avg_loss=0.07155]
[2018-11-23 21:16:29.464]  Step 256730  [20.959 sec/step, loss=0.07332, avg_loss=0.07154]
[2018-11-23 21:16:45.106]  Step 256731  [20.870 sec/step, loss=0.07041, avg_loss=0.07151]
[2018-11-23 21:16:54.383]  Generated 32 batches of size 32 in 8.508 sec
[2018-11-23 21:17:10.927]  Step 256732  [20.901 sec/step, loss=0.07293, avg_loss=0.07151]
[2018-11-23 21:17:32.959]  Step 256733  [20.928 sec/step, loss=0.07267, avg_loss=0.07151]
[2018-11-23 21:17:44.961]  Step 256734  [20.889 sec/step, loss=0.06850, avg_loss=0.07148]
[2018-11-23 21:18:07.683]  Step 256735  [20.876 sec/step, loss=0.07298, avg_loss=0.07148]
[2018-11-23 21:18:32.127]  Step 256736  [20.920 sec/step, loss=0.07306, avg_loss=0.07149]
[2018-11-23 21:18:58.399]  Step 256737  [20.946 sec/step, loss=0.07263, avg_loss=0.07148]
[2018-11-23 21:19:16.410]  Step 256738  [20.908 sec/step, loss=0.07227, avg_loss=0.07147]
[2018-11-23 21:19:28.867]  Step 256739  [20.930 sec/step, loss=0.06523, avg_loss=0.07146]
[2018-11-23 21:19:55.280]  Step 256740  [20.958 sec/step, loss=0.07312, avg_loss=0.07146]
[2018-11-23 21:20:14.355]  Step 256741  [21.061 sec/step, loss=0.07283, avg_loss=0.07165]
[2018-11-23 21:20:38.257]  Step 256742  [21.144 sec/step, loss=0.07295, avg_loss=0.07167]
[2018-11-23 21:21:01.126]  Step 256743  [21.153 sec/step, loss=0.07296, avg_loss=0.07167]
[2018-11-23 21:21:27.139]  Step 256744  [21.169 sec/step, loss=0.07366, avg_loss=0.07168]
[2018-11-23 21:21:52.473]  Step 256745  [21.203 sec/step, loss=0.07311, avg_loss=0.07168]
[2018-11-23 21:22:17.246]  Step 256746  [21.190 sec/step, loss=0.07347, avg_loss=0.07168]
[2018-11-23 21:22:27.684]  Step 256747  [21.066 sec/step, loss=0.06490, avg_loss=0.07160]
[2018-11-23 21:22:51.367]  Step 256748  [21.044 sec/step, loss=0.07343, avg_loss=0.07161]
[2018-11-23 21:23:08.489]  Step 256749  [20.979 sec/step, loss=0.07200, avg_loss=0.07160]
[2018-11-23 21:23:31.139]  Step 256750  [20.953 sec/step, loss=0.07342, avg_loss=0.07160]
[2018-11-23 21:23:31.139]  Writing summary at step: 256750
[2018-11-23 21:24:04.147]  Step 256751  [20.668 sec/step, loss=0.05387, avg_loss=0.07149]
[2018-11-23 21:24:24.517]  Step 256752  [20.626 sec/step, loss=0.07314, avg_loss=0.07149]
[2018-11-23 21:24:38.640]  Step 256753  [20.540 sec/step, loss=0.06999, avg_loss=0.07146]
[2018-11-23 21:25:16.893]  Step 256754  [20.715 sec/step, loss=0.06506, avg_loss=0.07138]
[2018-11-23 21:25:32.216]  Step 256755  [20.627 sec/step, loss=0.07112, avg_loss=0.07135]
[2018-11-23 21:25:58.627]  Step 256756  [20.753 sec/step, loss=0.07282, avg_loss=0.07138]
[2018-11-23 21:26:20.526]  Step 256757  [20.856 sec/step, loss=0.07257, avg_loss=0.07146]
[2018-11-23 21:26:45.367]  Step 256758  [20.916 sec/step, loss=0.07288, avg_loss=0.07146]
[2018-11-23 21:27:01.113]  Step 256759  [20.839 sec/step, loss=0.07003, avg_loss=0.07143]
[2018-11-23 21:27:20.912]  Step 256760  [20.822 sec/step, loss=0.07276, avg_loss=0.07142]
[2018-11-23 21:27:42.408]  Step 256761  [20.869 sec/step, loss=0.07353, avg_loss=0.07144]
[2018-11-23 21:28:03.412]  Step 256762  [20.959 sec/step, loss=0.07268, avg_loss=0.07148]
[2018-11-23 21:28:12.823]  Generated 32 batches of size 32 in 8.569 sec
[2018-11-23 21:28:26.954]  Step 256763  [20.974 sec/step, loss=0.07280, avg_loss=0.07147]
[2018-11-23 21:28:49.213]  Step 256764  [21.046 sec/step, loss=0.07245, avg_loss=0.07150]
[2018-11-23 21:29:09.024]  Step 256765  [21.030 sec/step, loss=0.07219, avg_loss=0.07149]
[2018-11-23 21:29:33.624]  Step 256766  [21.053 sec/step, loss=0.07368, avg_loss=0.07149]
[2018-11-23 21:29:52.341]  Step 256767  [21.003 sec/step, loss=0.07276, avg_loss=0.07149]
[2018-11-23 21:30:04.625]  Step 256768  [20.901 sec/step, loss=0.06825, avg_loss=0.07145]
[2018-11-23 21:30:27.610]  Step 256769  [20.952 sec/step, loss=0.07312, avg_loss=0.07148]
[2018-11-23 21:30:46.663]  Step 256770  [20.940 sec/step, loss=0.07207, avg_loss=0.07147]
[2018-11-23 21:31:06.881]  Step 256771  [20.946 sec/step, loss=0.07301, avg_loss=0.07148]
[2018-11-23 21:31:26.141]  Step 256772  [20.944 sec/step, loss=0.07187, avg_loss=0.07147]
[2018-11-23 21:31:50.631]  Step 256773  [21.013 sec/step, loss=0.07357, avg_loss=0.07149]
[2018-11-23 21:32:14.991]  Step 256774  [21.019 sec/step, loss=0.07366, avg_loss=0.07149]
[2018-11-23 21:32:30.467]  Step 256775  [20.987 sec/step, loss=0.07025, avg_loss=0.07146]
[2018-11-23 21:32:54.414]  Step 256776  [21.008 sec/step, loss=0.07280, avg_loss=0.07146]
[2018-11-23 21:33:15.379]  Step 256777  [20.977 sec/step, loss=0.07276, avg_loss=0.07145]
[2018-11-23 21:33:25.794]  Step 256778  [20.840 sec/step, loss=0.06533, avg_loss=0.07137]
[2018-11-23 21:33:47.146]  Step 256779  [20.811 sec/step, loss=0.07336, avg_loss=0.07137]
[2018-11-23 21:34:06.328]  Step 256780  [20.881 sec/step, loss=0.07227, avg_loss=0.07141]
[2018-11-23 21:34:27.118]  Step 256781  [20.910 sec/step, loss=0.07253, avg_loss=0.07142]
[2018-11-23 21:35:03.996]  Step 256782  [21.109 sec/step, loss=0.06432, avg_loss=0.07135]
[2018-11-23 21:35:21.315]  Step 256783  [21.052 sec/step, loss=0.07167, avg_loss=0.07133]
[2018-11-23 21:35:45.680]  Step 256784  [21.049 sec/step, loss=0.07286, avg_loss=0.07133]
[2018-11-23 21:35:54.686]  Step 256785  [20.944 sec/step, loss=0.05325, avg_loss=0.07114]
[2018-11-23 21:36:15.239]  Step 256786  [20.936 sec/step, loss=0.07233, avg_loss=0.07114]
[2018-11-23 21:36:33.884]  Step 256787  [20.863 sec/step, loss=0.07326, avg_loss=0.07114]
[2018-11-23 21:36:46.136]  Step 256788  [20.897 sec/step, loss=0.06861, avg_loss=0.07130]
[2018-11-23 21:37:01.759]  Step 256789  [20.847 sec/step, loss=0.06948, avg_loss=0.07126]
[2018-11-23 21:37:25.624]  Step 256790  [20.849 sec/step, loss=0.07333, avg_loss=0.07126]
[2018-11-23 21:37:47.429]  Step 256791  [20.824 sec/step, loss=0.07305, avg_loss=0.07126]
[2018-11-23 21:38:09.287]  Step 256792  [20.907 sec/step, loss=0.07266, avg_loss=0.07128]
[2018-11-23 21:38:31.863]  Step 256793  [20.898 sec/step, loss=0.07312, avg_loss=0.07129]
[2018-11-23 21:38:45.973]  Step 256794  [20.820 sec/step, loss=0.06963, avg_loss=0.07125]
[2018-11-23 21:38:58.065]  Generated 32 batches of size 32 in 11.247 sec
[2018-11-23 21:39:16.421]  Step 256795  [20.910 sec/step, loss=0.07301, avg_loss=0.07125]
[2018-11-23 21:39:35.895]  Step 256796  [20.877 sec/step, loss=0.07290, avg_loss=0.07124]
[2018-11-23 21:39:57.941]  Step 256797  [20.943 sec/step, loss=0.07277, avg_loss=0.07126]
[2018-11-23 21:40:20.398]  Step 256798  [20.946 sec/step, loss=0.07275, avg_loss=0.07127]
[2018-11-23 21:40:45.137]  Step 256799  [21.004 sec/step, loss=0.07297, avg_loss=0.07127]
[2018-11-23 21:41:08.148]  Step 256800  [21.030 sec/step, loss=0.07314, avg_loss=0.07127]
[2018-11-23 21:41:08.148]  Writing summary at step: 256800
[2018-11-23 21:41:51.339]  Step 256801  [21.064 sec/step, loss=0.07290, avg_loss=0.07127]
[2018-11-23 21:42:16.791]  Step 256802  [21.134 sec/step, loss=0.07402, avg_loss=0.07128]
[2018-11-23 21:42:32.636]  Step 256803  [20.860 sec/step, loss=0.07047, avg_loss=0.07134]
[2018-11-23 21:42:55.680]  Step 256804  [20.984 sec/step, loss=0.07281, avg_loss=0.07140]
[2018-11-23 21:43:18.016]  Step 256805  [20.965 sec/step, loss=0.07250, avg_loss=0.07139]
[2018-11-23 21:43:38.204]  Step 256806  [20.974 sec/step, loss=0.07299, avg_loss=0.07139]
[2018-11-23 21:44:00.205]  Step 256807  [21.037 sec/step, loss=0.07230, avg_loss=0.07142]
[2018-11-23 21:44:18.962]  Step 256808  [20.962 sec/step, loss=0.07279, avg_loss=0.07142]
[2018-11-23 21:44:43.168]  Step 256809  [20.969 sec/step, loss=0.07325, avg_loss=0.07142]
[2018-11-23 21:45:05.270]  Step 256810  [20.991 sec/step, loss=0.07276, avg_loss=0.07143]
[2018-11-23 21:45:29.736]  Step 256811  [20.998 sec/step, loss=0.07335, avg_loss=0.07143]
[2018-11-23 21:45:50.967]  Step 256812  [21.127 sec/step, loss=0.07303, avg_loss=0.07162]
[2018-11-23 21:45:59.627]  Step 256813  [21.001 sec/step, loss=0.05498, avg_loss=0.07144]
[2018-11-23 21:46:21.613]  Step 256814  [21.032 sec/step, loss=0.07342, avg_loss=0.07145]
[2018-11-23 21:46:46.172]  Step 256815  [21.103 sec/step, loss=0.07302, avg_loss=0.07149]
[2018-11-23 21:47:07.337]  Step 256816  [20.941 sec/step, loss=0.07316, avg_loss=0.07158]
[2018-11-23 21:47:31.121]  Step 256817  [21.040 sec/step, loss=0.07282, avg_loss=0.07161]
[2018-11-23 21:47:45.310]  Step 256818  [20.986 sec/step, loss=0.07008, avg_loss=0.07158]
[2018-11-23 21:48:09.540]  Step 256819  [21.007 sec/step, loss=0.07284, avg_loss=0.07159]
[2018-11-23 21:48:21.928]  Step 256820  [20.884 sec/step, loss=0.06842, avg_loss=0.07153]
[2018-11-23 21:48:37.885]  Step 256821  [20.866 sec/step, loss=0.06920, avg_loss=0.07151]
[2018-11-23 21:49:04.270]  Step 256822  [20.925 sec/step, loss=0.07306, avg_loss=0.07151]
[2018-11-23 21:49:22.702]  Step 256823  [20.863 sec/step, loss=0.07158, avg_loss=0.07150]
[2018-11-23 21:49:45.482]  Step 256824  [20.873 sec/step, loss=0.07280, avg_loss=0.07149]
[2018-11-23 21:50:05.928]  Step 256825  [20.889 sec/step, loss=0.07312, avg_loss=0.07149]
[2018-11-23 21:50:14.949]  Generated 32 batches of size 32 in 8.226 sec
[2018-11-23 21:50:26.728]  Step 256826  [20.877 sec/step, loss=0.07288, avg_loss=0.07148]
[2018-11-23 21:50:45.104]  Step 256827  [20.840 sec/step, loss=0.07191, avg_loss=0.07148]
[2018-11-23 21:51:09.729]  Step 256828  [20.830 sec/step, loss=0.07396, avg_loss=0.07148]
[2018-11-23 21:51:49.799]  Step 256829  [21.021 sec/step, loss=0.06471, avg_loss=0.07139]
[2018-11-23 21:52:08.934]  Step 256830  [20.966 sec/step, loss=0.07224, avg_loss=0.07138]
[2018-11-23 21:52:19.420]  Step 256831  [20.914 sec/step, loss=0.06530, avg_loss=0.07133]
[2018-11-23 21:52:44.442]  Step 256832  [20.906 sec/step, loss=0.07301, avg_loss=0.07133]
[2018-11-23 21:53:09.702]  Step 256833  [20.939 sec/step, loss=0.07331, avg_loss=0.07134]
[2018-11-23 21:53:29.876]  Step 256834  [21.020 sec/step, loss=0.07202, avg_loss=0.07137]
[2018-11-23 21:53:53.622]  Step 256835  [21.031 sec/step, loss=0.07282, avg_loss=0.07137]
[2018-11-23 21:54:17.545]  Step 256836  [21.025 sec/step, loss=0.07322, avg_loss=0.07137]
[2018-11-23 21:54:38.020]  Step 256837  [20.967 sec/step, loss=0.07300, avg_loss=0.07138]
[2018-11-23 21:55:00.333]  Step 256838  [21.010 sec/step, loss=0.07300, avg_loss=0.07138]
[2018-11-23 21:55:21.994]  Step 256839  [21.102 sec/step, loss=0.07231, avg_loss=0.07146]
[2018-11-23 21:55:44.370]  Step 256840  [21.062 sec/step, loss=0.07220, avg_loss=0.07145]
[2018-11-23 21:55:56.457]  Step 256841  [20.992 sec/step, loss=0.06827, avg_loss=0.07140]
[2018-11-23 21:56:06.666]  Step 256842  [20.855 sec/step, loss=0.06458, avg_loss=0.07132]
[2018-11-23 21:56:26.287]  Step 256843  [20.823 sec/step, loss=0.07218, avg_loss=0.07131]
[2018-11-23 21:57:04.486]  Step 256844  [20.945 sec/step, loss=0.06453, avg_loss=0.07122]
[2018-11-23 21:57:30.939]  Step 256845  [20.956 sec/step, loss=0.07282, avg_loss=0.07121]
[2018-11-23 21:57:52.084]  Step 256846  [20.920 sec/step, loss=0.07253, avg_loss=0.07121]
[2018-11-23 21:58:06.113]  Step 256847  [20.956 sec/step, loss=0.07011, avg_loss=0.07126]
[2018-11-23 21:58:31.284]  Step 256848  [20.970 sec/step, loss=0.07283, avg_loss=0.07125]
[2018-11-23 21:58:47.252]  Step 256849  [20.959 sec/step, loss=0.07055, avg_loss=0.07124]
[2018-11-23 21:59:09.103]  Step 256850  [20.951 sec/step, loss=0.07355, avg_loss=0.07124]
[2018-11-23 21:59:09.103]  Writing summary at step: 256850
[2018-11-23 21:59:40.278]  Step 256851  [21.089 sec/step, loss=0.07284, avg_loss=0.07143]
[2018-11-23 22:00:01.141]  Step 256852  [21.094 sec/step, loss=0.07254, avg_loss=0.07142]
[2018-11-23 22:00:24.714]  Step 256853  [21.188 sec/step, loss=0.07286, avg_loss=0.07145]
[2018-11-23 22:00:49.882]  Step 256854  [21.057 sec/step, loss=0.07283, avg_loss=0.07153]
[2018-11-23 22:01:10.982]  Step 256855  [21.115 sec/step, loss=0.07294, avg_loss=0.07155]
[2018-11-23 22:01:28.063]  Step 256856  [21.022 sec/step, loss=0.07190, avg_loss=0.07154]
[2018-11-23 22:01:37.466]  Generated 32 batches of size 32 in 8.624 sec
[2018-11-23 22:01:45.267]  Step 256857  [20.975 sec/step, loss=0.06960, avg_loss=0.07151]
[2018-11-23 22:02:07.922]  Step 256858  [20.953 sec/step, loss=0.07263, avg_loss=0.07151]
[2018-11-23 22:02:26.413]  Step 256859  [20.980 sec/step, loss=0.07273, avg_loss=0.07153]
[2018-11-23 22:02:44.561]  Step 256860  [20.964 sec/step, loss=0.07188, avg_loss=0.07152]
[2018-11-23 22:03:08.801]  Step 256861  [20.991 sec/step, loss=0.07350, avg_loss=0.07152]
[2018-11-23 22:03:27.946]  Step 256862  [20.973 sec/step, loss=0.07278, avg_loss=0.07152]
[2018-11-23 22:03:52.488]  Step 256863  [20.983 sec/step, loss=0.07322, avg_loss=0.07153]
[2018-11-23 22:04:17.836]  Step 256864  [21.014 sec/step, loss=0.07383, avg_loss=0.07154]
[2018-11-23 22:04:41.873]  Step 256865  [21.056 sec/step, loss=0.07326, avg_loss=0.07155]
[2018-11-23 22:05:06.729]  Step 256866  [21.058 sec/step, loss=0.07312, avg_loss=0.07155]
[2018-11-23 22:05:28.598]  Step 256867  [21.090 sec/step, loss=0.07246, avg_loss=0.07154]
[2018-11-23 22:05:51.784]  Step 256868  [21.199 sec/step, loss=0.07303, avg_loss=0.07159]
[2018-11-23 22:06:10.278]  Step 256869  [21.154 sec/step, loss=0.07263, avg_loss=0.07159]
[2018-11-23 22:06:26.796]  Step 256870  [21.129 sec/step, loss=0.07190, avg_loss=0.07159]
[2018-11-23 22:06:48.633]  Step 256871  [21.145 sec/step, loss=0.07327, avg_loss=0.07159]
[2018-11-23 22:07:11.494]  Step 256872  [21.181 sec/step, loss=0.07329, avg_loss=0.07160]
[2018-11-23 22:07:27.107]  Step 256873  [21.092 sec/step, loss=0.06890, avg_loss=0.07156]
[2018-11-23 22:07:49.311]  Step 256874  [21.071 sec/step, loss=0.07206, avg_loss=0.07154]
[2018-11-23 22:08:08.553]  Step 256875  [21.108 sec/step, loss=0.07193, avg_loss=0.07156]
[2018-11-23 22:08:23.832]  Step 256876  [21.022 sec/step, loss=0.07025, avg_loss=0.07153]
[2018-11-23 22:08:46.600]  Step 256877  [21.040 sec/step, loss=0.07326, avg_loss=0.07154]
[2018-11-23 22:09:06.956]  Step 256878  [21.139 sec/step, loss=0.07296, avg_loss=0.07161]
[2018-11-23 22:09:31.323]  Step 256879  [21.169 sec/step, loss=0.07308, avg_loss=0.07161]
[2018-11-23 22:09:45.098]  Step 256880  [21.115 sec/step, loss=0.07023, avg_loss=0.07159]
[2018-11-23 22:09:57.224]  Step 256881  [21.028 sec/step, loss=0.06893, avg_loss=0.07155]
[2018-11-23 22:10:21.364]  Step 256882  [20.901 sec/step, loss=0.07297, avg_loss=0.07164]
[2018-11-23 22:10:48.454]  Step 256883  [20.999 sec/step, loss=0.07254, avg_loss=0.07165]
[2018-11-23 22:11:07.725]  Step 256884  [20.948 sec/step, loss=0.07290, avg_loss=0.07165]
[2018-11-23 22:11:27.533]  Step 256885  [21.056 sec/step, loss=0.07230, avg_loss=0.07184]
[2018-11-23 22:11:48.927]  Step 256886  [21.064 sec/step, loss=0.07300, avg_loss=0.07185]
[2018-11-23 22:12:06.926]  Step 256887  [21.058 sec/step, loss=0.07169, avg_loss=0.07183]
[2018-11-23 22:12:31.913]  Step 256888  [21.185 sec/step, loss=0.07327, avg_loss=0.07188]
[2018-11-23 22:12:44.197]  Generated 32 batches of size 32 in 11.533 sec
[2018-11-23 22:12:47.517]  Step 256889  [21.185 sec/step, loss=0.06612, avg_loss=0.07184]
[2018-11-23 22:13:16.877]  Step 256890  [21.240 sec/step, loss=0.07346, avg_loss=0.07184]
[2018-11-23 22:13:42.989]  Step 256891  [21.283 sec/step, loss=0.07256, avg_loss=0.07184]
[2018-11-23 22:14:10.434]  Step 256892  [21.339 sec/step, loss=0.07301, avg_loss=0.07184]
[2018-11-23 22:14:34.451]  Step 256893  [21.353 sec/step, loss=0.07276, avg_loss=0.07184]
[2018-11-23 22:14:59.002]  Step 256894  [21.458 sec/step, loss=0.07338, avg_loss=0.07188]
[2018-11-23 22:15:41.439]  Step 256895  [21.577 sec/step, loss=0.06456, avg_loss=0.07179]
[2018-11-23 22:15:50.264]  Step 256896  [21.471 sec/step, loss=0.05392, avg_loss=0.07160]
[2018-11-23 22:16:13.444]  Step 256897  [21.482 sec/step, loss=0.07319, avg_loss=0.07161]
[2018-11-23 22:16:36.544]  Step 256898  [21.489 sec/step, loss=0.07286, avg_loss=0.07161]
[2018-11-23 22:16:58.290]  Step 256899  [21.459 sec/step, loss=0.07256, avg_loss=0.07160]
[2018-11-23 22:17:18.922]  Step 256900  [21.435 sec/step, loss=0.07252, avg_loss=0.07160]
[2018-11-23 22:17:18.922]  Writing summary at step: 256900
[2018-11-23 22:17:58.736]  Step 256901  [21.362 sec/step, loss=0.07152, avg_loss=0.07158]
[2018-11-23 22:18:23.420]  Step 256902  [21.354 sec/step, loss=0.07256, avg_loss=0.07157]
[2018-11-23 22:18:36.231]  Step 256903  [21.324 sec/step, loss=0.06887, avg_loss=0.07155]
[2018-11-23 22:19:01.010]  Step 256904  [21.341 sec/step, loss=0.07310, avg_loss=0.07156]
[2018-11-23 22:19:20.727]  Step 256905  [21.315 sec/step, loss=0.07253, avg_loss=0.07156]
[2018-11-23 22:19:45.274]  Step 256906  [21.358 sec/step, loss=0.07326, avg_loss=0.07156]
[2018-11-23 22:20:08.781]  Step 256907  [21.373 sec/step, loss=0.07216, avg_loss=0.07156]
[2018-11-23 22:20:35.717]  Step 256908  [21.455 sec/step, loss=0.07278, avg_loss=0.07156]
[2018-11-23 22:20:59.603]  Step 256909  [21.452 sec/step, loss=0.07212, avg_loss=0.07155]
[2018-11-23 22:21:24.925]  Step 256910  [21.484 sec/step, loss=0.07263, avg_loss=0.07154]
[2018-11-23 22:22:03.017]  Step 256911  [21.620 sec/step, loss=0.06502, avg_loss=0.07146]
[2018-11-23 22:22:27.887]  Step 256912  [21.657 sec/step, loss=0.07253, avg_loss=0.07146]
[2018-11-23 22:22:47.193]  Step 256913  [21.763 sec/step, loss=0.07260, avg_loss=0.07163]
[2018-11-23 22:22:56.109]  Step 256914  [21.633 sec/step, loss=0.05348, avg_loss=0.07143]
[2018-11-23 22:23:22.971]  Step 256915  [21.656 sec/step, loss=0.07354, avg_loss=0.07144]
[2018-11-23 22:23:47.824]  Step 256916  [21.692 sec/step, loss=0.07380, avg_loss=0.07144]
[2018-11-23 22:24:10.907]  Step 256917  [21.685 sec/step, loss=0.07292, avg_loss=0.07145]
[2018-11-23 22:24:25.805]  Step 256918  [21.693 sec/step, loss=0.07070, avg_loss=0.07145]
[2018-11-23 22:24:36.506]  Step 256919  [21.557 sec/step, loss=0.06585, avg_loss=0.07138]
[2018-11-23 22:24:46.428]  Generated 32 batches of size 32 in 9.090 sec
[2018-11-23 22:25:00.083]  Step 256920  [21.669 sec/step, loss=0.07297, avg_loss=0.07143]
[2018-11-23 22:25:26.523]  Step 256921  [21.774 sec/step, loss=0.07325, avg_loss=0.07147]
[2018-11-23 22:25:26.525]  Saving checkpoint to: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-256921 (requested by user)

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2020-05-19 15:01:00.810]  Devices available to tensorflow: [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 18028252166421375524
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 7543235466705368362
physical_device_desc: "device: XLA_CPU device"
]
[2020-05-19 15:01:00.810]  Checkpoint path: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt
[2020-05-19 15:01:00.810]  Loading training data from: /Users/Aaron/Desktop/Code/tacotron/training/train.txt
[2020-05-19 15:01:00.810]  Using model: tacotron
[2020-05-19 15:01:00.810]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: english_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: True
[2020-05-19 15:01:00.817]  Loaded metadata for 398 examples (1.06 hours)
[2020-05-19 15:01:01.652]  Loaded CMUDict with 116869 unambiguous entries
[2020-05-19 15:01:05.766]  Initialized Tacotron model. Dimensions: 
[2020-05-19 15:01:05.766]    embedding:               256
[2020-05-19 15:01:05.766]    prenet out:              128
[2020-05-19 15:01:05.766]    encoder out:             256
[2020-05-19 15:01:05.767]    attention out:           256
[2020-05-19 15:01:05.767]    concat attn & out:       512
[2020-05-19 15:01:05.767]    decoder cell out:        256
[2020-05-19 15:01:05.767]    decoder out (5 frames):  400
[2020-05-19 15:01:05.767]    decoder out (1 frame):   80
[2020-05-19 15:01:05.767]    postnet out:             256
[2020-05-19 15:01:05.767]    linear out:              1025
[2020-05-19 15:01:19.503]  Exiting due to exception: The passed save_path is not a valid checkpoint: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-254924

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2020-05-19 15:30:52.490]  Devices available to tensorflow: [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 10675407579399987651
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 2797293087901335772
physical_device_desc: "device: XLA_CPU device"
]
[2020-05-19 15:30:52.490]  Checkpoint path: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt
[2020-05-19 15:30:52.490]  Loading training data from: /Users/Aaron/Desktop/Code/tacotron/training/train.txt
[2020-05-19 15:30:52.490]  Using model: tacotron
[2020-05-19 15:30:52.490]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: english_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: True
[2020-05-19 15:30:52.494]  Loaded metadata for 398 examples (1.06 hours)
[2020-05-19 15:30:53.311]  Loaded CMUDict with 116869 unambiguous entries
[2020-05-19 15:30:57.194]  Initialized Tacotron model. Dimensions: 
[2020-05-19 15:30:57.194]    embedding:               256
[2020-05-19 15:30:57.195]    prenet out:              128
[2020-05-19 15:30:57.195]    encoder out:             256
[2020-05-19 15:30:57.195]    attention out:           256
[2020-05-19 15:30:57.195]    concat attn & out:       512
[2020-05-19 15:30:57.195]    decoder cell out:        256
[2020-05-19 15:30:57.195]    decoder out (5 frames):  400
[2020-05-19 15:30:57.195]    decoder out (1 frame):   80
[2020-05-19 15:30:57.196]    postnet out:             256
[2020-05-19 15:30:57.196]    linear out:              1025
[2020-05-19 15:31:10.869]  Exiting due to exception: The passed save_path is not a valid checkpoint: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-250000

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2020-05-19 15:31:29.694]  Devices available to tensorflow: [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 13827301772041510181
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 11920674782078278877
physical_device_desc: "device: XLA_CPU device"
]
[2020-05-19 15:31:29.694]  Checkpoint path: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt
[2020-05-19 15:31:29.694]  Loading training data from: /Users/Aaron/Desktop/Code/tacotron/training/train.txt
[2020-05-19 15:31:29.694]  Using model: tacotron
[2020-05-19 15:31:29.694]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: english_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: True
[2020-05-19 15:31:29.701]  Loaded metadata for 398 examples (1.06 hours)
[2020-05-19 15:31:30.520]  Loaded CMUDict with 116869 unambiguous entries
[2020-05-19 15:31:33.981]  Initialized Tacotron model. Dimensions: 
[2020-05-19 15:31:33.981]    embedding:               256
[2020-05-19 15:31:33.981]    prenet out:              128
[2020-05-19 15:31:33.981]    encoder out:             256
[2020-05-19 15:31:33.981]    attention out:           256
[2020-05-19 15:31:33.982]    concat attn & out:       512
[2020-05-19 15:31:33.982]    decoder cell out:        256
[2020-05-19 15:31:33.982]    decoder out (5 frames):  400
[2020-05-19 15:31:33.982]    decoder out (1 frame):   80
[2020-05-19 15:31:33.982]    postnet out:             256
[2020-05-19 15:31:33.983]    linear out:              1025
[2020-05-19 15:31:49.592]  Resuming from checkpoint: /Users/Aaron/Desktop/Code/tacotron/logs-tacotron/model.ckpt-250000 at commit: None
[2020-05-19 15:31:55.167]  Generated 32 batches of size 32 in 5.575 sec
[2020-05-19 15:32:12.547]  Step 250001  [22.953 sec/step, loss=0.27387, avg_loss=0.27387]
[2020-05-19 15:32:33.807]  Step 250002  [22.106 sec/step, loss=0.21065, avg_loss=0.24226]
[2020-05-19 15:32:49.932]  Step 250003  [20.112 sec/step, loss=0.21956, avg_loss=0.23469]
[2020-05-19 15:33:00.632]  Step 250004  [17.759 sec/step, loss=0.19260, avg_loss=0.22417]
[2020-05-19 15:33:13.135]  Step 250005  [16.708 sec/step, loss=0.15994, avg_loss=0.21132]
[2020-05-19 15:33:30.223]  Step 250006  [16.771 sec/step, loss=0.15763, avg_loss=0.20238]
